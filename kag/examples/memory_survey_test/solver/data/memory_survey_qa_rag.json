{
  "question": [
    "What role do memory-driven communication frameworks play in fostering a common understanding among agents?",
    "What does the adaptation time refer to in the context of memory writing and management?",
    "What are the challenges associated with storing information about agent-environment interactions?",
    "What do typical agent applications demonstrate about the importance of the memory module in different scenarios?",
    "How does integrating domain-specific knowledge through fine-tuning methods benefit agents?",
    "What are some approaches used in recommendation systems to simulate user behaviors and improve performance?",
    "What advancements have been made in transformer architecture for long-context large language models?",
    "How do practical downstream scenarios contribute to the evaluation of memory in agents?",
    "What role do memory-driven communication frameworks play in fostering a common understanding among agents?",
    "How are LLM-based agents adapted for use in the medical domain?",
    "What is the role of the Faiss vector store in obtaining top-K successful trajectories for a task?",
    "What are the two types of approaches for representing memory in parametric form?",
    "How are the knowledge, alignment, and safety control capabilities of LLMs evaluated?",
    "How do macroeconomic trends impact agents' decision-making in social network simulation systems?",
    "What is the purpose of the agent memory pool in social network simulation systems?",
    "What are the key problems in subjective evaluation?",
    "What is the focus of the survey on multimodal large language models presented at the 2023 IEEE International Conference on Big Data?",
    "How are SQL statements used in the memory reading operation in ChatDB?",
    "What is the purpose of using a flash memory cache mechanism in storing recent textual memories?",
    "What problems do LLM inaccuracies and bias cause, and how can they be addressed?",
    "What self-evolving features help LLM agents adapt autonomously?",
    "How does Reflexion use past chats to boost LLM task performance, and how does this compare to memory in other models?",
    "How does measuring a memory module independently improve its reliability over task-based evaluations?",
    "What societal issues stem from LLM bias, and how can trust be improved?",
    "How do agents use temporal caching for film suggestions?",
    "How might domain-specific tuning affect LLMs' general knowledge?",
    "How is memory read latency measured, and why does it matter for computational efficiency?",
    "How does contextual memory improve code consistency and refinement?",
    "How do memory sync and comms boost MAS adaptability and intelligence?",
    "How is memory effectiveness in LLM agents evaluated?",
    "How do agents use public info from digital sources in decisions?",
    "How do true positives and false negatives assess memory retrieval?",
    "How does memory consistency with roles boost realism and task adherence in social sims?",
    "How is historical data combined for memory in agent loops?",
    "How do memory trade-offs impact LLM inference cost and time?",
    "How does long-term memory affect an agent's exploration?",
    "How do LLM agents use past experiences and resources to enhance exploration and code generation?",
    "How does using past interactions and external knowledge help an agent adapt over trials?",
    "How do synced memory modules boost message interpretation and decision consistency?",
    "How does using external expertise boost an agent's performance but risk overfitting and memory loss?",
    "How does fine-tuning with domain expertise improve LLM agents' decision-making?",
    "How do selective fact adjustments in LLMs compare to pattern extraction in terms of memory use and efficiency?",
    "How does high-level info from past trials boost an agent's adaptability in new settings?",
    "How does RAG improve LLMs' accuracy and reduce errors?",
    "What time and memory challenges do LLM agents face in learning over time?",
    "How do LLM misconceptions impact reliability, and which models tackle this?",
    "Which method swaps adjacent elements to sort a list?",
    "How does RAG boost LLMs' accuracy and domain adaptation?",
    "What key questions and design factors are crucial for memory in LLM agents?",
    "How do TP, FP, & FN affect memory retrieval assessment?",
    "How do memory models aid agent sync and strategy in MAS via better communication?",
    "How do LLM agents use past interactions to improve decisions?",
    "How does the memory module boost agent accuracy and decisions in multi-agent simulations?",
    "How do LLM agents use concatenated sequences for better memory in personalized dialogues?",
    "What challenges do LLM agents face with time and memory in learning?",
    "How do LLM agents boost code coherence and error fixing via chat interfaces and memory?",
    "How does Reflexion use past trials to boost LLM agents' performance?",
    "Which model rates dialogue consistency?",
    "What task does CodeAgent aim for in code gen with complex dependencies?",
    "How do memory & simulation improve user modeling in recommender systems?",
    "How does ChatDB boost data retrieval with symbolic memory & SQL?",
    "What's the deployment issue for LLMs with more computing needs and memory limits?",
    "Which agents excel in dialogue and info gathering?",
    "How do agents boost efficiency with past successes?",
    "How do LLMs get molecule data?",
    "In which areas do LLMs aid query and extraction?",
    "How does quadratic growth in attention impact latency?",
    "Which method boosts agents' tool use in math?",
    "Why don't LLMs handle all text equally in long contexts?",
    "How are memory retrieval scores derived using TP, FP, and FN?",
    "Which framework did Montazeralghaem et al. propose for feedback at SIGIR 2020?",
    "How do targeted LLM tweaks avoid losing other info?",
    "How do memory frameworks help agents cooperate?",
    "How does MemGPT use virtual context for recent histories?",
    "In what scenarios do LLM agents use memory for suggestions?",
    "How do LLM tweaks stop forgetting during updates?",
    "How does SCM boost info recency with flash memory?",
    "How does MemoChat use topics to index memory?"
  ],
  "contexts": [
    [
      "#memory_survey#Conversation#memory_survey#Conversation\nConversationEngaginginconversationswithhumansisoneofthemostimportantapplicationsofagents,wherememoryplaysacrucialroleinthisprocess.\nBystoringcontextinformationinmemory,theagentsallowuserstoexperiencepersonalizedconversations,thusimprovingusers’satisfaction.\nTherefore,whenotherpartsoftheagentsaredetermined,theperformanceoftheconversationtaskscanreflecttheeffectivenessofdifferentmemorymodules.\nInthecontextofconversation,consistencyandengagementaretwocommonlyusedmethodstoevaluatetheeffectivenessoftheagents’memory.\nConsistencyreferstohowtheresponsefromagentsisconsistentwiththecontextbecausedramaticchangesshouldbeavoidedduringtheconversation.\nForexample,Luetal.\n[94]evaluatetheconsistencyofagentsoninteractivedialogues,usingGPT-4toscoreontheresponsesfromagents.\nEngagementreferstohowtheuserisengagedtocontinuetheconversation.\nItreflectsthequalityandattractionofagents’responses,aswellastheabilityofagentstocraftthepersonasforcurrentconversations.\nForexample,Leeetal.\n[101]assesstheengagingnessofresponsesbySCE-pscore,andPackeretal.\n[100]utilizeCSIMscoretoevaluatethememoryeffectonincreasingengagementofusers.\n6.\n2.\n2",
      "#memory_survey#PerspectiveofAgentApplications#memory_survey#PerspectiveofAgentApplications\nPerspectiveofAgentApplicationsInmanyapplications,memoryisanindispensablecomponentoftheagent.\nForexample,inaconver-sationalagent,thememorystoresinformationabouthistoricalconversations,whichisnecessaryfortheagenttogeneratethenextresponse.\nWithoutmemory,theagentdoesnotknowthecontext,andcannotcontinuetheconversation[94].\nInasimulationagent,memoryisofgreatimportancetomaketheagentconsistentlyfollowtheroleprofiles.\nWithoutmemory,theagentmayeasilystepoutoftheroleduringthesimulationprocess[95].\nBothoftheaboveexamplesshowthatthememoryisnotanoptionalcomponent,butisnecessaryfortheagentstoaccomplishgiventasks.\nIntheabovethreeperspectives,thefirstonerevealsthatthememorybuildsthecognitivebasisoftheagent.\nThesecondandthirdonesshowthatthememoryisnecessaryfortheagent’sevolvingprinciplesandapplications,whichprovideinsightsfordesigningagentswithmemorymechanisms.\n5",
      "#memory_survey#MemoryinLLM-basedMulti-agentApplications#memory_survey#MemoryinLLM-basedMulti-agentApplications\nMemoryinLLM-basedMulti-agentApplicationsTheexplorationofmemorymechanismswithinLLMshasburgeonedintothedynamicdomainofmulti-agentsystems(MAS),markingsignificantadvancementsintherealmsofsynchronization,communication,andthemanagementofinformationasymmetry.\nOnepivotalaspectthatemergesinthecooperativescenariosismemorysynchronizationamongagents.\nThisprocessisfundamentalforestablishingaunifiedknowledgebase,ensuringconsistencyindecision-makingacrossdifferentagents.\nForexample,Chenetal.\n[170]emphasizethesignificanceofintegratingsynchronizedmemorymodulesformulti-robotcollaboration.\nAnotherimportantaspectisthecommunicationamongagents,whichheavilyreliesonmemoryformaintainingcontextandinterpretingmessages.\nForexample,Mandietal.\n[171]illustratememory-drivencommunicationframeworksthatfosteracommonunderstandingamongagents.\nInadditiontocooperativescenarios,somestudiesalsofocusoncompetitivescenarios,andtheinformationasymmetrybecomesacrucialissue[172].\nLookingahead,theadvancementofmemoryinLLM-basedMASispoisedattheconfluenceoftechnologicalinnovationandstrategicapplication.\nItbeckonstheexplorationofnovelmemory27modulesthatcanfurtherenhanceagentsynchronization,enablemoreeffectivecommunication,andprovidestrategicadvantagesininformation-richenvironments.\nThedevelopmentofsuchmemorymodelswouldnotonlynecessitateaddressingthecurrentchallengesofmemoryintegrationandman-agement,butalsoexploretheuntappedpotentialsofmemoryinfacilitatingmorerobust,intelligent,andadaptableMAS.\nAsevidencedbypioneeringresearch,theevolvinglandscapeofLLM-basedMASsetsapromisingstageforfutureinnovationsinmemoryutilizationandmanagement.\nThisexplorationisexpectedtounravelnewdimensionsofmemoryintegration,pushingtheboundariesofwhatiscurrentlyachievableandsettingnewbenchmarksintherealmofMAS.\n8.\n3",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThememorymoduleisanimportantcomponentforsuchapplications,whichhelpstoaccuratelysimulatehumandynamicbehaviors.\nInpreviousstudies,Kaiyaetal.\n[148]proposeaSummarize-and-Forgetmemorymechanismforbetterself-monitoringinsocialscenarios.\nGaoetal.\n[2]focusonsocialnetworksimulationsystems.\nEachagentinthesystemhasamemorypool,whichconsistsofdiverseusermessagesfromonlineplatformstoidentifytheuser.\nLietal.\n[163]maintainconversationcontexts,encompassingtheeconomicenvironmentandagentdecisionsfrompreviousmonths,inordertosimulatetheimpactofbroadmacroeconomictrendsonagents’decision-makingandtomaketheagentsgraspmarketdynamics.\nLietal.\n[109]simulatethejob-seekingscenarioinhumansociety,wherethememoryofagentsincludesprofilesandgoalsinitiallyandisfurtherenrichedwithotherinformation,likedialoguesandpersonalreflections.\nHuaetal.\n[150]simulatethedecisionsandconsequencesoftheparticipatingcountriesinthewars,wheretheconversationsofagentsarecontinuouslymaintainedintomemory.\nThereareseveralinsightsindesigninganagent’smemoryforrole-playandsocialsimulation.\nFirst,thememoryshouldbeconsistentwiththeroles’characteristics,whichcanbeusedtoidentifyeachroleanddistinguishitfromtheothers.\nThisiscrucialforimprovingtherealismofrole-playandthediversityofsocialsimulation.\nSecond,thememoryshouldappropriatelyinfluencethesubsequent24actionsoftheagenttoensuretheconsistencyandrationalityofitsbehaviors.\nAdditionally,forhumanoidagents,theirmemorymechanismsshouldalignwiththefeaturesofhumanmemory,suchasforgettingandlong/short-termmemory,whichshouldrefertothetheoriesofcognitivepsychology.\n7.\n2PersonalAssistantLLM-basedagentsarewell-suitedforcreatingpersonalassistants,suchasagentscapableofengaginginlong-termconversationswithusers[94,101,153],aswellasthosetaskedwithautomaticallyseekinginformation[164].\nTheseagentsoftenneedtomemorizepreviousdialoguestomaintaintheconsistency,andremembercriticalstylesandeventstogeneratemorepersonalizedandrelevantresponses.\nLuetal.",
      "#memory_survey#Memory-assistedAgent-EnvironmentInteraction#memory_survey#Memory-assistedAgent-EnvironmentInteraction\nMemory-assistedAgent-EnvironmentInteractionAsmentionedatthebeginningofSection3,therearethreekeyphasesintheagent-environmentinteractionprocess.\nTheagentmemorymoduleimplementsthesephasesthroughthreeoperationsincludingmemorywriting,memorymanagement,andmemoryreading.\nMemoryWriting.\nThisoperationaimstoprojecttherawobservationsintotheactuallystoredmemorycontents,whicharemoreinformative[7]andconcise[6].\nItcorrespondstothefirstphaseoftheagent-environmentinteractionprocess.\nGivenataskTk,iftheagenttakesanactionaktatstept,andtheenvironmentprovidesanobservationokt,thenthememorywritingoperationcanbeformallyrepresentedas:mkt=W({akt,okt}),whereWisaprojectingfunction.\nmktisthefinallystoredmemorycontents,whichcanbeeithernaturallanguagesorparametricrepresentations.\nIntheabovetoyexample,fortask(A),theagentissupposedtoremembertheflightarrangementandthedecisionofattractionsafter[step2].\nFortask(B),theagentshouldmemorizethefactthatAlicehopestowatchmoviesat9:00PM,after[step1].\nMemoryManagement.\nThisoperationaimstoprocessthestoredmemoryinformationtomakeitmoreeffective,forexample,summarizinghigh-levelconceptstomaketheagentmoregeneral-1Foreachtask,therecanbemultipletrialsforexploringthefinalsolution,andallofthemcanbeincorporatedintothememory.\n9izable[6],mergingsimilarinformationtoreduceredundancy[7],andforgettingunimportantorirrelevantinformationtoremoveitsnegativeinfluence.\nThisoperationcorrespondstothesecondphaseoftheagent-environmentinteractionprocess.\nLetMkt−1bethememorycontentsfortaskkbeforestept,andsupposemktisthestoredinformationatsteptbasedontheabovememorywritingoperation,then,thememorymanagementoperationcanberepresentedby:Mkt=P(Mkt−1,mkt),wherePisafunctionthatiterativelyprocessesthestoredmemoryinformation.\nForthenarrowmemorydefinition,theiterationonlyhappenswithinthesametrial,andthememoryisemptiedwhenthetrialisended.\nForthebroadmemorydefinition,theiterationhappensacrossdifferenttrialsoreventasks,aswellastheintegrationsofexternalknowledge."
    ],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThismetricevaluateswhethertheagentcandiscoverrelevantmemorycontentstoanswerthequestions.\nDifferentfromtheabovemetric,whichfocusesonthefinalresults,referenceaccuracycaresmoreabouttheintermediateinformationtosupporttheagent’sfinaldecisions.\nInspecific,itcomparestheretrievedmemorywiththepre-preparedgroundtruth.\nFortheaboveproblemof\"WheredidAlicegotoday?\n\",ifthememorycontentsinclude(A)\"AlicehadlunchwithfriendsatWangfujingtoday.\n\"and(B)\"Alicehadroastduckforlunch\",thenabettermemorymoduleshouldselect(A)asareferencetoanswerthequestion.\nUsually,researchersleverageF1-scoretoevaluatethereferenceaccuracy,whichiscalculatedasF1=2·Precision·RecallPrecision+Recall,wheretheprecisionandrecallscoresarecalculatedasPrecision=TPTP+FN.\nTheTPrepresentsthenumberoftruepositivememorycontents,FPmeansthenumberoffalsepositivememorycontents,andFNindicatesthenumberoffalsenegativememorycontents.\nInpreviousworks,Luetal.\n[94]utilizeF1-scoretoevaluatetheretrievalprocessofthememory,andZhongetal.\n[6]focusonassessingwhetherrelatedmemorycanbesuccessfullyretrieved.\nTP+FPandRecall=TPResultCorrectnessandReferenceAccuracyarebothutilizedtoevaluatetheeffectivenessofthememorymodule.\nBeyondeffectiveness,efficiencyisalsoanimportantaspect,especiallyforreal-worldapplications.\nTherefore,wedescribetheevaluationofefficiencyasfollows.\nTime&HardwareCost.\nThetotaltimecostincludesthetimeleveragedformemoryadaptionandinference.\nTheadaptationtimereferstothetimeofmemorywritingandmemorymanagement,whiletheinferencetimeindicatesthetimelatencyofmemoryreading.\nInspecific,thedifferencefromthe21endtimetothestarttimeofmemoryoperationscanbeconsideredasthetimeconsumption.\nFormally,theaveragetimeconsumptionofeachtypeofoperationcanberepresentedas∆time=1MM(cid:88)i=1i−tstarttendi,whereMrepresentsthenumberoftheseoperations,tendimeanstheendtimeofthei-thoperation,andtstartindicatesthestarttimeofthatoperation.\nAsforthecomputationoverhead,itcanbeevaluatedibythepeakGPUmemoryallocation.\nInpreviousworks,Tacketal.",
      "#memory_survey#ObjectiveEvaluation#memory_survey#ObjectiveEvaluation\nUsually,researchersleverageF1-scoretoevaluatethereferenceaccuracy,whichiscalculatedasF1=2·Precision·RecallPrecision+Recall,wheretheprecisionandrecallscoresarecalculatedasPrecision=TPTP+FN.\nTheTPrepresentsthenumberoftruepositivememorycontents,FPmeansthenumberoffalsepositivememorycontents,andFNindicatesthenumberoffalsenegativememorycontents.\nInpreviousworks,Luetal.\n[94]utilizeF1-scoretoevaluatetheretrievalprocessofthememory,andZhongetal.\n[6]focusonassessingwhetherrelatedmemorycanbesuccessfullyretrieved.\nTP+FPandRecall=TPResultCorrectnessandReferenceAccuracyarebothutilizedtoevaluatetheeffectivenessofthememorymodule.\nBeyondeffectiveness,efficiencyisalsoanimportantaspect,especiallyforreal-worldapplications.\nTherefore,wedescribetheevaluationofefficiencyasfollows.\nTime&HardwareCost.\nThetotaltimecostincludesthetimeleveragedformemoryadaptionandinference.\nTheadaptationtimereferstothetimeofmemorywritingandmemorymanagement,whiletheinferencetimeindicatesthetimelatencyofmemoryreading.\nInspecific,thedifferencefromthe21endtimetothestarttimeofmemoryoperationscanbeconsideredasthetimeconsumption.\nFormally,theaveragetimeconsumptionofeachtypeofoperationcanberepresentedas∆time=1MM(cid:88)i=1i−tstarttendi,whereMrepresentsthenumberoftheseoperations,tendimeanstheendtimeofthei-thoperation,andtstartindicatesthestarttimeofthatoperation.\nAsforthecomputationoverhead,itcanbeevaluatedibythepeakGPUmemoryallocation.\nInpreviousworks,Tacketal.\n[106]utilizethepeakmemoryallocationandadaptationtimetoassesstheefficiencyofmemoryoperations.\nObjectiveevaluationoffersnumericstrategiestocomparedifferentmethodsofmemory,whichisimportanttobenchmarkthisfieldandpromotefuturedevelopments.\n6.\n2",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nFortextualmemory,eachLLMinferencerequirestointegratememoryintothecontextprompt,whichleadstohighercostsandlongerprocessingtimes.\nIncontrast,forparametricmemory,theinformationcanbeintegratedintotheparametersoftheLLM,eliminatingtheextracostsofthesecontexts.\nHowever,parametricmemorytakesadditionalcostsinthewritingprocess,buttextualmemoryiseasiertowrite,especiallyforsmallamountsofdata.\nInanutshell,textualmemoryismoreefficientinwriting,whileparametricmemoryismoreefficientinreading.\nInterpretability.\nTextualmemoryisusuallymoreexplainablethantheparametricone,sincenaturallanguagesarethemostnaturalandstraightforwardstrategiesforhumanstounderstand,whileparametricmemoryiscommonlyrepresentedinlatentspace.\nNevertheless,suchexplainabilityisobtainedatthecostofinformationdensity.\nThisisbecausethesequencesofwordsintextualmemoryarerepresentedinadiscretespace,whichisnotasdenseascontinuousspaceinparametricmemory.\nInconclusion,thetrade-offsbetweenthesetwotypesofmemoriesmakethemsuitablefordifferentapplications.\nForexample,forthetasksthatrequirerecallingrecentinteractions,likeconversationalandcontext-specifictasks,textualmemoryseemsmoreeffective.\nForthetasksthatrequirealargeamountofmemory,orwell-establishedknowledge,parametricmemorycanbeabetterchoice.\n5.\n3MemoryOperationsWeseparatetheentireprocedureofmemoryintothreeoperations:memorywriting,memorymanage-ment,andmemoryreading.\nThesethreetypicallycollaboratetoachievememoryfunction,providinginformationforLLMinference.\nWesummarizepreviousworksonmemoryoperationsinTable3.\n5.\n3.\n1MemoryWritingAftertheinformationisperceivedbytheagent,apartofitwillbestoredbytheagentforfurtherusagethroughthememorywritingoperation,anditiscrucialtorecognizewhichinformationisessentialtostore.\nManystudieschoosetostoretherawinformation,whileothersalsoputthesummaryoftherawinformationintothememorymodule.\nRepresentativeStudies.\nInTiM[97],therawinformationwillbeextractedastherelationbetweentwoentities,andstoredinastructureddatabase.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nNevertheless,suchexplainabilityisobtainedatthecostofinformationdensity.\nThisisbecausethesequencesofwordsintextualmemoryarerepresentedinadiscretespace,whichisnotasdenseascontinuousspaceinparametricmemory.\nInconclusion,thetrade-offsbetweenthesetwotypesofmemoriesmakethemsuitablefordifferentapplications.\nForexample,forthetasksthatrequirerecallingrecentinteractions,likeconversationalandcontext-specifictasks,textualmemoryseemsmoreeffective.\nForthetasksthatrequirealargeamountofmemory,orwell-establishedknowledge,parametricmemorycanbeabetterchoice.\n5.\n3MemoryOperationsWeseparatetheentireprocedureofmemoryintothreeoperations:memorywriting,memorymanage-ment,andmemoryreading.\nThesethreetypicallycollaboratetoachievememoryfunction,providinginformationforLLMinference.\nWesummarizepreviousworksonmemoryoperationsinTable3.\n5.\n3.\n1MemoryWritingAftertheinformationisperceivedbytheagent,apartofitwillbestoredbytheagentforfurtherusagethroughthememorywritingoperation,anditiscrucialtorecognizewhichinformationisessentialtostore.\nManystudieschoosetostoretherawinformation,whileothersalsoputthesummaryoftherawinformationintothememorymodule.\nRepresentativeStudies.\nInTiM[97],therawinformationwillbeextractedastherelationbetweentwoentities,andstoredinastructureddatabase.\nWhenwritingintothedatabase,similarcontentswillbestoredinthesamegroup.\nInSCM[98],itdesignsamemorycontrollertodecidewhentoexecutetheoperations.\nThecontrollerservesasaguideforthewholememorymodule.\nInMemGPT[100],thememorywritingisentirelyself-directed.\nTheagentscanautonomouslyupdatethememorybasedonthecontexts.\nInMemoChat[94],theagentssummarizeeachconversationsegmentbyabstractingthemainlydiscussedtopicsandstoringthemaskeysforindexingmemorypieces.\nDiscussion.\nPreviousresearchindicatesthatdesigningthestrategyofinformationextractionduringthememorywritingoperationisvital[94].\nThisisbecausetheoriginalinformationiscommonlylengthyandnoisy.",
      "#memory_survey#MemoryWriting#memory_survey#MemoryWriting\nMemoryWriting.\nThisoperationaimstoprojecttherawobservationsintotheactuallystoredmemorycontents,whicharemoreinformative[7]andconcise[6].\nItcorrespondstothefirstphaseoftheagent-environmentinteractionprocess.\nGivenataskTk,iftheagenttakesanactionaktatstept,andtheenvironmentprovidesanobservationokt,thenthememorywritingoperationcanbeformallyrepresentedas:mkt=W({akt,okt}),whereWisaprojectingfunction.\nmktisthefinallystoredmemorycontents,whichcanbeeithernaturallanguagesorparametricrepresentations.\nIntheabovetoyexample,fortask(A),theagentissupposedtoremembertheflightarrangementandthedecisionofattractionsafter[step2].\nFortask(B),theagentshouldmemorizethefactthatAlicehopestowatchmoviesat9:00PM,after[step1].",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nManystudieschoosetostoretherawinformation,whileothersalsoputthesummaryoftherawinformationintothememorymodule.\nRepresentativeStudies.\nInTiM[97],therawinformationwillbeextractedastherelationbetweentwoentities,andstoredinastructureddatabase.\nWhenwritingintothedatabase,similarcontentswillbestoredinthesamegroup.\nInSCM[98],itdesignsamemorycontrollertodecidewhentoexecutetheoperations.\nThecontrollerservesasaguideforthewholememorymodule.\nInMemGPT[100],thememorywritingisentirelyself-directed.\nTheagentscanautonomouslyupdatethememorybasedonthecontexts.\nInMemoChat[94],theagentssummarizeeachconversationsegmentbyabstractingthemainlydiscussedtopicsandstoringthemaskeysforindexingmemorypieces.\nDiscussion.\nPreviousresearchindicatesthatdesigningthestrategyofinformationextractionduringthememorywritingoperationisvital[94].\nThisisbecausetheoriginalinformationiscommonlylengthyandnoisy.\nBesides,differentenvironmentsmayprovidevariousformsoffeedback,andhowtoextractandrepresenttheinformationasmemoryisalsosignificantformemorywriting.\n5.\n3.\n2MemoryManagementForhumanbeings,memoryinformationisconstantlyprocessedandabstractedinthebrains.\nThememoryintheagentcanalsobemanagedbyreflectingtogeneratehigher-levelmemories,mergingredundantmemoryentries,andforgettingunimportant,earlymemories.\nRepresentativeStudies.\nInMemoryBank[6],theagentsprocessanddistilltheconversationsintoahigh-levelsummaryofdailyevents,similartohowhumansrecallkeyaspectsoftheirexperiences.\nThroughlong-terminteractions,theycontinuallyevaluateandrefinetheirknowledge,generatingdailyinsightsintopersonalitytraits.\nInVoyager[99],theagentsareabletorefinetheirmemorybasedonthefeedbackoftheenvironment.\nInGenerativeAgents[83],theagentscanreflecttogethigher-levelinformation,wheretheabstractthoughtsaregeneratedfromagents.\nThereflectionprocesswillbeactivatedwhenthereareaccumulatedeventsthatareenoughtoaddress.\nForGITM[93],inordertoestablishcommonreferenceplansforvarioussituations,keyactionsfrommultipleplansarefurthersummarizedinthememorymodule.\nDiscussion.",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.",
      "#memory_survey#Memory-assistedAgent-EnvironmentInteraction#memory_survey#Memory-assistedAgent-EnvironmentInteraction\nMemory-assistedAgent-EnvironmentInteractionAsmentionedatthebeginningofSection3,therearethreekeyphasesintheagent-environmentinteractionprocess.\nTheagentmemorymoduleimplementsthesephasesthroughthreeoperationsincludingmemorywriting,memorymanagement,andmemoryreading.\nMemoryWriting.\nThisoperationaimstoprojecttherawobservationsintotheactuallystoredmemorycontents,whicharemoreinformative[7]andconcise[6].\nItcorrespondstothefirstphaseoftheagent-environmentinteractionprocess.\nGivenataskTk,iftheagenttakesanactionaktatstept,andtheenvironmentprovidesanobservationokt,thenthememorywritingoperationcanbeformallyrepresentedas:mkt=W({akt,okt}),whereWisaprojectingfunction.\nmktisthefinallystoredmemorycontents,whichcanbeeithernaturallanguagesorparametricrepresentations.\nIntheabovetoyexample,fortask(A),theagentissupposedtoremembertheflightarrangementandthedecisionofattractionsafter[step2].\nFortask(B),theagentshouldmemorizethefactthatAlicehopestowatchmoviesat9:00PM,after[step1].\nMemoryManagement.\nThisoperationaimstoprocessthestoredmemoryinformationtomakeitmoreeffective,forexample,summarizinghigh-levelconceptstomaketheagentmoregeneral-1Foreachtask,therecanbemultipletrialsforexploringthefinalsolution,andallofthemcanbeincorporatedintothememory.\n9izable[6],mergingsimilarinformationtoreduceredundancy[7],andforgettingunimportantorirrelevantinformationtoremoveitsnegativeinfluence.\nThisoperationcorrespondstothesecondphaseoftheagent-environmentinteractionprocess.\nLetMkt−1bethememorycontentsfortaskkbeforestept,andsupposemktisthestoredinformationatsteptbasedontheabovememorywritingoperation,then,thememorymanagementoperationcanberepresentedby:Mkt=P(Mkt−1,mkt),wherePisafunctionthatiterativelyprocessesthestoredmemoryinformation.\nForthenarrowmemorydefinition,theiterationonlyhappenswithinthesametrial,andthememoryisemptiedwhenthetrialisended.\nForthebroadmemorydefinition,theiterationhappensacrossdifferenttrialsoreventasks,aswellastheintegrationsofexternalknowledge.",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nMoreover,someeffortsarededicatedtoenhancingthecapacityofLLMstohandlelongercontexts[118,119].\nWhilestoringalltheagent-environmentinteractionscanmaintaincomprehensiveinformation,obviouslimitationsexistintermsofcomputationalcost,inferencetime,andinferencerobustness.\nFirstly,thefast-growinglong-contextmemoryinpracticeresultsinhighcomputationalcostduringLLMinference,duetothequadraticgrowthofthetimecomplexityofattentioncomputationwithsequencelength.\nItthusrequiresmuchmorecomputingresourcesandsignificantlyincreasesinferencelatency,whichhindersitspracticaldeployment.\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.\nThismethodstoresandmaintainsthemostrecentlyacquiredmemoriesusingnaturallanguages,therebyenhancingtheefficiencyofmemoryinformationutilizationaccordingtothePrincipleofLocality[121].\nIntask(B)oftheexampleinSection3.\n1,wecanjustrememberAlice’spreferencesintherecentthreeyears,andtruncatethedistantpart,wheretherecentthreeyearscanbeconsideredasthememorywindowsize.\nInpreviousstudies,therearevariousstrategiestostorerecenttextualmemories.\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.\nDuringmemoryreading,matchingscoresarecalculatedforeachmemoryentry,andthetop-Kentrieswillbeusedforthedecision-makingprocessofagents.\n15Inexistingstudies,mostagentsutilizeretrievalmethodstoprocessthememoryinformation.\nForexample,Parketal.\n[83]firstcalculatetherelevancebetweenthecurrentcontextandmemoryentriesbycosinesimilarity,andobtaintheimportanceandrecencyaccordingtoauxiliaryinformation.\nMemoryBank[6]employsadual-towerdenseretrievalmodeltofindrelatedinformationfrompastconversations.\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage."
    ],
    [
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nIntheformerthreetypes,theyrecordtheinformationinsidetheagent-environmentinteractionloop,whilethelasttypeleveragesnaturallanguagestostoreinformationoutsidethatloop.\nCompleteInteractions.\nThismethodstoresalltheinformationoftheagent-environmentinteractionhistorybasedonlong-contextstrategies[116].\nFortheexampleinSection3.\n1,thememoryofthe14agentintask(A)afterstep2canbeimplementedbyconcatenatingalltheinformationbeforestep2,andthefinaltextualformmemoryis:\"Yourmemoryis[Step1](Agent).\n.\n.\n(OnlineTicketOffice).\n.\n.\n[Step2].\n.\n.\nPleaseinferbasedonyourmemory\".\nInthepreviouswork,differentmodelsstorethememoryinformationusingdifferentstrategies.\nForexample,inLongChat[116],theagentsfocusonunderstandingnaturallanguagesinlong-contextscenarios.\nItfine-tunesthefoundationmodelforbetteradaptingtomemorizecompleteinteractions.\nMemorySandbox[117]intendstoalleviatetheimpactofirrelevantmemoryinconversations.\nItdesignsatransparentandinteractivemethodtomanagethememoryofagents,whichremovesirrelevantmemorybeforeconcatenatingthemasaprompt.\nMoreover,someeffortsarededicatedtoenhancingthecapacityofLLMstohandlelongercontexts[118,119].\nWhilestoringalltheagent-environmentinteractionscanmaintaincomprehensiveinformation,obviouslimitationsexistintermsofcomputationalcost,inferencetime,andinferencerobustness.\nFirstly,thefast-growinglong-contextmemoryinpracticeresultsinhighcomputationalcostduringLLMinference,duetothequadraticgrowthofthetimecomplexityofattentioncomputationwithsequencelength.\nItthusrequiresmuchmorecomputingresourcesandsignificantlyincreasesinferencelatency,whichhindersitspracticaldeployment.\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nMemoryinTextualFormTextualformiscurrentlythemainstreammethodtorepresentthememorycontents,whichisfeaturedinbetterinterpretability,easierimplementation,andfasterread-writeefficiency.\nInspecific,thetextualformcanbebothnon-structuredrepresentationslikerawnaturallanguagesandstructuredinformationsuchastuples,databases,andsoon.\nIngeneral,previousstudiesusethetextualformmemorytostorefourtypesofinformationincluding(1)completeagent-environmentinteractions,(2)recentagent-environmentinteractions,(3)retrievedagent-environmentinteractions,and(4)externalknowledge.\nIntheformerthreemethods,thememoryleveragesnaturallanguagestodescribetheinformationwithintheagent-environmentinteractionloop.\nIntheformerthreetypes,theyrecordtheinformationinsidetheagent-environmentinteractionloop,whilethelasttypeleveragesnaturallanguagestostoreinformationoutsidethatloop.\nCompleteInteractions.\nThismethodstoresalltheinformationoftheagent-environmentinteractionhistorybasedonlong-contextstrategies[116].\nFortheexampleinSection3.\n1,thememoryofthe14agentintask(A)afterstep2canbeimplementedbyconcatenatingalltheinformationbeforestep2,andthefinaltextualformmemoryis:\"Yourmemoryis[Step1](Agent).\n.\n.\n(OnlineTicketOffice).\n.\n.\n[Step2].\n.\n.\nPleaseinferbasedonyourmemory\".\nInthepreviouswork,differentmodelsstorethememoryinformationusingdifferentstrategies.\nForexample,inLongChat[116],theagentsfocusonunderstandingnaturallanguagesinlong-contextscenarios.\nItfine-tunesthefoundationmodelforbetteradaptingtomemorizecompleteinteractions.\nMemorySandbox[117]intendstoalleviatetheimpactofirrelevantmemoryinconversations.\nItdesignsatransparentandinteractivemethodtomanagethememoryofagents,whichremovesirrelevantmemorybeforeconcatenatingthemasaprompt.\nMoreover,someeffortsarededicatedtoenhancingthecapacityofLLMstohandlelongercontexts[118,119].\nWhilestoringalltheagent-environmentinteractionscanmaintaincomprehensiveinformation,obviouslimitationsexistintermsofcomputationalcost,inferencetime,andinferencerobustness.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nIntheabovetoyexample,fortask(A),ifthereareseveralfailedtrials,thatis,thefeedbackfromAliceisnegative,thenthesetrialscanbeincorporatedintotheagent’smemorytoavoidfuturesimilarerrors(correspondingtoξk′).\nInaddition,fortask(B),theagentmayrecommendmoviesrelevanttotheattractionsthatAlicehasvisitedintask(A)tocaptureherrecentpreferences(correspondingto{ξ1,ξ2,.\n.\n.\n,ξk−1}).\nIntheagentdecisionprocess,ithasalsoreferredtothemagazineAttractionsinBeijingformakingtripplans,whichistheexternalknowledge(correspondingtoDkt,Ξk,Dkt)forthecurrenttaskTk.\n3.\n4Memory-assistedAgent-EnvironmentInteractionAsmentionedatthebeginningofSection3,therearethreekeyphasesintheagent-environmentinteractionprocess.\nTheagentmemorymoduleimplementsthesephasesthroughthreeoperationsincludingmemorywriting,memorymanagement,andmemoryreading.\nMemoryWriting.\nThisoperationaimstoprojecttherawobservationsintotheactuallystoredmemorycontents,whicharemoreinformative[7]andconcise[6].\nItcorrespondstothefirstphaseoftheagent-environmentinteractionprocess.\nGivenataskTk,iftheagenttakesanactionaktatstept,andtheenvironmentprovidesanobservationokt,thenthememorywritingoperationcanbeformallyrepresentedas:mkt=W({akt,okt}),whereWisaprojectingfunction.\nmktisthefinallystoredmemorycontents,whichcanbeeithernaturallanguagesorparametricrepresentations.\nIntheabovetoyexample,fortask(A),theagentissupposedtoremembertheflightarrangementandthedecisionofattractionsafter[step2].\nFortask(B),theagentshouldmemorizethefactthatAlicehopestowatchmoviesat9:00PM,after[step1].\nMemoryManagement.\nThisoperationaimstoprocessthestoredmemoryinformationtomakeitmoreeffective,forexample,summarizinghigh-levelconceptstomaketheagentmoregeneral-1Foreachtask,therecanbemultipletrialsforexploringthefinalsolution,andallofthemcanbeincorporatedintothememory.\n9izable[6],mergingsimilarinformationtoreduceredundancy[7],andforgettingunimportantorirrelevantinformationtoremoveitsnegativeinfluence.\nThisoperationcorrespondstothesecondphaseoftheagent-environmentinteractionprocess.",
      "#memory_survey#ExternalKnowledge#memory_survey#ExternalKnowledge\nExternalKnowledgeMemoryBank[6]RET-LLM[7]ChatDB[96]TiM[97]SCM[98]Voyager[99]MemGPT[100]MemoChat[94]MPC[101]GenerativeAgents[83]RecMind[102]Retroformer[103]ExpeL[82]Synapse[91]GITM[93]ReAct[104]Reflexion[5]RecAgent[95]Character-LLM[105]MAC[106]Huatuo[107]ChatDev[1]InteRecAgent[108]MetaAgents[109]TPTU[110,111]MetaGPT[112]S3[2]InvestLM[113]✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓×××××××××××✓✓✓✓×✓××××××××✓×××✓✓×××××××✓✓✓×✓✓✓×✓×✓×✓×✓××✓generatedintheagent-environmentinteractionprocess(e.\ng.\n,taskinternalinformation),whilethelatterisstaticinformationoutsidetheloop(e.\ng.\n,taskexternalinformation).\nWesummarizepreviousworksonmemorysourcesinTable1.\n5.\n1.\n1Inside-trialInformationIntheagent-environmentinteractionprocess,thehistoricalstepswithinatrialareusuallythemostrelevantandinformativesignalstosupporttheagent’sfutureactions.\nAlmostallthepreviousworksusethisinformationasapartofthememorysources.\nRepresentativeStudies.\nGenerativeAgents[83]aimstosimulatehuman’sdailybehaviorsbyusingLLM-basedagents.\nThememoryofanagentisderivedfromthehistoricalbehaviorstoachieveatarget,forexample,thecollectionofrelevantpaperswhenresearchingonaspecifictopic.\nMemoChat[94]aimstochatwithhumans,wherethememoryoftheagentisderivedbasedontheconversationhistoryofadialoguesession.\nTiM[97]aimstoenhancetheagent’sreasoningcapabilitybyself-generatingmultiplethoughtsafteraccomplishingatask,whichisusedasthememorytoprovidemoregeneralizableinformation.\nVoyager[99]focusesonbuildinggameagentsbasedonMinecraft,wherethememorycontainsexecutablecodesofpreliminaryandbasicactionstoaccomplishatask.\nItshouldbenotedthattheinside-trialinformationnotonlyincludesagent-environmentinteractions,butalsocontainsinteractioncontexts,suchastimeandlocationinformation.\n12Discussion.\nTheinside-trialinformationisthemostobviousandintuitivesourcethatshouldbeleveragedtoconstructtheagent’smemorysinceitishighlyrelevanttothecurrenttaskthattheagenthastoaccomplish.",
      "#memory_survey#BasicKnowledge#memory_survey#BasicKnowledge\nAccordingtotheinformationabove,IrecommendvisitingtheSummerPalaceaftershearrivesinBeijingbecauseitissuitabletospendawholeafternoonthereandwatchthesunset.\nThen,shecangototheForbiddenCitythenextday,whichwouldgiveherplentyoftime.\nFinally,shecanreturntoShanghaionthethirddayandtakearest.\nEnvironment(Alice):Ilovethisplan.\nThanks!\n8Fortask(B),thetrialis:[Step1]Agent:AccordingtomypreviousexperiencesofmovierecommendationsforAlice,shepreferstostartwatchingmoviesat9:00PM,becauseshehasfinishedworkbythen.\nIshouldaskAliceifsheisavailableatthattime.\nEnvironment(Alice):Ofcourse,itisanicetime!\n[Step2]Agent:Now,IneedtofindsomemoviesthatAlicehasmarked\"wanttowatch\"onNetflix.\nEnvironment(Netflix):Alice’swanttowatch:Interstellar,PlanetTerrorandCandleintheTomb.\n[Step3]Agent:SinceAliceneverwatcheshorrormoviesatnight,Interstellarwouldbemoresuitableforher.\nNow,IneedtoconfirmwithAliceaboutthemovie.\nEnvironment(Alice):Great!\nIlikeit!\n3.\n2"
    ],
    [
      "#memory_survey#Memory-enhancedAgentApplications#memory_survey#Memory-enhancedAgentApplications\nMemory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1",
      "#memory_survey#PerspectiveofAgentApplications#memory_survey#PerspectiveofAgentApplications\nPerspectiveofAgentApplicationsInmanyapplications,memoryisanindispensablecomponentoftheagent.\nForexample,inaconver-sationalagent,thememorystoresinformationabouthistoricalconversations,whichisnecessaryfortheagenttogeneratethenextresponse.\nWithoutmemory,theagentdoesnotknowthecontext,andcannotcontinuetheconversation[94].\nInasimulationagent,memoryisofgreatimportancetomaketheagentconsistentlyfollowtheroleprofiles.\nWithoutmemory,theagentmayeasilystepoutoftheroleduringthesimulationprocess[95].\nBothoftheaboveexamplesshowthatthememoryisnotanoptionalcomponent,butisnecessaryfortheagentstoaccomplishgiventasks.\nIntheabovethreeperspectives,thefirstonerevealsthatthememorybuildsthecognitivebasisoftheagent.\nThesecondandthirdonesshowthatthememoryisnecessaryfortheagent’sevolvingprinciplesandapplications,whichprovideinsightsfordesigningagentswithmemorymechanisms.\n5",
      "#memory_survey#OtherApplications#memory_survey#OtherApplications\nOtherApplicationsTherearesomeotherapplicationsofmemoryinLLM-basedagents.\nWangetal.\n[166]focusonthetaskofcloudrootcauseanalysis,usingmemorytostoreframeworkrules,taskrequirements,tools26documentation,few-shotexamples,andagentobservations.\nQiangetal.\n[167]solvetheproblemofontologymatching.\nTheagentssaveconversationaldialoguesandconstructarationaldatabaseforretrievingexternalknowledge.\nWenetal.\n[168]investigateautonomousdriving,whosememorymoduleisconstructedbyavectordatabaseandcontainstheexperiencesfrompastdrivingscenarios.\nWangetal.\n[169]proposetoimproveuseracceptancetesting,whichemploysaself-reflectionmechanism.\nAftereachtrial,theoperationagentsummarizestheconversationandupdatesthememorypool,untilthegoalofthecurrentstepisaccomplished.\nFordifferentapplications,thefocusofmemoryvaries,asitinherentlyservesthedownstreamtasks.\nTherefore,thedesignshouldalsoconsidertherequirementsoftasks.\n8",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nInfact,nearlyallthememory-equippedagentscanevaluatetheeffectofmemorybyablationstudies,comparingtheperformancebetweenwith/withoutmemorymodules.\nTheevaluationonspecificscenarioscanbetterreflectthesignificanceofmemoryforthedownstreamapplicationspractically.\n6.\n3DiscussionsComparedwithdirectevaluation,indirectevaluationviaspecifictaskscanbeeasiertoconduct,sincetherearealreadymanypublicbenchmarks.\nHowever,theperformanceontaskscanbeattributedtovariousfactors,andmemoryisonlyoneofthem,whichmaymaketheevaluationresultsbiased.\nBydirectevaluation,theeffectivenessofthememorymodulecanbeindependentlyevaluated,whichimprovesthereliabilityoftheevaluationresults.\nHowever,toourknowledge,therearenoopen-sourcedbenchmarkstailoredforthememorymodulesinLLM-basedagents.\n7Memory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1Role-playingandSocialSimulationRole-playingrepresentsaclassicapplicationofLLM-basedagents,wherememoryplaysacrucialroleinsidetheagents.\nItendowsroleswithdistinctcharacteristics,differentiatingthemfromoneanother.\nManypreviousstudieshaveexploredmethodsforconstructingrolememories[105,143,145–147].\nShaoetal.\n[105]constructthememoryofrolesbyexperienceuploading,whichutilizesSFTtoinjectmemoryintomodelparameters.\nLietal.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nByrememberinghistoricalinformation,thememorycanhelptobetterdecidewhenandhowtomakeexplorations,forexample,focusingmoreonpreviouslyfailedtrialsoractionswithlowerexploringfrequencies[93].\n(3)Knowledgeabstraction.\nAnotherimportantfunctionofthememoryistosummarizeandabstracthigh-levelinformationfromrawobservations,whichisthebasisfortheagenttobemoreadaptiveandgeneralizabletounseenenvironments[82].\nInsummary,self-evolutionisthebasiccharacteristicofLLM-basedagents,andmemoryisofkeyimportancetoself-evolution.\n4.\n3PerspectiveofAgentApplicationsInmanyapplications,memoryisanindispensablecomponentoftheagent.\nForexample,inaconver-sationalagent,thememorystoresinformationabouthistoricalconversations,whichisnecessaryfortheagenttogeneratethenextresponse.\nWithoutmemory,theagentdoesnotknowthecontext,andcannotcontinuetheconversation[94].\nInasimulationagent,memoryisofgreatimportancetomaketheagentconsistentlyfollowtheroleprofiles.\nWithoutmemory,theagentmayeasilystepoutoftheroleduringthesimulationprocess[95].\nBothoftheaboveexamplesshowthatthememoryisnotanoptionalcomponent,butisnecessaryfortheagentstoaccomplishgiventasks.\nIntheabovethreeperspectives,thefirstonerevealsthatthememorybuildsthecognitivebasisoftheagent.\nThesecondandthirdonesshowthatthememoryisnecessaryfortheagent’sevolvingprinciplesandapplications,whichprovideinsightsfordesigningagentswithmemorymechanisms.\n5HowtoImplementtheMemoryofLLM-basedAgentInthissection,wediscusstheimplementationofthememorymodulefromthreeperspectives:memorysources,memoryforms,andmemoryoperations.\nMemorysourcesrefertowherethememorycontentscomefrom.\nMemoryformsfocusonhowtorepresentthememorycontents.\nMemoryoperationsaimtoprocessthememorycontents.\nThesethreeperspectivesprovideacomprehensivereviewofmemoryimplementationmethods,whichishelpfulforfutureresearch.\nForbetterdemonstration,wepresentanoverviewofimplementationmethodsinFigure4.\n5.\n1MemorySourcesInpreviousworks,thememorycontentsmaycomefromdifferentsources."
    ],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.\nAnotherlimitationoffine-tuningliesinthecomputationalcostandtimeconsumption,aswellastherequirementofalargeamountofdata.\nTherefore,mostfine-tuningapproachesareappliedtoofflinescenarios,andcanseldomdealwithonlinescenarios,suchasfine-tuningwithagentobservationsandtrialexperiences.\nDuetothefrequentagent-environmentinteractions,itisunaffordableforthecostofbackpropagationtofine-tuneeverystepoftheonlineanddynamicinteractions.\nMemoryEditingMethods.\nApartfromthefine-tuningapproaches,anothertypeofmethodsforinfusingmemoryintomodelparametersisknowledgeediting[133,134].\nUnlikefine-tuningmethodsthatextractpatternsfromcertaindatasets,knowledgeeditingmethodsspecificallytargetandadjustonlythefactsthatneedtobechanged.\nItensuresthatunrelatedknowledgeremainsunaffected.\nKnowledgeeditingmethodsaremoresuitableforsmall-scalememoryadjustments.\nGenerally,theyhavelowercomputationalcosts,makingthemmoresuitableforonlinescenarios.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.\nAnotherlimitationoffine-tuningliesinthecomputationalcostandtimeconsumption,aswellastherequirementofalargeamountofdata.\nTherefore,mostfine-tuningapproachesareappliedtoofflinescenarios,andcanseldomdealwithonlinescenarios,suchasfine-tuningwithagentobservationsandtrialexperiences.\nDuetothefrequentagent-environmentinteractions,itisunaffordableforthecostofbackpropagationtofine-tuneeverystepoftheonlineanddynamicinteractions.\nMemoryEditingMethods.",
      "#memory_survey#MemoryinParametricForm#memory_survey#MemoryinParametricForm\nMemoryinParametricFormAnalternativetypeofapproachesistorepresentmemoryinparametricform.\nTheydonottakeuptheextralengthofcontextinprompts,sotheyarenotconstrainedbythelengthlimitationsofLLMcontext.\nHowever,theparametricmemoryformisstillunder-researched,andwecategorizepreviousworksintotwotypes:fine-tuningmethodsandmemoryeditingmethods.\nFine-tuningMethods.\nIntegratingexternalknowledgeintothememoryofagentsisbeneficialforenrichingdomain-specificknowledgeontopofitsgeneralknowledge.\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.",
      "#memory_survey#MemoryinParametricForm#memory_survey#MemoryinParametricForm\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.\nAnotherlimitationoffine-tuningliesinthecomputationalcostandtimeconsumption,aswellastherequirementofalargeamountofdata.\nTherefore,mostfine-tuningapproachesareappliedtoofflinescenarios,andcanseldomdealwithonlinescenarios,suchasfine-tuningwithagentobservationsandtrialexperiences.\nDuetothefrequentagent-environmentinteractions,itisunaffordableforthecostofbackpropagationtofine-tuneeverystepoftheonlineanddynamicinteractions.\nMemoryEditingMethods.\nApartfromthefine-tuningapproaches,anothertypeofmethodsforinfusingmemoryintomodelparametersisknowledgeediting[133,134].\nUnlikefine-tuningmethodsthatextractpatternsfromcertaindatasets,knowledgeeditingmethodsspecificallytargetandadjustonlythefactsthatneedtobechanged.\nItensuresthatunrelatedknowledgeremainsunaffected.\nKnowledgeeditingmethodsaremoresuitableforsmall-scalememoryadjustments.\nGenerally,theyhavelowercomputationalcosts,makingthemmoresuitableforonlinescenarios.\nInourexampleoftask(B),Alicealwayswatchesmoviesat9:00PMfromtheagent’smemory,butshemayrecentlychangeherworkandwouldnotbeemptyat9:00PM.\nIfso,therelatedmemory(suchasroutinesat9:00PM)shouldbeedited,whichcanbeimplementedbyknowledgeeditingmethods.\nInpreviousstudies,MAC[106]intendstodesignaneffectiveandefficientmemoryadaptationframeworkforonlinescenarios.\nItutilizesmeta-learningtosubstitutetheoptimizationstep.\nPer-sonalityEdit[135]focusesoneditingthepersonalityofLLMsandagents,whereitchangestheirtraitsbasedontheoriessuchasthebig-fivefactor.\nMEND[134]utilizestheideaofmeta-learningtotrainalightweightmodel,whichiscapableofgeneratingmodificationsformodelparametersofapre-trainedlanguagemodel.\nAPP[136]studieswhetheraddinganewfactleadstocatastrophicforgettingofexistingfacts.\nItfocusesontheimpactofneighborperturbationonmemoryaddition.",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32]andParketal.\n[33]systematicallyreviewthetechniquesofmodelcompression.\nDingetal.\n[81]andXuetal.\n[29]analyzeandconcludethestudiesonparameterefficientfine-tuning.\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28]andDingetal.\n[81]putmorefocusesontheefficiencyofresourceutilizationinageneralsense.\nEvaluation.\nThesurveysinthiscategoryfocusonhowtoevaluatethecapabilityofLLMs.\nSpecifi-cally,Changetal.\n[34]comprehensivelysummarizetheevaluationmethodsfromanoverallperspec-tive.\nItencompassesdifferentevaluationtasks,methods,andbenchmarks,whichserveascriticalpartsinassessingLLMperformances.\nGuoetal.\n[35]caremoreabouttheevaluationtargetsanddescribehowtoevaluatetheknowledge,alignment,andsafetycontrolcapabilitiesofLLMs,whichsupplementevaluationmetricsbeyondperformance.\nApplications.\nThesurveysinthiscategoryaimtosummarizemodelsthatleverageLLMstoimprovedifferentapplications.\nMoreconcretely,Zhuetal.\n[37]focusonthefieldofinformationretrieval(IR)andsummarizestudiesonLLM-basedqueryprocesses.\nXuetal.\n[38]paymoreattentiontoinformationextraction(IE)andprovidecomprehensivetaxonomiesforLLM-basedmodelsinthisfield.\nLietal.\n[50],Linetal.\n[51]andWangetal.\n[52]discusstheapplicationsofLLMsinthefieldofrecommendersystem,wheretheyutilizeagentstogeneratedataandproviderecommendations.\nFanetal.\n[39],Wangetal.\n[40],andZhengetal.\n[41]concentrateonhowLLMscanbenefitsoftwareengineering(SE)intermsofsoftwaredesign,development,andtesting.\nZengetal.\n[42]summarizeLLM-basedmethodsinthefieldofrobotics.\nCuietal.\n[43]andYangetal.\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal."
    ],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\nForbothsimulatingusersinrecommendersystemsandcapturingtheirpreferences,retainingper-sonalizedinformationthroughmemoryisessential.\nAcriticalchallengeliesinhowtoalignthepersonalizedinformationandfeedbackwithLLMs,andstorethemintothememoryofagents.\nItisalsoanimportanttaskforbridgingthegapbetweenconventionalrecommendationmodelsandLLMs.\n7.\n6",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nByleveragingexternalresources,theagentscanlearnfromcode-relatedknowledgeandstoreitintotheirmemory,therebyenhancingthecapabilitiesofcodegeneration.\nInaddition,thememorycanimprovethecontinuityandconsistencyincodegeneration.\nByintegratingcontextualmemory,theagentcanbetterunderstandtherequirementsforsoftwaredevelopment,therebyenhancingthecoherenceofthegeneratedcode.\nFurthermore,thememoryisalsocrucialfortheiterativeoptimizationofcode,asitcanidentifythedeveloper’stargetsbasedonthehistories.\n257.\n5RecommendationInthefieldofrecommendation,somepreviousworksfocusonsimulatingusersinrecommendersystems[95,108],wherethememorycanrepresenttheuserprofilesandhistoriesintherealworld.\nOtherstrytoimprovetheperformanceofrecommendation,orprovideotherformatsofrecommendationinterfaces[149,102].\nWangetal.\n[95]simulateuserbehaviorsinrecommendationscenariostogeneratedataforrecommendersystems,andtheagentsstorepastobservationsandinsightsintoahierarchicalmemory.\nInHuangetal.\n[108],thememoryinLLM-basedagentscanarchivetheuser’sconversationalhistoryoverextendedperiods,aswellascapturethemostrecentdialoguespertinenttothecurrentprompt,tosimulateinteractiverecommendersystems.\nItalsousesanactor-criticreflectiontoimprovetherobustnessofagents.\nItemagentsanduseragentsareequippedwithdifferentmemoriesin[149],whereitemagentsareendowedwithdynamicmemorymodulesdesignedtocaptureandpreserveinformationpertinenttotheirintrinsicattributesandtheinclinationsoftheiradopters.\nForuseragents,theadaptivememoryupdatingmechanismplaysapivotalroleinaligningtheagents’operationswithuserbehaviorsandpreferences.\nWangetal.\n[102]memorizeindividualizeduserinformationlikereviewsorratingsforitems,andacquiredomain-specificknowledgeandreal-timeinformationbywebsearchingtools.\nForbothsimulatingusersinrecommendersystemsandcapturingtheirpreferences,retainingper-sonalizedinformationthroughmemoryisessential.\nAcriticalchallengeliesinhowtoalignthepersonalizedinformationandfeedbackwithLLMs,andstorethemintothememoryofagents.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nManypreviousstudieshaveexploredmethodsforconstructingrolememories[105,143,145–147].\nShaoetal.\n[105]constructthememoryofrolesbyexperienceuploading,whichutilizesSFTtoinjectmemoryintomodelparameters.\nLietal.\n[143]enhancelargelanguagemodelsforrole-playingviaanimprovedpromptandthecharactermemoryextractedfromscripts,whereuserqueriesand23Table4:Summarizationofmemory-enhancedagentsapplications.\nApplicationsModelsApplicationsModelsRole-playingSocialSimulationPersonalAssistantGameCharacter-LLM[105]ChatHaruhi[143]RoleLLM[145]NarrativePlay[146]CharacterGLM[147]GenerativeAgents[83]LyfeAgents[148]S3[2]MetaAgents[109]WarAgent[150]MemoryBank[6]RET-LLM[7]MemoChat[94]MemGPT[100]MPC[101]AutoGen[153]ChatDB[96]TiM[97]SCM[98]Voyager[99]GITM[93]JARVIS[159]LARP[161]CodeGenerationRecommendationMedicineFinanceScienceRTLFixer[142]GameGPT[144]ChatDev[1]MetaGPT[109]CodeAgent[114]RecAgent[95]InteRecAgent[108]RecMind[102]AgentCF[149]Huatuo[107]DoctorGLM[129]Radiology-GPT[132]Wangetal.\n[151]EHRAgent[152]ChatDoctor[115]InvestLM[113]TradingGPT[154]QuantAgent[155]FinMem[156]Koaetal.\n[157]Chemist-X[158]ChemDFM[160]MatChat[162]chatbot’sresponsesareconcatenatedtoformasequenceasmemory.\nWangetal.\n[145]infuserole-specificknowledgeandepisodememoriesintoLLM-basedagents,wherecontextQApairsareconcatenatedtoformepisodememory.\nZhaoetal.\n[146]aimtogeneratehuman-likeresponses,guidedbypersonalitytraitsextractedfromnarratives,whichcanbestoredandretrievedbyrelevanceandimportance.\nZhouetal.\n[147]generatecharacter-baseddialoguesfordifferentrolesandempowerLLM-basedagentswithcorrespondingstylesbySFT.\nSocialsimulationisbasicallyanextensionofrole-playing,whichfocusesmoreonmulti-agentmodeling.\nThememorymoduleisanimportantcomponentforsuchapplications,whichhelpstoaccuratelysimulatehumandynamicbehaviors.\nInpreviousstudies,Kaiyaetal.\n[148]proposeaSummarize-and-Forgetmemorymechanismforbetterself-monitoringinsocialscenarios.\nGaoetal.\n[2]focusonsocialnetworksimulationsystems.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nFormally,theaveragetimeconsumptionofeachtypeofoperationcanberepresentedas∆time=1MM(cid:88)i=1i−tstarttendi,whereMrepresentsthenumberoftheseoperations,tendimeanstheendtimeofthei-thoperation,andtstartindicatesthestarttimeofthatoperation.\nAsforthecomputationoverhead,itcanbeevaluatedibythepeakGPUmemoryallocation.\nInpreviousworks,Tacketal.\n[106]utilizethepeakmemoryallocationandadaptationtimetoassesstheefficiencyofmemoryoperations.\nObjectiveevaluationoffersnumericstrategiestocomparedifferentmethodsofmemory,whichisimportanttobenchmarkthisfieldandpromotefuturedevelopments.\n6.\n2IndirectEvaluationBesidestheabovemethodthatdirectlyevaluatesthememorymodule,evaluatingviataskcompletionisalsoapopularevaluationstrategy.\nTheintuitionbehindthistypeofapproachesisthatiftheagentcansuccessfullycompleteataskthathighlydependsonmemory,itsuggeststhatthedesignedmemorymoduleiseffective.\nInthefollowingparts,wepresentseveralrepresentativetasksthatareleveragedtoevaluatethememorymoduleinindirectways.\n6.\n2.\n1ConversationEngaginginconversationswithhumansisoneofthemostimportantapplicationsofagents,wherememoryplaysacrucialroleinthisprocess.\nBystoringcontextinformationinmemory,theagentsallowuserstoexperiencepersonalizedconversations,thusimprovingusers’satisfaction.\nTherefore,whenotherpartsoftheagentsaredetermined,theperformanceoftheconversationtaskscanreflecttheeffectivenessofdifferentmemorymodules.\nInthecontextofconversation,consistencyandengagementaretwocommonlyusedmethodstoevaluatetheeffectivenessoftheagents’memory.\nConsistencyreferstohowtheresponsefromagentsisconsistentwiththecontextbecausedramaticchangesshouldbeavoidedduringtheconversation.\nForexample,Luetal.\n[94]evaluatetheconsistencyofagentsoninteractivedialogues,usingGPT-4toscoreontheresponsesfromagents.\nEngagementreferstohowtheuserisengagedtocontinuetheconversation.\nItreflectsthequalityandattractionofagents’responses,aswellastheabilityofagentstocraftthepersonasforcurrentconversations.\nForexample,Leeetal.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nInfact,nearlyallthememory-equippedagentscanevaluatetheeffectofmemorybyablationstudies,comparingtheperformancebetweenwith/withoutmemorymodules.\nTheevaluationonspecificscenarioscanbetterreflectthesignificanceofmemoryforthedownstreamapplicationspractically.\n6.\n3DiscussionsComparedwithdirectevaluation,indirectevaluationviaspecifictaskscanbeeasiertoconduct,sincetherearealreadymanypublicbenchmarks.\nHowever,theperformanceontaskscanbeattributedtovariousfactors,andmemoryisonlyoneofthem,whichmaymaketheevaluationresultsbiased.\nBydirectevaluation,theeffectivenessofthememorymodulecanbeindependentlyevaluated,whichimprovesthereliabilityoftheevaluationresults.\nHowever,toourknowledge,therearenoopen-sourcedbenchmarkstailoredforthememorymodulesinLLM-basedagents.\n7Memory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1Role-playingandSocialSimulationRole-playingrepresentsaclassicapplicationofLLM-basedagents,wherememoryplaysacrucialroleinsidetheagents.\nItendowsroleswithdistinctcharacteristics,differentiatingthemfromoneanother.\nManypreviousstudieshaveexploredmethodsforconstructingrolememories[105,143,145–147].\nShaoetal.\n[105]constructthememoryofrolesbyexperienceuploading,whichutilizesSFTtoinjectmemoryintomodelparameters.\nLietal."
    ],
    [
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[17]NingyuZhang,YunzhiYao,BozhongTian,PengWang,ShuminDeng,MengruWang,ZekunXi,ShengyuMao,JintianZhang,YuanshengNi,etal.\nAcomprehensivestudyofknowledgeeditingforlargelanguagemodels.\narXivpreprintarXiv:2401.\n01286,2024.\n[18]YujiaQin,ShengdingHu,YankaiLin,WeizeChen,NingDing,GanquCui,ZheniZeng,YufeiHuang,ChaojunXiao,ChiHan,etal.\nToollearningwithfoundationmodels.\narXivpreprintarXiv:2304.\n08354,2023.\n[19]YunpengHuang,JingweiXu,ZixuJiang,JunyuLai,ZenanLi,YuanYao,TaolueChen,LijuanYang,ZhouXin,andXiaoxingMa.\nAdvancingtransformerarchitectureinlong-contextlargelanguagemodels:Acomprehensivesurvey.\narXivpreprintarXiv:2311.\n12351,2023.\n29[20]XindiWang,MahsaSalmani,ParsaOmidi,XiangyuRen,MehdiRezagholizadeh,andAr-maghanEshaghi.\nBeyondthelimits:Asurveyoftechniquestoextendthecontextlengthinlargelanguagemodels.\narXivpreprintarXiv:2402.\n02244,2024.\n[21]SauravPawar,SMTonmoy,SMZaman,VinijaJain,AmanChadha,andAmitavaDas.\nThewhat,why,andhowofcontextlengthextensiontechniquesinlargelanguagemodels–adetailedsurvey.\narXivpreprintarXiv:2401.\n07872,2024.\n[22]JiayangWu,WenshengGan,ZefengChen,ShichengWan,andSYuPhilip.\nMultimodallargelanguagemodels:Asurvey.\nIn2023IEEEInternationalConferenceonBigData(BigData),pages2247–2256.\nIEEE,2023.\n[23]ShezhengSong,XiaopengLi,andShashaLi.\nHowtobridgethegapbetweenmodalities:Acomprehensivesurveyonmultimodallargelanguagemodel.\narXivpreprintarXiv:2311.\n07594,2023.\n[24]DavideCaffagni,FedericoCocchi,LucaBarsellotti,NicholasMoratelli,SaraSarto,LorenzoBaraldi,MarcellaCornia,andRitaCucchiara.\nThe(r)evolutionofmultimodallargelanguagemodels:Asurvey.\narXivpreprintarXiv:2402.\n12451,2024.\n[25]ShukangYin,ChaoyouFu,SiruiZhao,KeLi,XingSun,TongXu,andEnhongChen.\nAsurveyonmultimodallargelanguagemodels.\narXivpreprintarXiv:2306.\n13549,2023.\n[26]GuangjiBai,ZhengChai,ChenLing,ShiyuWang,JiayingLu,NanZhang,TingweiShi,ZiyangYu,MengdanZhu,YifeiZhang,etal.\nBeyondefficiency:Asystematicsurveyofresource-efficientlargelanguagemodels.\narXivpreprintarXiv:2401.\n00625,2024.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[26]GuangjiBai,ZhengChai,ChenLing,ShiyuWang,JiayingLu,NanZhang,TingweiShi,ZiyangYu,MengdanZhu,YifeiZhang,etal.\nBeyondefficiency:Asystematicsurveyofresource-efficientlargelanguagemodels.\narXivpreprintarXiv:2401.\n00625,2024.\n[27]ZhongweiWan,XinWang,CheLiu,SamiulAlam,YuZheng,ZhongnanQu,ShenYan,YiZhu,QuanluZhang,MosharafChowdhury,etal.\nEfficientlargelanguagemodels:Asurvey.\narXivpreprintarXiv:2312.\n03863,1,2023.\n[28]XupengMiao,GabrieleOliaro,ZhihaoZhang,XinhaoCheng,HongyiJin,TianqiChen,andZhihaoJia.\nTowardsefficientgenerativelargelanguagemodelserving:Asurveyfromalgorithmstosystems.\narXivpreprintarXiv:2312.\n15234,2023.\n[29]LinglingXu,HaoranXie,Si-ZhaoJoeQin,XiaohuiTao,andFuLeeWang.\nParameter-efficientfine-tuningmethodsforpretrainedlanguagemodels:Acriticalreviewandassessment.\narXivpreprintarXiv:2312.\n12148,2023.\n[30]XunyuZhu,JianLi,YongLiu,CanMa,andWeipingWang.\nAsurveyonmodelcompressionforlargelanguagemodels.\narXivpreprintarXiv:2308.\n07633,2023.\n[31]CanwenXuandJulianMcAuley.\nAsurveyonmodelcompressionandaccelerationforpretrainedlanguagemodels.\nInProceedingsoftheAAAIConferenceonArtificialIntelligence,volume37,pages10566–10575,2023.\n[32]WenxiaoWang,WeiChen,YicongLuo,YongliuLong,ZhengkaiLin,LiyeZhang,BinbinLin,DengCai,andXiaofeiHe.\nModelcompressionandefficientinferenceforlargelanguagemodels:Asurvey.\narXivpreprintarXiv:2402.\n09748,2024.\n[33]SeungcheolPark,JaehyeonChoi,SojinLee,andUKang.\nAcomprehensivesurveyofcompressionalgorithmsforlanguagemodels.\narXivpreprintarXiv:2401.\n15347,2024.\n[34]YupengChang,XuWang,JindongWang,YuanWu,LinyiYang,KaijieZhu,HaoChen,XiaoyuanYi,CunxiangWang,YidongWang,etal.\nAsurveyonevaluationoflargelanguagemodels.\nACMTransactionsonIntelligentSystemsandTechnology,2023.\n[35]ZishanGuo,RenrenJin,ChuangLiu,YufeiHuang,DanShi,LinhaoYu,YanLiu,JiaxuanLi,BojianXiong,DeyiXiong,etal.\nEvaluatinglargelanguagemodels:Acomprehensivesurvey.\narXivpreprintarXiv:2310.\n19736,2023.\n[36]JingfengYang,HongyeJin,RuixiangTang,XiaotianHan,QizhangFeng,HaomingJiang,BingYin,andXiaHu.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[111]YilunKong,JingqingRuan,YihongChen,BinZhang,TianpengBao,ShiweiShi,GuoqingDu,XiaoruHu,HangyuMao,ZiyueLi,etal.\nTptu-v2:Boostingtaskplanningandtoolusageoflargelanguagemodel-basedagentsinreal-worldsystems.\narXivpreprintarXiv:2311.\n11315,2023.\n[112]SiruiHong,XiawuZheng,JonathanChen,YuhengCheng,JinlinWang,CeyaoZhang,ZiliWang,StevenKaShingYau,ZijuanLin,LiyangZhou,etal.\nMetagpt:Metaprogrammingformulti-agentcollaborativeframework.\narXivpreprintarXiv:2308.\n00352,2023.\n[113]YiYang,YixuanTang,andKarYanTam.\nInvestlm:Alargelanguagemodelforinvestmentusingfinancialdomaininstructiontuning.\narXivpreprintarXiv:2309.\n13064,2023.\n[114]KechiZhang,JiaLi,GeLi,XianjieShi,andZhiJin.\nCodeagent:Enhancingcodegenerationwithtool-integratedagentsystemsforreal-worldrepo-levelcodingchallenges.\narXivpreprintarXiv:2401.\n07339,2024.\n[115]LiYunxiang,LiZihan,ZhangKai,DanRuilong,andZhangYou.\nChatdoctor:Amedicalchatmodelfine-tunedonllamamodelusingmedicaldomainknowledge.\narXivpreprintarXiv:2303.\n14070,2023.\n[116]DachengLi,RulinShao,AnzeXie,YingSheng,LianminZheng,JosephGonzalez,IonStoica,XuezheMa,andHaoZhang.\nHowlongcancontextlengthofopen-sourcellmstrulypromise?\nInNeurIPS2023WorkshoponInstructionTuningandInstructionFollowing,2023.\n[117]ZihengHuang,SebastianGutierrez,HemanthKamana,andStephenMacNeil.\nMemorysandbox:Transparentandinteractivememorymanagementforconversationalagents.\nInAdjunctProceedingsofthe36thAnnualACMSymposiumonUserInterfaceSoftwareandTechnology,pages1–3,2023.\n[118]ArkaPal,DeepKarkhanis,ManleyRoberts,SamuelDooley,ArvindSundararajan,andSiddarthaNaidu.\nGiraffe:Adventuresinexpandingcontextlengthsinllms.\narXivpreprintarXiv:2308.\n10882,2023.\n[119]SzymonTworkowski,KonradStaniszewski,MikołajPacek,YuhuaiWu,HenrykMichalewski,andPiotrMiło´s.\nFocusedtransformer:Contrastivetrainingforcontextscaling,2023.\n[120]NelsonFLiu,KevinLin,JohnHewitt,AshwinParanjape,MicheleBevilacqua,FabioPetroni,andPercyLiang.\nLostinthemiddle:Howlanguagemodelsuselongcontexts.\narXivpreprintarXiv:2307.\n03172,2023.\n[121]PeterJDenning.\nThelocalityprinciple.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[120]NelsonFLiu,KevinLin,JohnHewitt,AshwinParanjape,MicheleBevilacqua,FabioPetroni,andPercyLiang.\nLostinthemiddle:Howlanguagemodelsuselongcontexts.\narXivpreprintarXiv:2307.\n03172,2023.\n[121]PeterJDenning.\nThelocalityprinciple.\nCommunicationsoftheACM,48(7):19–24,2005.\n35[122]HermannEbbinghaus.\nMemory:Acontributiontoexperimentalpsychology,trans.\nHARuger&CEBussenius.\nTeachersCollege.\n[rWvH],1885.\n[123]JaapMJMurreandJoeriDros.\nReplicationandanalysisofebbinghaus’forgettingcurve.\nPloSone,10(7):e0120644,2015.\n[124]JeffJohnson,MatthijsDouze,andHervéJégou.\nBillion-scalesimilaritysearchwithgpus.\nIEEETransactionsonBigData,7(3):535–547,2019.\n[125]TimoSchick,JaneDwivedi-Yu,RobertoDessì,RobertaRaileanu,MariaLomeli,LukeZettle-moyer,NicolaCancedda,andThomasScialom.\nToolformer:Languagemodelscanteachthemselvestousetools.\narXivpreprintarXiv:2302.\n04761,2023.\n[126]YujiaQin,ShihaoLiang,YiningYe,KunlunZhu,LanYan,YaxiLu,YankaiLin,XinCong,XiangruTang,BillQian,etal.\nToolllm:Facilitatinglargelanguagemodelstomaster16000+real-worldapis.\narXivpreprintarXiv:2307.\n16789,2023.\n[127]HugoTouvron,ThibautLavril,GautierIzacard,XavierMartinet,Marie-AnneLachaux,Timo-théeLacroix,BaptisteRozière,NamanGoyal,EricHambro,FaisalAzhar,etal.\nLlama:Openandefficientfoundationlanguagemodels.\narXivpreprintarXiv:2302.\n13971,2023.\n[128]ZhibinGou,ZhihongShao,YeyunGong,YujiuYang,MinlieHuang,NanDuan,WeizhuChen,etal.\nTora:Atool-integratedreasoningagentformathematicalproblemsolving.\narXivpreprintarXiv:2309.\n17452,2023.\n[129]HonglinXiong,ShengWang,YitaoZhu,ZihaoZhao,YuxiaoLiu,QianWang,andDinggangShen.\nDoctorglm:Fine-tuningyourchinesedoctorisnotaherculeantask.\narXivpreprintarXiv:2304.\n01097,2023.\n[130]AohanZeng,XiaoLiu,ZhengxiaoDu,ZihanWang,HanyuLai,MingDing,ZhuoyiYang,YifanXu,WendiZheng,XiaoXia,etal.\nGlm-130b:Anopenbilingualpre-trainedmodel.\narXivpreprintarXiv:2210.\n02414,2022.\n[131]EdwardJHu,YelongShen,PhillipWallis,ZeyuanAllen-Zhu,YuanzhiLi,SheanWang,LuWang,andWeizhuChen.\nLora:Low-rankadaptationoflargelanguagemodels.\narXivpreprintarXiv:2106.\n09685,2021.",
      "#memory_survey#Long-contextApplications#memory_survey#Long-contextApplications\nLong-contextApplicationsBeyondtheabovegeneralapplications,inmanyscenarios,LLM-basedagentshavetomakedecisionsbasedonextremelylongprompts.\nInthesescenarios,thelongpromptsareusuallyregardedasthememorycontents,whichplayanimportantroleindrivingagentbehaviors.\n22Inpreviousworks,Huangetal.\n[19]organizeacomprehensivesurveyforlong-contextLLMs,whichprovidesasummaryofevaluationmetricsonlong-contextscenarios.\nMoreover,Shahametal.\n[138]proposeazero-shotbenchmarkforevaluatingagents’understandingoflong-contextnaturallanguages.\nAsforspecificlong-contexttasks,long-contextpassageretrievalisoneoftheimportanttasksforevaluatingthelong-contextabilityofagents.\nItrequiresagentstofindthecorrectparagraphinalongcontextthatcorrespondstothegivenquestionsordescriptions[139].\nLong-contextsummarizationisanotherrepresentativetask.\nItrequestsagentstoformulateaglobalunderstandingofthewholecontext,andsummarizesitaccordingtothedescriptions,wheresomemetricsonmatchingscoreslikeROUGEcanbeutilizedtocomparetheresultswithgroundtruths.\nTheevaluationoflong-contextapplicationsprovidesbroaderapproachestoassessthefunctionofmemoryinagents,focusingonpracticaldownstreamscenarios.\nThecomprehensivebenchmarks[138,140]alsoprovideanobjectiveassessmentfortheabilityoflong-contextunderstanding.\n6.\n2.\n4"
    ],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\n[138]proposeazero-shotbenchmarkforevaluatingagents’understandingoflong-contextnaturallanguages.\nAsforspecificlong-contexttasks,long-contextpassageretrievalisoneoftheimportanttasksforevaluatingthelong-contextabilityofagents.\nItrequiresagentstofindthecorrectparagraphinalongcontextthatcorrespondstothegivenquestionsordescriptions[139].\nLong-contextsummarizationisanotherrepresentativetask.\nItrequestsagentstoformulateaglobalunderstandingofthewholecontext,andsummarizesitaccordingtothedescriptions,wheresomemetricsonmatchingscoreslikeROUGEcanbeutilizedtocomparetheresultswithgroundtruths.\nTheevaluationoflong-contextapplicationsprovidesbroaderapproachestoassessthefunctionofmemoryinagents,focusingonpracticaldownstreamscenarios.\nThecomprehensivebenchmarks[138,140]alsoprovideanobjectiveassessmentfortheabilityoflong-contextunderstanding.\n6.\n2.\n4OtherTasksInadditiontotheabovethreetypesofmajortasksforindirectevaluation,therearealsosomeothermetricsingeneraltasksthatcanrevealtheeffectivenessofthememorymodule.\nSuccessratereferstotheproportionoftasksthatagentscansuccessfullysolve.\nForYaoetal.\n[104],Shinnetal.\n[5]andZhaoetal.\n[82],theyassesshowmanyspacialtaskscanbecorrectlycompletedthroughreasoningandmemoryinAlfWorld[141].\nInZhuetal.\n[93],theyevaluatethesuccessrateofproducingdifferentitemsinMinecrafttoshowtheeffectofmemory.\nMoreover,Shinnetal.\n[5]measurethesuccessrateofpassedproblemsbygeneratedcodes,andZhengetal.\n[91]calculatethesuccessrateofcomputercontrolandaccuracyofelementselectiontoshowthefunctionoftrajectory-as-exemplarmemory.\nExplorationdegreetypicallyappearsinexploratorygames,whichreflectstheextentthatagentscanexploretheenvironment.\nForexample,Wangetal.\n[99]comparethenumbersofdistinctitemsexploredinMinecrafttoreflecttheskilllearninginmemory.\nInfact,nearlyallthememory-equippedagentscanevaluatetheeffectofmemorybyablationstudies,comparingtheperformancebetweenwith/withoutmemorymodules.\nTheevaluationonspecificscenarioscanbetterreflectthesignificanceofmemoryforthedownstreamapplicationspractically.\n6.",
      "#memory_survey#HowtoEvaluatetheMemoryinLLM-basedAgent#memory_survey#HowtoEvaluatetheMemoryinLLM-basedAgent\nHowtoEvaluatetheMemoryinLLM-basedAgentHowtoeffectivelyevaluatethememorymoduleremainsanopenproblem,wherediverseevaluationstrategieshavebeenproposedinpreviousworksaccordingtodifferentapplications.\nToclearlyshowthecommonideasofdifferentevaluationmethods,inthissection,wesummarizeageneralframework,whichincludestwobroadevaluationstrategies(seeFigure5foranoverview),thatis,(1)directevaluation,whichindependentlymeasuresthecapabilityofthememorymodule.\n(2)indirectevaluation,whichevaluatesthememorymoduleviaend-to-endagenttasks.\nIfthetaskscanbeeffectivelyaccomplished,thememorymoduleisdemonstratedtobeuseful.\n6.\n1",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nInfact,nearlyallthememory-equippedagentscanevaluatetheeffectofmemorybyablationstudies,comparingtheperformancebetweenwith/withoutmemorymodules.\nTheevaluationonspecificscenarioscanbetterreflectthesignificanceofmemoryforthedownstreamapplicationspractically.\n6.\n3DiscussionsComparedwithdirectevaluation,indirectevaluationviaspecifictaskscanbeeasiertoconduct,sincetherearealreadymanypublicbenchmarks.\nHowever,theperformanceontaskscanbeattributedtovariousfactors,andmemoryisonlyoneofthem,whichmaymaketheevaluationresultsbiased.\nBydirectevaluation,theeffectivenessofthememorymodulecanbeindependentlyevaluated,whichimprovesthereliabilityoftheevaluationresults.\nHowever,toourknowledge,therearenoopen-sourcedbenchmarkstailoredforthememorymodulesinLLM-basedagents.\n7Memory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1Role-playingandSocialSimulationRole-playingrepresentsaclassicapplicationofLLM-basedagents,wherememoryplaysacrucialroleinsidetheagents.\nItendowsroleswithdistinctcharacteristics,differentiatingthemfromoneanother.\nManypreviousstudieshaveexploredmethodsforconstructingrolememories[105,143,145–147].\nShaoetal.\n[105]constructthememoryofrolesbyexperienceuploading,whichutilizesSFTtoinjectmemoryintomodelparameters.\nLietal.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nThememoryofanagentisderivedfromthehistoricalbehaviorstoachieveatarget,forexample,thecollectionofrelevantpaperswhenresearchingonaspecifictopic.\nMemoChat[94]aimstochatwithhumans,wherethememoryoftheagentisderivedbasedontheconversationhistoryofadialoguesession.\nTiM[97]aimstoenhancetheagent’sreasoningcapabilitybyself-generatingmultiplethoughtsafteraccomplishingatask,whichisusedasthememorytoprovidemoregeneralizableinformation.\nVoyager[99]focusesonbuildinggameagentsbasedonMinecraft,wherethememorycontainsexecutablecodesofpreliminaryandbasicactionstoaccomplishatask.\nItshouldbenotedthattheinside-trialinformationnotonlyincludesagent-environmentinteractions,butalsocontainsinteractioncontexts,suchastimeandlocationinformation.\n12Discussion.\nTheinside-trialinformationisthemostobviousandintuitivesourcethatshouldbeleveragedtoconstructtheagent’smemorysinceitishighlyrelevanttothecurrenttaskthattheagenthastoaccomplish.\nHowever,relyingsolelyoninside-trialinformationmaypreventtheagentfromaccumulatingvaluableknowledgefromvarioustasksandlearningmoregeneralizableinformation.\nThus,manystudiesalsoexplorehowtoeffectivelyutilizetheinformationacrossdifferenttaskstobuildthememorymodule,whichisdetailedinthefollowingsections.\n5.\n1.\n2Cross-trialInformationForLLM-basedagents,theinformationaccumulatedacrossmultipletrialsintheenvironmentisalsoacrucialpartofthememory,typicallyincludingsuccessfulandfailedactionsandtheirinsights,suchasfailurereasons,commonactionpatternstosucceed,andsoon.\nRepresentativeStudies.\nOneofthemostprominentstudiesisReflexion[5],whichproposesverbalreinforcementlearningforLLM-basedagents.\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nFormally,theaveragetimeconsumptionofeachtypeofoperationcanberepresentedas∆time=1MM(cid:88)i=1i−tstarttendi,whereMrepresentsthenumberoftheseoperations,tendimeanstheendtimeofthei-thoperation,andtstartindicatesthestarttimeofthatoperation.\nAsforthecomputationoverhead,itcanbeevaluatedibythepeakGPUmemoryallocation.\nInpreviousworks,Tacketal.\n[106]utilizethepeakmemoryallocationandadaptationtimetoassesstheefficiencyofmemoryoperations.\nObjectiveevaluationoffersnumericstrategiestocomparedifferentmethodsofmemory,whichisimportanttobenchmarkthisfieldandpromotefuturedevelopments.\n6.\n2IndirectEvaluationBesidestheabovemethodthatdirectlyevaluatesthememorymodule,evaluatingviataskcompletionisalsoapopularevaluationstrategy.\nTheintuitionbehindthistypeofapproachesisthatiftheagentcansuccessfullycompleteataskthathighlydependsonmemory,itsuggeststhatthedesignedmemorymoduleiseffective.\nInthefollowingparts,wepresentseveralrepresentativetasksthatareleveragedtoevaluatethememorymoduleinindirectways.\n6.\n2.\n1ConversationEngaginginconversationswithhumansisoneofthemostimportantapplicationsofagents,wherememoryplaysacrucialroleinthisprocess.\nBystoringcontextinformationinmemory,theagentsallowuserstoexperiencepersonalizedconversations,thusimprovingusers’satisfaction.\nTherefore,whenotherpartsoftheagentsaredetermined,theperformanceoftheconversationtaskscanreflecttheeffectivenessofdifferentmemorymodules.\nInthecontextofconversation,consistencyandengagementaretwocommonlyusedmethodstoevaluatetheeffectivenessoftheagents’memory.\nConsistencyreferstohowtheresponsefromagentsisconsistentwiththecontextbecausedramaticchangesshouldbeavoidedduringtheconversation.\nForexample,Luetal.\n[94]evaluatetheconsistencyofagentsoninteractivedialogues,usingGPT-4toscoreontheresponsesfromagents.\nEngagementreferstohowtheuserisengagedtocontinuetheconversation.\nItreflectsthequalityandattractionofagents’responses,aswellastheabilityofagentstocraftthepersonasforcurrentconversations.\nForexample,Leeetal."
    ],
    [
      "#memory_survey#Conversation#memory_survey#Conversation\nConversationEngaginginconversationswithhumansisoneofthemostimportantapplicationsofagents,wherememoryplaysacrucialroleinthisprocess.\nBystoringcontextinformationinmemory,theagentsallowuserstoexperiencepersonalizedconversations,thusimprovingusers’satisfaction.\nTherefore,whenotherpartsoftheagentsaredetermined,theperformanceoftheconversationtaskscanreflecttheeffectivenessofdifferentmemorymodules.\nInthecontextofconversation,consistencyandengagementaretwocommonlyusedmethodstoevaluatetheeffectivenessoftheagents’memory.\nConsistencyreferstohowtheresponsefromagentsisconsistentwiththecontextbecausedramaticchangesshouldbeavoidedduringtheconversation.\nForexample,Luetal.\n[94]evaluatetheconsistencyofagentsoninteractivedialogues,usingGPT-4toscoreontheresponsesfromagents.\nEngagementreferstohowtheuserisengagedtocontinuetheconversation.\nItreflectsthequalityandattractionofagents’responses,aswellastheabilityofagentstocraftthepersonasforcurrentconversations.\nForexample,Leeetal.\n[101]assesstheengagingnessofresponsesbySCE-pscore,andPackeretal.\n[100]utilizeCSIMscoretoevaluatethememoryeffectonincreasingengagementofusers.\n6.\n2.\n2",
      "#memory_survey#PerspectiveofAgentApplications#memory_survey#PerspectiveofAgentApplications\nPerspectiveofAgentApplicationsInmanyapplications,memoryisanindispensablecomponentoftheagent.\nForexample,inaconver-sationalagent,thememorystoresinformationabouthistoricalconversations,whichisnecessaryfortheagenttogeneratethenextresponse.\nWithoutmemory,theagentdoesnotknowthecontext,andcannotcontinuetheconversation[94].\nInasimulationagent,memoryisofgreatimportancetomaketheagentconsistentlyfollowtheroleprofiles.\nWithoutmemory,theagentmayeasilystepoutoftheroleduringthesimulationprocess[95].\nBothoftheaboveexamplesshowthatthememoryisnotanoptionalcomponent,butisnecessaryfortheagentstoaccomplishgiventasks.\nIntheabovethreeperspectives,thefirstonerevealsthatthememorybuildsthecognitivebasisoftheagent.\nThesecondandthirdonesshowthatthememoryisnecessaryfortheagent’sevolvingprinciplesandapplications,whichprovideinsightsfordesigningagentswithmemorymechanisms.\n5",
      "#memory_survey#MemoryinLLM-basedMulti-agentApplications#memory_survey#MemoryinLLM-basedMulti-agentApplications\nMemoryinLLM-basedMulti-agentApplicationsTheexplorationofmemorymechanismswithinLLMshasburgeonedintothedynamicdomainofmulti-agentsystems(MAS),markingsignificantadvancementsintherealmsofsynchronization,communication,andthemanagementofinformationasymmetry.\nOnepivotalaspectthatemergesinthecooperativescenariosismemorysynchronizationamongagents.\nThisprocessisfundamentalforestablishingaunifiedknowledgebase,ensuringconsistencyindecision-makingacrossdifferentagents.\nForexample,Chenetal.\n[170]emphasizethesignificanceofintegratingsynchronizedmemorymodulesformulti-robotcollaboration.\nAnotherimportantaspectisthecommunicationamongagents,whichheavilyreliesonmemoryformaintainingcontextandinterpretingmessages.\nForexample,Mandietal.\n[171]illustratememory-drivencommunicationframeworksthatfosteracommonunderstandingamongagents.\nInadditiontocooperativescenarios,somestudiesalsofocusoncompetitivescenarios,andtheinformationasymmetrybecomesacrucialissue[172].\nLookingahead,theadvancementofmemoryinLLM-basedMASispoisedattheconfluenceoftechnologicalinnovationandstrategicapplication.\nItbeckonstheexplorationofnovelmemory27modulesthatcanfurtherenhanceagentsynchronization,enablemoreeffectivecommunication,andprovidestrategicadvantagesininformation-richenvironments.\nThedevelopmentofsuchmemorymodelswouldnotonlynecessitateaddressingthecurrentchallengesofmemoryintegrationandman-agement,butalsoexploretheuntappedpotentialsofmemoryinfacilitatingmorerobust,intelligent,andadaptableMAS.\nAsevidencedbypioneeringresearch,theevolvinglandscapeofLLM-basedMASsetsapromisingstageforfutureinnovationsinmemoryutilizationandmanagement.\nThisexplorationisexpectedtounravelnewdimensionsofmemoryintegration,pushingtheboundariesofwhatiscurrentlyachievableandsettingnewbenchmarksintherealmofMAS.\n8.\n3",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThememorymoduleisanimportantcomponentforsuchapplications,whichhelpstoaccuratelysimulatehumandynamicbehaviors.\nInpreviousstudies,Kaiyaetal.\n[148]proposeaSummarize-and-Forgetmemorymechanismforbetterself-monitoringinsocialscenarios.\nGaoetal.\n[2]focusonsocialnetworksimulationsystems.\nEachagentinthesystemhasamemorypool,whichconsistsofdiverseusermessagesfromonlineplatformstoidentifytheuser.\nLietal.\n[163]maintainconversationcontexts,encompassingtheeconomicenvironmentandagentdecisionsfrompreviousmonths,inordertosimulatetheimpactofbroadmacroeconomictrendsonagents’decision-makingandtomaketheagentsgraspmarketdynamics.\nLietal.\n[109]simulatethejob-seekingscenarioinhumansociety,wherethememoryofagentsincludesprofilesandgoalsinitiallyandisfurtherenrichedwithotherinformation,likedialoguesandpersonalreflections.\nHuaetal.\n[150]simulatethedecisionsandconsequencesoftheparticipatingcountriesinthewars,wheretheconversationsofagentsarecontinuouslymaintainedintomemory.\nThereareseveralinsightsindesigninganagent’smemoryforrole-playandsocialsimulation.\nFirst,thememoryshouldbeconsistentwiththeroles’characteristics,whichcanbeusedtoidentifyeachroleanddistinguishitfromtheothers.\nThisiscrucialforimprovingtherealismofrole-playandthediversityofsocialsimulation.\nSecond,thememoryshouldappropriatelyinfluencethesubsequent24actionsoftheagenttoensuretheconsistencyandrationalityofitsbehaviors.\nAdditionally,forhumanoidagents,theirmemorymechanismsshouldalignwiththefeaturesofhumanmemory,suchasforgettingandlong/short-termmemory,whichshouldrefertothetheoriesofcognitivepsychology.\n7.\n2PersonalAssistantLLM-basedagentsarewell-suitedforcreatingpersonalassistants,suchasagentscapableofengaginginlong-termconversationswithusers[94,101,153],aswellasthosetaskedwithautomaticallyseekinginformation[164].\nTheseagentsoftenneedtomemorizepreviousdialoguestomaintaintheconsistency,andremembercriticalstylesandeventstogeneratemorepersonalizedandrelevantresponses.\nLuetal.",
      "#memory_survey#Memory-assistedAgent-EnvironmentInteraction#memory_survey#Memory-assistedAgent-EnvironmentInteraction\nMemory-assistedAgent-EnvironmentInteractionAsmentionedatthebeginningofSection3,therearethreekeyphasesintheagent-environmentinteractionprocess.\nTheagentmemorymoduleimplementsthesephasesthroughthreeoperationsincludingmemorywriting,memorymanagement,andmemoryreading.\nMemoryWriting.\nThisoperationaimstoprojecttherawobservationsintotheactuallystoredmemorycontents,whicharemoreinformative[7]andconcise[6].\nItcorrespondstothefirstphaseoftheagent-environmentinteractionprocess.\nGivenataskTk,iftheagenttakesanactionaktatstept,andtheenvironmentprovidesanobservationokt,thenthememorywritingoperationcanbeformallyrepresentedas:mkt=W({akt,okt}),whereWisaprojectingfunction.\nmktisthefinallystoredmemorycontents,whichcanbeeithernaturallanguagesorparametricrepresentations.\nIntheabovetoyexample,fortask(A),theagentissupposedtoremembertheflightarrangementandthedecisionofattractionsafter[step2].\nFortask(B),theagentshouldmemorizethefactthatAlicehopestowatchmoviesat9:00PM,after[step1].\nMemoryManagement.\nThisoperationaimstoprocessthestoredmemoryinformationtomakeitmoreeffective,forexample,summarizinghigh-levelconceptstomaketheagentmoregeneral-1Foreachtask,therecanbemultipletrialsforexploringthefinalsolution,andallofthemcanbeincorporatedintothememory.\n9izable[6],mergingsimilarinformationtoreduceredundancy[7],andforgettingunimportantorirrelevantinformationtoremoveitsnegativeinfluence.\nThisoperationcorrespondstothesecondphaseoftheagent-environmentinteractionprocess.\nLetMkt−1bethememorycontentsfortaskkbeforestept,andsupposemktisthestoredinformationatsteptbasedontheabovememorywritingoperation,then,thememorymanagementoperationcanberepresentedby:Mkt=P(Mkt−1,mkt),wherePisafunctionthatiterativelyprocessesthestoredmemoryinformation.\nForthenarrowmemorydefinition,theiterationonlyhappenswithinthesametrial,andthememoryisemptiedwhenthetrialisended.\nForthebroadmemorydefinition,theiterationhappensacrossdifferenttrialsoreventasks,aswellastheintegrationsofexternalknowledge."
    ],
    [
      "#memory_survey#Memory-enhancedAgentApplications#memory_survey#Memory-enhancedAgentApplications\nMemory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain.",
      "#memory_survey#ExternalKnowledge#memory_survey#ExternalKnowledge\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain.\nItfine-tunesanacquisitionprocesstoretrieveexternalknowledgefromWikipediaandmedicaldatabases.\nDiscussion.\nTheexternalknowledgecanbeobtainedfrombothprivateandpublicsources.\nItprovidesLLM-basedagentswithmuchknowledgebeyondtheirinternalenvironment,whichmightbedifficultorevenimpossiblefortheagenttoacquirebyagent-environmentinteractions.",
      "#memory_survey#ExpertSysteminSpecificDomains#memory_survey#ExpertSysteminSpecificDomains\nExpertSysteminSpecificDomainsMedicineDomain.\nInthefieldofmedicine,mostofthepreviousworksempowerLLM-basedagentswithexternalknowledgeintheirmemory[107,129,132,151,115].\nWangetal.\n[107]fine-tuneLLaMA[127]withmedicalknowledgegraphCMeKG[165]inQAform,inordertoenhancetheirmedicaldomainknowledge.\nXiongetal.\n[129]adoptLoRA[131]toefficientlyfine-tuneonfoundationmodelsforhealthcare.\nWangetal.\n[151]empowerLLM-basedagentstoacquiretext-basedexternalknowledgeasreasoningreference.\nBesides,Shietal.\n[152]buildmemoryuponthemostrelevantsuccessfulcasesfrompastexperiences,andusesimilaritymetricfortheretrievalofrelevantquestionsinthemedicinedomain.\nFinanceDomain.\nSomepreviousworksalsoapplyLLM-basedagentsinthefinancedomain,whosememorycanstorefinancialknowledge[113],marketinformation[154,156],andsuccessfulexperi-ences[157,155].\nYangetal.\n[113]constructfinancialinvestmentdatasettofine-tuneLLaMA[127]toempowerknowledgeoninvestment.\nLietal.\n[154]designalayered-memorystructuretostoredifferenttypesofmarketinginformation.\nWangetal.\n[155]recordtheongoinginteractionlikeexchangesandinformationtoensureconsistentresponse,andrecordprioroutputsasexperiencesforretrievingrelevantexamplestoprovideadiverselearningcontextforagents.\nKoaetal.\n[157]storepastpricemovementandexplanations,andgeneratereflectionsonprevioustrials.\nYuetal.\n[156]adoptalayeredmemorymechanismtoprovideabundantinformationforreasoning.\nScience.\nInthedomainofscience,someexistingworksdesignLLM-basedagentswithalargeamountofknowledgeinmemorytosolveproblems[158,160,162].\nChenetal.\n[158]includemoleculedatabaseandonlineliteratureasexternalknowledgeformemoryinLLM-basedagents,andretrievethemwhentheyneedrelatedinformation.\nZhaoetal.\n[160]andChenetal.\n[162]empowerdomainknowledgebyfine-tuninginChemistryandstructuredmaterialsrespectively.\nTobuildanexpertsystembasedonagentsinaspecificverticaldomain,itisnecessarytoretainthedomain-specificknowledgeintheirmemory.\nHowever,thereareseveralchallenges.",
      "#memory_survey#MemoryinParametricForm#memory_survey#MemoryinParametricForm\nMemoryinParametricFormAnalternativetypeofapproachesistorepresentmemoryinparametricform.\nTheydonottakeuptheextralengthofcontextinprompts,sotheyarenotconstrainedbythelengthlimitationsofLLMcontext.\nHowever,theparametricmemoryformisstillunder-researched,andwecategorizepreviousworksintotwotypes:fine-tuningmethodsandmemoryeditingmethods.\nFine-tuningMethods.\nIntegratingexternalknowledgeintothememoryofagentsisbeneficialforenrichingdomain-specificknowledgeontopofitsgeneralknowledge.\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters."
    ],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.\nDuringmemoryreading,matchingscoresarecalculatedforeachmemoryentry,andthetop-Kentrieswillbeusedforthedecision-makingprocessofagents.\n15Inexistingstudies,mostagentsutilizeretrievalmethodstoprocessthememoryinformation.\nForexample,Parketal.\n[83]firstcalculatetherelevancebetweenthecurrentcontextandmemoryentriesbycosinesimilarity,andobtaintheimportanceandrecencyaccordingtoauxiliaryinformation.\nMemoryBank[6]employsadual-towerdenseretrievalmodeltofindrelatedinformationfrompastconversations.\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage.\nItutilizesLocality-SensitiveHashing(LSH)toretrievetupleswithrelativeentriesinthedatabasetoprovidemoreinformation.\nInaddition,ChatDB[96]designstoutilizesymbolicmemory,andproposestogenerateSQLstatementstoretrievefromdatabasetoobtainstoredinformation.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTiM[97]aimstoenhancetheagent’sreasoningcapabilitybyself-generatingmultiplethoughtsafteraccomplishingatask,whichisusedasthememorytoprovidemoregeneralizableinformation.\nVoyager[99]focusesonbuildinggameagentsbasedonMinecraft,wherethememorycontainsexecutablecodesofpreliminaryandbasicactionstoaccomplishatask.\nItshouldbenotedthattheinside-trialinformationnotonlyincludesagent-environmentinteractions,butalsocontainsinteractioncontexts,suchastimeandlocationinformation.\n12Discussion.\nTheinside-trialinformationisthemostobviousandintuitivesourcethatshouldbeleveragedtoconstructtheagent’smemorysinceitishighlyrelevanttothecurrenttaskthattheagenthastoaccomplish.\nHowever,relyingsolelyoninside-trialinformationmaypreventtheagentfromaccumulatingvaluableknowledgefromvarioustasksandlearningmoregeneralizableinformation.\nThus,manystudiesalsoexplorehowtoeffectivelyutilizetheinformationacrossdifferenttaskstobuildthememorymodule,whichisdetailedinthefollowingsections.\n5.\n1.\n2Cross-trialInformationForLLM-basedagents,theinformationaccumulatedacrossmultipletrialsintheenvironmentisalsoacrucialpartofthememory,typicallyincludingsuccessfulandfailedactionsandtheirinsights,suchasfailurereasons,commonactionpatternstosucceed,andsoon.\nRepresentativeStudies.\nOneofthemostprominentstudiesisReflexion[5],whichproposesverbalreinforcementlearningforLLM-basedagents.\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.",
      "#memory_survey#ExternalKnowledge#memory_survey#ExternalKnowledge\nItshouldbenotedthattheinside-trialinformationnotonlyincludesagent-environmentinteractions,butalsocontainsinteractioncontexts,suchastimeandlocationinformation.\n12Discussion.\nTheinside-trialinformationisthemostobviousandintuitivesourcethatshouldbeleveragedtoconstructtheagent’smemorysinceitishighlyrelevanttothecurrenttaskthattheagenthastoaccomplish.\nHowever,relyingsolelyoninside-trialinformationmaypreventtheagentfromaccumulatingvaluableknowledgefromvarioustasksandlearningmoregeneralizableinformation.\nThus,manystudiesalsoexplorehowtoeffectivelyutilizetheinformationacrossdifferenttaskstobuildthememorymodule,whichisdetailedinthefollowingsections.\n5.\n1.\n2Cross-trialInformationForLLM-basedagents,theinformationaccumulatedacrossmultipletrialsintheenvironmentisalsoacrucialpartofthememory,typicallyincludingsuccessfulandfailedactionsandtheirinsights,suchasfailurereasons,commonactionpatternstosucceed,andsoon.\nRepresentativeStudies.\nOneofthemostprominentstudiesisReflexion[5],whichproposesverbalreinforcementlearningforLLM-basedagents.\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.\nDuringmemoryreading,matchingscoresarecalculatedforeachmemoryentry,andthetop-Kentrieswillbeusedforthedecision-makingprocessofagents.\n15Inexistingstudies,mostagentsutilizeretrievalmethodstoprocessthememoryinformation.\nForexample,Parketal.\n[83]firstcalculatetherelevancebetweenthecurrentcontextandmemoryentriesbycosinesimilarity,andobtaintheimportanceandrecencyaccordingtoauxiliaryinformation.\nMemoryBank[6]employsadual-towerdenseretrievalmodeltofindrelatedinformationfrompastconversations.\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage."
    ],
    [
      "#memory_survey#MemoryForms#memory_survey#MemoryForms\nMemoryFormsIngeneral,therearetwoformstorepresentthememorycontents:textualformandparametricform.\nIntextualform,theinformationisexplicitlyretainedandrecalledbynaturallanguages.\nInparametric3https://www.\nwikipedia.\norg13Table2:Summarizationofthememoryforms.\nWeuse✓and×tolabelwhetherornotthecorrespondingmemoryformisadoptedinthemodel.\nModelsMemoryBank[6]RET-LLM[7]ChatDB[96]TiM[97]SCM[98]Voyager[99]MemGPT[100]MemoChat[94]MPC[101]GenerativeAgents[83]RecMind[102]Retroformer[103]ExpeL[82]Synapse[91]GITM[93]ReAct[104]Reflexion[5]RecAgent[95]Character-LLM[105]MAC[106]Huatuo[107]ChatDev[1]InteRecAgent[108]MetaAgents[109]TPTU[110,111]MetaGPT[112]S3[2]InvestLM[113]TextualFormParametricFormCompleteRecentRetrievedExternalFine-tuningEditing××××××××××✓✓✓×✓✓✓×××✓✓××✓✓×✓××××✓×✓××××××××××✓✓×××✓×××××✓✓✓✓✓✓✓✓✓✓××✓✓✓××✓××××✓✓××✓××××××××××××✓✓×✓✓✓×××××✓×✓××××××××××××××✓××××××✓×✓××××××✓×××××××××××××××××××✓××××××××form,thememoryinformationisencodedintoparametersandimplicitlyinfluencestheagent’sactions.\nWesummarizepreviousworksonmemoryformswiththeirimplementationsinTable2.\n5.\n2.\n1",
      "#memory_survey#MemoryinParametricForm#memory_survey#MemoryinParametricForm\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.\nAnotherlimitationoffine-tuningliesinthecomputationalcostandtimeconsumption,aswellastherequirementofalargeamountofdata.\nTherefore,mostfine-tuningapproachesareappliedtoofflinescenarios,andcanseldomdealwithonlinescenarios,suchasfine-tuningwithagentobservationsandtrialexperiences.\nDuetothefrequentagent-environmentinteractions,itisunaffordableforthecostofbackpropagationtofine-tuneeverystepoftheonlineanddynamicinteractions.\nMemoryEditingMethods.\nApartfromthefine-tuningapproaches,anothertypeofmethodsforinfusingmemoryintomodelparametersisknowledgeediting[133,134].\nUnlikefine-tuningmethodsthatextractpatternsfromcertaindatasets,knowledgeeditingmethodsspecificallytargetandadjustonlythefactsthatneedtobechanged.\nItensuresthatunrelatedknowledgeremainsunaffected.\nKnowledgeeditingmethodsaremoresuitableforsmall-scalememoryadjustments.\nGenerally,theyhavelowercomputationalcosts,makingthemmoresuitableforonlinescenarios.\nInourexampleoftask(B),Alicealwayswatchesmoviesat9:00PMfromtheagent’smemory,butshemayrecentlychangeherworkandwouldnotbeemptyat9:00PM.\nIfso,therelatedmemory(suchasroutinesat9:00PM)shouldbeedited,whichcanbeimplementedbyknowledgeeditingmethods.\nInpreviousstudies,MAC[106]intendstodesignaneffectiveandefficientmemoryadaptationframeworkforonlinescenarios.\nItutilizesmeta-learningtosubstitutetheoptimizationstep.\nPer-sonalityEdit[135]focusesoneditingthepersonalityofLLMsandagents,whereitchangestheirtraitsbasedontheoriessuchasthebig-fivefactor.\nMEND[134]utilizestheideaofmeta-learningtotrainalightweightmodel,whichiscapableofgeneratingmodificationsformodelparametersofapre-trainedlanguagemodel.\nAPP[136]studieswhetheraddinganewfactleadstocatastrophicforgettingofexistingfacts.\nItfocusesontheimpactofneighborperturbationonmemoryaddition.",
      "#memory_survey#MoreAdvancesinParametricMemory#memory_survey#MoreAdvancesinParametricMemory\nMoreAdvancesinParametricMemoryAtpresent,thememoryofLLM-basedagentsispredominantlyintextualform,especiallyforcontextualknowledgesuchasobservationrecords,trialexperiences,andtextualknowledgedatabases.\nAlthoughtextualmemorypossessestheadvantagesofbeinginterpretableandeasytoexpandandedit,italsoimpliesasacrificeinefficiencycomparedtoparametricmemory.\nEssentially,parametricmemoryboastsahigherinformationdensity,expressingsemanticsthroughcontinuousreal-numbervectorsinalatentspace,whereastextualmemoryemploysacombinationoftokensinadiscretespaceforsemanticexpression.\nThus,parametricmemoryoffersaricherexpressivespace,anditssoftencodingismorerobustcomparedtothehard-codedformoftokensequences.\nAdditionally,parametricmemoryismorestorage-efficient,whereitdoesnotrequiretheexplicitstorageofextensivetexts,similartoaknowledgecompressionprocess.\nAsforthememorymanagement,suchasmergingandreflection,parametricmemorydoesnotnecessarilydesignmanualrulesliketextualmemorydoes,butcanemployoptimizationmethodstolearntheseprocessesimplicitly.\nMoreover,pluggableparametricmemoryissimilartoadigitallifecard,capableofendowingagentswiththerequisitecharacteristics.\nForexample,Huatuo[107]aimstoenhanceagentswithexpertiseinthebiomedicalfieldbyrefiningtheLlama[127]modelonChinesemedicalknowledgebases.\nMAC[106]isdesignedtocreateaparametricmemoryadaptationframeworksuitableforonlinesettings,employingmeta-learningtechniquestoreplacethetraditionaloptimizationphase.\nAlthoughparametricmemoryholdsgreatprospects,itcurrentlyfacesnumerouschallenges.\nForemostamongtheseistheissueofefficiency:howtoeffectivelytransformtextualinformationintoparametersormodificationsofparametersisacriticalquestion.\nPresently,researcherscantransfervastamountsofdomainknowledgeintotheparametersofLLMsbySFT.\nHowever,itistime-consumingandrequiresextensivetextcorpus,makingitunsuitableforsituationalknowledge.\nOneviableapproachistoemploymeta-learningtoletmodelslearntomemorize.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nTherefore,mostfine-tuningapproachesareappliedtoofflinescenarios,andcanseldomdealwithonlinescenarios,suchasfine-tuningwithagentobservationsandtrialexperiences.\nDuetothefrequentagent-environmentinteractions,itisunaffordableforthecostofbackpropagationtofine-tuneeverystepoftheonlineanddynamicinteractions.\nMemoryEditingMethods.\nApartfromthefine-tuningapproaches,anothertypeofmethodsforinfusingmemoryintomodelparametersisknowledgeediting[133,134].\nUnlikefine-tuningmethodsthatextractpatternsfromcertaindatasets,knowledgeeditingmethodsspecificallytargetandadjustonlythefactsthatneedtobechanged.\nItensuresthatunrelatedknowledgeremainsunaffected.\nKnowledgeeditingmethodsaremoresuitableforsmall-scalememoryadjustments.\nGenerally,theyhavelowercomputationalcosts,makingthemmoresuitableforonlinescenarios.\nInourexampleoftask(B),Alicealwayswatchesmoviesat9:00PMfromtheagent’smemory,butshemayrecentlychangeherworkandwouldnotbeemptyat9:00PM.\nIfso,therelatedmemory(suchasroutinesat9:00PM)shouldbeedited,whichcanbeimplementedbyknowledgeeditingmethods.\nInpreviousstudies,MAC[106]intendstodesignaneffectiveandefficientmemoryadaptationframeworkforonlinescenarios.\nItutilizesmeta-learningtosubstitutetheoptimizationstep.\nPer-sonalityEdit[135]focusesoneditingthepersonalityofLLMsandagents,whereitchangestheirtraitsbasedontheoriessuchasthebig-fivefactor.\nMEND[134]utilizestheideaofmeta-learningtotrainalightweightmodel,whichiscapableofgeneratingmodificationsformodelparametersofapre-trainedlanguagemodel.\nAPP[136]studieswhetheraddinganewfactleadstocatastrophicforgettingofexistingfacts.\nItfocusesontheimpactofneighborperturbationonmemoryaddition.\nMoreover,KnowledgeEditor[133]trainsahyper-networktopredictthemodificationofmodelpa-rameterswheninjectingmemorybasedonalearning-to-updateproblemformulation.\nWangetal.\n[137]proposeanewoptimizationtargettochangethepoisoningknowledgeofLLM,andmaintainthegeneralperformanceatthesametime.",
      "#memory_survey#MoreAdvancesinParametricMemory#memory_survey#MoreAdvancesinParametricMemory\nPresently,researcherscantransfervastamountsofdomainknowledgeintotheparametersofLLMsbySFT.\nHowever,itistime-consumingandrequiresextensivetextcorpus,makingitunsuitableforsituationalknowledge.\nOneviableapproachistoemploymeta-learningtoletmodelslearntomemorize.\nForexample,MEND[134]leveragesthemethodofmeta-learningtotrainacompactmodelthathastheabilitytoproduceadjustmentsfortheparametersofapre-trainedlanguagemodel.\nMoreover,thelackofinterpretabilityassociatedwithparametricmemorycanbeahindrance,especiallyindomainsrequiringhighlevelsoftrust,suchasmedicine.\nTherefore,enhancingthecredibilityandinterpretabilityofparametricmemoryisanurgentissuethatneedstobeaddressed.\n8.\n2",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.\nAnotherlimitationoffine-tuningliesinthecomputationalcostandtimeconsumption,aswellastherequirementofalargeamountofdata.\nTherefore,mostfine-tuningapproachesareappliedtoofflinescenarios,andcanseldomdealwithonlinescenarios,suchasfine-tuningwithagentobservationsandtrialexperiences.\nDuetothefrequentagent-environmentinteractions,itisunaffordableforthecostofbackpropagationtofine-tuneeverystepoftheonlineanddynamicinteractions.\nMemoryEditingMethods.\nApartfromthefine-tuningapproaches,anothertypeofmethodsforinfusingmemoryintomodelparametersisknowledgeediting[133,134].\nUnlikefine-tuningmethodsthatextractpatternsfromcertaindatasets,knowledgeeditingmethodsspecificallytargetandadjustonlythefactsthatneedtobechanged.\nItensuresthatunrelatedknowledgeremainsunaffected.\nKnowledgeeditingmethodsaremoresuitableforsmall-scalememoryadjustments.\nGenerally,theyhavelowercomputationalcosts,makingthemmoresuitableforonlinescenarios.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain.\nItfine-tunesanacquisitionprocesstoretrieveexternalknowledgefromWikipediaandmedicaldatabases.\nDiscussion.\nTheexternalknowledgecanbeobtainedfrombothprivateandpublicsources.\nItprovidesLLM-basedagentswithmuchknowledgebeyondtheirinternalenvironment,whichmightbedifficultorevenimpossiblefortheagenttoacquirebyagent-environmentinteractions.\nMoreover,mostexternalknowledgecanbeacquiredbyaccessingtheAPIsofvarioustoolsdynamicallyinrealtimeaccordingtothetaskneeds,thusmitigatingtheproblemofoutdatedknowledge.\nIntegratingexternalknowledgeintothememoryofLLM-basedagentssignificantlyexpandstheirknowledgeboundaries,providingthemwithunlimited,up-to-date,andwell-foundedknowledgefordecision-making.\n5.\n2MemoryFormsIngeneral,therearetwoformstorepresentthememorycontents:textualformandparametricform.\nIntextualform,theinformationisexplicitlyretainedandrecalledbynaturallanguages.\nInparametric3https://www.\nwikipedia.\norg13Table2:Summarizationofthememoryforms.\nWeuse✓and×tolabelwhetherornotthecorrespondingmemoryformisadoptedinthemodel.\nModelsMemoryBank[6]RET-LLM[7]ChatDB[96]TiM[97]SCM[98]Voyager[99]MemGPT[100]MemoChat[94]MPC[101]GenerativeAgents[83]RecMind[102]Retroformer[103]ExpeL[82]Synapse[91]GITM[93]ReAct[104]Reflexion[5]RecAgent[95]Character-LLM[105]MAC[106]Huatuo[107]ChatDev[1]InteRecAgent[108]MetaAgents[109]TPTU[110,111]MetaGPT[112]S3[2]InvestLM[113]TextualFormParametricFormCompleteRecentRetrievedExternalFine-tuningEditing××××××××××✓✓✓×✓✓✓×××✓✓××✓✓×✓××××✓×✓××××××××××✓✓×××✓×××××✓✓✓✓✓✓✓✓✓✓××✓✓✓××✓××××✓✓××✓××××××××××××✓✓×✓✓✓×××××✓×✓××××××××××××××✓××××××✓×✓××××××✓×××××××××××××××××××✓××××××××form,thememoryinformationisencodedintoparametersandimplicitlyinfluencestheagent’sactions.\nWesummarizepreviousworksonmemoryformswiththeirimplementationsinTable2.\n5.\n2.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nInexistingmodels,Toolformer[125]proposestoteachLLMtousetools,whichcanacquireexternalknowledgeforbettersolvingtasks.\nFurthermore,ToolLLM[126]empowersLlama[127]withtheabilitytoutilizemoreAPIsinRapidAPI5andtoenablemulti-toolusage,whichprovidesageneralinterfacetoextendagents’ability.\nInTPTU[110],theagentsareincorporatedinbothtaskplanningandtoolusage,inordertotackleintricateproblems.\nThefollow-upwork[111]furtherimprovesitsabilityextensivelylikeretrieval.\nInToRA[128],theagentsarerequiredtosolvemathematicalproblems.\nTheyutilizeimitationlearningtoimprovetheirabilitytouseprogram-basedtools.\nTheabovemethodssignificantlyadvancethecapabilitiesofagentsbyallowingthemtoaccessexternalup-to-dateandreal-worldinformationfromdiversesources.\nHowever,thereliabilityofthisinformationcanbequestionableduetopotentialinaccuraciesandbiases[18].\nFurthermore,theintegrationoftoolsintoagentsdemandsacomprehensiveunderstandingtointerprettheretrievedinformationacrossvariouscontexts,whichcanincurhighercomputationalcostsandcomplicationsinaligningexternaldatawithinternaldecision-makingprocesses.\nAdditionally,utilizingexternalAPIsbringsforthconcernsregardingprivacy,datasecurity,andcompliancewithusagepolicies,necessitatingrigorousmanagementandoversight[18].\n5.\n2.\n2MemoryinParametricFormAnalternativetypeofapproachesistorepresentmemoryinparametricform.\nTheydonottakeuptheextralengthofcontextinprompts,sotheyarenotconstrainedbythelengthlimitationsofLLMcontext.\nHowever,theparametricmemoryformisstillunder-researched,andwecategorizepreviousworksintotwotypes:fine-tuningmethodsandmemoryeditingmethods.\nFine-tuningMethods.\nIntegratingexternalknowledgeintothememoryofagentsisbeneficialforenrichingdomain-specificknowledgeontopofitsgeneralknowledge.\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nItensuresthatunrelatedknowledgeremainsunaffected.\nKnowledgeeditingmethodsaremoresuitableforsmall-scalememoryadjustments.\nGenerally,theyhavelowercomputationalcosts,makingthemmoresuitableforonlinescenarios.\nInourexampleoftask(B),Alicealwayswatchesmoviesat9:00PMfromtheagent’smemory,butshemayrecentlychangeherworkandwouldnotbeemptyat9:00PM.\nIfso,therelatedmemory(suchasroutinesat9:00PM)shouldbeedited,whichcanbeimplementedbyknowledgeeditingmethods.\nInpreviousstudies,MAC[106]intendstodesignaneffectiveandefficientmemoryadaptationframeworkforonlinescenarios.\nItutilizesmeta-learningtosubstitutetheoptimizationstep.\nPer-sonalityEdit[135]focusesoneditingthepersonalityofLLMsandagents,whereitchangestheirtraitsbasedontheoriessuchasthebig-fivefactor.\nMEND[134]utilizestheideaofmeta-learningtotrainalightweightmodel,whichiscapableofgeneratingmodificationsformodelparametersofapre-trainedlanguagemodel.\nAPP[136]studieswhetheraddinganewfactleadstocatastrophicforgettingofexistingfacts.\nItfocusesontheimpactofneighborperturbationonmemoryaddition.\nMoreover,KnowledgeEditor[133]trainsahyper-networktopredictthemodificationofmodelpa-rameterswheninjectingmemorybasedonalearning-to-updateproblemformulation.\nWangetal.\n[137]proposeanewoptimizationtargettochangethepoisoningknowledgeofLLM,andmaintainthegeneralperformanceatthesametime.\nForLLM-basedagents,theagentscanchangebadmemorybyknowledgeediting,whichcanbeconsideredasatypeofforgettingmechanism.\nKnowledgeeditingmethodsprovideaninnovativewaytoupdatetheinformationstoredwithintheparametersofLLMs.\nByspecificallytargetingandadjustingthefacts,thesemethodscanensurethenon-targetedknowledgeunaffectedduringupdates,thusmitigatingtheissueofcatastrophicforgetting.\nMoreover,thetargetedadjustmentmechanismallowsformoreefficientandlessresource-intensiveupdates,makingknowledgeeditinganappealingchoiceforhigh-precisionandreal-timemodifications.\nHowever,despitethesepromisingdevelopments,computationalcostsofmeta-trainingandthepreservationofunrelatedmemoriesremainsignificantchallenges.\n5.\n2.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain.\nItfine-tunesanacquisitionprocesstoretrieveexternalknowledgefromWikipediaandmedicaldatabases.\nDiscussion.\nTheexternalknowledgecanbeobtainedfrombothprivateandpublicsources.\nItprovidesLLM-basedagentswithmuchknowledgebeyondtheirinternalenvironment,whichmightbedifficultorevenimpossiblefortheagenttoacquirebyagent-environmentinteractions.\nMoreover,mostexternalknowledgecanbeacquiredbyaccessingtheAPIsofvarioustoolsdynamicallyinrealtimeaccordingtothetaskneeds,thusmitigatingtheproblemofoutdatedknowledge.\nIntegratingexternalknowledgeintothememoryofLLM-basedagentssignificantlyexpandstheirknowledgeboundaries,providingthemwithunlimited,up-to-date,andwell-foundedknowledgefordecision-making.\n5.\n2MemoryFormsIngeneral,therearetwoformstorepresentthememorycontents:textualformandparametricform.\nIntextualform,theinformationisexplicitlyretainedandrecalledbynaturallanguages.\nInparametric3https://www.\nwikipedia.\norg13Table2:Summarizationofthememoryforms.\nWeuse✓and×tolabelwhetherornotthecorrespondingmemoryformisadoptedinthemodel.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.\nAnotherlimitationoffine-tuningliesinthecomputationalcostandtimeconsumption,aswellastherequirementofalargeamountofdata.\nTherefore,mostfine-tuningapproachesareappliedtoofflinescenarios,andcanseldomdealwithonlinescenarios,suchasfine-tuningwithagentobservationsandtrialexperiences.\nDuetothefrequentagent-environmentinteractions,itisunaffordableforthecostofbackpropagationtofine-tuneeverystepoftheonlineanddynamicinteractions.\nMemoryEditingMethods.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nMoreover,thetargetedadjustmentmechanismallowsformoreefficientandlessresource-intensiveupdates,makingknowledgeeditinganappealingchoiceforhigh-precisionandreal-timemodifications.\nHowever,despitethesepromisingdevelopments,computationalcostsofmeta-trainingandthepreservationofunrelatedmemoriesremainsignificantchallenges.\n5.\n2.\n3AdvantagesandDisadvantagesofTextualandParametricMemoryTextualmemoryandparametricmemoryhavetheirstrengthsandweaknessesrespectively,makingthemsuitablefordifferentmemorycontentsandapplicationscenarios.\nInthissection,wediscusstheadvantagesanddisadvantagesofthesetwoformsofmemoryfromvariousaspects.\nEffectiveness.\nThetextualmemorystoresrawinformationabouttheagent-environmentinteractions,whichismorecomprehensiveanddetailed.\nHowever,itisconstrainedbythetokenlimitationofLLMprompts,whichmakestheagenthardtostoreextensiveinformation.\nIncontrast,theparametricmemoryisnotlimitedbythepromptlength,butitmaysufferfrominformationlosswhentransformingtextsintoparameters,andthecomplexmemorytrainingcanbringadditionalchallenges.\n17Efficiency.\nFortextualmemory,eachLLMinferencerequirestointegratememoryintothecontextprompt,whichleadstohighercostsandlongerprocessingtimes.\nIncontrast,forparametricmemory,theinformationcanbeintegratedintotheparametersoftheLLM,eliminatingtheextracostsofthesecontexts.\nHowever,parametricmemorytakesadditionalcostsinthewritingprocess,buttextualmemoryiseasiertowrite,especiallyforsmallamountsofdata.\nInanutshell,textualmemoryismoreefficientinwriting,whileparametricmemoryismoreefficientinreading.\nInterpretability.\nTextualmemoryisusuallymoreexplainablethantheparametricone,sincenaturallanguagesarethemostnaturalandstraightforwardstrategiesforhumanstounderstand,whileparametricmemoryiscommonlyrepresentedinlatentspace.\nNevertheless,suchexplainabilityisobtainedatthecostofinformationdensity.\nThisisbecausethesequencesofwordsintextualmemoryarerepresentedinadiscretespace,whichisnotasdenseascontinuousspaceinparametricmemory.",
      "#memory_survey#MemoryinParametricForm#memory_survey#MemoryinParametricForm\nMemoryinParametricFormAnalternativetypeofapproachesistorepresentmemoryinparametricform.\nTheydonottakeuptheextralengthofcontextinprompts,sotheyarenotconstrainedbythelengthlimitationsofLLMcontext.\nHowever,theparametricmemoryformisstillunder-researched,andwecategorizepreviousworksintotwotypes:fine-tuningmethodsandmemoryeditingmethods.\nFine-tuningMethods.\nIntegratingexternalknowledgeintothememoryofagentsisbeneficialforenrichingdomain-specificknowledgeontopofitsgeneralknowledge.\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.",
      "#memory_survey#AdvantagesandDisadvantagesofTextualandParametricMemory#memory_survey#AdvantagesandDisadvantagesofTextualandParametricMemory\nAdvantagesandDisadvantagesofTextualandParametricMemoryTextualmemoryandparametricmemoryhavetheirstrengthsandweaknessesrespectively,makingthemsuitablefordifferentmemorycontentsandapplicationscenarios.\nInthissection,wediscusstheadvantagesanddisadvantagesofthesetwoformsofmemoryfromvariousaspects.\nEffectiveness.\nThetextualmemorystoresrawinformationabouttheagent-environmentinteractions,whichismorecomprehensiveanddetailed.\nHowever,itisconstrainedbythetokenlimitationofLLMprompts,whichmakestheagenthardtostoreextensiveinformation.\nIncontrast,theparametricmemoryisnotlimitedbythepromptlength,butitmaysufferfrominformationlosswhentransformingtextsintoparameters,andthecomplexmemorytrainingcanbringadditionalchallenges.\n17Efficiency.\nFortextualmemory,eachLLMinferencerequirestointegratememoryintothecontextprompt,whichleadstohighercostsandlongerprocessingtimes.\nIncontrast,forparametricmemory,theinformationcanbeintegratedintotheparametersoftheLLM,eliminatingtheextracostsofthesecontexts.\nHowever,parametricmemorytakesadditionalcostsinthewritingprocess,buttextualmemoryiseasiertowrite,especiallyforsmallamountsofdata.\nInanutshell,textualmemoryismoreefficientinwriting,whileparametricmemoryismoreefficientinreading.\nInterpretability.\nTextualmemoryisusuallymoreexplainablethantheparametricone,sincenaturallanguagesarethemostnaturalandstraightforwardstrategiesforhumanstounderstand,whileparametricmemoryiscommonlyrepresentedinlatentspace.\nNevertheless,suchexplainabilityisobtainedatthecostofinformationdensity.\nThisisbecausethesequencesofwordsintextualmemoryarerepresentedinadiscretespace,whichisnotasdenseascontinuousspaceinparametricmemory.\nInconclusion,thetrade-offsbetweenthesetwotypesofmemoriesmakethemsuitablefordifferentapplications.\nForexample,forthetasksthatrequirerecallingrecentinteractions,likeconversationalandcontext-specifictasks,textualmemoryseemsmoreeffective.\nForthetasksthatrequirealargeamountofmemory,orwell-establishedknowledge,parametricmemorycanbeabetterchoice.\n5.\n3",
      "#memory_survey#MemoryinParametricForm#memory_survey#MemoryinParametricForm\nMEND[134]utilizestheideaofmeta-learningtotrainalightweightmodel,whichiscapableofgeneratingmodificationsformodelparametersofapre-trainedlanguagemodel.\nAPP[136]studieswhetheraddinganewfactleadstocatastrophicforgettingofexistingfacts.\nItfocusesontheimpactofneighborperturbationonmemoryaddition.\nMoreover,KnowledgeEditor[133]trainsahyper-networktopredictthemodificationofmodelpa-rameterswheninjectingmemorybasedonalearning-to-updateproblemformulation.\nWangetal.\n[137]proposeanewoptimizationtargettochangethepoisoningknowledgeofLLM,andmaintainthegeneralperformanceatthesametime.\nForLLM-basedagents,theagentscanchangebadmemorybyknowledgeediting,whichcanbeconsideredasatypeofforgettingmechanism.\nKnowledgeeditingmethodsprovideaninnovativewaytoupdatetheinformationstoredwithintheparametersofLLMs.\nByspecificallytargetingandadjustingthefacts,thesemethodscanensurethenon-targetedknowledgeunaffectedduringupdates,thusmitigatingtheissueofcatastrophicforgetting.\nMoreover,thetargetedadjustmentmechanismallowsformoreefficientandlessresource-intensiveupdates,makingknowledgeeditinganappealingchoiceforhigh-precisionandreal-timemodifications.\nHowever,despitethesepromisingdevelopments,computationalcostsofmeta-trainingandthepreservationofunrelatedmemoriesremainsignificantchallenges.\n5.\n2.\n3",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nIntextualform,theinformationisexplicitlyretainedandrecalledbynaturallanguages.\nInparametric3https://www.\nwikipedia.\norg13Table2:Summarizationofthememoryforms.\nWeuse✓and×tolabelwhetherornotthecorrespondingmemoryformisadoptedinthemodel.\nModelsMemoryBank[6]RET-LLM[7]ChatDB[96]TiM[97]SCM[98]Voyager[99]MemGPT[100]MemoChat[94]MPC[101]GenerativeAgents[83]RecMind[102]Retroformer[103]ExpeL[82]Synapse[91]GITM[93]ReAct[104]Reflexion[5]RecAgent[95]Character-LLM[105]MAC[106]Huatuo[107]ChatDev[1]InteRecAgent[108]MetaAgents[109]TPTU[110,111]MetaGPT[112]S3[2]InvestLM[113]TextualFormParametricFormCompleteRecentRetrievedExternalFine-tuningEditing××××××××××✓✓✓×✓✓✓×××✓✓××✓✓×✓××××✓×✓××××××××××✓✓×××✓×××××✓✓✓✓✓✓✓✓✓✓××✓✓✓××✓××××✓✓××✓××××××××××××✓✓×✓✓✓×××××✓×✓××××××××××××××✓××××××✓×✓××××××✓×××××××××××××××××××✓××××××××form,thememoryinformationisencodedintoparametersandimplicitlyinfluencestheagent’sactions.\nWesummarizepreviousworksonmemoryformswiththeirimplementationsinTable2.\n5.\n2.\n1MemoryinTextualFormTextualformiscurrentlythemainstreammethodtorepresentthememorycontents,whichisfeaturedinbetterinterpretability,easierimplementation,andfasterread-writeefficiency.\nInspecific,thetextualformcanbebothnon-structuredrepresentationslikerawnaturallanguagesandstructuredinformationsuchastuples,databases,andsoon.\nIngeneral,previousstudiesusethetextualformmemorytostorefourtypesofinformationincluding(1)completeagent-environmentinteractions,(2)recentagent-environmentinteractions,(3)retrievedagent-environmentinteractions,and(4)externalknowledge.\nIntheformerthreemethods,thememoryleveragesnaturallanguagestodescribetheinformationwithintheagent-environmentinteractionloop.\nIntheformerthreetypes,theyrecordtheinformationinsidetheagent-environmentinteractionloop,whilethelasttypeleveragesnaturallanguagestostoreinformationoutsidethatloop.\nCompleteInteractions.\nThismethodstoresalltheinformationoftheagent-environmentinteractionhistorybasedonlong-contextstrategies[116].\nFortheexampleinSection3.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThefollow-upwork[111]furtherimprovesitsabilityextensivelylikeretrieval.\nInToRA[128],theagentsarerequiredtosolvemathematicalproblems.\nTheyutilizeimitationlearningtoimprovetheirabilitytouseprogram-basedtools.\nTheabovemethodssignificantlyadvancethecapabilitiesofagentsbyallowingthemtoaccessexternalup-to-dateandreal-worldinformationfromdiversesources.\nHowever,thereliabilityofthisinformationcanbequestionableduetopotentialinaccuraciesandbiases[18].\nFurthermore,theintegrationoftoolsintoagentsdemandsacomprehensiveunderstandingtointerprettheretrievedinformationacrossvariouscontexts,whichcanincurhighercomputationalcostsandcomplicationsinaligningexternaldatawithinternaldecision-makingprocesses.\nAdditionally,utilizingexternalAPIsbringsforthconcernsregardingprivacy,datasecurity,andcompliancewithusagepolicies,necessitatingrigorousmanagementandoversight[18].\n5.\n2.\n2MemoryinParametricFormAnalternativetypeofapproachesistorepresentmemoryinparametricform.\nTheydonottakeuptheextralengthofcontextinprompts,sotheyarenotconstrainedbythelengthlimitationsofLLMcontext.\nHowever,theparametricmemoryformisstillunder-researched,andwecategorizepreviousworksintotwotypes:fine-tuningmethodsandmemoryeditingmethods.\nFine-tuningMethods.\nIntegratingexternalknowledgeintothememoryofagentsisbeneficialforenrichingdomain-specificknowledgeontopofitsgeneralknowledge.\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nMoreover,KnowledgeEditor[133]trainsahyper-networktopredictthemodificationofmodelpa-rameterswheninjectingmemorybasedonalearning-to-updateproblemformulation.\nWangetal.\n[137]proposeanewoptimizationtargettochangethepoisoningknowledgeofLLM,andmaintainthegeneralperformanceatthesametime.\nForLLM-basedagents,theagentscanchangebadmemorybyknowledgeediting,whichcanbeconsideredasatypeofforgettingmechanism.\nKnowledgeeditingmethodsprovideaninnovativewaytoupdatetheinformationstoredwithintheparametersofLLMs.\nByspecificallytargetingandadjustingthefacts,thesemethodscanensurethenon-targetedknowledgeunaffectedduringupdates,thusmitigatingtheissueofcatastrophicforgetting.\nMoreover,thetargetedadjustmentmechanismallowsformoreefficientandlessresource-intensiveupdates,makingknowledgeeditinganappealingchoiceforhigh-precisionandreal-timemodifications.\nHowever,despitethesepromisingdevelopments,computationalcostsofmeta-trainingandthepreservationofunrelatedmemoriesremainsignificantchallenges.\n5.\n2.\n3AdvantagesandDisadvantagesofTextualandParametricMemoryTextualmemoryandparametricmemoryhavetheirstrengthsandweaknessesrespectively,makingthemsuitablefordifferentmemorycontentsandapplicationscenarios.\nInthissection,wediscusstheadvantagesanddisadvantagesofthesetwoformsofmemoryfromvariousaspects.\nEffectiveness.\nThetextualmemorystoresrawinformationabouttheagent-environmentinteractions,whichismorecomprehensiveanddetailed.\nHowever,itisconstrainedbythetokenlimitationofLLMprompts,whichmakestheagenthardtostoreextensiveinformation.\nIncontrast,theparametricmemoryisnotlimitedbythepromptlength,butitmaysufferfrominformationlosswhentransformingtextsintoparameters,andthecomplexmemorytrainingcanbringadditionalchallenges.\n17Efficiency.\nFortextualmemory,eachLLMinferencerequirestointegratememoryintothecontextprompt,whichleadstohighercostsandlongerprocessingtimes.\nIncontrast,forparametricmemory,theinformationcanbeintegratedintotheparametersoftheLLM,eliminatingtheextracostsofthesecontexts.",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\nSurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.\n[70]presentthefirstcomprehensivesurveytosummarizethebackground,evolutionpaths,modelarchitectures,trainingmethodologies,andevaluationstrategiesofLLMs.\nHadietal.\n[71]andMinetal.\n[72]alsoconductLLMsurveysfromtheholisticview,which,however,providedifferenttaxonomiesandunderstandingsonLLMs.\nFollowingthesesurveys,peoplediveintospecificaspectsofLLMsandreviewthecorrespondingmilestonestudiesandkeytechnologies.\nTheseaspectscanbeclassifiedintofourcategoriesincludingthefundamentalproblems,evaluation,applications,andchallengesofLLMs.\nFundamentalproblems.\nThesurveysinthiscategoryaimtosummarizetechniquesthatcanbeleveragedtotacklefundamentalproblemsofLLMs.\nSpecifically,Zhangetal.\n[8]provideacomprehensivesurveyonthemethodsofsupervisedfine-tuning,whichisakeytechniqueforbettertrainingLLMs.\nShenetal.\n[9],Wangetal.\n[10]andLiuetal.\n[11]presentsurveysonthealignmentofLLMs,whichisakeyrequirementforLLMstoproduceoutputsconsistentwithhumanvalues.\nGaoetal.\n[12]proposeasurveyontheretrieval-augmentedgeneration(RAG)capabilityofLLMs,whichiskeytoprovidingLLMswithfactualandup-to-dateknowledgeandremovinghallucinations.\nQinetal.\n[18]summarizethestate-of-the-artmethodsonenablingLLMstoleverageexternaltools,whichisfundamentalforLLMstoexpandtheircapabilityindomainsthatrequirespecializedknowledge.\nWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16]andZhangetal.\n[17]presentsurveysonthedirectionofLLMknowledgeediting,whichisimportantforcustomizingLLMstosatisfyspecificrequirements.\nHuangetal.\n[19],Wangetal.\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal."
    ],
    [
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal.\n[47]summarizetheapplicationsofLLMsinmedicine.\nLietal.\n[48]focusontheapplicationsofLLMsinfinance.\nHeetal.\n[49]reviewthemodelsonleveragingLLMstoimprovethedevelopmentofpsychology.\n5SupervisedFine-tuningZhangetal.\n[8].\nAlignmentShenetal.\n[9],Wangetal.\n[10],Liuetal.\n[11].\nRetrievalAugmentationGaoetal.\n[12].\nKnowledgeEditingWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16],Zhangetal.\n[17].\nFundamentalProblemsToolUsageQinetal.\n[18].\nLong-contextMultimodalEfficiencyHuangetal.\n[19],Wangetal.\n[20],Pawaretal.\n[21].\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24],Yinetal.\n[25].\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28,28],Xuetal.\n[29],Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32],Parketal.\n[33].\nEvaluationChangetal.\n[34],Guoetal.\n[35].\nInformationProcessingSoftwareEngineeringYangetal.\n[36],Zhuetal.\n[37],Xuetal.\n[38].\nFanetal.\n[39],Wangetal.\n[40],Zhengetal.\n[41].\nRoboticsZengetal.\n[42].\nApplicationsAutonomousDrivingCuietal.\n[43],Yangetal.\n[44].\nLLMs[70–73]MedecineFinancePsychologyHeetal.\n[45],Zhouetal.\n[46],Wangetal.\n[47].\nLietal.\n[48].\nHeetal.\n[49].\nRecommendationLietal.\n[50],Linetal.\n[51],Wangetal.\n[52].\nHallucinationZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Ton-moyetal.\n[58],Jiangetal.\n[59].\nChallengesBias&FairnessGallegosetal.\n[60],Koteketal.\n[61],Lietal.\n[62].\nExplainabilityZhaoetal.\n[63].\nSecurityYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68],Dasetal.\n[69].\nPlanningHuangetal.\n[74].\nFundamentalProblemsMemoryOurSurvey.\nMulti-agentsGuoetal.\n[75].\nLLM-basedAgent[3,4,77–80]EvaluationApplicationsChallengesLietal.\n[76].\nFigure2:TheorganizationofrelatedsurveysonLLMsandLLM-basedagents.\n6Challenges.\nThesurveysinthiscategoryfocusontrustworthinessinLLMs,suchashallucination,bias,unfairness,explainability,security,andprivacy.",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32]andParketal.\n[33]systematicallyreviewthetechniquesofmodelcompression.\nDingetal.\n[81]andXuetal.\n[29]analyzeandconcludethestudiesonparameterefficientfine-tuning.\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28]andDingetal.\n[81]putmorefocusesontheefficiencyofresourceutilizationinageneralsense.\nEvaluation.\nThesurveysinthiscategoryfocusonhowtoevaluatethecapabilityofLLMs.\nSpecifi-cally,Changetal.\n[34]comprehensivelysummarizetheevaluationmethodsfromanoverallperspec-tive.\nItencompassesdifferentevaluationtasks,methods,andbenchmarks,whichserveascriticalpartsinassessingLLMperformances.\nGuoetal.\n[35]caremoreabouttheevaluationtargetsanddescribehowtoevaluatetheknowledge,alignment,andsafetycontrolcapabilitiesofLLMs,whichsupplementevaluationmetricsbeyondperformance.\nApplications.\nThesurveysinthiscategoryaimtosummarizemodelsthatleverageLLMstoimprovedifferentapplications.\nMoreconcretely,Zhuetal.\n[37]focusonthefieldofinformationretrieval(IR)andsummarizestudiesonLLM-basedqueryprocesses.\nXuetal.\n[38]paymoreattentiontoinformationextraction(IE)andprovidecomprehensivetaxonomiesforLLM-basedmodelsinthisfield.\nLietal.\n[50],Linetal.\n[51]andWangetal.\n[52]discusstheapplicationsofLLMsinthefieldofrecommendersystem,wheretheyutilizeagentstogeneratedataandproviderecommendations.\nFanetal.\n[39],Wangetal.\n[40],andZhengetal.\n[41]concentrateonhowLLMscanbenefitsoftwareengineering(SE)intermsofsoftwaredesign,development,andtesting.\nZengetal.\n[42]summarizeLLM-basedmethodsinthefieldofrobotics.\nCuietal.\n[43]andYangetal.\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal.",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\nSurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.\n[70]presentthefirstcomprehensivesurveytosummarizethebackground,evolutionpaths,modelarchitectures,trainingmethodologies,andevaluationstrategiesofLLMs.\nHadietal.\n[71]andMinetal.\n[72]alsoconductLLMsurveysfromtheholisticview,which,however,providedifferenttaxonomiesandunderstandingsonLLMs.\nFollowingthesesurveys,peoplediveintospecificaspectsofLLMsandreviewthecorrespondingmilestonestudiesandkeytechnologies.\nTheseaspectscanbeclassifiedintofourcategoriesincludingthefundamentalproblems,evaluation,applications,andchallengesofLLMs.\nFundamentalproblems.\nThesurveysinthiscategoryaimtosummarizetechniquesthatcanbeleveragedtotacklefundamentalproblemsofLLMs.\nSpecifically,Zhangetal.\n[8]provideacomprehensivesurveyonthemethodsofsupervisedfine-tuning,whichisakeytechniqueforbettertrainingLLMs.\nShenetal.\n[9],Wangetal.\n[10]andLiuetal.\n[11]presentsurveysonthealignmentofLLMs,whichisakeyrequirementforLLMstoproduceoutputsconsistentwithhumanvalues.\nGaoetal.\n[12]proposeasurveyontheretrieval-augmentedgeneration(RAG)capabilityofLLMs,whichiskeytoprovidingLLMswithfactualandup-to-dateknowledgeandremovinghallucinations.\nQinetal.\n[18]summarizethestate-of-the-artmethodsonenablingLLMstoleverageexternaltools,whichisfundamentalforLLMstoexpandtheircapabilityindomainsthatrequirespecializedknowledge.\nWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16]andZhangetal.\n[17]presentsurveysonthedirectionofLLMknowledgeediting,whichisimportantforcustomizingLLMstosatisfyspecificrequirements.\nHuangetal.\n[19],Wangetal.\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32]andParketal.\n[33]systematicallyreviewthetechniquesofmodelcompression.\nDingetal.\n[81]andXuetal.\n[29]analyzeandconcludethestudiesonparameterefficientfine-tuning.\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28]andDingetal.\n[81]putmorefocusesontheefficiencyofresourceutilizationinageneralsense.\nEvaluation.\nThesurveysinthiscategoryfocusonhowtoevaluatethecapabilityofLLMs.\nSpecifi-cally,Changetal.\n[34]comprehensivelysummarizetheevaluationmethodsfromanoverallperspec-tive.\nItencompassesdifferentevaluationtasks,methods,andbenchmarks,whichserveascriticalpartsinassessingLLMperformances.\nGuoetal.\n[35]caremoreabouttheevaluationtargetsanddescribehowtoevaluatetheknowledge,alignment,andsafetycontrolcapabilitiesofLLMs,whichsupplementevaluationmetricsbeyondperformance.\nApplications.\nThesurveysinthiscategoryaimtosummarizemodelsthatleverageLLMstoimprovedifferentapplications.\nMoreconcretely,Zhuetal.\n[37]focusonthefieldofinformationretrieval(IR)andsummarizestudiesonLLM-basedqueryprocesses.\nXuetal.\n[38]paymoreattentiontoinformationextraction(IE)andprovidecomprehensivetaxonomiesforLLM-basedmodelsinthisfield.\nLietal.\n[50],Linetal.\n[51]andWangetal.\n[52]discusstheapplicationsofLLMsinthefieldofrecommendersystem,wheretheyutilizeagentstogeneratedataandproviderecommendations.\nFanetal.\n[39],Wangetal.\n[40],andZhengetal.\n[41]concentrateonhowLLMscanbenefitsoftwareengineering(SE)intermsofsoftwaredesign,development,andtesting.\nZengetal.\n[42]summarizeLLM-basedmethodsinthefieldofrobotics.\nCuietal.\n[43]andYangetal.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTosystemicallysummarizethestudiesinthisfield,researchershavewrittenalotofsurveypapers.\nInthissection,webrieflyreviewthesesurveys(seeFigure2foranoverview),highlightingtheirmajorfocusesandcontributionstobetterpositionourstudy.\n2.\n1SurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.\n[70]presentthefirstcomprehensivesurveytosummarizethebackground,evolutionpaths,modelarchitectures,trainingmethodologies,andevaluationstrategiesofLLMs.\nHadietal.\n[71]andMinetal.\n[72]alsoconductLLMsurveysfromtheholisticview,which,however,providedifferenttaxonomiesandunderstandingsonLLMs.\nFollowingthesesurveys,peoplediveintospecificaspectsofLLMsandreviewthecorrespondingmilestonestudiesandkeytechnologies.\nTheseaspectscanbeclassifiedintofourcategoriesincludingthefundamentalproblems,evaluation,applications,andchallengesofLLMs.\nFundamentalproblems.\nThesurveysinthiscategoryaimtosummarizetechniquesthatcanbeleveragedtotacklefundamentalproblemsofLLMs.\nSpecifically,Zhangetal.\n[8]provideacomprehensivesurveyonthemethodsofsupervisedfine-tuning,whichisakeytechniqueforbettertrainingLLMs.\nShenetal.\n[9],Wangetal.\n[10]andLiuetal.\n[11]presentsurveysonthealignmentofLLMs,whichisakeyrequirementforLLMstoproduceoutputsconsistentwithhumanvalues.\nGaoetal.\n[12]proposeasurveyontheretrieval-augmentedgeneration(RAG)capabilityofLLMs,whichiskeytoprovidingLLMswithfactualandup-to-dateknowledgeandremovinghallucinations.\nQinetal.\n[18]summarizethestate-of-the-artmethodsonenablingLLMstoleverageexternaltools,whichisfundamentalforLLMstoexpandtheircapabilityindomainsthatrequirespecializedknowledge.\nWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16]andZhangetal.\n[17]presentsurveysonthedirectionofLLMknowledgeediting,whichisimportantforcustomizingLLMstosatisfyspecificrequirements.\nHuangetal.\n[19],Wangetal.\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal."
    ],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThememorymoduleisanimportantcomponentforsuchapplications,whichhelpstoaccuratelysimulatehumandynamicbehaviors.\nInpreviousstudies,Kaiyaetal.\n[148]proposeaSummarize-and-Forgetmemorymechanismforbetterself-monitoringinsocialscenarios.\nGaoetal.\n[2]focusonsocialnetworksimulationsystems.\nEachagentinthesystemhasamemorypool,whichconsistsofdiverseusermessagesfromonlineplatformstoidentifytheuser.\nLietal.\n[163]maintainconversationcontexts,encompassingtheeconomicenvironmentandagentdecisionsfrompreviousmonths,inordertosimulatetheimpactofbroadmacroeconomictrendsonagents’decision-makingandtomaketheagentsgraspmarketdynamics.\nLietal.\n[109]simulatethejob-seekingscenarioinhumansociety,wherethememoryofagentsincludesprofilesandgoalsinitiallyandisfurtherenrichedwithotherinformation,likedialoguesandpersonalreflections.\nHuaetal.\n[150]simulatethedecisionsandconsequencesoftheparticipatingcountriesinthewars,wheretheconversationsofagentsarecontinuouslymaintainedintomemory.\nThereareseveralinsightsindesigninganagent’smemoryforrole-playandsocialsimulation.\nFirst,thememoryshouldbeconsistentwiththeroles’characteristics,whichcanbeusedtoidentifyeachroleanddistinguishitfromtheothers.\nThisiscrucialforimprovingtherealismofrole-playandthediversityofsocialsimulation.\nSecond,thememoryshouldappropriatelyinfluencethesubsequent24actionsoftheagenttoensuretheconsistencyandrationalityofitsbehaviors.\nAdditionally,forhumanoidagents,theirmemorymechanismsshouldalignwiththefeaturesofhumanmemory,suchasforgettingandlong/short-termmemory,whichshouldrefertothetheoriesofcognitivepsychology.\n7.\n2PersonalAssistantLLM-basedagentsarewell-suitedforcreatingpersonalassistants,suchasagentscapableofengaginginlong-termconversationswithusers[94,101,153],aswellasthosetaskedwithautomaticallyseekinginformation[164].\nTheseagentsoftenneedtomemorizepreviousdialoguestomaintaintheconsistency,andremembercriticalstylesandeventstogeneratemorepersonalizedandrelevantresponses.\nLuetal.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nManypreviousstudieshaveexploredmethodsforconstructingrolememories[105,143,145–147].\nShaoetal.\n[105]constructthememoryofrolesbyexperienceuploading,whichutilizesSFTtoinjectmemoryintomodelparameters.\nLietal.\n[143]enhancelargelanguagemodelsforrole-playingviaanimprovedpromptandthecharactermemoryextractedfromscripts,whereuserqueriesand23Table4:Summarizationofmemory-enhancedagentsapplications.\nApplicationsModelsApplicationsModelsRole-playingSocialSimulationPersonalAssistantGameCharacter-LLM[105]ChatHaruhi[143]RoleLLM[145]NarrativePlay[146]CharacterGLM[147]GenerativeAgents[83]LyfeAgents[148]S3[2]MetaAgents[109]WarAgent[150]MemoryBank[6]RET-LLM[7]MemoChat[94]MemGPT[100]MPC[101]AutoGen[153]ChatDB[96]TiM[97]SCM[98]Voyager[99]GITM[93]JARVIS[159]LARP[161]CodeGenerationRecommendationMedicineFinanceScienceRTLFixer[142]GameGPT[144]ChatDev[1]MetaGPT[109]CodeAgent[114]RecAgent[95]InteRecAgent[108]RecMind[102]AgentCF[149]Huatuo[107]DoctorGLM[129]Radiology-GPT[132]Wangetal.\n[151]EHRAgent[152]ChatDoctor[115]InvestLM[113]TradingGPT[154]QuantAgent[155]FinMem[156]Koaetal.\n[157]Chemist-X[158]ChemDFM[160]MatChat[162]chatbot’sresponsesareconcatenatedtoformasequenceasmemory.\nWangetal.\n[145]infuserole-specificknowledgeandepisodememoriesintoLLM-basedagents,wherecontextQApairsareconcatenatedtoformepisodememory.\nZhaoetal.\n[146]aimtogeneratehuman-likeresponses,guidedbypersonalitytraitsextractedfromnarratives,whichcanbestoredandretrievedbyrelevanceandimportance.\nZhouetal.\n[147]generatecharacter-baseddialoguesfordifferentrolesandempowerLLM-basedagentswithcorrespondingstylesbySFT.\nSocialsimulationisbasicallyanextensionofrole-playing,whichfocusesmoreonmulti-agentmodeling.\nThememorymoduleisanimportantcomponentforsuchapplications,whichhelpstoaccuratelysimulatehumandynamicbehaviors.\nInpreviousstudies,Kaiyaetal.\n[148]proposeaSummarize-and-Forgetmemorymechanismforbetterself-monitoringinsocialscenarios.\nGaoetal.\n[2]focusonsocialnetworksimulationsystems.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[141]MohitShridhar,XingdiYuan,Marc-AlexandreCôté,YonatanBisk,AdamTrischler,andMatthewHausknecht.\nAlfworld:Aligningtextandembodiedenvironmentsforinteractivelearning.\narXivpreprintarXiv:2010.\n03768,2020.\n[142]YunDaTsai,MingjieLiu,andHaoxingRen.\nRtlfixer:Automaticallyfixingrtlsyntaxerrorswithlargelanguagemodels.\narXivpreprintarXiv:2311.\n16543,2023.\n[143]ChengLi,ZiangLeng,ChenxiYan,JunyiShen,HaoWang,WeishiMi,YayingFei,XiaoyangFeng,SongYan,HaoShengWang,etal.\nChatharuhi:Revivinganimecharacterinrealityvialargelanguagemodel.\narXivpreprintarXiv:2308.\n09597,2023.\n[144]DakeChen,HanbinWang,YunhaoHuo,YuzhaoLi,andHaoyangZhang.\nGamegpt:Multi-agentcollaborativeframeworkforgamedevelopment.\narXivpreprintarXiv:2310.\n08067,2023.\n[145]ZekunMooreWang,ZhongyuanPeng,HaoranQue,JiahengLiu,WangchunshuZhou,YuhanWu,HongchengGuo,RuitongGan,ZehaoNi,ManZhang,etal.\nRolellm:Benchmarking,eliciting,andenhancingrole-playingabilitiesoflargelanguagemodels.\narXivpreprintarXiv:2310.\n00746,2023.\n[146]RuncongZhao,WenjiaZhang,JiazhengLi,LixingZhu,YanranLi,YulanHe,andLinGui.\nNarrativeplay:Interactivenarrativeunderstanding.\narXivpreprintarXiv:2310.\n01459,2023.\n[147]JinfengZhou,ZhuangChen,DazhenWan,BosiWen,YiSong,JifanYu,YongkangHuang,Lib-iaoPeng,JiamingYang,XiyaoXiao,etal.\nCharacterglm:Customizingchineseconversationalaicharacterswithlargelanguagemodels.\narXivpreprintarXiv:2311.\n16832,2023.\n[148]ZhaoKaiya,MichelangeloNaim,JovanaKondic,ManuelCortes,JiaxinGe,ShuyingLuo,GuangyuRobertYang,andAndrewAhn.\nLyfeagents:Generativeagentsforlow-costreal-timesocialinteractions.\narXivpreprintarXiv:2310.\n02172,2023.\n[149]JunjieZhang,YupengHou,RuobingXie,WenqiSun,JulianMcAuley,WayneXinZhao,LeyuLin,andJi-RongWen.\nAgentcf:Collaborativelearningwithautonomouslanguageagentsforrecommendersystems.\narXivpreprintarXiv:2310.\n09233,2023.\n[150]WenyueHua,LizhouFan,LingyaoLi,KaiMei,JianchaoJi,YingqiangGe,LibbyHemphill,andYongfengZhang.\nWarandpeace(waragent):Largelanguagemodel-basedmulti-agentsimulationofworldwars.\narXivpreprintarXiv:2311.\n17227,2023.",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nFurthermore,theintegrationoftoolsintoagentsdemandsacomprehensiveunderstandingtointerprettheretrievedinformationacrossvariouscontexts,whichcanincurhighercomputationalcostsandcomplicationsinaligningexternaldatawithinternaldecision-makingprocesses.\nAdditionally,utilizingexternalAPIsbringsforthconcernsregardingprivacy,datasecurity,andcompliancewithusagepolicies,necessitatingrigorousmanagementandoversight[18].\n5.\n2.\n2",
      "#memory_survey#Conclusion#memory_survey#Conclusion\nACMComputingSurveys,56(2):1–40,2023.\n[73]GrégoireMialon,RobertoDessì,MariaLomeli,ChristoforosNalmpantis,RamPasunuru,RobertaRaileanu,BaptisteRozière,TimoSchick,JaneDwivedi-Yu,AsliCelikyilmaz,etal.\nAugmentedlanguagemodels:asurvey.\narXivpreprintarXiv:2302.\n07842,2023.\n[74]XuHuang,WeiwenLiu,XiaolongChen,XingmeiWang,HaoWang,DefuLian,YashengWang,RuimingTang,andEnhongChen.\nUnderstandingtheplanningofllmagents:Asurvey.\narXivpreprintarXiv:2402.\n02716,2024.\n[75]TaichengGuo,XiuyingChen,YaqiWang,RuidiChang,ShichaoPei,NiteshVChawla,OlafWiest,andXiangliangZhang.\nLargelanguagemodelbasedmulti-agents:Asurveyofprogressandchallenges.\narXivpreprintarXiv:2402.\n01680,2024.\n[76]YuanchunLi,HaoWen,WeijunWang,XiangyuLi,YizhenYuan,GuohongLiu,JiachengLiu,WenxingXu,XiangWang,YiSun,etal.\nPersonalllmagents:Insightsandsurveyaboutthecapability,efficiencyandsecurity.\narXivpreprintarXiv:2401.\n05459,2024.\n[77]PengyuZhao,ZijianJin,andNingCheng.\nAnin-depthsurveyoflargelanguagemodel-basedartificialintelligenceagents.\narXivpreprintarXiv:2309.\n14365,2023.\n[78]YuhengCheng,CeyaoZhang,ZhengwenZhang,XiangruiMeng,SiruiHong,WenhaoLi,ZihaoWang,ZekaiWang,FengYin,JunhuaZhao,etal.\nExploringlargelanguagemodelbasedintelligentagents:Definitions,methods,andprospects.\narXivpreprintarXiv:2401.\n03428,2024.\n[79]ZaneDurante,QiuyuanHuang,NaokiWake,RanGong,JaeSungPark,BidiptaSarkar,RohanTaori,YusukeNoda,DemetriTerzopoulos,YejinChoi,etal.\nAgentai:Surveyingthehorizonsofmultimodalinteraction.\narXivpreprintarXiv:2401.\n03568,2024.\n[80]YingqiangGe,YujieRen,WenyueHua,ShuyuanXu,JuntaoTan,andYongfengZhang.\nLlmasos(llmao),agentsasapps:Envisioningaios,agentsandtheaios-agentecosystem.\narXivpreprintarXiv:2312.\n03815,2023.\n[81]NingDing,YujiaQin,GuangYang,FuchaoWei,ZonghanYang,YushengSu,ShengdingHu,YulinChen,Chi-MinChan,WeizeChen,etal.\nDeltatuning:Acomprehensivestudyofparameterefficientmethodsforpre-trainedlanguagemodels.\narXivpreprintarXiv:2203.\n06904,2022.\n[82]AndrewZhao,DanielHuang,QuentinXu,MatthieuLin,Yong-JinLiu,andGaoHuang.\nExpel:Llmagentsareexperientiallearners."
    ],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThememorymoduleisanimportantcomponentforsuchapplications,whichhelpstoaccuratelysimulatehumandynamicbehaviors.\nInpreviousstudies,Kaiyaetal.\n[148]proposeaSummarize-and-Forgetmemorymechanismforbetterself-monitoringinsocialscenarios.\nGaoetal.\n[2]focusonsocialnetworksimulationsystems.\nEachagentinthesystemhasamemorypool,whichconsistsofdiverseusermessagesfromonlineplatformstoidentifytheuser.\nLietal.\n[163]maintainconversationcontexts,encompassingtheeconomicenvironmentandagentdecisionsfrompreviousmonths,inordertosimulatetheimpactofbroadmacroeconomictrendsonagents’decision-makingandtomaketheagentsgraspmarketdynamics.\nLietal.\n[109]simulatethejob-seekingscenarioinhumansociety,wherethememoryofagentsincludesprofilesandgoalsinitiallyandisfurtherenrichedwithotherinformation,likedialoguesandpersonalreflections.\nHuaetal.\n[150]simulatethedecisionsandconsequencesoftheparticipatingcountriesinthewars,wheretheconversationsofagentsarecontinuouslymaintainedintomemory.\nThereareseveralinsightsindesigninganagent’smemoryforrole-playandsocialsimulation.\nFirst,thememoryshouldbeconsistentwiththeroles’characteristics,whichcanbeusedtoidentifyeachroleanddistinguishitfromtheothers.\nThisiscrucialforimprovingtherealismofrole-playandthediversityofsocialsimulation.\nSecond,thememoryshouldappropriatelyinfluencethesubsequent24actionsoftheagenttoensuretheconsistencyandrationalityofitsbehaviors.\nAdditionally,forhumanoidagents,theirmemorymechanismsshouldalignwiththefeaturesofhumanmemory,suchasforgettingandlong/short-termmemory,whichshouldrefertothetheoriesofcognitivepsychology.\n7.\n2PersonalAssistantLLM-basedagentsarewell-suitedforcreatingpersonalassistants,suchasagentscapableofengaginginlong-termconversationswithusers[94,101,153],aswellasthosetaskedwithautomaticallyseekinginformation[164].\nTheseagentsoftenneedtomemorizepreviousdialoguestomaintaintheconsistency,andremembercriticalstylesandeventstogeneratemorepersonalizedandrelevantresponses.\nLuetal.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nManypreviousstudieshaveexploredmethodsforconstructingrolememories[105,143,145–147].\nShaoetal.\n[105]constructthememoryofrolesbyexperienceuploading,whichutilizesSFTtoinjectmemoryintomodelparameters.\nLietal.\n[143]enhancelargelanguagemodelsforrole-playingviaanimprovedpromptandthecharactermemoryextractedfromscripts,whereuserqueriesand23Table4:Summarizationofmemory-enhancedagentsapplications.\nApplicationsModelsApplicationsModelsRole-playingSocialSimulationPersonalAssistantGameCharacter-LLM[105]ChatHaruhi[143]RoleLLM[145]NarrativePlay[146]CharacterGLM[147]GenerativeAgents[83]LyfeAgents[148]S3[2]MetaAgents[109]WarAgent[150]MemoryBank[6]RET-LLM[7]MemoChat[94]MemGPT[100]MPC[101]AutoGen[153]ChatDB[96]TiM[97]SCM[98]Voyager[99]GITM[93]JARVIS[159]LARP[161]CodeGenerationRecommendationMedicineFinanceScienceRTLFixer[142]GameGPT[144]ChatDev[1]MetaGPT[109]CodeAgent[114]RecAgent[95]InteRecAgent[108]RecMind[102]AgentCF[149]Huatuo[107]DoctorGLM[129]Radiology-GPT[132]Wangetal.\n[151]EHRAgent[152]ChatDoctor[115]InvestLM[113]TradingGPT[154]QuantAgent[155]FinMem[156]Koaetal.\n[157]Chemist-X[158]ChemDFM[160]MatChat[162]chatbot’sresponsesareconcatenatedtoformasequenceasmemory.\nWangetal.\n[145]infuserole-specificknowledgeandepisodememoriesintoLLM-basedagents,wherecontextQApairsareconcatenatedtoformepisodememory.\nZhaoetal.\n[146]aimtogeneratehuman-likeresponses,guidedbypersonalitytraitsextractedfromnarratives,whichcanbestoredandretrievedbyrelevanceandimportance.\nZhouetal.\n[147]generatecharacter-baseddialoguesfordifferentrolesandempowerLLM-basedagentswithcorrespondingstylesbySFT.\nSocialsimulationisbasicallyanextensionofrole-playing,whichfocusesmoreonmulti-agentmodeling.\nThememorymoduleisanimportantcomponentforsuchapplications,whichhelpstoaccuratelysimulatehumandynamicbehaviors.\nInpreviousstudies,Kaiyaetal.\n[148]proposeaSummarize-and-Forgetmemorymechanismforbetterself-monitoringinsocialscenarios.\nGaoetal.\n[2]focusonsocialnetworksimulationsystems.",
      "#memory_survey#PerspectiveofAgentApplications#memory_survey#PerspectiveofAgentApplications\nPerspectiveofAgentApplicationsInmanyapplications,memoryisanindispensablecomponentoftheagent.\nForexample,inaconver-sationalagent,thememorystoresinformationabouthistoricalconversations,whichisnecessaryfortheagenttogeneratethenextresponse.\nWithoutmemory,theagentdoesnotknowthecontext,andcannotcontinuetheconversation[94].\nInasimulationagent,memoryisofgreatimportancetomaketheagentconsistentlyfollowtheroleprofiles.\nWithoutmemory,theagentmayeasilystepoutoftheroleduringthesimulationprocess[95].\nBothoftheaboveexamplesshowthatthememoryisnotanoptionalcomponent,butisnecessaryfortheagentstoaccomplishgiventasks.\nIntheabovethreeperspectives,thefirstonerevealsthatthememorybuildsthecognitivebasisoftheagent.\nThesecondandthirdonesshowthatthememoryisnecessaryfortheagent’sevolvingprinciplesandapplications,whichprovideinsightsfordesigningagentswithmemorymechanisms.\n5",
      "#memory_survey#Memory-enhancedAgentApplications#memory_survey#Memory-enhancedAgentApplications\nMemory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nByleveragingexternalresources,theagentscanlearnfromcode-relatedknowledgeandstoreitintotheirmemory,therebyenhancingthecapabilitiesofcodegeneration.\nInaddition,thememorycanimprovethecontinuityandconsistencyincodegeneration.\nByintegratingcontextualmemory,theagentcanbetterunderstandtherequirementsforsoftwaredevelopment,therebyenhancingthecoherenceofthegeneratedcode.\nFurthermore,thememoryisalsocrucialfortheiterativeoptimizationofcode,asitcanidentifythedeveloper’stargetsbasedonthehistories.\n257.\n5RecommendationInthefieldofrecommendation,somepreviousworksfocusonsimulatingusersinrecommendersystems[95,108],wherethememorycanrepresenttheuserprofilesandhistoriesintherealworld.\nOtherstrytoimprovetheperformanceofrecommendation,orprovideotherformatsofrecommendationinterfaces[149,102].\nWangetal.\n[95]simulateuserbehaviorsinrecommendationscenariostogeneratedataforrecommendersystems,andtheagentsstorepastobservationsandinsightsintoahierarchicalmemory.\nInHuangetal.\n[108],thememoryinLLM-basedagentscanarchivetheuser’sconversationalhistoryoverextendedperiods,aswellascapturethemostrecentdialoguespertinenttothecurrentprompt,tosimulateinteractiverecommendersystems.\nItalsousesanactor-criticreflectiontoimprovetherobustnessofagents.\nItemagentsanduseragentsareequippedwithdifferentmemoriesin[149],whereitemagentsareendowedwithdynamicmemorymodulesdesignedtocaptureandpreserveinformationpertinenttotheirintrinsicattributesandtheinclinationsoftheiradopters.\nForuseragents,theadaptivememoryupdatingmechanismplaysapivotalroleinaligningtheagents’operationswithuserbehaviorsandpreferences.\nWangetal.\n[102]memorizeindividualizeduserinformationlikereviewsorratingsforitems,andacquiredomain-specificknowledgeandreal-timeinformationbywebsearchingtools.\nForbothsimulatingusersinrecommendersystemsandcapturingtheirpreferences,retainingper-sonalizedinformationthroughmemoryisessential.\nAcriticalchallengeliesinhowtoalignthepersonalizedinformationandfeedbackwithLLMs,andstorethemintothememoryofagents."
    ],
    [
      "#memory_survey#SubjectiveEvaluation#memory_survey#SubjectiveEvaluation\nTheformercanobtainabsoluteandquantitativeevaluationresults,whilethelattercanremovethelabelingnoiseswhenindependentlyscoringeachcandidate.\nInaddition,thegranularityoftheratingsshouldalsobecarefullydesigned.\nToocoarseratingsmaynoteffectivelydiscriminatethecapabilitiesofdifferentmemorymodules,whiletoofine-grainedonesmaybringmoreeffortfortheworkerstomakejudgments.\nIngeneral,subjectiveevaluationcanbeusedinawiderangeofscenarios,whereonejustneedstodefinetheevaluationaspectsandletrecruitedworkersmakejudgments.\nThismethodisusuallymoreexplainablesincetheworkerscanprovidethereasonsfortheirjudgments.\nHowever,subjectiveevaluationiscostlyduetotheneedtoemployhumanevaluators.\nAdditionally,differentgroupsofevaluatorsmayhavevariousbiases,makingtheresultsdifficulttoreproduceandcompare.\n6.\n1.\n2",
      "#memory_survey#SubjectiveEvaluation#memory_survey#SubjectiveEvaluation\nSubjectiveEvaluationInsubjectiveevaluation,therearetwokeyproblems,thatis,(1)whataspectsshouldbeevaluatedand(2)howtoconducttheevaluationprocess.\nTobeginwith,thefollowingtwoaspectsarethemostcommonperspectivesleveragedtoevaluatethememorymodule.\nCoherence.\nThisaspectreferstowhethertherecalledmemoryisnaturalandsuitableforthecurrentcontext.\nForexample,iftheagentismakingaplanforAlice’stravel,thememoryshouldberelatedtoherpreferencefortravelingratherthanworking.\nInpreviousworks,Modarressietal.\n[7]studywhetherthememorymodulecouldprovideproperreferencesamongtheever-changingknowledge.\nLiangetal.\n[98]presentsomeexamplestodemonstratetherelationbetweenthecurrentqueryandhistoricalmemory.\nZhongetal.\n[6]andLiuetal.\n[97]assessthecoherenceofresponsesthatintegratecontextandretrievedmemorybyscoringlabels.\nLeeetal.\n[101]focusonthecontradictionbetweentherecalledmemoryandcontexts.\nRationality.\nThisaspectaimstoevaluatewhethertherecalledmemoryisreasonable.\nForexample,iftheagentisaskedtoanswer\"WhereistheSummerPalace\",therecalledmemoryshouldbe\"TheSummerPalaceisinBeijing\"ratherthan\"TheSummerPalaceisontheMoon\".\nInpreviousworks,Leeetal.\n[101]askcrowdworkerstodirectlyscoretherationalityoftheretrievedmemory.\nZhongetal.\n[6]andLiuetal.\n[97]recruithumanevaluatorstocheckifthememorycontainsreasonableanswersforthecurrentquestion.\nAsforhowtoconducttheevaluationprocess,therearetwoimportantproblems.\nThefirstoneishowtoselectthehumanevaluators.\nIngeneral,theevaluatorsshouldbefamiliarwiththeevaluationtask,whichensuresthatthelabelingresultsareconvincingandreliable.\nInaddition,thebackgroundsoftheevaluatorsshouldbediversetoremovesubjectivebiasesofspecifichumangroups.\nThesecondproblemishowtolabeltheoutputsofthememorymodule.\nUsually,onecaneitherdirectlyscorethe20results[6]ormakecomparisonsbetweentwocandidates[95].\nTheformercanobtainabsoluteandquantitativeevaluationresults,whilethelattercanremovethelabelingnoiseswhenindependentlyscoringeachcandidate.\nInaddition,thegranularityoftheratingsshouldalsobecarefullydesigned.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nInaddition,thegranularityoftheratingsshouldalsobecarefullydesigned.\nToocoarseratingsmaynoteffectivelydiscriminatethecapabilitiesofdifferentmemorymodules,whiletoofine-grainedonesmaybringmoreeffortfortheworkerstomakejudgments.\nIngeneral,subjectiveevaluationcanbeusedinawiderangeofscenarios,whereonejustneedstodefinetheevaluationaspectsandletrecruitedworkersmakejudgments.\nThismethodisusuallymoreexplainablesincetheworkerscanprovidethereasonsfortheirjudgments.\nHowever,subjectiveevaluationiscostlyduetotheneedtoemployhumanevaluators.\nAdditionally,differentgroupsofevaluatorsmayhavevariousbiases,makingtheresultsdifficulttoreproduceandcompare.\n6.\n1.\n2ObjectiveEvaluationInobjectiveevaluation,previousworkusuallydefinesnumericmetricstoevaluatetheeffectivenessandefficiencyofthememorymodule.\nResultCorrectness.\nThismetricmeasureswhethertheagentcansuccessfullyanswerpre-definedquestionsdirectlybasedonthememorymodule.\nForexample,thequestioncouldbe\"WheredidAlicegotoday?\n\"withtwochoices\"A:theSummerPalace\"and\"B:theGreatWall\".\nThen,theagentshouldchoosethecorrectanswerbasedontheproblemanditsmemory.\nTheagent-generatedanswerwillbecomparedwiththegroundtruth.\nFormally,theaccuracycanbecalculatedasCorrectness=1NN(cid:88)i=1I[ai=ˆai],whereNisthenumberofproblems,airepresentsthegroundtruthforthei-thproblem,ˆaimeanstheanswergivenbytheagent,andI[ai=ˆai]isthematchingfunctioncommonlyrepresentedasI[ai=ˆai]=(cid:26)10ifai=ˆai,ifai̸=ˆai.\nInpreviousworks,Huetal.\n[96]constructquestionsfrompasthistorieswithannotatedgroundtruthsandcalculatetheaccuracyofwhethertherecalledmemorycouldmatchthecorrectanswers.\nSimilarly,Packeretal.\n[100]generatequestionsandanswersthatcanonlybederivedfrompastsessions,andcomparetheresponsesfromtheagentswiththegroundtruthstocalculatetheaccuracy.\nReferenceAccuracy.\nThismetricevaluateswhethertheagentcandiscoverrelevantmemorycontentstoanswerthequestions.\nDifferentfromtheabovemetric,whichfocusesonthefinalresults,referenceaccuracycaresmoreabouttheintermediateinformationtosupporttheagent’sfinaldecisions.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTosomeextent,thememoryreadingandwritingoperationsarecollaborative,andtheformsofmemorywritinggreatlyinfluencethemethodsofmemoryreading.\nFortheformsoftextual19Figure5:Anoverviewoftheevaluationmethodsofthememorymodule.\nmemory,mostpreviousworksusethetextsimilarityandotherauxiliaryinformationforreading.\nFortheformsofparametricmemory,existingmodelsmayjustutilizetheupdatedparametersforinference,whichcanbeseenasanimplicitreadingprocess.\n6HowtoEvaluatetheMemoryinLLM-basedAgentHowtoeffectivelyevaluatethememorymoduleremainsanopenproblem,wherediverseevaluationstrategieshavebeenproposedinpreviousworksaccordingtodifferentapplications.\nToclearlyshowthecommonideasofdifferentevaluationmethods,inthissection,wesummarizeageneralframework,whichincludestwobroadevaluationstrategies(seeFigure5foranoverview),thatis,(1)directevaluation,whichindependentlymeasuresthecapabilityofthememorymodule.\n(2)indirectevaluation,whichevaluatesthememorymoduleviaend-to-endagenttasks.\nIfthetaskscanbeeffectivelyaccomplished,thememorymoduleisdemonstratedtobeuseful.\n6.\n1DirectEvaluationThistypeofapproachesregardsthememoryoftheagentsasastand-alonecomponentandevaluatesitseffectivenessindependently.\nPreviousstudiescanbecategorizedintotwoclasses:subjectiveevaluationandobjectiveevaluation.\nThesubjectiveevaluationaimstomeasurememoryeffectivenessbasedonhumanjudgments,whichcanbewidelyusedinthescenariosthatlackobjectivegroundtruths.\nObjectiveevaluationassessesmemoryeffectivenessbasedonnumericalmetrics,whichmakesiteasytocomparedifferentmemorymodules.\n6.\n1.\n1SubjectiveEvaluationInsubjectiveevaluation,therearetwokeyproblems,thatis,(1)whataspectsshouldbeevaluatedand(2)howtoconducttheevaluationprocess.\nTobeginwith,thefollowingtwoaspectsarethemostcommonperspectivesleveragedtoevaluatethememorymodule.\nCoherence.\nThisaspectreferstowhethertherecalledmemoryisnaturalandsuitableforthecurrentcontext.\nForexample,iftheagentismakingaplanforAlice’stravel,thememoryshouldberelatedtoherpreferencefortravelingratherthanworking.\nInpreviousworks,Modarressietal.",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\nSurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.\n[70]presentthefirstcomprehensivesurveytosummarizethebackground,evolutionpaths,modelarchitectures,trainingmethodologies,andevaluationstrategiesofLLMs.\nHadietal.\n[71]andMinetal.\n[72]alsoconductLLMsurveysfromtheholisticview,which,however,providedifferenttaxonomiesandunderstandingsonLLMs.\nFollowingthesesurveys,peoplediveintospecificaspectsofLLMsandreviewthecorrespondingmilestonestudiesandkeytechnologies.\nTheseaspectscanbeclassifiedintofourcategoriesincludingthefundamentalproblems,evaluation,applications,andchallengesofLLMs.\nFundamentalproblems.\nThesurveysinthiscategoryaimtosummarizetechniquesthatcanbeleveragedtotacklefundamentalproblemsofLLMs.\nSpecifically,Zhangetal.\n[8]provideacomprehensivesurveyonthemethodsofsupervisedfine-tuning,whichisakeytechniqueforbettertrainingLLMs.\nShenetal.\n[9],Wangetal.\n[10]andLiuetal.\n[11]presentsurveysonthealignmentofLLMs,whichisakeyrequirementforLLMstoproduceoutputsconsistentwithhumanvalues.\nGaoetal.\n[12]proposeasurveyontheretrieval-augmentedgeneration(RAG)capabilityofLLMs,whichiskeytoprovidingLLMswithfactualandup-to-dateknowledgeandremovinghallucinations.\nQinetal.\n[18]summarizethestate-of-the-artmethodsonenablingLLMstoleverageexternaltools,whichisfundamentalforLLMstoexpandtheircapabilityindomainsthatrequirespecializedknowledge.\nWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16]andZhangetal.\n[17]presentsurveysonthedirectionofLLMknowledgeediting,whichisimportantforcustomizingLLMstosatisfyspecificrequirements.\nHuangetal.\n[19],Wangetal.\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal."
    ],
    [
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[35]ZishanGuo,RenrenJin,ChuangLiu,YufeiHuang,DanShi,LinhaoYu,YanLiu,JiaxuanLi,BojianXiong,DeyiXiong,etal.\nEvaluatinglargelanguagemodels:Acomprehensivesurvey.\narXivpreprintarXiv:2310.\n19736,2023.\n[36]JingfengYang,HongyeJin,RuixiangTang,XiaotianHan,QizhangFeng,HaomingJiang,BingYin,andXiaHu.\nHarnessingthepowerofllmsinpractice:Asurveyonchatgptandbeyond.\narXivpreprintarXiv:2304.\n13712,2023.\n30[37]YutaoZhu,HuayingYuan,ShutingWang,JiongnanLiu,WenhanLiu,ChenlongDeng,ZhichengDou,andJi-RongWen.\nLargelanguagemodelsforinformationretrieval:Asurvey.\narXivpreprintarXiv:2308.\n07107,2023.\n[38]DerongXu,WeiChen,WenjunPeng,ChaoZhang,TongXu,XiangyuZhao,XianWu,YefengZheng,andEnhongChen.\nLargelanguagemodelsforgenerativeinformationextraction:Asurvey.\narXivpreprintarXiv:2312.\n17617,2023.\n[39]AngelaFan,BelizGokkaya,MarkHarman,MityaLyubarskiy,ShubhoSengupta,ShinYoo,andJieMZhang.\nLargelanguagemodelsforsoftwareengineering:Surveyandopenproblems.\narXivpreprintarXiv:2310.\n03533,2023.\n[40]JunjieWang,YuchaoHuang,ChunyangChen,ZheLiu,SongWang,andQingWang.\nSoftwaretestingwithlargelanguagemodels:Survey,landscape,andvision.\nIEEETransactionsonSoftwareEngineering,2024.\n[41]ZibinZheng,KaiwenNing,YanlinWang,JingwenZhang,DewuZheng,MingxiYe,andJiachiChen.\nAsurveyoflargelanguagemodelsforcode:Evolution,benchmarking,andfuturetrends.\narXivpreprintarXiv:2311.\n10372,2023.\n[42]FanlongZeng,WenshengGan,YonghengWang,NingLiu,andPhilipSYu.\nLargelanguagemodelsforrobotics:Asurvey.\narXivpreprintarXiv:2311.\n07226,2023.\n[43]CanCui,YunshengMa,XuCao,WenqianYe,YangZhou,KaizhaoLiang,JintaiChen,JuanwuLu,ZichongYang,Kuei-DaLiao,etal.\nAsurveyonmultimodallargelanguagemodelsforautonomousdriving.\nInProceedingsoftheIEEE/CVFWinterConferenceonApplicationsofComputerVision,pages958–979,2024.\n[44]ZhenjieYang,XiaosongJia,HongyangLi,andJunchiYan.\nAsurveyoflargelanguagemodelsforautonomousdriving.\narXivpreprintarXiv:2311.\n01043,2023.\n[45]KaiHe,RuiMao,QikaLin,YuchengRuan,XiangLan,MenglingFeng,andErikCambria.",
      "#memory_survey#RelatedSurveys#memory_survey#RelatedSurveys\nRelatedSurveysInthepasttwoyears,LLMshaveattractedmuchattentionfromtheacademicandindustrycommu-nities.\nTosystemicallysummarizethestudiesinthisfield,researchershavewrittenalotofsurveypapers.\nInthissection,webrieflyreviewthesesurveys(seeFigure2foranoverview),highlightingtheirmajorfocusesandcontributionstobetterpositionourstudy.\n2.\n1",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[63]HaiyanZhao,HanjieChen,FanYang,NinghaoLiu,HuiqiDeng,HengyiCai,ShuaiqiangWang,DaweiYin,andMengnanDu.\nExplainabilityforlargelanguagemodels:Asurvey.\nACMTransactionsonIntelligentSystemsandTechnology,2023.\n[64]YifanYao,JinhaoDuan,KaidiXu,YuanfangCai,EricSun,andYueZhang.\nAsurveyonlargelanguagemodel(llm)securityandprivacy:Thegood,thebad,andtheugly.\narXivpreprintarXiv:2312.\n02003,1,2023.\n[65]ErfanShayegani,MdAbdullahAlMamun,YuFu,PedramZaree,YueDong,andNaelAbu-Ghazaleh.\nSurveyofvulnerabilitiesinlargelanguagemodelsrevealedbyadversarialattacks.\narXivpreprintarXiv:2310.\n10844,2023.\n[66]SethNeelandPeterChang.\nPrivacyissuesinlargelanguagemodels:Asurvey.\narXivpreprintarXiv:2312.\n06717,2023.\n[67]VictoriaSmith,AliShahinShamsabadi,CarolynAshurst,andAdrianWeller.\nIdentifyingandmitigatingprivacyrisksstemmingfromlanguagemodels:Asurvey.\narXivpreprintarXiv:2310.\n01424,2023.\n[68]ZhichenDong,ZhanhuiZhou,ChaoYang,JingShao,andYuQiao.\nAttacks,defensesandevaluationsforllmconversationsafety:Asurvey.\narXivpreprintarXiv:2402.\n09283,2024.\n[69]BadhanChandraDas,MHadiAmini,andYanzhaoWu.\nSecurityandprivacychallengesoflargelanguagemodels:Asurvey.\narXivpreprintarXiv:2402.\n00888,2024.\n[70]WayneXinZhao,KunZhou,JunyiLi,TianyiTang,XiaoleiWang,YupengHou,YingqianMin,BeichenZhang,JunjieZhang,ZicanDong,etal.\nAsurveyoflargelanguagemodels.\narXivpreprintarXiv:2303.\n18223,2023.\n32[71]MuhammadUsmanHadi,RizwanQureshi,AbbasShah,MuhammadIrfan,AnasZafar,MuhammadBilalShaikh,NaveedAkhtar,JiaWu,SeyedaliMirjalili,etal.\nAsurveyonlargelanguagemodels:Applications,challenges,limitations,andpracticalusage.\nAuthoreaPreprints,2023.\n[72]BonanMin,HayleyRoss,EliorSulem,AmirPouranBenVeyseh,ThienHuuNguyen,OscarSainz,EnekoAgirre,IlanaHeintz,andDanRoth.\nRecentadvancesinnaturallanguageprocessingvialargepre-trainedlanguagemodels:Asurvey.\nACMComputingSurveys,56(2):1–40,2023.\n[73]GrégoireMialon,RobertoDessì,MariaLomeli,ChristoforosNalmpantis,RamPasunuru,RobertaRaileanu,BaptisteRozière,TimoSchick,JaneDwivedi-Yu,AsliCelikyilmaz,etal.\nAugmentedlanguagemodels:asurvey.",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal.\n[47]summarizetheapplicationsofLLMsinmedicine.\nLietal.\n[48]focusontheapplicationsofLLMsinfinance.\nHeetal.\n[49]reviewthemodelsonleveragingLLMstoimprovethedevelopmentofpsychology.\n5SupervisedFine-tuningZhangetal.\n[8].\nAlignmentShenetal.\n[9],Wangetal.\n[10],Liuetal.\n[11].\nRetrievalAugmentationGaoetal.\n[12].\nKnowledgeEditingWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16],Zhangetal.\n[17].\nFundamentalProblemsToolUsageQinetal.\n[18].\nLong-contextMultimodalEfficiencyHuangetal.\n[19],Wangetal.\n[20],Pawaretal.\n[21].\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24],Yinetal.\n[25].\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28,28],Xuetal.\n[29],Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32],Parketal.\n[33].\nEvaluationChangetal.\n[34],Guoetal.\n[35].\nInformationProcessingSoftwareEngineeringYangetal.\n[36],Zhuetal.\n[37],Xuetal.\n[38].\nFanetal.\n[39],Wangetal.\n[40],Zhengetal.\n[41].\nRoboticsZengetal.\n[42].\nApplicationsAutonomousDrivingCuietal.\n[43],Yangetal.\n[44].\nLLMs[70–73]MedecineFinancePsychologyHeetal.\n[45],Zhouetal.\n[46],Wangetal.\n[47].\nLietal.\n[48].\nHeetal.\n[49].\nRecommendationLietal.\n[50],Linetal.\n[51],Wangetal.\n[52].\nHallucinationZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Ton-moyetal.\n[58],Jiangetal.\n[59].\nChallengesBias&FairnessGallegosetal.\n[60],Koteketal.\n[61],Lietal.\n[62].\nExplainabilityZhaoetal.\n[63].\nSecurityYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68],Dasetal.\n[69].\nPlanningHuangetal.\n[74].\nFundamentalProblemsMemoryOurSurvey.\nMulti-agentsGuoetal.\n[75].\nLLM-basedAgent[3,4,77–80]EvaluationApplicationsChallengesLietal.\n[76].\nFigure2:TheorganizationofrelatedsurveysonLLMsandLLM-basedagents.\n6Challenges.\nThesurveysinthiscategoryfocusontrustworthinessinLLMs,suchashallucination,bias,unfairness,explainability,security,andprivacy.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[17]NingyuZhang,YunzhiYao,BozhongTian,PengWang,ShuminDeng,MengruWang,ZekunXi,ShengyuMao,JintianZhang,YuanshengNi,etal.\nAcomprehensivestudyofknowledgeeditingforlargelanguagemodels.\narXivpreprintarXiv:2401.\n01286,2024.\n[18]YujiaQin,ShengdingHu,YankaiLin,WeizeChen,NingDing,GanquCui,ZheniZeng,YufeiHuang,ChaojunXiao,ChiHan,etal.\nToollearningwithfoundationmodels.\narXivpreprintarXiv:2304.\n08354,2023.\n[19]YunpengHuang,JingweiXu,ZixuJiang,JunyuLai,ZenanLi,YuanYao,TaolueChen,LijuanYang,ZhouXin,andXiaoxingMa.\nAdvancingtransformerarchitectureinlong-contextlargelanguagemodels:Acomprehensivesurvey.\narXivpreprintarXiv:2311.\n12351,2023.\n29[20]XindiWang,MahsaSalmani,ParsaOmidi,XiangyuRen,MehdiRezagholizadeh,andAr-maghanEshaghi.\nBeyondthelimits:Asurveyoftechniquestoextendthecontextlengthinlargelanguagemodels.\narXivpreprintarXiv:2402.\n02244,2024.\n[21]SauravPawar,SMTonmoy,SMZaman,VinijaJain,AmanChadha,andAmitavaDas.\nThewhat,why,andhowofcontextlengthextensiontechniquesinlargelanguagemodels–adetailedsurvey.\narXivpreprintarXiv:2401.\n07872,2024.\n[22]JiayangWu,WenshengGan,ZefengChen,ShichengWan,andSYuPhilip.\nMultimodallargelanguagemodels:Asurvey.\nIn2023IEEEInternationalConferenceonBigData(BigData),pages2247–2256.\nIEEE,2023.\n[23]ShezhengSong,XiaopengLi,andShashaLi.\nHowtobridgethegapbetweenmodalities:Acomprehensivesurveyonmultimodallargelanguagemodel.\narXivpreprintarXiv:2311.\n07594,2023.\n[24]DavideCaffagni,FedericoCocchi,LucaBarsellotti,NicholasMoratelli,SaraSarto,LorenzoBaraldi,MarcellaCornia,andRitaCucchiara.\nThe(r)evolutionofmultimodallargelanguagemodels:Asurvey.\narXivpreprintarXiv:2402.\n12451,2024.\n[25]ShukangYin,ChaoyouFu,SiruiZhao,KeLi,XingSun,TongXu,andEnhongChen.\nAsurveyonmultimodallargelanguagemodels.\narXivpreprintarXiv:2306.\n13549,2023.\n[26]GuangjiBai,ZhengChai,ChenLing,ShiyuWang,JiayingLu,NanZhang,TingweiShi,ZiyangYu,MengdanZhu,YifeiZhang,etal.\nBeyondefficiency:Asystematicsurveyofresource-efficientlargelanguagemodels.\narXivpreprintarXiv:2401.\n00625,2024.",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\nSurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.\n[70]presentthefirstcomprehensivesurveytosummarizethebackground,evolutionpaths,modelarchitectures,trainingmethodologies,andevaluationstrategiesofLLMs.\nHadietal.\n[71]andMinetal.\n[72]alsoconductLLMsurveysfromtheholisticview,which,however,providedifferenttaxonomiesandunderstandingsonLLMs.\nFollowingthesesurveys,peoplediveintospecificaspectsofLLMsandreviewthecorrespondingmilestonestudiesandkeytechnologies.\nTheseaspectscanbeclassifiedintofourcategoriesincludingthefundamentalproblems,evaluation,applications,andchallengesofLLMs.\nFundamentalproblems.\nThesurveysinthiscategoryaimtosummarizetechniquesthatcanbeleveragedtotacklefundamentalproblemsofLLMs.\nSpecifically,Zhangetal.\n[8]provideacomprehensivesurveyonthemethodsofsupervisedfine-tuning,whichisakeytechniqueforbettertrainingLLMs.\nShenetal.\n[9],Wangetal.\n[10]andLiuetal.\n[11]presentsurveysonthealignmentofLLMs,whichisakeyrequirementforLLMstoproduceoutputsconsistentwithhumanvalues.\nGaoetal.\n[12]proposeasurveyontheretrieval-augmentedgeneration(RAG)capabilityofLLMs,whichiskeytoprovidingLLMswithfactualandup-to-dateknowledgeandremovinghallucinations.\nQinetal.\n[18]summarizethestate-of-the-artmethodsonenablingLLMstoleverageexternaltools,whichisfundamentalforLLMstoexpandtheircapabilityindomainsthatrequirespecializedknowledge.\nWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16]andZhangetal.\n[17]presentsurveysonthedirectionofLLMknowledgeediting,whichisimportantforcustomizingLLMstosatisfyspecificrequirements.\nHuangetal.\n[19],Wangetal.\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[44]ZhenjieYang,XiaosongJia,HongyangLi,andJunchiYan.\nAsurveyoflargelanguagemodelsforautonomousdriving.\narXivpreprintarXiv:2311.\n01043,2023.\n[45]KaiHe,RuiMao,QikaLin,YuchengRuan,XiangLan,MenglingFeng,andErikCambria.\nAsurveyoflargelanguagemodelsforhealthcare:fromdata,technology,andapplicationstoaccountabilityandethics.\narXivpreprintarXiv:2310.\n05694,2023.\n[46]HongjianZhou,BoyangGu,XinyuZou,YiruLi,SamSChen,PeilinZhou,JunlingLiu,YiningHua,ChengfengMao,XianWu,etal.\nAsurveyoflargelanguagemodelsinmedicine:Progress,application,andchallenge.\narXivpreprintarXiv:2311.\n05112,2023.\n[47]BenyouWang,QianqianXie,JiahuanPei,ZhihongChen,PrayagTiwari,ZhaoLi,andJieFu.\nPre-trainedlanguagemodelsinbiomedicaldomain:Asystematicsurvey.\nACMComputingSurveys,56(3):1–52,2023.\n[48]YinhengLi,ShaofeiWang,HanDing,andHangChen.\nLargelanguagemodelsinfinance:Asurvey.\nInProceedingsoftheFourthACMInternationalConferenceonAIinFinance,pages374–382,2023.\n[49]TianyuHe,GuanghuiFu,YijingYu,FanWang,JianqiangLi,QingZhao,ChangweiSong,HongzhiQi,DanLuo,HuijingZou,etal.\nTowardsapsychologicalgeneralistai:Asur-veyofcurrentapplicationsoflargelanguagemodelsandfutureprospects.\narXivpreprintarXiv:2312.\n04578,2023.\n[50]LeiLi,YongfengZhang,DugangLiu,andLiChen.\nLargelanguagemodelsforgenerativerecommendation:Asurveyandvisionarydiscussions.\narXivpreprintarXiv:2309.\n01157,2023.\n[51]JianghaoLin,XinyiDai,YunjiaXi,WeiwenLiu,BoChen,XiangyangLi,ChenxuZhu,HuifengGuo,YongYu,RuimingTang,etal.\nHowcanrecommendersystemsbenefitfromlargelanguagemodels:Asurvey.\narXivpreprintarXiv:2306.\n05817,2023.\n[52]WenjieWang,XinyuLin,FuliFeng,XiangnanHe,andTat-SengChua.\nGenerativerecommen-dation:Towardsnext-generationrecommenderparadigm.\narXivpreprintarXiv:2304.\n03516,2023.\n31[53]YueZhang,YafuLi,LeyangCui,DengCai,LemaoLiu,TingchenFu,XintingHuang,EnboZhao,YuZhang,YulongChen,etal.\nSiren’ssongintheaiocean:asurveyonhallucinationinlargelanguagemodels.\narXivpreprintarXiv:2309.\n01219,2023.",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32]andParketal.\n[33]systematicallyreviewthetechniquesofmodelcompression.\nDingetal.\n[81]andXuetal.\n[29]analyzeandconcludethestudiesonparameterefficientfine-tuning.\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28]andDingetal.\n[81]putmorefocusesontheefficiencyofresourceutilizationinageneralsense.\nEvaluation.\nThesurveysinthiscategoryfocusonhowtoevaluatethecapabilityofLLMs.\nSpecifi-cally,Changetal.\n[34]comprehensivelysummarizetheevaluationmethodsfromanoverallperspec-tive.\nItencompassesdifferentevaluationtasks,methods,andbenchmarks,whichserveascriticalpartsinassessingLLMperformances.\nGuoetal.\n[35]caremoreabouttheevaluationtargetsanddescribehowtoevaluatetheknowledge,alignment,andsafetycontrolcapabilitiesofLLMs,whichsupplementevaluationmetricsbeyondperformance.\nApplications.\nThesurveysinthiscategoryaimtosummarizemodelsthatleverageLLMstoimprovedifferentapplications.\nMoreconcretely,Zhuetal.\n[37]focusonthefieldofinformationretrieval(IR)andsummarizestudiesonLLM-basedqueryprocesses.\nXuetal.\n[38]paymoreattentiontoinformationextraction(IE)andprovidecomprehensivetaxonomiesforLLM-basedmodelsinthisfield.\nLietal.\n[50],Linetal.\n[51]andWangetal.\n[52]discusstheapplicationsofLLMsinthefieldofrecommendersystem,wheretheyutilizeagentstogeneratedataandproviderecommendations.\nFanetal.\n[39],Wangetal.\n[40],andZhengetal.\n[41]concentrateonhowLLMscanbenefitsoftwareengineering(SE)intermsofsoftwaredesign,development,andtesting.\nZengetal.\n[42]summarizeLLM-basedmethodsinthefieldofrobotics.\nCuietal.\n[43]andYangetal.\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[26]GuangjiBai,ZhengChai,ChenLing,ShiyuWang,JiayingLu,NanZhang,TingweiShi,ZiyangYu,MengdanZhu,YifeiZhang,etal.\nBeyondefficiency:Asystematicsurveyofresource-efficientlargelanguagemodels.\narXivpreprintarXiv:2401.\n00625,2024.\n[27]ZhongweiWan,XinWang,CheLiu,SamiulAlam,YuZheng,ZhongnanQu,ShenYan,YiZhu,QuanluZhang,MosharafChowdhury,etal.\nEfficientlargelanguagemodels:Asurvey.\narXivpreprintarXiv:2312.\n03863,1,2023.\n[28]XupengMiao,GabrieleOliaro,ZhihaoZhang,XinhaoCheng,HongyiJin,TianqiChen,andZhihaoJia.\nTowardsefficientgenerativelargelanguagemodelserving:Asurveyfromalgorithmstosystems.\narXivpreprintarXiv:2312.\n15234,2023.\n[29]LinglingXu,HaoranXie,Si-ZhaoJoeQin,XiaohuiTao,andFuLeeWang.\nParameter-efficientfine-tuningmethodsforpretrainedlanguagemodels:Acriticalreviewandassessment.\narXivpreprintarXiv:2312.\n12148,2023.\n[30]XunyuZhu,JianLi,YongLiu,CanMa,andWeipingWang.\nAsurveyonmodelcompressionforlargelanguagemodels.\narXivpreprintarXiv:2308.\n07633,2023.\n[31]CanwenXuandJulianMcAuley.\nAsurveyonmodelcompressionandaccelerationforpretrainedlanguagemodels.\nInProceedingsoftheAAAIConferenceonArtificialIntelligence,volume37,pages10566–10575,2023.\n[32]WenxiaoWang,WeiChen,YicongLuo,YongliuLong,ZhengkaiLin,LiyeZhang,BinbinLin,DengCai,andXiaofeiHe.\nModelcompressionandefficientinferenceforlargelanguagemodels:Asurvey.\narXivpreprintarXiv:2402.\n09748,2024.\n[33]SeungcheolPark,JaehyeonChoi,SojinLee,andUKang.\nAcomprehensivesurveyofcompressionalgorithmsforlanguagemodels.\narXivpreprintarXiv:2401.\n15347,2024.\n[34]YupengChang,XuWang,JindongWang,YuanWu,LinyiYang,KaijieZhu,HaoChen,XiaoyuanYi,CunxiangWang,YidongWang,etal.\nAsurveyonevaluationoflargelanguagemodels.\nACMTransactionsonIntelligentSystemsandTechnology,2023.\n[35]ZishanGuo,RenrenJin,ChuangLiu,YufeiHuang,DanShi,LinhaoYu,YanLiu,JiaxuanLi,BojianXiong,DeyiXiong,etal.\nEvaluatinglargelanguagemodels:Acomprehensivesurvey.\narXivpreprintarXiv:2310.\n19736,2023.\n[36]JingfengYang,HongyeJin,RuixiangTang,XiaotianHan,QizhangFeng,HaomingJiang,BingYin,andXiaHu.",
      "#memory_survey#Introduction#memory_survey#Introduction\n(2)WesystematicallysummarizeexistingstudiesondesigningandevaluatingthememorymoduleinLLM-basedagents,providingcleartaxonomiesandintuitiveinsights.\n(3)Wepresenttypicalagentapplicationstoshowtheimportanceofthememorymoduleindifferentscenarios.\n(4)Weanalyzethekeylimitationsofexistingmemorymodulesandshowpotentialsolutionsforinspiringfuturestudies.\nToourknowledge,thisisthefirstsurveyonthememorymechanismofLLM-basedagents.\nTherestofthissurveyisorganizedasfollows.\nFirst,weprovideasystematicalmeta-surveyforthefieldsofLLMsandLLM-basedagentsinSection2,categorizingdifferentsurveysandsummarizingtheirkeycontributions.\nThen,wediscusstheproblemsof“whatis”,“whydoweneed”and“howtoimplementandevaluate”thememorymoduleinLLM-basedagentsinSection3to6.\nNext,weshowtheapplicationsofmemory-enhancedagentsinSection7.\nThediscussionsofthelimitationsofexistingworkandfuturedirectionscomeatlastinSection8andSection9.\n42",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n31[53]YueZhang,YafuLi,LeyangCui,DengCai,LemaoLiu,TingchenFu,XintingHuang,EnboZhao,YuZhang,YulongChen,etal.\nSiren’ssongintheaiocean:asurveyonhallucinationinlargelanguagemodels.\narXivpreprintarXiv:2309.\n01219,2023.\n[54]LeiHuang,WeijiangYu,WeitaoMa,WeihongZhong,ZhangyinFeng,HaotianWang,Qian-glongChen,WeihuaPeng,XiaochengFeng,BingQin,etal.\nAsurveyonhallucinationinlargelanguagemodels:Principles,taxonomy,challenges,andopenquestions.\narXivpreprintarXiv:2311.\n05232,2023.\n[55]VipulaRawte,AmitSheth,andAmitavaDas.\nAsurveyofhallucinationinlargefoundationmodels.\narXivpreprintarXiv:2309.\n05922,2023.\n[56]HongbinYe,TongLiu,AijiaZhang,WeiHua,andWeiqiangJia.\nCognitivemirage:Areviewofhallucinationsinlargelanguagemodels.\narXivpreprintarXiv:2309.\n06794,2023.\n[57]ZiweiJi,NayeonLee,RitaFrieske,TiezhengYu,DanSu,YanXu,EtsukoIshii,YeJinBang,AndreaMadotto,andPascaleFung.\nSurveyofhallucinationinnaturallanguagegeneration.\nACMComputingSurveys,55(12):1–38,2023.\n[58]SMTonmoy,SMZaman,VinijaJain,AnkuRani,VipulaRawte,AmanChadha,andAmitavaDas.\nAcomprehensivesurveyofhallucinationmitigationtechniquesinlargelanguagemodels.\narXivpreprintarXiv:2401.\n01313,2024.\n[59]XuhuiJiang,YuxingTian,FengruiHua,ChengjinXu,YuanzhuoWang,andJianGuo.\nAsurveyonlargelanguagemodelhallucinationviaacreativityperspective.\narXivpreprintarXiv:2402.\n06647,2024.\n[60]IsabelOGallegos,RyanARossi,JoeBarrow,MdMehrabTanjim,SungchulKim,FranckDernoncourt,TongYu,RuiyiZhang,andNesreenKAhmed.\nBiasandfairnessinlargelanguagemodels:Asurvey.\narXivpreprintarXiv:2309.\n00770,2023.\n[61]HadasKotek,RikkerDockum,andDavidSun.\nGenderbiasandstereotypesinlargelanguagemodels.\nInProceedingsofTheACMCollectiveIntelligenceConference,pages12–24,2023.\n[62]YingjiLi,MengnanDu,RuiSong,XinWang,andYingWang.\nAsurveyonfairnessinlargelanguagemodels.\narXivpreprintarXiv:2308.\n10149,2023.\n[63]HaiyanZhao,HanjieChen,FanYang,NinghaoLiu,HuiqiDeng,HengyiCai,ShuaiqiangWang,DaweiYin,andMengnanDu.\nExplainabilityforlargelanguagemodels:Asurvey.\nACMTransactionsonIntelligentSystemsandTechnology,2023.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[167]ZhangchengQiang,WeiqingWang,andKerryTaylor.\nAgent-om:Leveraginglargelanguagemodelsforontologymatching.\narXivpreprintarXiv:2312.\n00326,2023.\n[168]LichengWen,DaochengFu,XinLi,XinyuCai,TaoMa,PinlongCai,MinDou,BotianShi,LiangHe,andYuQiao.\nDilu:Aknowledge-drivenapproachtoautonomousdrivingwithlargelanguagemodels.\narXivpreprintarXiv:2309.\n16292,2023.\n[169]ZhitaoWang,WeiWang,ZiraoLi,LongWang,CanYi,XinjieXu,LuyangCao,HanjingSu,ShouzhiChen,andJunZhou.\nXuat-copilot:Multi-agentcollaborativesystemforautomateduseracceptancetestingwithlargelanguagemodel.\narXivpreprintarXiv:2401.\n02705,2024.\n[170]YongchaoChen,JacobArkin,YangZhang,NicholasRoy,andChuchuFan.\nScalablemulti-robotcollaborationwithlargelanguagemodels:Centralizedordecentralizedsystems?\narXivpreprintarXiv:2309.\n15943,2023.\n[171]ZhaoMandi,ShreeyaJain,andShuranSong.\nRoco:Dialecticmulti-robotcollaborationwithlargelanguagemodels.\narXivpreprintarXiv:2307.\n04738,2023.\n[172]JonathanLight,MinCai,ShengShen,andZiniuHu.\nFromtexttotactic:Evaluatingllmsplayingthegameofavalon.\narXivpreprintarXiv:2310.\n05036,2023.\n38[173]BingLiu.\nLifelongmachinelearning:aparadigmforcontinuouslearning.\nFrontiersofComputerScience,11:359–361,2017.\n[174]GatiVAher,RosaIArriaga,andAdamTaumanKalai.\nUsinglargelanguagemodelstosimulatemultiplehumansandreplicatehumansubjectstudies.\nInInternationalConferenceonMachineLearning,pages337–371.\nPMLR,2023.\n39",
      "#memory_survey#Recommendation#memory_survey#Recommendation\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32]andParketal.\n[33]systematicallyreviewthetechniquesofmodelcompression.\nDingetal.\n[81]andXuetal.\n[29]analyzeandconcludethestudiesonparameterefficientfine-tuning.\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28]andDingetal.\n[81]putmorefocusesontheefficiencyofresourceutilizationinageneralsense.\nEvaluation.\nThesurveysinthiscategoryfocusonhowtoevaluatethecapabilityofLLMs.\nSpecifi-cally,Changetal.\n[34]comprehensivelysummarizetheevaluationmethodsfromanoverallperspec-tive.\nItencompassesdifferentevaluationtasks,methods,andbenchmarks,whichserveascriticalpartsinassessingLLMperformances.\nGuoetal.\n[35]caremoreabouttheevaluationtargetsanddescribehowtoevaluatetheknowledge,alignment,andsafetycontrolcapabilitiesofLLMs,whichsupplementevaluationmetricsbeyondperformance.\nApplications.\nThesurveysinthiscategoryaimtosummarizemodelsthatleverageLLMstoimprovedifferentapplications.\nMoreconcretely,Zhuetal.\n[37]focusonthefieldofinformationretrieval(IR)andsummarizestudiesonLLM-basedqueryprocesses.\nXuetal.\n[38]paymoreattentiontoinformationextraction(IE)andprovidecomprehensivetaxonomiesforLLM-basedmodelsinthisfield.\nLietal.\n[50],Linetal.\n[51]andWangetal.\n[52]discusstheapplicationsofLLMsinthefieldofrecommendersystem,wheretheyutilizeagentstogeneratedataandproviderecommendations.\nFanetal.\n[39],Wangetal.\n[40],andZhengetal.\n[41]concentrateonhowLLMscanbenefitsoftwareengineering(SE)intermsofsoftwaredesign,development,andtesting.\nZengetal.\n[42]summarizeLLM-basedmethodsinthefieldofrobotics.\nCuietal.\n[43]andYangetal.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTosystemicallysummarizethestudiesinthisfield,researchershavewrittenalotofsurveypapers.\nInthissection,webrieflyreviewthesesurveys(seeFigure2foranoverview),highlightingtheirmajorfocusesandcontributionstobetterpositionourstudy.\n2.\n1SurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.\n[70]presentthefirstcomprehensivesurveytosummarizethebackground,evolutionpaths,modelarchitectures,trainingmethodologies,andevaluationstrategiesofLLMs.\nHadietal.\n[71]andMinetal.\n[72]alsoconductLLMsurveysfromtheholisticview,which,however,providedifferenttaxonomiesandunderstandingsonLLMs.\nFollowingthesesurveys,peoplediveintospecificaspectsofLLMsandreviewthecorrespondingmilestonestudiesandkeytechnologies.\nTheseaspectscanbeclassifiedintofourcategoriesincludingthefundamentalproblems,evaluation,applications,andchallengesofLLMs.\nFundamentalproblems.\nThesurveysinthiscategoryaimtosummarizetechniquesthatcanbeleveragedtotacklefundamentalproblemsofLLMs.\nSpecifically,Zhangetal.\n[8]provideacomprehensivesurveyonthemethodsofsupervisedfine-tuning,whichisakeytechniqueforbettertrainingLLMs.\nShenetal.\n[9],Wangetal.\n[10]andLiuetal.\n[11]presentsurveysonthealignmentofLLMs,whichisakeyrequirementforLLMstoproduceoutputsconsistentwithhumanvalues.\nGaoetal.\n[12]proposeasurveyontheretrieval-augmentedgeneration(RAG)capabilityofLLMs,whichiskeytoprovidingLLMswithfactualandup-to-dateknowledgeandremovinghallucinations.\nQinetal.\n[18]summarizethestate-of-the-artmethodsonenablingLLMstoleverageexternaltools,whichisfundamentalforLLMstoexpandtheircapabilityindomainsthatrequirespecializedknowledge.\nWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16]andZhangetal.\n[17]presentsurveysonthedirectionofLLMknowledgeediting,whichisimportantforcustomizingLLMstosatisfyspecificrequirements.\nHuangetal.\n[19],Wangetal.\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\nACMComputingSurveys,56(2):1–40,2023.\n[73]GrégoireMialon,RobertoDessì,MariaLomeli,ChristoforosNalmpantis,RamPasunuru,RobertaRaileanu,BaptisteRozière,TimoSchick,JaneDwivedi-Yu,AsliCelikyilmaz,etal.\nAugmentedlanguagemodels:asurvey.\narXivpreprintarXiv:2302.\n07842,2023.\n[74]XuHuang,WeiwenLiu,XiaolongChen,XingmeiWang,HaoWang,DefuLian,YashengWang,RuimingTang,andEnhongChen.\nUnderstandingtheplanningofllmagents:Asurvey.\narXivpreprintarXiv:2402.\n02716,2024.\n[75]TaichengGuo,XiuyingChen,YaqiWang,RuidiChang,ShichaoPei,NiteshVChawla,OlafWiest,andXiangliangZhang.\nLargelanguagemodelbasedmulti-agents:Asurveyofprogressandchallenges.\narXivpreprintarXiv:2402.\n01680,2024.\n[76]YuanchunLi,HaoWen,WeijunWang,XiangyuLi,YizhenYuan,GuohongLiu,JiachengLiu,WenxingXu,XiangWang,YiSun,etal.\nPersonalllmagents:Insightsandsurveyaboutthecapability,efficiencyandsecurity.\narXivpreprintarXiv:2401.\n05459,2024.\n[77]PengyuZhao,ZijianJin,andNingCheng.\nAnin-depthsurveyoflargelanguagemodel-basedartificialintelligenceagents.\narXivpreprintarXiv:2309.\n14365,2023.\n[78]YuhengCheng,CeyaoZhang,ZhengwenZhang,XiangruiMeng,SiruiHong,WenhaoLi,ZihaoWang,ZekaiWang,FengYin,JunhuaZhao,etal.\nExploringlargelanguagemodelbasedintelligentagents:Definitions,methods,andprospects.\narXivpreprintarXiv:2401.\n03428,2024.\n[79]ZaneDurante,QiuyuanHuang,NaokiWake,RanGong,JaeSungPark,BidiptaSarkar,RohanTaori,YusukeNoda,DemetriTerzopoulos,YejinChoi,etal.\nAgentai:Surveyingthehorizonsofmultimodalinteraction.\narXivpreprintarXiv:2401.\n03568,2024.\n[80]YingqiangGe,YujieRen,WenyueHua,ShuyuanXu,JuntaoTan,andYongfengZhang.\nLlmasos(llmao),agentsasapps:Envisioningaios,agentsandtheaios-agentecosystem.\narXivpreprintarXiv:2312.\n03815,2023.\n[81]NingDing,YujiaQin,GuangYang,FuchaoWei,ZonghanYang,YushengSu,ShengdingHu,YulinChen,Chi-MinChan,WeizeChen,etal.\nDeltatuning:Acomprehensivestudyofparameterefficientmethodsforpre-trainedlanguagemodels.\narXivpreprintarXiv:2203.\n06904,2022.\n[82]AndrewZhao,DanielHuang,QuentinXu,MatthieuLin,Yong-JinLiu,andGaoHuang.\nExpel:Llmagentsareexperientiallearners.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nForthememorydesign,wediscusspreviousworksfromthreedimensions,thatis,memorysources,memoryforms,andmemoryoperations.\nForthememoryevaluation,weintroducetwowidelyusedapproachesincludingdirectevaluationandindirectevaluationviaspecificagenttasks.\nNext,wediscussagentapplicationsincludingrole-playing,socialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,andexpertsystems,inordertoshowtheimportanceofthememorymoduleinpracticalscenarios.\nAtlast,weanalyzethelimitationsofexistingworkandhighlightsignificantfuturedirections.\nThemaincontributionsofthispapercanbesummarizedasfollows:(1)Weformallydefinethemem-orymoduleandcomprehensivelyanalyzeitsnecessityforLLM-basedagents.\n(2)WesystematicallysummarizeexistingstudiesondesigningandevaluatingthememorymoduleinLLM-basedagents,providingcleartaxonomiesandintuitiveinsights.\n(3)Wepresenttypicalagentapplicationstoshowtheimportanceofthememorymoduleindifferentscenarios.\n(4)Weanalyzethekeylimitationsofexistingmemorymodulesandshowpotentialsolutionsforinspiringfuturestudies.\nToourknowledge,thisisthefirstsurveyonthememorymechanismofLLM-basedagents.\nTherestofthissurveyisorganizedasfollows.\nFirst,weprovideasystematicalmeta-surveyforthefieldsofLLMsandLLM-basedagentsinSection2,categorizingdifferentsurveysandsummarizingtheirkeycontributions.\nThen,wediscusstheproblemsof“whatis”,“whydoweneed”and“howtoimplementandevaluate”thememorymoduleinLLM-basedagentsinSection3to6.\nNext,weshowtheapplicationsofmemory-enhancedagentsinSection7.\nThediscussionsofthelimitationsofexistingworkandfuturedirectionscomeatlastinSection8andSection9.\n42RelatedSurveysInthepasttwoyears,LLMshaveattractedmuchattentionfromtheacademicandindustrycommu-nities.\nTosystemicallysummarizethestudiesinthisfield,researchershavewrittenalotofsurveypapers.\nInthissection,webrieflyreviewthesesurveys(seeFigure2foranoverview),highlightingtheirmajorfocusesandcontributionstobetterpositionourstudy.\n2.\n1SurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[120]NelsonFLiu,KevinLin,JohnHewitt,AshwinParanjape,MicheleBevilacqua,FabioPetroni,andPercyLiang.\nLostinthemiddle:Howlanguagemodelsuselongcontexts.\narXivpreprintarXiv:2307.\n03172,2023.\n[121]PeterJDenning.\nThelocalityprinciple.\nCommunicationsoftheACM,48(7):19–24,2005.\n35[122]HermannEbbinghaus.\nMemory:Acontributiontoexperimentalpsychology,trans.\nHARuger&CEBussenius.\nTeachersCollege.\n[rWvH],1885.\n[123]JaapMJMurreandJoeriDros.\nReplicationandanalysisofebbinghaus’forgettingcurve.\nPloSone,10(7):e0120644,2015.\n[124]JeffJohnson,MatthijsDouze,andHervéJégou.\nBillion-scalesimilaritysearchwithgpus.\nIEEETransactionsonBigData,7(3):535–547,2019.\n[125]TimoSchick,JaneDwivedi-Yu,RobertoDessì,RobertaRaileanu,MariaLomeli,LukeZettle-moyer,NicolaCancedda,andThomasScialom.\nToolformer:Languagemodelscanteachthemselvestousetools.\narXivpreprintarXiv:2302.\n04761,2023.\n[126]YujiaQin,ShihaoLiang,YiningYe,KunlunZhu,LanYan,YaxiLu,YankaiLin,XinCong,XiangruTang,BillQian,etal.\nToolllm:Facilitatinglargelanguagemodelstomaster16000+real-worldapis.\narXivpreprintarXiv:2307.\n16789,2023.\n[127]HugoTouvron,ThibautLavril,GautierIzacard,XavierMartinet,Marie-AnneLachaux,Timo-théeLacroix,BaptisteRozière,NamanGoyal,EricHambro,FaisalAzhar,etal.\nLlama:Openandefficientfoundationlanguagemodels.\narXivpreprintarXiv:2302.\n13971,2023.\n[128]ZhibinGou,ZhihongShao,YeyunGong,YujiuYang,MinlieHuang,NanDuan,WeizhuChen,etal.\nTora:Atool-integratedreasoningagentformathematicalproblemsolving.\narXivpreprintarXiv:2309.\n17452,2023.\n[129]HonglinXiong,ShengWang,YitaoZhu,ZihaoZhao,YuxiaoLiu,QianWang,andDinggangShen.\nDoctorglm:Fine-tuningyourchinesedoctorisnotaherculeantask.\narXivpreprintarXiv:2304.\n01097,2023.\n[130]AohanZeng,XiaoLiu,ZhengxiaoDu,ZihanWang,HanyuLai,MingDing,ZhuoyiYang,YifanXu,WendiZheng,XiaoXia,etal.\nGlm-130b:Anopenbilingualpre-trainedmodel.\narXivpreprintarXiv:2210.\n02414,2022.\n[131]EdwardJHu,YelongShen,PhillipWallis,ZeyuanAllen-Zhu,YuanzhiLi,SheanWang,LuWang,andWeizhuChen.\nLora:Low-rankadaptationoflargelanguagemodels.\narXivpreprintarXiv:2106.\n09685,2021."
    ],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.\nDuringmemoryreading,matchingscoresarecalculatedforeachmemoryentry,andthetop-Kentrieswillbeusedforthedecision-makingprocessofagents.\n15Inexistingstudies,mostagentsutilizeretrievalmethodstoprocessthememoryinformation.\nForexample,Parketal.\n[83]firstcalculatetherelevancebetweenthecurrentcontextandmemoryentriesbycosinesimilarity,andobtaintheimportanceandrecencyaccordingtoauxiliaryinformation.\nMemoryBank[6]employsadual-towerdenseretrievalmodeltofindrelatedinformationfrompastconversations.\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage.\nItutilizesLocality-SensitiveHashing(LSH)toretrievetupleswithrelativeentriesinthedatabasetoprovidemoreinformation.\nInaddition,ChatDB[96]designstoutilizesymbolicmemory,andproposestogenerateSQLstatementstoretrievefromdatabasetoobtainstoredinformation.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nThereflectionprocesswillbeactivatedwhenthereareaccumulatedeventsthatareenoughtoaddress.\nForGITM[93],inordertoestablishcommonreferenceplansforvarioussituations,keyactionsfrommultipleplansarefurthersummarizedinthememorymodule.\nDiscussion.\nMostofthememorymanagementoperationsareinspiredbytheworkingmechanismofhumanbrains.\nWiththestrongcapabilityofLLMstosimulatehumanminds,theseoperationscanhelptheagentstobettergeneratehigh-levelinformationandinteractwithenvironments.\n18Table3:Summarizationofthememoryoperations.\nIfamodeldoesnothavespecialdesignsonthememoryoperations,weuse◦tolabelit,otherwise,itisdenotedby✓.\n×meansthatthememoryoperationsarenotdiscussedinthepaper.\nModelsWritingMergingReflectionForgettingReadingManagementMemoryBank[6]RET-LLM[7]ChatDB[96]TiM[97]SCM[98]Voyager[99]MemGPT[100]MemoChat[94]MPC[101]GenerativeAgents[83]RecMind[102]Retroformer[103]ExpeL[82]Synapse[91]GITM[93]ReAct[104]Reflexion[5]RecAgent[95]Character-LLM[105]MAC[106]Huatuo[107]ChatDev[1]InteRecAgent[108]MetaAgents[109]TPTU[110,111]MetaGPT[112]S3[2]InvestLM[113]✓✓✓✓✓✓✓✓✓✓◦✓✓✓◦◦✓✓✓✓✓✓✓✓◦✓✓✓✓××✓✓××××××✓✓×✓×✓✓×✓××✓×××××✓×✓××✓✓××✓×✓✓×✓×✓✓×✓×✓✓✓✓✓✓×✓××✓×××××✓×××××××✓××××××××✓×✓✓✓✓✓✓✓✓✓✓✓◦◦✓✓◦◦✓◦✓◦✓✓✓✓✓✓◦5.\n3.\n3MemoryReadingWhentheagentsrequireinformationforreasoninganddecision-making,thememoryreadingoperationwillextractrelatedinformationfrommemoryforusage.\nTherefore,howtoaccesstherelatedinformationforthecurrentstateisimportant.\nDuetothemassivequantityofmemoryentities,andthefactthatnotallofthemarepertinenttothecurrentstate,carefuldesignisrequiredtoextractusefulinformationbasedonrelevanceandothertask-orientatedfactors.\nRepresentativeStudies.\nInChatDB[96],thememoryreadingoperationisexecutedbytheSQLstatements.\nThesestatementswillbegeneratedbyagentsasaseriesofChain-of-Memoryinadvance.\nInMPC[101],theagentscanretrieverelevantmemoryfromthememorypool.\nThismethodalsoproposestoprovideChain-of-Thoughtexamplesforignoringcertainmemory.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nWiththestrongcapabilityofLLMstosimulatehumanminds,theseoperationscanhelptheagentstobettergeneratehigh-levelinformationandinteractwithenvironments.\n18Table3:Summarizationofthememoryoperations.\nIfamodeldoesnothavespecialdesignsonthememoryoperations,weuse◦tolabelit,otherwise,itisdenotedby✓.\n×meansthatthememoryoperationsarenotdiscussedinthepaper.\nModelsWritingMergingReflectionForgettingReadingManagementMemoryBank[6]RET-LLM[7]ChatDB[96]TiM[97]SCM[98]Voyager[99]MemGPT[100]MemoChat[94]MPC[101]GenerativeAgents[83]RecMind[102]Retroformer[103]ExpeL[82]Synapse[91]GITM[93]ReAct[104]Reflexion[5]RecAgent[95]Character-LLM[105]MAC[106]Huatuo[107]ChatDev[1]InteRecAgent[108]MetaAgents[109]TPTU[110,111]MetaGPT[112]S3[2]InvestLM[113]✓✓✓✓✓✓✓✓✓✓◦✓✓✓◦◦✓✓✓✓✓✓✓✓◦✓✓✓✓××✓✓××××××✓✓×✓×✓✓×✓××✓×××××✓×✓××✓✓××✓×✓✓×✓×✓✓×✓×✓✓✓✓✓✓×✓××✓×××××✓×××××××✓××××××××✓×✓✓✓✓✓✓✓✓✓✓✓◦◦✓✓◦◦✓◦✓◦✓✓✓✓✓✓◦5.\n3.\n3MemoryReadingWhentheagentsrequireinformationforreasoninganddecision-making,thememoryreadingoperationwillextractrelatedinformationfrommemoryforusage.\nTherefore,howtoaccesstherelatedinformationforthecurrentstateisimportant.\nDuetothemassivequantityofmemoryentities,andthefactthatnotallofthemarepertinenttothecurrentstate,carefuldesignisrequiredtoextractusefulinformationbasedonrelevanceandothertask-orientatedfactors.\nRepresentativeStudies.\nInChatDB[96],thememoryreadingoperationisexecutedbytheSQLstatements.\nThesestatementswillbegeneratedbyagentsasaseriesofChain-of-Memoryinadvance.\nInMPC[101],theagentscanretrieverelevantmemoryfromthememorypool.\nThismethodalsoproposestoprovideChain-of-Thoughtexamplesforignoringcertainmemory.\nExpeL[82]utilizestheFaiss[124]vectorstoreasthepoolofmemory,andobtainsthetop-Ksuccessfultrajectoriesthatsharethehighestsimilarityscoreswiththecurrenttask.\nDiscussion.\nTosomeextent,thememoryreadingandwritingoperationsarecollaborative,andtheformsofmemorywritinggreatlyinfluencethemethodsofmemoryreading.\nFortheformsoftextual19Figure5:Anoverviewoftheevaluationmethodsofthememorymodule.",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.\nDuringmemoryreading,matchingscoresarecalculatedforeachmemoryentry,andthetop-Kentrieswillbeusedforthedecision-makingprocessofagents.\n15Inexistingstudies,mostagentsutilizeretrievalmethodstoprocessthememoryinformation.\nForexample,Parketal.\n[83]firstcalculatetherelevancebetweenthecurrentcontextandmemoryentriesbycosinesimilarity,andobtaintheimportanceandrecencyaccordingtoauxiliaryinformation.\nMemoryBank[6]employsadual-towerdenseretrievalmodeltofindrelatedinformationfrompastconversations.\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage.\nItutilizesLocality-SensitiveHashing(LSH)toretrievetupleswithrelativeentriesinthedatabasetoprovidemoreinformation.\nInaddition,ChatDB[96]designstoutilizesymbolicmemory,andproposestogenerateSQLstatementstoretrievefromdatabasetoobtainstoredinformation.\nTheretrievalmethodsconsiderablydependontheaccuracyandefficiencyofobtainingexpectedinformation.\nAninaccurateretrievalstrategycanpotentiallyacquireunrelatedinformationthatisunhelpfulforagentinference.\nAndaheavyretrievalsystemcanleadtolargecomputationalcostsandlongtimelatency,especiallywhenhandlingmassiveinformation.\nMoreover,retrievalmethodstypicallystorehomogeneousinformationinsidetheenvironment,wherealltheinformationisinaconsistentform.\nForheterogeneousinformationoutsidetheenvironment,it’sdifficulttodirectlyapplythesamemethodformemorystorage.\nExternalKnowledge.",
      "#memory_survey#Memory-assistedAgent-EnvironmentInteraction#memory_survey#Memory-assistedAgent-EnvironmentInteraction\nForthenarrowmemorydefinition,theiterationonlyhappenswithinthesametrial,andthememoryisemptiedwhenthetrialisended.\nForthebroadmemorydefinition,theiterationhappensacrossdifferenttrialsoreventasks,aswellastheintegrationsofexternalknowledge.\nFortask(B)intheabovetoyexample,theagentcanconcludethatAliceenjoyswatchingsciencefictionmoviesintheevening,whichcanbeusedasadefaultruletomakerecommendationsforAliceinthefuture.\nMemoryReading.\nThisoperationaimstoobtainimportantinformationfromthememorytosupportthenextagentaction.\nItcorrespondstothethirdphaseoftheagent-environmentinteractionprocess.\nSupposeMktisthecontextofthenextaction,thenthememoryreadingoperationcanberepresentedby:tisthememorycontentsfortaskkatstept,ckˆMkt=R(Mkt,ckt+1),whereRisusuallyimplementedbycomputingthesimilaritybetweenMktisusedaspartsofthefinalprompttodrivetheagent’snextaction.\nFortask(B)intheabovetoyexample,whentheagentdecidesonthefinalrecommendedmoviein[Step3],itshouldfocusonthe“wanttowatch”listin[Step2]andselectonefromit.\ntandckt+1[82].\nˆMkBasedontheaboveoperations,wecanderiveaunifiedfunctionfortheevolvingprocessfrom{akt,okt}toakt+1,thatis:akt+1=LLM{R(P(Mkt−1,W({akt,okt})),ckt+1)},whereLLMisthelargelanguagemodel.\nThecompleteagent-environmentinteractionprocesscanbeeasilyobtainedbyiterativelyexpandingthisfunction(seeFigure3(b)foranintuitiveillustration).\nRemark.\nThisfunctionprovidesageneralformulationoftheagentmemorizingprocess.\nPreviousworksmayusedifferentspecifications.\nForexample,in[5],RandParesetasidenticalfunctions,andPonlytakeseffectattheendofatrial.\nInParketal.\n[83],Risimplementedbasedonthreecriteriaincludingsimilarity,timeinterval,andimportance,andPisrealizedbyareflectionprocesstoobtainmoreabstractthoughts.\nInthissection,wefocusontheoverallframeworkoftheagent’smemoryoperations.\nMoredetailedrealizationsofW,P,andRaredeferredinSection5.\n4"
    ],
    [
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.\nThismethodstoresandmaintainsthemostrecentlyacquiredmemoriesusingnaturallanguages,therebyenhancingtheefficiencyofmemoryinformationutilizationaccordingtothePrincipleofLocality[121].\nIntask(B)oftheexampleinSection3.\n1,wecanjustrememberAlice’spreferencesintherecentthreeyears,andtruncatethedistantpart,wheretherecentthreeyearscanbeconsideredasthememorywindowsize.\nInpreviousstudies,therearevariousstrategiestostorerecenttextualmemories.\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.\nThismethodstoresandmaintainsthemostrecentlyacquiredmemoriesusingnaturallanguages,therebyenhancingtheefficiencyofmemoryinformationutilizationaccordingtothePrincipleofLocality[121].\nIntask(B)oftheexampleinSection3.\n1,wecanjustrememberAlice’spreferencesintherecentthreeyears,andtruncatethedistantpart,wheretherecentthreeyearscanbeconsideredasthememorywindowsize.\nInpreviousstudies,therearevariousstrategiestostorerecenttextualmemories.\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nMoreover,someeffortsarededicatedtoenhancingthecapacityofLLMstohandlelongercontexts[118,119].\nWhilestoringalltheagent-environmentinteractionscanmaintaincomprehensiveinformation,obviouslimitationsexistintermsofcomputationalcost,inferencetime,andinferencerobustness.\nFirstly,thefast-growinglong-contextmemoryinpracticeresultsinhighcomputationalcostduringLLMinference,duetothequadraticgrowthofthetimecomplexityofattentioncomputationwithsequencelength.\nItthusrequiresmuchmorecomputingresourcesandsignificantlyincreasesinferencelatency,whichhindersitspracticaldeployment.\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.\nThismethodstoresandmaintainsthemostrecentlyacquiredmemoriesusingnaturallanguages,therebyenhancingtheefficiencyofmemoryinformationutilizationaccordingtothePrincipleofLocality[121].\nIntask(B)oftheexampleinSection3.\n1,wecanjustrememberAlice’spreferencesintherecentthreeyears,andtruncatethedistantpart,wheretherecentthreeyearscanbeconsideredasthememorywindowsize.\nInpreviousstudies,therearevariousstrategiestostorerecenttextualmemories.\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.\nDuringmemoryreading,matchingscoresarecalculatedforeachmemoryentry,andthetop-Kentrieswillbeusedforthedecision-makingprocessofagents.\n15Inexistingstudies,mostagentsutilizeretrievalmethodstoprocessthememoryinformation.\nForexample,Parketal.\n[83]firstcalculatetherelevancebetweenthecurrentcontextandmemoryentriesbycosinesimilarity,andobtaintheimportanceandrecencyaccordingtoauxiliaryinformation.\nMemoryBank[6]employsadual-towerdenseretrievalmodeltofindrelatedinformationfrompastconversations.\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage."
    ],
    [
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\nFigure2:TheorganizationofrelatedsurveysonLLMsandLLM-basedagents.\n6Challenges.\nThesurveysinthiscategoryfocusontrustworthinessinLLMs,suchashallucination,bias,unfairness,explainability,security,andprivacy.\nHallucinationinLLMsreferstotheproblemthatLLMsmaygeneratemisconceptionsorfabrications,impactingtheirreliabilityfordownstreamapplications.\nZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Tonmoyetal.\n[58]andJiangetal.\n[59]summarizethemainstreammodelsforalleviatingthehallucinationprobleminLLMs.\nThebiasandunfairnessproblemsrefertothephenomenonthatLLMsmayunequallytreatdifferenthumansorobjectives,whichcanleadtothepropagationofsocietalstereotypesanddiscrimination.\nGallegosetal.\n[60],Koteketal.\n[61]andLietal.\n[62]comprehensivelydiscussthesechallengesandsummarizeexistingmethodsforalleviatingthem.\nTheproblemofexplainabilitymeansthattheinternalworkingmechanismsofLLMsarestillunclear.\nZhaoetal.\n[63]systematicallydiscussthisproblemandsummarizepreviouseffortsonimprovingtheexplainabilityofLLMs.\nSecurityandprivacyarealsochallengingproblems,whichhavebeencomprehensivelysurveyedinYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68]andDasetal.\n[69].\n2.\n2",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal.\n[47]summarizetheapplicationsofLLMsinmedicine.\nLietal.\n[48]focusontheapplicationsofLLMsinfinance.\nHeetal.\n[49]reviewthemodelsonleveragingLLMstoimprovethedevelopmentofpsychology.\n5SupervisedFine-tuningZhangetal.\n[8].\nAlignmentShenetal.\n[9],Wangetal.\n[10],Liuetal.\n[11].\nRetrievalAugmentationGaoetal.\n[12].\nKnowledgeEditingWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16],Zhangetal.\n[17].\nFundamentalProblemsToolUsageQinetal.\n[18].\nLong-contextMultimodalEfficiencyHuangetal.\n[19],Wangetal.\n[20],Pawaretal.\n[21].\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24],Yinetal.\n[25].\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28,28],Xuetal.\n[29],Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32],Parketal.\n[33].\nEvaluationChangetal.\n[34],Guoetal.\n[35].\nInformationProcessingSoftwareEngineeringYangetal.\n[36],Zhuetal.\n[37],Xuetal.\n[38].\nFanetal.\n[39],Wangetal.\n[40],Zhengetal.\n[41].\nRoboticsZengetal.\n[42].\nApplicationsAutonomousDrivingCuietal.\n[43],Yangetal.\n[44].\nLLMs[70–73]MedecineFinancePsychologyHeetal.\n[45],Zhouetal.\n[46],Wangetal.\n[47].\nLietal.\n[48].\nHeetal.\n[49].\nRecommendationLietal.\n[50],Linetal.\n[51],Wangetal.\n[52].\nHallucinationZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Ton-moyetal.\n[58],Jiangetal.\n[59].\nChallengesBias&FairnessGallegosetal.\n[60],Koteketal.\n[61],Lietal.\n[62].\nExplainabilityZhaoetal.\n[63].\nSecurityYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68],Dasetal.\n[69].\nPlanningHuangetal.\n[74].\nFundamentalProblemsMemoryOurSurvey.\nMulti-agentsGuoetal.\n[75].\nLLM-basedAgent[3,4,77–80]EvaluationApplicationsChallengesLietal.\n[76].\nFigure2:TheorganizationofrelatedsurveysonLLMsandLLM-basedagents.\n6Challenges.\nThesurveysinthiscategoryfocusontrustworthinessinLLMs,suchashallucination,bias,unfairness,explainability,security,andprivacy.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTosystemicallysummarizethestudiesinthisfield,researchershavewrittenalotofsurveypapers.\nInthissection,webrieflyreviewthesesurveys(seeFigure2foranoverview),highlightingtheirmajorfocusesandcontributionstobetterpositionourstudy.\n2.\n1SurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.\n[70]presentthefirstcomprehensivesurveytosummarizethebackground,evolutionpaths,modelarchitectures,trainingmethodologies,andevaluationstrategiesofLLMs.\nHadietal.\n[71]andMinetal.\n[72]alsoconductLLMsurveysfromtheholisticview,which,however,providedifferenttaxonomiesandunderstandingsonLLMs.\nFollowingthesesurveys,peoplediveintospecificaspectsofLLMsandreviewthecorrespondingmilestonestudiesandkeytechnologies.\nTheseaspectscanbeclassifiedintofourcategoriesincludingthefundamentalproblems,evaluation,applications,andchallengesofLLMs.\nFundamentalproblems.\nThesurveysinthiscategoryaimtosummarizetechniquesthatcanbeleveragedtotacklefundamentalproblemsofLLMs.\nSpecifically,Zhangetal.\n[8]provideacomprehensivesurveyonthemethodsofsupervisedfine-tuning,whichisakeytechniqueforbettertrainingLLMs.\nShenetal.\n[9],Wangetal.\n[10]andLiuetal.\n[11]presentsurveysonthealignmentofLLMs,whichisakeyrequirementforLLMstoproduceoutputsconsistentwithhumanvalues.\nGaoetal.\n[12]proposeasurveyontheretrieval-augmentedgeneration(RAG)capabilityofLLMs,whichiskeytoprovidingLLMswithfactualandup-to-dateknowledgeandremovinghallucinations.\nQinetal.\n[18]summarizethestate-of-the-artmethodsonenablingLLMstoleverageexternaltools,whichisfundamentalforLLMstoexpandtheircapabilityindomainsthatrequirespecializedknowledge.\nWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16]andZhangetal.\n[17]presentsurveysonthedirectionofLLMknowledgeediting,whichisimportantforcustomizingLLMstosatisfyspecificrequirements.\nHuangetal.\n[19],Wangetal.\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\nSurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.\n[70]presentthefirstcomprehensivesurveytosummarizethebackground,evolutionpaths,modelarchitectures,trainingmethodologies,andevaluationstrategiesofLLMs.\nHadietal.\n[71]andMinetal.\n[72]alsoconductLLMsurveysfromtheholisticview,which,however,providedifferenttaxonomiesandunderstandingsonLLMs.\nFollowingthesesurveys,peoplediveintospecificaspectsofLLMsandreviewthecorrespondingmilestonestudiesandkeytechnologies.\nTheseaspectscanbeclassifiedintofourcategoriesincludingthefundamentalproblems,evaluation,applications,andchallengesofLLMs.\nFundamentalproblems.\nThesurveysinthiscategoryaimtosummarizetechniquesthatcanbeleveragedtotacklefundamentalproblemsofLLMs.\nSpecifically,Zhangetal.\n[8]provideacomprehensivesurveyonthemethodsofsupervisedfine-tuning,whichisakeytechniqueforbettertrainingLLMs.\nShenetal.\n[9],Wangetal.\n[10]andLiuetal.\n[11]presentsurveysonthealignmentofLLMs,whichisakeyrequirementforLLMstoproduceoutputsconsistentwithhumanvalues.\nGaoetal.\n[12]proposeasurveyontheretrieval-augmentedgeneration(RAG)capabilityofLLMs,whichiskeytoprovidingLLMswithfactualandup-to-dateknowledgeandremovinghallucinations.\nQinetal.\n[18]summarizethestate-of-the-artmethodsonenablingLLMstoleverageexternaltools,whichisfundamentalforLLMstoexpandtheircapabilityindomainsthatrequirespecializedknowledge.\nWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16]andZhangetal.\n[17]presentsurveysonthedirectionofLLMknowledgeediting,whichisimportantforcustomizingLLMstosatisfyspecificrequirements.\nHuangetal.\n[19],Wangetal.\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal.",
      "#memory_survey#Introduction#memory_survey#Introduction\n[7]designbothmemoryreadingandwritingoperationstointeractwithenvironmentsfortasksolving.\nWhilepreviousstudieshavedesignedmanypromisingmemorymodules,therestilllacksasystemicstudytoviewthememorymodulesfromaholisticperspective.\nTobridgethisgap,inthispaper,wecomprehensivelyreviewpreviousstudiestopresentcleartaxonomiesandkeyprinciplesfordesigningandevaluatingthememorymodule.\nInspecific,wediscussthreekeyproblemsincluding:(1)whatisthememoryofLLM-basedagents?\n(2)whydoweneedthememoryinLLM-basedagents?\nand(3)howtoimplementandevaluatethememoryinLLM-basedagents?\nTobeginwith,wedetailtheconceptsofmemoryinLLM-basedagents,providingbothnarrowandbroaddefinitions.\nThen,weanalyzethenecessityofmemoryinLLM-basedagents,showingitsimportancefromthreeperspectivesincludingcognitivepsychology,self-evolution,andagentapplications.\nBasedontheproblemsof“what”and“why”,wepresentcommonlyusedstrategiestodesignandevaluatethememorymodules.\nForthememorydesign,wediscusspreviousworksfromthreedimensions,thatis,memorysources,memoryforms,andmemoryoperations.\nForthememoryevaluation,weintroducetwowidelyusedapproachesincludingdirectevaluationandindirectevaluationviaspecificagenttasks.\nNext,wediscussagentapplicationsincludingrole-playing,socialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,andexpertsystems,inordertoshowtheimportanceofthememorymoduleinpracticalscenarios.\nAtlast,weanalyzethelimitationsofexistingworkandhighlightsignificantfuturedirections.\nThemaincontributionsofthispapercanbesummarizedasfollows:(1)Weformallydefinethemem-orymoduleandcomprehensivelyanalyzeitsnecessityforLLM-basedagents.\n(2)WesystematicallysummarizeexistingstudiesondesigningandevaluatingthememorymoduleinLLM-basedagents,providingcleartaxonomiesandintuitiveinsights.\n(3)Wepresenttypicalagentapplicationstoshowtheimportanceofthememorymoduleindifferentscenarios.\n(4)Weanalyzethekeylimitationsofexistingmemorymodulesandshowpotentialsolutionsforinspiringfuturestudies."
    ],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain.",
      "#memory_survey#ExternalKnowledge#memory_survey#ExternalKnowledge\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain.\nItfine-tunesanacquisitionprocesstoretrieveexternalknowledgefromWikipediaandmedicaldatabases.\nDiscussion.\nTheexternalknowledgecanbeobtainedfrombothprivateandpublicsources.\nItprovidesLLM-basedagentswithmuchknowledgebeyondtheirinternalenvironment,whichmightbedifficultorevenimpossiblefortheagenttoacquirebyagent-environmentinteractions.",
      "#memory_survey#PerspectiveofSelf-Evolution#memory_survey#PerspectiveofSelf-Evolution\nPerspectiveofSelf-EvolutionToaccomplishdifferentpracticaltasks,agentshavetoself-evolveindynamicenvironments[90].\nIntheagent-environmentinteractionprocess,thememoryiskeytothefollowingaspects:(1)Experienceaccumulation.\nAnimportantfunctionofthememoryistorememberpasterrorplannings,inappropriatebehaviors,orfailedexperiences,soastomaketheagentmoreeffectiveforhandlingsimilartasksinthefuture[91].\nThisisextremelyimportantforenhancingthelearningefficiencyoftheagentintheself-evolvingprocess.\n(2)Environmentexploration.\nToautonomouslyevolveintheenvironment,theagentshavetoexploredifferentactionsandlearnfromthefeedback[92].\nByrememberinghistoricalinformation,thememorycanhelptobetterdecidewhenandhowtomakeexplorations,forexample,focusingmoreonpreviouslyfailedtrialsoractionswithlowerexploringfrequencies[93].\n(3)Knowledgeabstraction.\nAnotherimportantfunctionofthememoryistosummarizeandabstracthigh-levelinformationfromrawobservations,whichisthebasisfortheagenttobemoreadaptiveandgeneralizabletounseenenvironments[82].\nInsummary,self-evolutionisthebasiccharacteristicofLLM-basedagents,andmemoryisofkeyimportancetoself-evolution.\n4.\n3",
      "#memory_survey#Memory-enhancedAgentApplications#memory_survey#Memory-enhancedAgentApplications\nMemory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1",
      "#memory_survey#Introduction#memory_survey#Introduction\n[7]designbothmemoryreadingandwritingoperationstointeractwithenvironmentsfortasksolving.\nWhilepreviousstudieshavedesignedmanypromisingmemorymodules,therestilllacksasystemicstudytoviewthememorymodulesfromaholisticperspective.\nTobridgethisgap,inthispaper,wecomprehensivelyreviewpreviousstudiestopresentcleartaxonomiesandkeyprinciplesfordesigningandevaluatingthememorymodule.\nInspecific,wediscussthreekeyproblemsincluding:(1)whatisthememoryofLLM-basedagents?\n(2)whydoweneedthememoryinLLM-basedagents?\nand(3)howtoimplementandevaluatethememoryinLLM-basedagents?\nTobeginwith,wedetailtheconceptsofmemoryinLLM-basedagents,providingbothnarrowandbroaddefinitions.\nThen,weanalyzethenecessityofmemoryinLLM-basedagents,showingitsimportancefromthreeperspectivesincludingcognitivepsychology,self-evolution,andagentapplications.\nBasedontheproblemsof“what”and“why”,wepresentcommonlyusedstrategiestodesignandevaluatethememorymodules.\nForthememorydesign,wediscusspreviousworksfromthreedimensions,thatis,memorysources,memoryforms,andmemoryoperations.\nForthememoryevaluation,weintroducetwowidelyusedapproachesincludingdirectevaluationandindirectevaluationviaspecificagenttasks.\nNext,wediscussagentapplicationsincludingrole-playing,socialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,andexpertsystems,inordertoshowtheimportanceofthememorymoduleinpracticalscenarios.\nAtlast,weanalyzethelimitationsofexistingworkandhighlightsignificantfuturedirections.\nThemaincontributionsofthispapercanbesummarizedasfollows:(1)Weformallydefinethemem-orymoduleandcomprehensivelyanalyzeitsnecessityforLLM-basedagents.\n(2)WesystematicallysummarizeexistingstudiesondesigningandevaluatingthememorymoduleinLLM-basedagents,providingcleartaxonomiesandintuitiveinsights.\n(3)Wepresenttypicalagentapplicationstoshowtheimportanceofthememorymoduleindifferentscenarios.\n(4)Weanalyzethekeylimitationsofexistingmemorymodulesandshowpotentialsolutionsforinspiringfuturestudies."
    ],
    [
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nThememoryofanagentisderivedfromthehistoricalbehaviorstoachieveatarget,forexample,thecollectionofrelevantpaperswhenresearchingonaspecifictopic.\nMemoChat[94]aimstochatwithhumans,wherethememoryoftheagentisderivedbasedontheconversationhistoryofadialoguesession.\nTiM[97]aimstoenhancetheagent’sreasoningcapabilitybyself-generatingmultiplethoughtsafteraccomplishingatask,whichisusedasthememorytoprovidemoregeneralizableinformation.\nVoyager[99]focusesonbuildinggameagentsbasedonMinecraft,wherethememorycontainsexecutablecodesofpreliminaryandbasicactionstoaccomplishatask.\nItshouldbenotedthattheinside-trialinformationnotonlyincludesagent-environmentinteractions,butalsocontainsinteractioncontexts,suchastimeandlocationinformation.\n12Discussion.\nTheinside-trialinformationisthemostobviousandintuitivesourcethatshouldbeleveragedtoconstructtheagent’smemorysinceitishighlyrelevanttothecurrenttaskthattheagenthastoaccomplish.\nHowever,relyingsolelyoninside-trialinformationmaypreventtheagentfromaccumulatingvaluableknowledgefromvarioustasksandlearningmoregeneralizableinformation.\nThus,manystudiesalsoexplorehowtoeffectivelyutilizetheinformationacrossdifferenttaskstobuildthememorymodule,whichisdetailedinthefollowingsections.\n5.\n1.\n2Cross-trialInformationForLLM-basedagents,theinformationaccumulatedacrossmultipletrialsintheenvironmentisalsoacrucialpartofthememory,typicallyincludingsuccessfulandfailedactionsandtheirinsights,suchasfailurereasons,commonactionpatternstosucceed,andsoon.\nRepresentativeStudies.\nOneofthemostprominentstudiesisReflexion[5],whichproposesverbalreinforcementlearningforLLM-basedagents.\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nThesethreeperspectivesprovideacomprehensivereviewofmemoryimplementationmethods,whichishelpfulforfutureresearch.\nForbetterdemonstration,wepresentanoverviewofimplementationmethodsinFigure4.\n5.\n1MemorySourcesInpreviousworks,thememorycontentsmaycomefromdifferentsources.\nBasedonourformulationinSection3,thesesourcescanbeclassifiedintothreecategories,thatis,theinformationinsideatrial,theinformationacrossdifferenttrials,andtheexternalknowledge.\nTheformertwoaredynamically11Table1:Summarizationofthememorysources.\nWeuse✓and×tolabelwhetherornotthecorrespondingsourceisadoptedinthemodel.\nModelsInside-trialInformationCross-trialInformationExternalKnowledgeMemoryBank[6]RET-LLM[7]ChatDB[96]TiM[97]SCM[98]Voyager[99]MemGPT[100]MemoChat[94]MPC[101]GenerativeAgents[83]RecMind[102]Retroformer[103]ExpeL[82]Synapse[91]GITM[93]ReAct[104]Reflexion[5]RecAgent[95]Character-LLM[105]MAC[106]Huatuo[107]ChatDev[1]InteRecAgent[108]MetaAgents[109]TPTU[110,111]MetaGPT[112]S3[2]InvestLM[113]✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓×××××××××××✓✓✓✓×✓××××××××✓×××✓✓×××××××✓✓✓×✓✓✓×✓×✓×✓×✓××✓generatedintheagent-environmentinteractionprocess(e.\ng.\n,taskinternalinformation),whilethelatterisstaticinformationoutsidetheloop(e.\ng.\n,taskexternalinformation).\nWesummarizepreviousworksonmemorysourcesinTable1.\n5.\n1.\n1Inside-trialInformationIntheagent-environmentinteractionprocess,thehistoricalstepswithinatrialareusuallythemostrelevantandinformativesignalstosupporttheagent’sfutureactions.\nAlmostallthepreviousworksusethisinformationasapartofthememorysources.\nRepresentativeStudies.\nGenerativeAgents[83]aimstosimulatehuman’sdailybehaviorsbyusingLLM-basedagents.\nThememoryofanagentisderivedfromthehistoricalbehaviorstoachieveatarget,forexample,thecollectionofrelevantpaperswhenresearchingonaspecifictopic.\nMemoChat[94]aimstochatwithhumans,wherethememoryoftheagentisderivedbasedontheconversationhistoryofadialoguesession.",
      "#memory_survey#ExternalKnowledge#memory_survey#ExternalKnowledge\nItshouldbenotedthattheinside-trialinformationnotonlyincludesagent-environmentinteractions,butalsocontainsinteractioncontexts,suchastimeandlocationinformation.\n12Discussion.\nTheinside-trialinformationisthemostobviousandintuitivesourcethatshouldbeleveragedtoconstructtheagent’smemorysinceitishighlyrelevanttothecurrenttaskthattheagenthastoaccomplish.\nHowever,relyingsolelyoninside-trialinformationmaypreventtheagentfromaccumulatingvaluableknowledgefromvarioustasksandlearningmoregeneralizableinformation.\nThus,manystudiesalsoexplorehowtoeffectivelyutilizetheinformationacrossdifferenttaskstobuildthememorymodule,whichisdetailedinthefollowingsections.\n5.\n1.\n2Cross-trialInformationForLLM-basedagents,theinformationaccumulatedacrossmultipletrialsintheenvironmentisalsoacrucialpartofthememory,typicallyincludingsuccessfulandfailedactionsandtheirinsights,suchasfailurereasons,commonactionpatternstosucceed,andsoon.\nRepresentativeStudies.\nOneofthemostprominentstudiesisReflexion[5],whichproposesverbalreinforcementlearningforLLM-basedagents.\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTiM[97]aimstoenhancetheagent’sreasoningcapabilitybyself-generatingmultiplethoughtsafteraccomplishingatask,whichisusedasthememorytoprovidemoregeneralizableinformation.\nVoyager[99]focusesonbuildinggameagentsbasedonMinecraft,wherethememorycontainsexecutablecodesofpreliminaryandbasicactionstoaccomplishatask.\nItshouldbenotedthattheinside-trialinformationnotonlyincludesagent-environmentinteractions,butalsocontainsinteractioncontexts,suchastimeandlocationinformation.\n12Discussion.\nTheinside-trialinformationisthemostobviousandintuitivesourcethatshouldbeleveragedtoconstructtheagent’smemorysinceitishighlyrelevanttothecurrenttaskthattheagenthastoaccomplish.\nHowever,relyingsolelyoninside-trialinformationmaypreventtheagentfromaccumulatingvaluableknowledgefromvarioustasksandlearningmoregeneralizableinformation.\nThus,manystudiesalsoexplorehowtoeffectivelyutilizetheinformationacrossdifferenttaskstobuildthememorymodule,whichisdetailedinthefollowingsections.\n5.\n1.\n2Cross-trialInformationForLLM-basedagents,theinformationaccumulatedacrossmultipletrialsintheenvironmentisalsoacrucialpartofthememory,typicallyincludingsuccessfulandfailedactionsandtheirinsights,suchasfailurereasons,commonactionpatternstosucceed,andsoon.\nRepresentativeStudies.\nOneofthemostprominentstudiesisReflexion[5],whichproposesverbalreinforcementlearningforLLM-basedagents.\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nWiththestrongcapabilityofLLMstosimulatehumanminds,theseoperationscanhelptheagentstobettergeneratehigh-levelinformationandinteractwithenvironments.\n18Table3:Summarizationofthememoryoperations.\nIfamodeldoesnothavespecialdesignsonthememoryoperations,weuse◦tolabelit,otherwise,itisdenotedby✓.\n×meansthatthememoryoperationsarenotdiscussedinthepaper.\nModelsWritingMergingReflectionForgettingReadingManagementMemoryBank[6]RET-LLM[7]ChatDB[96]TiM[97]SCM[98]Voyager[99]MemGPT[100]MemoChat[94]MPC[101]GenerativeAgents[83]RecMind[102]Retroformer[103]ExpeL[82]Synapse[91]GITM[93]ReAct[104]Reflexion[5]RecAgent[95]Character-LLM[105]MAC[106]Huatuo[107]ChatDev[1]InteRecAgent[108]MetaAgents[109]TPTU[110,111]MetaGPT[112]S3[2]InvestLM[113]✓✓✓✓✓✓✓✓✓✓◦✓✓✓◦◦✓✓✓✓✓✓✓✓◦✓✓✓✓××✓✓××××××✓✓×✓×✓✓×✓××✓×××××✓×✓××✓✓××✓×✓✓×✓×✓✓×✓×✓✓✓✓✓✓×✓××✓×××××✓×××××××✓××××××××✓×✓✓✓✓✓✓✓✓✓✓✓◦◦✓✓◦◦✓◦✓◦✓✓✓✓✓✓◦5.\n3.\n3MemoryReadingWhentheagentsrequireinformationforreasoninganddecision-making,thememoryreadingoperationwillextractrelatedinformationfrommemoryforusage.\nTherefore,howtoaccesstherelatedinformationforthecurrentstateisimportant.\nDuetothemassivequantityofmemoryentities,andthefactthatnotallofthemarepertinenttothecurrentstate,carefuldesignisrequiredtoextractusefulinformationbasedonrelevanceandothertask-orientatedfactors.\nRepresentativeStudies.\nInChatDB[96],thememoryreadingoperationisexecutedbytheSQLstatements.\nThesestatementswillbegeneratedbyagentsasaseriesofChain-of-Memoryinadvance.\nInMPC[101],theagentscanretrieverelevantmemoryfromthememorypool.\nThismethodalsoproposestoprovideChain-of-Thoughtexamplesforignoringcertainmemory.\nExpeL[82]utilizestheFaiss[124]vectorstoreasthepoolofmemory,andobtainsthetop-Ksuccessfultrajectoriesthatsharethehighestsimilarityscoreswiththecurrenttask.\nDiscussion.\nTosomeextent,thememoryreadingandwritingoperationsarecollaborative,andtheformsofmemorywritinggreatlyinfluencethemethodsofmemoryreading.\nFortheformsoftextual19Figure5:Anoverviewoftheevaluationmethodsofthememorymodule."
    ],
    [
      "#memory_survey#Discussions#memory_survey#Discussions\nDiscussionsComparedwithdirectevaluation,indirectevaluationviaspecifictaskscanbeeasiertoconduct,sincetherearealreadymanypublicbenchmarks.\nHowever,theperformanceontaskscanbeattributedtovariousfactors,andmemoryisonlyoneofthem,whichmaymaketheevaluationresultsbiased.\nBydirectevaluation,theeffectivenessofthememorymodulecanbeindependentlyevaluated,whichimprovesthereliabilityoftheevaluationresults.\nHowever,toourknowledge,therearenoopen-sourcedbenchmarkstailoredforthememorymodulesinLLM-basedagents.\n7",
      "#memory_survey#IndirectEvaluation#memory_survey#IndirectEvaluation\nIndirectEvaluationBesidestheabovemethodthatdirectlyevaluatesthememorymodule,evaluatingviataskcompletionisalsoapopularevaluationstrategy.\nTheintuitionbehindthistypeofapproachesisthatiftheagentcansuccessfullycompleteataskthathighlydependsonmemory,itsuggeststhatthedesignedmemorymoduleiseffective.\nInthefollowingparts,wepresentseveralrepresentativetasksthatareleveragedtoevaluatethememorymoduleinindirectways.\n6.\n2.\n1",
      "#memory_survey#HowtoEvaluatetheMemoryinLLM-basedAgent#memory_survey#HowtoEvaluatetheMemoryinLLM-basedAgent\nHowtoEvaluatetheMemoryinLLM-basedAgentHowtoeffectivelyevaluatethememorymoduleremainsanopenproblem,wherediverseevaluationstrategieshavebeenproposedinpreviousworksaccordingtodifferentapplications.\nToclearlyshowthecommonideasofdifferentevaluationmethods,inthissection,wesummarizeageneralframework,whichincludestwobroadevaluationstrategies(seeFigure5foranoverview),thatis,(1)directevaluation,whichindependentlymeasuresthecapabilityofthememorymodule.\n(2)indirectevaluation,whichevaluatesthememorymoduleviaend-to-endagenttasks.\nIfthetaskscanbeeffectivelyaccomplished,thememorymoduleisdemonstratedtobeuseful.\n6.\n1",
      "#memory_survey#OtherTasks#memory_survey#OtherTasks\nOtherTasksInadditiontotheabovethreetypesofmajortasksforindirectevaluation,therearealsosomeothermetricsingeneraltasksthatcanrevealtheeffectivenessofthememorymodule.\nSuccessratereferstotheproportionoftasksthatagentscansuccessfullysolve.\nForYaoetal.\n[104],Shinnetal.\n[5]andZhaoetal.\n[82],theyassesshowmanyspacialtaskscanbecorrectlycompletedthroughreasoningandmemoryinAlfWorld[141].\nInZhuetal.\n[93],theyevaluatethesuccessrateofproducingdifferentitemsinMinecrafttoshowtheeffectofmemory.\nMoreover,Shinnetal.\n[5]measurethesuccessrateofpassedproblemsbygeneratedcodes,andZhengetal.\n[91]calculatethesuccessrateofcomputercontrolandaccuracyofelementselectiontoshowthefunctionoftrajectory-as-exemplarmemory.\nExplorationdegreetypicallyappearsinexploratorygames,whichreflectstheextentthatagentscanexploretheenvironment.\nForexample,Wangetal.\n[99]comparethenumbersofdistinctitemsexploredinMinecrafttoreflecttheskilllearninginmemory.\nInfact,nearlyallthememory-equippedagentscanevaluatetheeffectofmemorybyablationstudies,comparingtheperformancebetweenwith/withoutmemorymodules.\nTheevaluationonspecificscenarioscanbetterreflectthesignificanceofmemoryforthedownstreamapplicationspractically.\n6.\n3",
      "#memory_survey#Memory-assistedAgent-EnvironmentInteraction#memory_survey#Memory-assistedAgent-EnvironmentInteraction\nMemory-assistedAgent-EnvironmentInteractionAsmentionedatthebeginningofSection3,therearethreekeyphasesintheagent-environmentinteractionprocess.\nTheagentmemorymoduleimplementsthesephasesthroughthreeoperationsincludingmemorywriting,memorymanagement,andmemoryreading.\nMemoryWriting.\nThisoperationaimstoprojecttherawobservationsintotheactuallystoredmemorycontents,whicharemoreinformative[7]andconcise[6].\nItcorrespondstothefirstphaseoftheagent-environmentinteractionprocess.\nGivenataskTk,iftheagenttakesanactionaktatstept,andtheenvironmentprovidesanobservationokt,thenthememorywritingoperationcanbeformallyrepresentedas:mkt=W({akt,okt}),whereWisaprojectingfunction.\nmktisthefinallystoredmemorycontents,whichcanbeeithernaturallanguagesorparametricrepresentations.\nIntheabovetoyexample,fortask(A),theagentissupposedtoremembertheflightarrangementandthedecisionofattractionsafter[step2].\nFortask(B),theagentshouldmemorizethefactthatAlicehopestowatchmoviesat9:00PM,after[step1].\nMemoryManagement.\nThisoperationaimstoprocessthestoredmemoryinformationtomakeitmoreeffective,forexample,summarizinghigh-levelconceptstomaketheagentmoregeneral-1Foreachtask,therecanbemultipletrialsforexploringthefinalsolution,andallofthemcanbeincorporatedintothememory.\n9izable[6],mergingsimilarinformationtoreduceredundancy[7],andforgettingunimportantorirrelevantinformationtoremoveitsnegativeinfluence.\nThisoperationcorrespondstothesecondphaseoftheagent-environmentinteractionprocess.\nLetMkt−1bethememorycontentsfortaskkbeforestept,andsupposemktisthestoredinformationatsteptbasedontheabovememorywritingoperation,then,thememorymanagementoperationcanberepresentedby:Mkt=P(Mkt−1,mkt),wherePisafunctionthatiterativelyprocessesthestoredmemoryinformation.\nForthenarrowmemorydefinition,theiterationonlyhappenswithinthesametrial,andthememoryisemptiedwhenthetrialisended.\nForthebroadmemorydefinition,theiterationhappensacrossdifferenttrialsoreventasks,aswellastheintegrationsofexternalknowledge."
    ],
    [
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\nFigure2:TheorganizationofrelatedsurveysonLLMsandLLM-basedagents.\n6Challenges.\nThesurveysinthiscategoryfocusontrustworthinessinLLMs,suchashallucination,bias,unfairness,explainability,security,andprivacy.\nHallucinationinLLMsreferstotheproblemthatLLMsmaygeneratemisconceptionsorfabrications,impactingtheirreliabilityfordownstreamapplications.\nZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Tonmoyetal.\n[58]andJiangetal.\n[59]summarizethemainstreammodelsforalleviatingthehallucinationprobleminLLMs.\nThebiasandunfairnessproblemsrefertothephenomenonthatLLMsmayunequallytreatdifferenthumansorobjectives,whichcanleadtothepropagationofsocietalstereotypesanddiscrimination.\nGallegosetal.\n[60],Koteketal.\n[61]andLietal.\n[62]comprehensivelydiscussthesechallengesandsummarizeexistingmethodsforalleviatingthem.\nTheproblemofexplainabilitymeansthattheinternalworkingmechanismsofLLMsarestillunclear.\nZhaoetal.\n[63]systematicallydiscussthisproblemandsummarizepreviouseffortsonimprovingtheexplainabilityofLLMs.\nSecurityandprivacyarealsochallengingproblems,whichhavebeencomprehensivelysurveyedinYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68]andDasetal.\n[69].\n2.\n2",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal.\n[47]summarizetheapplicationsofLLMsinmedicine.\nLietal.\n[48]focusontheapplicationsofLLMsinfinance.\nHeetal.\n[49]reviewthemodelsonleveragingLLMstoimprovethedevelopmentofpsychology.\n5SupervisedFine-tuningZhangetal.\n[8].\nAlignmentShenetal.\n[9],Wangetal.\n[10],Liuetal.\n[11].\nRetrievalAugmentationGaoetal.\n[12].\nKnowledgeEditingWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16],Zhangetal.\n[17].\nFundamentalProblemsToolUsageQinetal.\n[18].\nLong-contextMultimodalEfficiencyHuangetal.\n[19],Wangetal.\n[20],Pawaretal.\n[21].\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24],Yinetal.\n[25].\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28,28],Xuetal.\n[29],Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32],Parketal.\n[33].\nEvaluationChangetal.\n[34],Guoetal.\n[35].\nInformationProcessingSoftwareEngineeringYangetal.\n[36],Zhuetal.\n[37],Xuetal.\n[38].\nFanetal.\n[39],Wangetal.\n[40],Zhengetal.\n[41].\nRoboticsZengetal.\n[42].\nApplicationsAutonomousDrivingCuietal.\n[43],Yangetal.\n[44].\nLLMs[70–73]MedecineFinancePsychologyHeetal.\n[45],Zhouetal.\n[46],Wangetal.\n[47].\nLietal.\n[48].\nHeetal.\n[49].\nRecommendationLietal.\n[50],Linetal.\n[51],Wangetal.\n[52].\nHallucinationZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Ton-moyetal.\n[58],Jiangetal.\n[59].\nChallengesBias&FairnessGallegosetal.\n[60],Koteketal.\n[61],Lietal.\n[62].\nExplainabilityZhaoetal.\n[63].\nSecurityYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68],Dasetal.\n[69].\nPlanningHuangetal.\n[74].\nFundamentalProblemsMemoryOurSurvey.\nMulti-agentsGuoetal.\n[75].\nLLM-basedAgent[3,4,77–80]EvaluationApplicationsChallengesLietal.\n[76].\nFigure2:TheorganizationofrelatedsurveysonLLMsandLLM-basedagents.\n6Challenges.\nThesurveysinthiscategoryfocusontrustworthinessinLLMs,suchashallucination,bias,unfairness,explainability,security,andprivacy.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68],Dasetal.\n[69].\nPlanningHuangetal.\n[74].\nFundamentalProblemsMemoryOurSurvey.\nMulti-agentsGuoetal.\n[75].\nLLM-basedAgent[3,4,77–80]EvaluationApplicationsChallengesLietal.\n[76].\nFigure2:TheorganizationofrelatedsurveysonLLMsandLLM-basedagents.\n6Challenges.\nThesurveysinthiscategoryfocusontrustworthinessinLLMs,suchashallucination,bias,unfairness,explainability,security,andprivacy.\nHallucinationinLLMsreferstotheproblemthatLLMsmaygeneratemisconceptionsorfabrications,impactingtheirreliabilityfordownstreamapplications.\nZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Tonmoyetal.\n[58]andJiangetal.\n[59]summarizethemainstreammodelsforalleviatingthehallucinationprobleminLLMs.\nThebiasandunfairnessproblemsrefertothephenomenonthatLLMsmayunequallytreatdifferenthumansorobjectives,whichcanleadtothepropagationofsocietalstereotypesanddiscrimination.\nGallegosetal.\n[60],Koteketal.\n[61]andLietal.\n[62]comprehensivelydiscussthesechallengesandsummarizeexistingmethodsforalleviatingthem.\nTheproblemofexplainabilitymeansthattheinternalworkingmechanismsofLLMsarestillunclear.\nZhaoetal.\n[63]systematicallydiscussthisproblemandsummarizepreviouseffortsonimprovingtheexplainabilityofLLMs.\nSecurityandprivacyarealsochallengingproblems,whichhavebeencomprehensivelysurveyedinYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68]andDasetal.\n[69].\n2.\n2SurveysonLargeLanguageModel-basedAgentsBasedonthecapabilityofLLMs,peoplehaveconductedalotofstudiesonbuildingLLM-basedagents,whichcanautonomouslyperceiveenvironments,takeactions,accumulateknowledge,andevolvethemselves.\nInthisfield,Wangetal.\n[3]presentthefirstsurveypapertosystematicallysummarizeLLM-basedagentsfromtheperspectivesofagentconstruction,agentapplication,andagentevaluation.\nXietal.\n[4],Zhaoetal.\n[77],Chengetal.\n[78]andGeetal.\n[80]alsosummarizeLLM-basedagentstudiesfromtheoverallperspective,buttheyhavedifferentfocusesandtaxonomies,deliveringmorediverseunderstandingsonthisfield.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\n[40],andZhengetal.\n[41]concentrateonhowLLMscanbenefitsoftwareengineering(SE)intermsofsoftwaredesign,development,andtesting.\nZengetal.\n[42]summarizeLLM-basedmethodsinthefieldofrobotics.\nCuietal.\n[43]andYangetal.\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal.\n[47]summarizetheapplicationsofLLMsinmedicine.\nLietal.\n[48]focusontheapplicationsofLLMsinfinance.\nHeetal.\n[49]reviewthemodelsonleveragingLLMstoimprovethedevelopmentofpsychology.\n5SupervisedFine-tuningZhangetal.\n[8].\nAlignmentShenetal.\n[9],Wangetal.\n[10],Liuetal.\n[11].\nRetrievalAugmentationGaoetal.\n[12].\nKnowledgeEditingWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16],Zhangetal.\n[17].\nFundamentalProblemsToolUsageQinetal.\n[18].\nLong-contextMultimodalEfficiencyHuangetal.\n[19],Wangetal.\n[20],Pawaretal.\n[21].\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24],Yinetal.\n[25].\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28,28],Xuetal.\n[29],Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32],Parketal.\n[33].\nEvaluationChangetal.\n[34],Guoetal.\n[35].\nInformationProcessingSoftwareEngineeringYangetal.\n[36],Zhuetal.\n[37],Xuetal.\n[38].\nFanetal.\n[39],Wangetal.\n[40],Zhengetal.\n[41].\nRoboticsZengetal.\n[42].\nApplicationsAutonomousDrivingCuietal.\n[43],Yangetal.\n[44].\nLLMs[70–73]MedecineFinancePsychologyHeetal.\n[45],Zhouetal.\n[46],Wangetal.\n[47].\nLietal.\n[48].\nHeetal.\n[49].\nRecommendationLietal.\n[50],Linetal.\n[51],Wangetal.\n[52].\nHallucinationZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Ton-moyetal.\n[58],Jiangetal.\n[59].\nChallengesBias&FairnessGallegosetal.\n[60],Koteketal.\n[61],Lietal.\n[62].\nExplainabilityZhaoetal.\n[63].\nSecurityYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68],Dasetal.\n[69].\nPlanningHuangetal.\n[74].\nFundamentalProblemsMemoryOurSurvey.\nMulti-agentsGuoetal.\n[75].\nLLM-basedAgent[3,4,77–80]EvaluationApplicationsChallengesLietal.\n[76].",
      "#memory_survey#Introduction#memory_survey#Introduction\n[7]designbothmemoryreadingandwritingoperationstointeractwithenvironmentsfortasksolving.\nWhilepreviousstudieshavedesignedmanypromisingmemorymodules,therestilllacksasystemicstudytoviewthememorymodulesfromaholisticperspective.\nTobridgethisgap,inthispaper,wecomprehensivelyreviewpreviousstudiestopresentcleartaxonomiesandkeyprinciplesfordesigningandevaluatingthememorymodule.\nInspecific,wediscussthreekeyproblemsincluding:(1)whatisthememoryofLLM-basedagents?\n(2)whydoweneedthememoryinLLM-basedagents?\nand(3)howtoimplementandevaluatethememoryinLLM-basedagents?\nTobeginwith,wedetailtheconceptsofmemoryinLLM-basedagents,providingbothnarrowandbroaddefinitions.\nThen,weanalyzethenecessityofmemoryinLLM-basedagents,showingitsimportancefromthreeperspectivesincludingcognitivepsychology,self-evolution,andagentapplications.\nBasedontheproblemsof“what”and“why”,wepresentcommonlyusedstrategiestodesignandevaluatethememorymodules.\nForthememorydesign,wediscusspreviousworksfromthreedimensions,thatis,memorysources,memoryforms,andmemoryoperations.\nForthememoryevaluation,weintroducetwowidelyusedapproachesincludingdirectevaluationandindirectevaluationviaspecificagenttasks.\nNext,wediscussagentapplicationsincludingrole-playing,socialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,andexpertsystems,inordertoshowtheimportanceofthememorymoduleinpracticalscenarios.\nAtlast,weanalyzethelimitationsofexistingworkandhighlightsignificantfuturedirections.\nThemaincontributionsofthispapercanbesummarizedasfollows:(1)Weformallydefinethemem-orymoduleandcomprehensivelyanalyzeitsnecessityforLLM-basedagents.\n(2)WesystematicallysummarizeexistingstudiesondesigningandevaluatingthememorymoduleinLLM-basedagents,providingcleartaxonomiesandintuitiveinsights.\n(3)Wepresenttypicalagentapplicationstoshowtheimportanceofthememorymoduleindifferentscenarios.\n(4)Weanalyzethekeylimitationsofexistingmemorymodulesandshowpotentialsolutionsforinspiringfuturestudies."
    ],
    [
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.\nThismethodstoresandmaintainsthemostrecentlyacquiredmemoriesusingnaturallanguages,therebyenhancingtheefficiencyofmemoryinformationutilizationaccordingtothePrincipleofLocality[121].\nIntask(B)oftheexampleinSection3.\n1,wecanjustrememberAlice’spreferencesintherecentthreeyears,andtruncatethedistantpart,wheretherecentthreeyearscanbeconsideredasthememorywindowsize.\nInpreviousstudies,therearevariousstrategiestostorerecenttextualmemories.\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nEnvironment(Alice):Ofcourse,itisanicetime!\n[Step2]Agent:Now,IneedtofindsomemoviesthatAlicehasmarked\"wanttowatch\"onNetflix.\nEnvironment(Netflix):Alice’swanttowatch:Interstellar,PlanetTerrorandCandleintheTomb.\n[Step3]Agent:SinceAliceneverwatcheshorrormoviesatnight,Interstellarwouldbemoresuitableforher.\nNow,IneedtoconfirmwithAliceaboutthemovie.\nEnvironment(Alice):Great!\nIlikeit!\n3.\n2NarrowDefinitionoftheAgentMemoryInanarrowsense,thememoryoftheagentisonlyrelevanttothehistoricalinformationwithinthesametrial.\nFormally,foragiventask,thehistoricalinformationofthetrialbeforesteptisξt={a1,o1,a2,o2,.\n.\n.\n,at−1,ot−1},andthenthememoryisderivedbasedonξt.\nIntheabovetoyexample,fortask(A),theagentat[step3]needstoarrangethevisitingorderforAlice;atthistime,itsmemorycontainstheinformationabouttheselectedattractionsandarrivaltimein[step1]and[step2].\nFortask(B),theagenthastochooseamovieforAliceat[step3];atthistime,itsmemorycontainsthearrangedtimetowatchfilms.\n3.\n3BroadDefinitionoftheAgentMemory1,okt−1,ok1,.\n.\n.\n,akt={akInabroadsense,thememoryoftheagentcancomefrommuchwidersources,forexample,theinformationacrossdifferenttrialsandtheexternalknowledgebeyondtheagent-environmentinteractions.\nFormally,givenaseriesofsequentialtasks{T1,T2,.\n.\n.\n,TK},fortaskTk,thememoryinformationatsteptcomesfromthreesources:(1)thehistoricalinformationwithinthesametrial,thatis,ξkt−1},whereweaddsuperscriptktolabelthetaskindex.\n(2)Thehistoricalinformationacrossdifferenttrials,thatis,Ξk={ξ1,ξ2,.\n.\n.\n,ξk−1,ξk′},whereξj(j∈{1,.\n.\n.\n,k−1})representsthetrialsoftaskj1,andξk′denotesthepreviouslyexploredtrialsfortaskTk.\n(3)Externalknowledge,whichisrepresentedbyDkt.\nThememoryoftheagentisderivedbasedon(ξkt).\nIntheabovetoyexample,fortask(A),ifthereareseveralfailedtrials,thatis,thefeedbackfromAliceisnegative,thenthesetrialscanbeincorporatedintotheagent’smemorytoavoidfuturesimilarerrors(correspondingtoξk′).\nInaddition,fortask(B),theagentmayrecommendmoviesrelevanttotheattractionsthatAlicehasvisitedintask(A)tocaptureherrecentpreferences(correspondingto{ξ1,ξ2,.\n.\n.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nByleveragingexternalresources,theagentscanlearnfromcode-relatedknowledgeandstoreitintotheirmemory,therebyenhancingthecapabilitiesofcodegeneration.\nInaddition,thememorycanimprovethecontinuityandconsistencyincodegeneration.\nByintegratingcontextualmemory,theagentcanbetterunderstandtherequirementsforsoftwaredevelopment,therebyenhancingthecoherenceofthegeneratedcode.\nFurthermore,thememoryisalsocrucialfortheiterativeoptimizationofcode,asitcanidentifythedeveloper’stargetsbasedonthehistories.\n257.\n5RecommendationInthefieldofrecommendation,somepreviousworksfocusonsimulatingusersinrecommendersystems[95,108],wherethememorycanrepresenttheuserprofilesandhistoriesintherealworld.\nOtherstrytoimprovetheperformanceofrecommendation,orprovideotherformatsofrecommendationinterfaces[149,102].\nWangetal.\n[95]simulateuserbehaviorsinrecommendationscenariostogeneratedataforrecommendersystems,andtheagentsstorepastobservationsandinsightsintoahierarchicalmemory.\nInHuangetal.\n[108],thememoryinLLM-basedagentscanarchivetheuser’sconversationalhistoryoverextendedperiods,aswellascapturethemostrecentdialoguespertinenttothecurrentprompt,tosimulateinteractiverecommendersystems.\nItalsousesanactor-criticreflectiontoimprovetherobustnessofagents.\nItemagentsanduseragentsareequippedwithdifferentmemoriesin[149],whereitemagentsareendowedwithdynamicmemorymodulesdesignedtocaptureandpreserveinformationpertinenttotheirintrinsicattributesandtheinclinationsoftheiradopters.\nForuseragents,theadaptivememoryupdatingmechanismplaysapivotalroleinaligningtheagents’operationswithuserbehaviorsandpreferences.\nWangetal.\n[102]memorizeindividualizeduserinformationlikereviewsorratingsforitems,andacquiredomain-specificknowledgeandreal-timeinformationbywebsearchingtools.\nForbothsimulatingusersinrecommendersystemsandcapturingtheirpreferences,retainingper-sonalizedinformationthroughmemoryisessential.\nAcriticalchallengeliesinhowtoalignthepersonalizedinformationandfeedbackwithLLMs,andstorethemintothememoryofagents.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.\nDuringmemoryreading,matchingscoresarecalculatedforeachmemoryentry,andthetop-Kentrieswillbeusedforthedecision-makingprocessofagents.\n15Inexistingstudies,mostagentsutilizeretrievalmethodstoprocessthememoryinformation.\nForexample,Parketal.\n[83]firstcalculatetherelevancebetweenthecurrentcontextandmemoryentriesbycosinesimilarity,andobtaintheimportanceandrecencyaccordingtoauxiliaryinformation.\nMemoryBank[6]employsadual-towerdenseretrievalmodeltofindrelatedinformationfrompastconversations.\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage.\nItutilizesLocality-SensitiveHashing(LSH)toretrievetupleswithrelativeentriesinthedatabasetoprovidemoreinformation.\nInaddition,ChatDB[96]designstoutilizesymbolicmemory,andproposestogenerateSQLstatementstoretrievefromdatabasetoobtainstoredinformation."
    ],
    [
      "#memory_survey#MemoryinParametricForm#memory_survey#MemoryinParametricForm\nMemoryinParametricFormAnalternativetypeofapproachesistorepresentmemoryinparametricform.\nTheydonottakeuptheextralengthofcontextinprompts,sotheyarenotconstrainedbythelengthlimitationsofLLMcontext.\nHowever,theparametricmemoryformisstillunder-researched,andwecategorizepreviousworksintotwotypes:fine-tuningmethodsandmemoryeditingmethods.\nFine-tuningMethods.\nIntegratingexternalknowledgeintothememoryofagentsisbeneficialforenrichingdomain-specificknowledgeontopofitsgeneralknowledge.\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.\nAnotherlimitationoffine-tuningliesinthecomputationalcostandtimeconsumption,aswellastherequirementofalargeamountofdata.\nTherefore,mostfine-tuningapproachesareappliedtoofflinescenarios,andcanseldomdealwithonlinescenarios,suchasfine-tuningwithagentobservationsandtrialexperiences.\nDuetothefrequentagent-environmentinteractions,itisunaffordableforthecostofbackpropagationtofine-tuneeverystepoftheonlineanddynamicinteractions.\nMemoryEditingMethods.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.\nAnotherlimitationoffine-tuningliesinthecomputationalcostandtimeconsumption,aswellastherequirementofalargeamountofdata.\nTherefore,mostfine-tuningapproachesareappliedtoofflinescenarios,andcanseldomdealwithonlinescenarios,suchasfine-tuningwithagentobservationsandtrialexperiences.\nDuetothefrequentagent-environmentinteractions,itisunaffordableforthecostofbackpropagationtofine-tuneeverystepoftheonlineanddynamicinteractions.\nMemoryEditingMethods.\nApartfromthefine-tuningapproaches,anothertypeofmethodsforinfusingmemoryintomodelparametersisknowledgeediting[133,134].\nUnlikefine-tuningmethodsthatextractpatternsfromcertaindatasets,knowledgeeditingmethodsspecificallytargetandadjustonlythefactsthatneedtobechanged.\nItensuresthatunrelatedknowledgeremainsunaffected.\nKnowledgeeditingmethodsaremoresuitableforsmall-scalememoryadjustments.\nGenerally,theyhavelowercomputationalcosts,makingthemmoresuitableforonlinescenarios.",
      "#memory_survey#ExpertSysteminSpecificDomains#memory_survey#ExpertSysteminSpecificDomains\nExpertSysteminSpecificDomainsMedicineDomain.\nInthefieldofmedicine,mostofthepreviousworksempowerLLM-basedagentswithexternalknowledgeintheirmemory[107,129,132,151,115].\nWangetal.\n[107]fine-tuneLLaMA[127]withmedicalknowledgegraphCMeKG[165]inQAform,inordertoenhancetheirmedicaldomainknowledge.\nXiongetal.\n[129]adoptLoRA[131]toefficientlyfine-tuneonfoundationmodelsforhealthcare.\nWangetal.\n[151]empowerLLM-basedagentstoacquiretext-basedexternalknowledgeasreasoningreference.\nBesides,Shietal.\n[152]buildmemoryuponthemostrelevantsuccessfulcasesfrompastexperiences,andusesimilaritymetricfortheretrievalofrelevantquestionsinthemedicinedomain.\nFinanceDomain.\nSomepreviousworksalsoapplyLLM-basedagentsinthefinancedomain,whosememorycanstorefinancialknowledge[113],marketinformation[154,156],andsuccessfulexperi-ences[157,155].\nYangetal.\n[113]constructfinancialinvestmentdatasettofine-tuneLLaMA[127]toempowerknowledgeoninvestment.\nLietal.\n[154]designalayered-memorystructuretostoredifferenttypesofmarketinginformation.\nWangetal.\n[155]recordtheongoinginteractionlikeexchangesandinformationtoensureconsistentresponse,andrecordprioroutputsasexperiencesforretrievingrelevantexamplestoprovideadiverselearningcontextforagents.\nKoaetal.\n[157]storepastpricemovementandexplanations,andgeneratereflectionsonprevioustrials.\nYuetal.\n[156]adoptalayeredmemorymechanismtoprovideabundantinformationforreasoning.\nScience.\nInthedomainofscience,someexistingworksdesignLLM-basedagentswithalargeamountofknowledgeinmemorytosolveproblems[158,160,162].\nChenetal.\n[158]includemoleculedatabaseandonlineliteratureasexternalknowledgeformemoryinLLM-basedagents,andretrievethemwhentheyneedrelatedinformation.\nZhaoetal.\n[160]andChenetal.\n[162]empowerdomainknowledgebyfine-tuninginChemistryandstructuredmaterialsrespectively.\nTobuildanexpertsystembasedonagentsinaspecificverticaldomain,itisnecessarytoretainthedomain-specificknowledgeintheirmemory.\nHowever,thereareseveralchallenges.",
      "#memory_survey#ExternalKnowledge#memory_survey#ExternalKnowledge\nTheexternalknowledgecanbeobtainedfrombothprivateandpublicsources.\nItprovidesLLM-basedagentswithmuchknowledgebeyondtheirinternalenvironment,whichmightbedifficultorevenimpossiblefortheagenttoacquirebyagent-environmentinteractions.\nMoreover,mostexternalknowledgecanbeacquiredbyaccessingtheAPIsofvarioustoolsdynamicallyinrealtimeaccordingtothetaskneeds,thusmitigatingtheproblemofoutdatedknowledge.\nIntegratingexternalknowledgeintothememoryofLLM-basedagentssignificantlyexpandstheirknowledgeboundaries,providingthemwithunlimited,up-to-date,andwell-foundedknowledgefordecision-making.\n5.\n2"
    ],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThismetricevaluateswhethertheagentcandiscoverrelevantmemorycontentstoanswerthequestions.\nDifferentfromtheabovemetric,whichfocusesonthefinalresults,referenceaccuracycaresmoreabouttheintermediateinformationtosupporttheagent’sfinaldecisions.\nInspecific,itcomparestheretrievedmemorywiththepre-preparedgroundtruth.\nFortheaboveproblemof\"WheredidAlicegotoday?\n\",ifthememorycontentsinclude(A)\"AlicehadlunchwithfriendsatWangfujingtoday.\n\"and(B)\"Alicehadroastduckforlunch\",thenabettermemorymoduleshouldselect(A)asareferencetoanswerthequestion.\nUsually,researchersleverageF1-scoretoevaluatethereferenceaccuracy,whichiscalculatedasF1=2·Precision·RecallPrecision+Recall,wheretheprecisionandrecallscoresarecalculatedasPrecision=TPTP+FN.\nTheTPrepresentsthenumberoftruepositivememorycontents,FPmeansthenumberoffalsepositivememorycontents,andFNindicatesthenumberoffalsenegativememorycontents.\nInpreviousworks,Luetal.\n[94]utilizeF1-scoretoevaluatetheretrievalprocessofthememory,andZhongetal.\n[6]focusonassessingwhetherrelatedmemorycanbesuccessfullyretrieved.\nTP+FPandRecall=TPResultCorrectnessandReferenceAccuracyarebothutilizedtoevaluatetheeffectivenessofthememorymodule.\nBeyondeffectiveness,efficiencyisalsoanimportantaspect,especiallyforreal-worldapplications.\nTherefore,wedescribetheevaluationofefficiencyasfollows.\nTime&HardwareCost.\nThetotaltimecostincludesthetimeleveragedformemoryadaptionandinference.\nTheadaptationtimereferstothetimeofmemorywritingandmemorymanagement,whiletheinferencetimeindicatesthetimelatencyofmemoryreading.\nInspecific,thedifferencefromthe21endtimetothestarttimeofmemoryoperationscanbeconsideredasthetimeconsumption.\nFormally,theaveragetimeconsumptionofeachtypeofoperationcanberepresentedas∆time=1MM(cid:88)i=1i−tstarttendi,whereMrepresentsthenumberoftheseoperations,tendimeanstheendtimeofthei-thoperation,andtstartindicatesthestarttimeofthatoperation.\nAsforthecomputationoverhead,itcanbeevaluatedibythepeakGPUmemoryallocation.\nInpreviousworks,Tacketal.",
      "#memory_survey#ObjectiveEvaluation#memory_survey#ObjectiveEvaluation\nUsually,researchersleverageF1-scoretoevaluatethereferenceaccuracy,whichiscalculatedasF1=2·Precision·RecallPrecision+Recall,wheretheprecisionandrecallscoresarecalculatedasPrecision=TPTP+FN.\nTheTPrepresentsthenumberoftruepositivememorycontents,FPmeansthenumberoffalsepositivememorycontents,andFNindicatesthenumberoffalsenegativememorycontents.\nInpreviousworks,Luetal.\n[94]utilizeF1-scoretoevaluatetheretrievalprocessofthememory,andZhongetal.\n[6]focusonassessingwhetherrelatedmemorycanbesuccessfullyretrieved.\nTP+FPandRecall=TPResultCorrectnessandReferenceAccuracyarebothutilizedtoevaluatetheeffectivenessofthememorymodule.\nBeyondeffectiveness,efficiencyisalsoanimportantaspect,especiallyforreal-worldapplications.\nTherefore,wedescribetheevaluationofefficiencyasfollows.\nTime&HardwareCost.\nThetotaltimecostincludesthetimeleveragedformemoryadaptionandinference.\nTheadaptationtimereferstothetimeofmemorywritingandmemorymanagement,whiletheinferencetimeindicatesthetimelatencyofmemoryreading.\nInspecific,thedifferencefromthe21endtimetothestarttimeofmemoryoperationscanbeconsideredasthetimeconsumption.\nFormally,theaveragetimeconsumptionofeachtypeofoperationcanberepresentedas∆time=1MM(cid:88)i=1i−tstarttendi,whereMrepresentsthenumberoftheseoperations,tendimeanstheendtimeofthei-thoperation,andtstartindicatesthestarttimeofthatoperation.\nAsforthecomputationoverhead,itcanbeevaluatedibythepeakGPUmemoryallocation.\nInpreviousworks,Tacketal.\n[106]utilizethepeakmemoryallocationandadaptationtimetoassesstheefficiencyofmemoryoperations.\nObjectiveevaluationoffersnumericstrategiestocomparedifferentmethodsofmemory,whichisimportanttobenchmarkthisfieldandpromotefuturedevelopments.\n6.\n2",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.\nDuringmemoryreading,matchingscoresarecalculatedforeachmemoryentry,andthetop-Kentrieswillbeusedforthedecision-makingprocessofagents.\n15Inexistingstudies,mostagentsutilizeretrievalmethodstoprocessthememoryinformation.\nForexample,Parketal.\n[83]firstcalculatetherelevancebetweenthecurrentcontextandmemoryentriesbycosinesimilarity,andobtaintheimportanceandrecencyaccordingtoauxiliaryinformation.\nMemoryBank[6]employsadual-towerdenseretrievalmodeltofindrelatedinformationfrompastconversations.\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nThesestatementswillbegeneratedbyagentsasaseriesofChain-of-Memoryinadvance.\nInMPC[101],theagentscanretrieverelevantmemoryfromthememorypool.\nThismethodalsoproposestoprovideChain-of-Thoughtexamplesforignoringcertainmemory.\nExpeL[82]utilizestheFaiss[124]vectorstoreasthepoolofmemory,andobtainsthetop-Ksuccessfultrajectoriesthatsharethehighestsimilarityscoreswiththecurrenttask.\nDiscussion.\nTosomeextent,thememoryreadingandwritingoperationsarecollaborative,andtheformsofmemorywritinggreatlyinfluencethemethodsofmemoryreading.\nFortheformsoftextual19Figure5:Anoverviewoftheevaluationmethodsofthememorymodule.\nmemory,mostpreviousworksusethetextsimilarityandotherauxiliaryinformationforreading.\nFortheformsofparametricmemory,existingmodelsmayjustutilizetheupdatedparametersforinference,whichcanbeseenasanimplicitreadingprocess.\n6",
      "#memory_survey#Memory-basedLifelongLearning#memory_survey#Memory-basedLifelongLearning\nMemory-basedLifelongLearningLifelonglearningisanadvancedtopicinartificialintelligence,extendingthelearningcapabilitiesofagentsacrosstheirlife-longspan[173].\nAgentscancontinuouslyinteractwiththeirenvironment,persistentlyobserveenvironments,andacquireexternalknowledge,enablingamodeofenhancementlikehumans.\nThememoryofanagentiskeytoachievinglifelonglearning,asitneedstolearntostoreandapplythepastobservations.\nLifelonglearninginLLM-basedagentsholdssignificantpracticalvalue,suchasinlong-termsocialsimulationsandpersonalassistance.\nHowever,italsofacesseveralchallenges.\nFirstly,lifelonglearningistemporal,necessitatingthatanagent’smemorycapturestemporality.\nThistemporalitycouldcauseinteractionsbetweenmemories,suchasmemoryoverlap.\nFurthermore,duetotheextendedperiodoflifelonglearning,itneedstostoreavastamountofmemoriesandretrievethemwhenneeded,possiblyincorporatingacertainmechanismforforgetting.\n8.\n4"
    ],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\nSomeofthemcanacquireexternaldatabasesorAPIstoobtaingeneralknowledge[99,93,159,161].\nWangetal.\n[99]saveobtainedskillsintomemoryforfurtherusageinMinecraft.\nZhuetal.\n[93]storeandretrievesuccessfultrajectoriesasexamplesforsimilartasks,andutilizeexternalMinecraftWikibyAPIcalls.\nWangetal.\n[159]constructmultimodalmemoryasaknowledgelibraryandprovideexamplesforpromptbyretrievinginteractiveexperiences.\nYanetal.\n[161]maintainworkingmemoryfordecision-making,saveandretrieverelevantpastexperiences,andimplementexternaldatasetsforgeneralknowledge.\nInsummary,nomatterinside-trialorcross-trialinformation,thekeyaspectofmemoryistoreflectonpastinteractionsanddrawexperiencesthatcanbeappliedtothesubsequentexploration.\nInadditiontoaccumulatingexperiencethroughself-involvingtrials,absorbingexternalknowledgeaspartoftheagent’smemoryisalsoanimportantwaytoenhancetheexploratorycapabilitiesoftheagent.\n7.\n4CodeGenerationInthescenarioofcodegeneration,LLM-basedagentscansearchrelevantinformationfromthememory,therebyobtainingmoreknowledgefordevelopment.\nTheycansavepreviousexperiencesforfutureproblems,andalsomaintaincontextinconversationaldevelopmentinterfaces[142,144,1,109].\nTsaietal.\n[142]constructanexternalnon-parametricmemorydatabase,whichstoresthecompilererrorsandhumanexpertinstructionsforautomaticsyntaxerrorfixing.\nIn[144],personalinformationwillbestoredinthememory,andhelpsinretainingcontextandknowledgefordecision-making.\nQianetal.\n[1]adoptmulti-agentstodevelopsoftware,whereeachrolemaintainsamemorytostorethepastconversationswithotherroles.\nLietal.\n[109]alsofocusonsoftwaredevelopment,andtheagentcanretrieveitshistoricalrecordspreservedinmemorywhenerrorsoccur.\nZhangetal.\n[114]cansearchrelevantinformationwhentheyfaceproblemsoncodegeneration.\nByleveragingexternalresources,theagentscanlearnfromcode-relatedknowledgeandstoreitintotheirmemory,therebyenhancingthecapabilitiesofcodegeneration.\nInaddition,thememorycanimprovethecontinuityandconsistencyincodegeneration.",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nMoreover,someeffortsarededicatedtoenhancingthecapacityofLLMstohandlelongercontexts[118,119].\nWhilestoringalltheagent-environmentinteractionscanmaintaincomprehensiveinformation,obviouslimitationsexistintermsofcomputationalcost,inferencetime,andinferencerobustness.\nFirstly,thefast-growinglong-contextmemoryinpracticeresultsinhighcomputationalcostduringLLMinference,duetothequadraticgrowthofthetimecomplexityofattentioncomputationwithsequencelength.\nItthusrequiresmuchmorecomputingresourcesandsignificantlyincreasesinferencelatency,whichhindersitspracticaldeployment.\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.\nThismethodstoresandmaintainsthemostrecentlyacquiredmemoriesusingnaturallanguages,therebyenhancingtheefficiencyofmemoryinformationutilizationaccordingtothePrincipleofLocality[121].\nIntask(B)oftheexampleinSection3.\n1,wecanjustrememberAlice’spreferencesintherecentthreeyears,andtruncatethedistantpart,wheretherecentthreeyearscanbeconsideredasthememorywindowsize.\nInpreviousstudies,therearevariousstrategiestostorerecenttextualmemories.\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.\nThismethodstoresandmaintainsthemostrecentlyacquiredmemoriesusingnaturallanguages,therebyenhancingtheefficiencyofmemoryinformationutilizationaccordingtothePrincipleofLocality[121].\nIntask(B)oftheexampleinSection3.\n1,wecanjustrememberAlice’spreferencesintherecentthreeyears,andtruncatethedistantpart,wheretherecentthreeyearscanbeconsideredasthememorywindowsize.\nInpreviousstudies,therearevariousstrategiestostorerecenttextualmemories.\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.\nThismethodstoresandmaintainsthemostrecentlyacquiredmemoriesusingnaturallanguages,therebyenhancingtheefficiencyofmemoryinformationutilizationaccordingtothePrincipleofLocality[121].\nIntask(B)oftheexampleinSection3.\n1,wecanjustrememberAlice’spreferencesintherecentthreeyears,andtruncatethedistantpart,wheretherecentthreeyearscanbeconsideredasthememorywindowsize.\nInpreviousstudies,therearevariousstrategiestostorerecenttextualmemories.\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.",
      "#memory_survey#Memory-basedLifelongLearning#memory_survey#Memory-basedLifelongLearning\nMemory-basedLifelongLearningLifelonglearningisanadvancedtopicinartificialintelligence,extendingthelearningcapabilitiesofagentsacrosstheirlife-longspan[173].\nAgentscancontinuouslyinteractwiththeirenvironment,persistentlyobserveenvironments,andacquireexternalknowledge,enablingamodeofenhancementlikehumans.\nThememoryofanagentiskeytoachievinglifelonglearning,asitneedstolearntostoreandapplythepastobservations.\nLifelonglearninginLLM-basedagentsholdssignificantpracticalvalue,suchasinlong-termsocialsimulationsandpersonalassistance.\nHowever,italsofacesseveralchallenges.\nFirstly,lifelonglearningistemporal,necessitatingthatanagent’smemorycapturestemporality.\nThistemporalitycouldcauseinteractionsbetweenmemories,suchasmemoryoverlap.\nFurthermore,duetotheextendedperiodoflifelonglearning,itneedstostoreavastamountofmemoriesandretrievethemwhenneeded,possiblyincorporatingacertainmechanismforforgetting.\n8.\n4"
    ],
    [
      "#memory_survey#MemoryinLLM-basedMulti-agentApplications#memory_survey#MemoryinLLM-basedMulti-agentApplications\nMemoryinLLM-basedMulti-agentApplicationsTheexplorationofmemorymechanismswithinLLMshasburgeonedintothedynamicdomainofmulti-agentsystems(MAS),markingsignificantadvancementsintherealmsofsynchronization,communication,andthemanagementofinformationasymmetry.\nOnepivotalaspectthatemergesinthecooperativescenariosismemorysynchronizationamongagents.\nThisprocessisfundamentalforestablishingaunifiedknowledgebase,ensuringconsistencyindecision-makingacrossdifferentagents.\nForexample,Chenetal.\n[170]emphasizethesignificanceofintegratingsynchronizedmemorymodulesformulti-robotcollaboration.\nAnotherimportantaspectisthecommunicationamongagents,whichheavilyreliesonmemoryformaintainingcontextandinterpretingmessages.\nForexample,Mandietal.\n[171]illustratememory-drivencommunicationframeworksthatfosteracommonunderstandingamongagents.\nInadditiontocooperativescenarios,somestudiesalsofocusoncompetitivescenarios,andtheinformationasymmetrybecomesacrucialissue[172].\nLookingahead,theadvancementofmemoryinLLM-basedMASispoisedattheconfluenceoftechnologicalinnovationandstrategicapplication.\nItbeckonstheexplorationofnovelmemory27modulesthatcanfurtherenhanceagentsynchronization,enablemoreeffectivecommunication,andprovidestrategicadvantagesininformation-richenvironments.\nThedevelopmentofsuchmemorymodelswouldnotonlynecessitateaddressingthecurrentchallengesofmemoryintegrationandman-agement,butalsoexploretheuntappedpotentialsofmemoryinfacilitatingmorerobust,intelligent,andadaptableMAS.\nAsevidencedbypioneeringresearch,theevolvinglandscapeofLLM-basedMASsetsapromisingstageforfutureinnovationsinmemoryutilizationandmanagement.\nThisexplorationisexpectedtounravelnewdimensionsofmemoryintegration,pushingtheboundariesofwhatiscurrentlyachievableandsettingnewbenchmarksintherealmofMAS.\n8.\n3",
      "#memory_survey#Conversation#memory_survey#Conversation\nConversationEngaginginconversationswithhumansisoneofthemostimportantapplicationsofagents,wherememoryplaysacrucialroleinthisprocess.\nBystoringcontextinformationinmemory,theagentsallowuserstoexperiencepersonalizedconversations,thusimprovingusers’satisfaction.\nTherefore,whenotherpartsoftheagentsaredetermined,theperformanceoftheconversationtaskscanreflecttheeffectivenessofdifferentmemorymodules.\nInthecontextofconversation,consistencyandengagementaretwocommonlyusedmethodstoevaluatetheeffectivenessoftheagents’memory.\nConsistencyreferstohowtheresponsefromagentsisconsistentwiththecontextbecausedramaticchangesshouldbeavoidedduringtheconversation.\nForexample,Luetal.\n[94]evaluatetheconsistencyofagentsoninteractivedialogues,usingGPT-4toscoreontheresponsesfromagents.\nEngagementreferstohowtheuserisengagedtocontinuetheconversation.\nItreflectsthequalityandattractionofagents’responses,aswellastheabilityofagentstocraftthepersonasforcurrentconversations.\nForexample,Leeetal.\n[101]assesstheengagingnessofresponsesbySCE-pscore,andPackeretal.\n[100]utilizeCSIMscoretoevaluatethememoryeffectonincreasingengagementofusers.\n6.\n2.\n2",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThememorymoduleisanimportantcomponentforsuchapplications,whichhelpstoaccuratelysimulatehumandynamicbehaviors.\nInpreviousstudies,Kaiyaetal.\n[148]proposeaSummarize-and-Forgetmemorymechanismforbetterself-monitoringinsocialscenarios.\nGaoetal.\n[2]focusonsocialnetworksimulationsystems.\nEachagentinthesystemhasamemorypool,whichconsistsofdiverseusermessagesfromonlineplatformstoidentifytheuser.\nLietal.\n[163]maintainconversationcontexts,encompassingtheeconomicenvironmentandagentdecisionsfrompreviousmonths,inordertosimulatetheimpactofbroadmacroeconomictrendsonagents’decision-makingandtomaketheagentsgraspmarketdynamics.\nLietal.\n[109]simulatethejob-seekingscenarioinhumansociety,wherethememoryofagentsincludesprofilesandgoalsinitiallyandisfurtherenrichedwithotherinformation,likedialoguesandpersonalreflections.\nHuaetal.\n[150]simulatethedecisionsandconsequencesoftheparticipatingcountriesinthewars,wheretheconversationsofagentsarecontinuouslymaintainedintomemory.\nThereareseveralinsightsindesigninganagent’smemoryforrole-playandsocialsimulation.\nFirst,thememoryshouldbeconsistentwiththeroles’characteristics,whichcanbeusedtoidentifyeachroleanddistinguishitfromtheothers.\nThisiscrucialforimprovingtherealismofrole-playandthediversityofsocialsimulation.\nSecond,thememoryshouldappropriatelyinfluencethesubsequent24actionsoftheagenttoensuretheconsistencyandrationalityofitsbehaviors.\nAdditionally,forhumanoidagents,theirmemorymechanismsshouldalignwiththefeaturesofhumanmemory,suchasforgettingandlong/short-termmemory,whichshouldrefertothetheoriesofcognitivepsychology.\n7.\n2PersonalAssistantLLM-basedagentsarewell-suitedforcreatingpersonalassistants,suchasagentscapableofengaginginlong-termconversationswithusers[94,101,153],aswellasthosetaskedwithautomaticallyseekinginformation[164].\nTheseagentsoftenneedtomemorizepreviousdialoguestomaintaintheconsistency,andremembercriticalstylesandeventstogeneratemorepersonalizedandrelevantresponses.\nLuetal.",
      "#memory_survey#Introduction#memory_survey#Introduction\nIntroduction\"Withoutmemory,thereisnoculture.\nWithoutmemory,therewouldbenocivilization,nosociety,nofuture.\n\"ElieWiesel,1928-2016Recently,largelanguagemodels(LLMs)haveachievedremarkablesuccessinalargenumberofdomains,rangingfromartificialintelligenceandsoftwareengineeringtoeducationandsocialsci-ence[1–3].\nOriginalLLMsusuallyaccomplishdifferenttaskswithoutinteractingwithenvironments.\nHowever,toachievethefinalgoalofartificialgeneralintelligence(AGI),intelligentmachinesshouldbeabletoimprovethemselvesbyautonomouslyexploringandlearningfromtherealworld.\nForexample,ifatrip-planningagentintendstobookaticket,itshouldsendanorderrequesttotheticketwebsite,andobservetheresponsebeforetakingthenextaction.\nApersonalassistantagentshouldadjustitsbehaviorsaccordingtotheuser’sfeedback,providingpersonalizedresponsestoimproveuser’ssatisfaction.\nTofurtherpushtheboundaryofLLMstowardsAGI,recentyearshavewitnessedalargenumberofstudiesonLLM-basedagents[3,4],wherethekeyistoequipLLMswithadditionalmodulestoenhancetheirself-evolvingcapabilityinreal-worldenvironments.\nAmongalltheaddedmodules,memoryisakeycomponentthatdifferentiatestheagentsfromoriginalLLMs,makinganagenttrulyanagent(seeFigure1).\nItplaysanextremelyimportantroleindetermininghowtheagentaccumulatesknowledge,processeshistoricalexperience,retrievesinformativeknowledgetosupportitsactions,andsoon.\nAroundthememorymodule,peoplehavedevotedmuchefforttodesigningitsinformationsources,storageforms,andoperationmechanisms.\nForexample,Shinnetal.\n[5]incorporatebothin-trialandcross-trialinformationtobuildthememorymoduleforenhancingtheagent’sreasoningcapability.\nZhongetal.\n[6]storememoryinformationintheformofnaturallanguages,whichisexplainableandfriendlytotheusers.\nModarressietal.\n[7]designbothmemoryreadingandwritingoperationstointeractwithenvironmentsfortasksolving.\nWhilepreviousstudieshavedesignedmanypromisingmemorymodules,therestilllacksasystemicstudytoviewthememorymodulesfromaholisticperspective.",
      "#memory_survey#Memory-basedLifelongLearning#memory_survey#Memory-basedLifelongLearning\nMemory-basedLifelongLearningLifelonglearningisanadvancedtopicinartificialintelligence,extendingthelearningcapabilitiesofagentsacrosstheirlife-longspan[173].\nAgentscancontinuouslyinteractwiththeirenvironment,persistentlyobserveenvironments,andacquireexternalknowledge,enablingamodeofenhancementlikehumans.\nThememoryofanagentiskeytoachievinglifelonglearning,asitneedstolearntostoreandapplythepastobservations.\nLifelonglearninginLLM-basedagentsholdssignificantpracticalvalue,suchasinlong-termsocialsimulationsandpersonalassistance.\nHowever,italsofacesseveralchallenges.\nFirstly,lifelonglearningistemporal,necessitatingthatanagent’smemorycapturestemporality.\nThistemporalitycouldcauseinteractionsbetweenmemories,suchasmemoryoverlap.\nFurthermore,duetotheextendedperiodoflifelonglearning,itneedstostoreavastamountofmemoriesandretrievethemwhenneeded,possiblyincorporatingacertainmechanismforforgetting.\n8.\n4"
    ],
    [
      "#memory_survey#HowtoEvaluatetheMemoryinLLM-basedAgent#memory_survey#HowtoEvaluatetheMemoryinLLM-basedAgent\nHowtoEvaluatetheMemoryinLLM-basedAgentHowtoeffectivelyevaluatethememorymoduleremainsanopenproblem,wherediverseevaluationstrategieshavebeenproposedinpreviousworksaccordingtodifferentapplications.\nToclearlyshowthecommonideasofdifferentevaluationmethods,inthissection,wesummarizeageneralframework,whichincludestwobroadevaluationstrategies(seeFigure5foranoverview),thatis,(1)directevaluation,whichindependentlymeasuresthecapabilityofthememorymodule.\n(2)indirectevaluation,whichevaluatesthememorymoduleviaend-to-endagenttasks.\nIfthetaskscanbeeffectivelyaccomplished,thememorymoduleisdemonstratedtobeuseful.\n6.\n1",
      "#memory_survey#Memory-enhancedAgentApplications#memory_survey#Memory-enhancedAgentApplications\nMemory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nInfact,nearlyallthememory-equippedagentscanevaluatetheeffectofmemorybyablationstudies,comparingtheperformancebetweenwith/withoutmemorymodules.\nTheevaluationonspecificscenarioscanbetterreflectthesignificanceofmemoryforthedownstreamapplicationspractically.\n6.\n3DiscussionsComparedwithdirectevaluation,indirectevaluationviaspecifictaskscanbeeasiertoconduct,sincetherearealreadymanypublicbenchmarks.\nHowever,theperformanceontaskscanbeattributedtovariousfactors,andmemoryisonlyoneofthem,whichmaymaketheevaluationresultsbiased.\nBydirectevaluation,theeffectivenessofthememorymodulecanbeindependentlyevaluated,whichimprovesthereliabilityoftheevaluationresults.\nHowever,toourknowledge,therearenoopen-sourcedbenchmarkstailoredforthememorymodulesinLLM-basedagents.\n7Memory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1Role-playingandSocialSimulationRole-playingrepresentsaclassicapplicationofLLM-basedagents,wherememoryplaysacrucialroleinsidetheagents.\nItendowsroleswithdistinctcharacteristics,differentiatingthemfromoneanother.\nManypreviousstudieshaveexploredmethodsforconstructingrolememories[105,143,145–147].\nShaoetal.\n[105]constructthememoryofrolesbyexperienceuploading,whichutilizesSFTtoinjectmemoryintomodelparameters.\nLietal.",
      "#memory_survey#WhyWeNeedtheMemoryinLLM-basedAgent#memory_survey#WhyWeNeedtheMemoryinLLM-basedAgent\nWhyWeNeedtheMemoryinLLM-basedAgentAbove,wehaveintroducedwhatisthememoryofLLM-basedagents.\nBeforecomprehensivelypresentinghowtoimplementit,inthissection,webrieflyshowwhymemoryisnecessaryforbuildingLLM-basedagents,whereweexpandourdiscussionfromthreeperspectivesincludingcognitivepsychology,self-evolution,andagentapplications.\n4.\n1",
      "#memory_survey#Memory-assistedAgent-EnvironmentInteraction#memory_survey#Memory-assistedAgent-EnvironmentInteraction\nForthenarrowmemorydefinition,theiterationonlyhappenswithinthesametrial,andthememoryisemptiedwhenthetrialisended.\nForthebroadmemorydefinition,theiterationhappensacrossdifferenttrialsoreventasks,aswellastheintegrationsofexternalknowledge.\nFortask(B)intheabovetoyexample,theagentcanconcludethatAliceenjoyswatchingsciencefictionmoviesintheevening,whichcanbeusedasadefaultruletomakerecommendationsforAliceinthefuture.\nMemoryReading.\nThisoperationaimstoobtainimportantinformationfromthememorytosupportthenextagentaction.\nItcorrespondstothethirdphaseoftheagent-environmentinteractionprocess.\nSupposeMktisthecontextofthenextaction,thenthememoryreadingoperationcanberepresentedby:tisthememorycontentsfortaskkatstept,ckˆMkt=R(Mkt,ckt+1),whereRisusuallyimplementedbycomputingthesimilaritybetweenMktisusedaspartsofthefinalprompttodrivetheagent’snextaction.\nFortask(B)intheabovetoyexample,whentheagentdecidesonthefinalrecommendedmoviein[Step3],itshouldfocusonthe“wanttowatch”listin[Step2]andselectonefromit.\ntandckt+1[82].\nˆMkBasedontheaboveoperations,wecanderiveaunifiedfunctionfortheevolvingprocessfrom{akt,okt}toakt+1,thatis:akt+1=LLM{R(P(Mkt−1,W({akt,okt})),ckt+1)},whereLLMisthelargelanguagemodel.\nThecompleteagent-environmentinteractionprocesscanbeeasilyobtainedbyiterativelyexpandingthisfunction(seeFigure3(b)foranintuitiveillustration).\nRemark.\nThisfunctionprovidesageneralformulationoftheagentmemorizingprocess.\nPreviousworksmayusedifferentspecifications.\nForexample,in[5],RandParesetasidenticalfunctions,andPonlytakeseffectattheendofatrial.\nInParketal.\n[83],Risimplementedbasedonthreecriteriaincludingsimilarity,timeinterval,andimportance,andPisrealizedbyareflectionprocesstoobtainmoreabstractthoughts.\nInthissection,wefocusontheoverallframeworkoftheagent’smemoryoperations.\nMoredetailedrealizationsofW,P,andRaredeferredinSection5.\n4"
    ],
    [
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nMoreover,retrievalmethodstypicallystorehomogeneousinformationinsidetheenvironment,wherealltheinformationisinaconsistentform.\nForheterogeneousinformationoutsidetheenvironment,it’sdifficulttodirectlyapplythesamemethodformemorystorage.\nExternalKnowledge.\nToobtainmoreinformation,someagentsacquireexternalknowledgebyinvokingtools,withtheaimoftransformingadditionalrelevantknowledgeintotheirownmemoriesfordecision-making.\nForinstance,accessingexternalknowledgethroughApplicationProgrammingInterface(API)isacommonpractice[104,5].\nNowadays,abundantpublicinformation,suchasWikipediaandOpenWeatherMap4,areavailableonline(eitherfreeofchargeoronapayingbasis),andcanbeconvenientlyaccessedthroughAPIcalls.\nForinstance,in[Step2]oftask(A)oftheexampleinSection3.\n1,externalknowledgefromthedigitalmagazineisobtainedwithtoolmethods.\nInexistingmodels,Toolformer[125]proposestoteachLLMtousetools,whichcanacquireexternalknowledgeforbettersolvingtasks.\nFurthermore,ToolLLM[126]empowersLlama[127]withtheabilitytoutilizemoreAPIsinRapidAPI5andtoenablemulti-toolusage,whichprovidesageneralinterfacetoextendagents’ability.\nInTPTU[110],theagentsareincorporatedinbothtaskplanningandtoolusage,inordertotackleintricateproblems.\nThefollow-upwork[111]furtherimprovesitsabilityextensivelylikeretrieval.\nInToRA[128],theagentsarerequiredtosolvemathematicalproblems.\nTheyutilizeimitationlearningtoimprovetheirabilitytouseprogram-basedtools.\nTheabovemethodssignificantlyadvancethecapabilitiesofagentsbyallowingthemtoaccessexternalup-to-dateandreal-worldinformationfromdiversesources.\nHowever,thereliabilityofthisinformationcanbequestionableduetopotentialinaccuraciesandbiases[18].\nFurthermore,theintegrationoftoolsintoagentsdemandsacomprehensiveunderstandingtointerprettheretrievedinformationacrossvariouscontexts,whichcanincurhighercomputationalcostsandcomplicationsinaligningexternaldatawithinternaldecision-makingprocesses.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage.\nItutilizesLocality-SensitiveHashing(LSH)toretrievetupleswithrelativeentriesinthedatabasetoprovidemoreinformation.\nInaddition,ChatDB[96]designstoutilizesymbolicmemory,andproposestogenerateSQLstatementstoretrievefromdatabasetoobtainstoredinformation.\nTheretrievalmethodsconsiderablydependontheaccuracyandefficiencyofobtainingexpectedinformation.\nAninaccurateretrievalstrategycanpotentiallyacquireunrelatedinformationthatisunhelpfulforagentinference.\nAndaheavyretrievalsystemcanleadtolargecomputationalcostsandlongtimelatency,especiallywhenhandlingmassiveinformation.\nMoreover,retrievalmethodstypicallystorehomogeneousinformationinsidetheenvironment,wherealltheinformationisinaconsistentform.\nForheterogeneousinformationoutsidetheenvironment,it’sdifficulttodirectlyapplythesamemethodformemorystorage.\nExternalKnowledge.\nToobtainmoreinformation,someagentsacquireexternalknowledgebyinvokingtools,withtheaimoftransformingadditionalrelevantknowledgeintotheirownmemoriesfordecision-making.\nForinstance,accessingexternalknowledgethroughApplicationProgrammingInterface(API)isacommonpractice[104,5].\nNowadays,abundantpublicinformation,suchasWikipediaandOpenWeatherMap4,areavailableonline(eitherfreeofchargeoronapayingbasis),andcanbeconvenientlyaccessedthroughAPIcalls.\nForinstance,in[Step2]oftask(A)oftheexampleinSection3.\n1,externalknowledgefromthedigitalmagazineisobtainedwithtoolmethods.\nInexistingmodels,Toolformer[125]proposestoteachLLMtousetools,whichcanacquireexternalknowledgeforbettersolvingtasks.\nFurthermore,ToolLLM[126]empowersLlama[127]withtheabilitytoutilizemoreAPIsinRapidAPI5andtoenablemulti-toolusage,whichprovidesageneralinterfacetoextendagents’ability.",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nFurthermore,theintegrationoftoolsintoagentsdemandsacomprehensiveunderstandingtointerprettheretrievedinformationacrossvariouscontexts,whichcanincurhighercomputationalcostsandcomplicationsinaligningexternaldatawithinternaldecision-makingprocesses.\nAdditionally,utilizingexternalAPIsbringsforthconcernsregardingprivacy,datasecurity,andcompliancewithusagepolicies,necessitatingrigorousmanagementandoversight[18].\n5.\n2.\n2",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nItutilizesLocality-SensitiveHashing(LSH)toretrievetupleswithrelativeentriesinthedatabasetoprovidemoreinformation.\nInaddition,ChatDB[96]designstoutilizesymbolicmemory,andproposestogenerateSQLstatementstoretrievefromdatabasetoobtainstoredinformation.\nTheretrievalmethodsconsiderablydependontheaccuracyandefficiencyofobtainingexpectedinformation.\nAninaccurateretrievalstrategycanpotentiallyacquireunrelatedinformationthatisunhelpfulforagentinference.\nAndaheavyretrievalsystemcanleadtolargecomputationalcostsandlongtimelatency,especiallywhenhandlingmassiveinformation.\nMoreover,retrievalmethodstypicallystorehomogeneousinformationinsidetheenvironment,wherealltheinformationisinaconsistentform.\nForheterogeneousinformationoutsidetheenvironment,it’sdifficulttodirectlyapplythesamemethodformemorystorage.\nExternalKnowledge.\nToobtainmoreinformation,someagentsacquireexternalknowledgebyinvokingtools,withtheaimoftransformingadditionalrelevantknowledgeintotheirownmemoriesfordecision-making.\nForinstance,accessingexternalknowledgethroughApplicationProgrammingInterface(API)isacommonpractice[104,5].\nNowadays,abundantpublicinformation,suchasWikipediaandOpenWeatherMap4,areavailableonline(eitherfreeofchargeoronapayingbasis),andcanbeconvenientlyaccessedthroughAPIcalls.\nForinstance,in[Step2]oftask(A)oftheexampleinSection3.\n1,externalknowledgefromthedigitalmagazineisobtainedwithtoolmethods.\nInexistingmodels,Toolformer[125]proposestoteachLLMtousetools,whichcanacquireexternalknowledgeforbettersolvingtasks.\nFurthermore,ToolLLM[126]empowersLlama[127]withtheabilitytoutilizemoreAPIsinRapidAPI5andtoenablemulti-toolusage,whichprovidesageneralinterfacetoextendagents’ability.\nInTPTU[110],theagentsareincorporatedinbothtaskplanningandtoolusage,inordertotackleintricateproblems.\nThefollow-upwork[111]furtherimprovesitsabilityextensivelylikeretrieval.\nInToRA[128],theagentsarerequiredtosolvemathematicalproblems.\nTheyutilizeimitationlearningtoimprovetheirabilitytouseprogram-basedtools.",
      "#memory_survey#ExternalKnowledge#memory_survey#ExternalKnowledge\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain.\nItfine-tunesanacquisitionprocesstoretrieveexternalknowledgefromWikipediaandmedicaldatabases.\nDiscussion.\nTheexternalknowledgecanbeobtainedfrombothprivateandpublicsources.\nItprovidesLLM-basedagentswithmuchknowledgebeyondtheirinternalenvironment,whichmightbedifficultorevenimpossiblefortheagenttoacquirebyagent-environmentinteractions."
    ],
    [
      "#memory_survey#ObjectiveEvaluation#memory_survey#ObjectiveEvaluation\nObjectiveEvaluationInobjectiveevaluation,previousworkusuallydefinesnumericmetricstoevaluatetheeffectivenessandefficiencyofthememorymodule.\nResultCorrectness.\nThismetricmeasureswhethertheagentcansuccessfullyanswerpre-definedquestionsdirectlybasedonthememorymodule.\nForexample,thequestioncouldbe\"WheredidAlicegotoday?\n\"withtwochoices\"A:theSummerPalace\"and\"B:theGreatWall\".\nThen,theagentshouldchoosethecorrectanswerbasedontheproblemanditsmemory.\nTheagent-generatedanswerwillbecomparedwiththegroundtruth.\nFormally,theaccuracycanbecalculatedasCorrectness=1NN(cid:88)i=1I[ai=ˆai],whereNisthenumberofproblems,airepresentsthegroundtruthforthei-thproblem,ˆaimeanstheanswergivenbytheagent,andI[ai=ˆai]isthematchingfunctioncommonlyrepresentedasI[ai=ˆai]=(cid:26)10ifai=ˆai,ifai̸=ˆai.\nInpreviousworks,Huetal.\n[96]constructquestionsfrompasthistorieswithannotatedgroundtruthsandcalculatetheaccuracyofwhethertherecalledmemorycouldmatchthecorrectanswers.\nSimilarly,Packeretal.\n[100]generatequestionsandanswersthatcanonlybederivedfrompastsessions,andcomparetheresponsesfromtheagentswiththegroundtruthstocalculatetheaccuracy.\nReferenceAccuracy.\nThismetricevaluateswhethertheagentcandiscoverrelevantmemorycontentstoanswerthequestions.\nDifferentfromtheabovemetric,whichfocusesonthefinalresults,referenceaccuracycaresmoreabouttheintermediateinformationtosupporttheagent’sfinaldecisions.\nInspecific,itcomparestheretrievedmemorywiththepre-preparedgroundtruth.\nFortheaboveproblemof\"WheredidAlicegotoday?\n\",ifthememorycontentsinclude(A)\"AlicehadlunchwithfriendsatWangfujingtoday.\n\"and(B)\"Alicehadroastduckforlunch\",thenabettermemorymoduleshouldselect(A)asareferencetoanswerthequestion.\nUsually,researchersleverageF1-scoretoevaluatethereferenceaccuracy,whichiscalculatedasF1=2·Precision·RecallPrecision+Recall,wheretheprecisionandrecallscoresarecalculatedasPrecision=TPTP+FN.\nTheTPrepresentsthenumberoftruepositivememorycontents,FPmeansthenumberoffalsepositivememorycontents,andFNindicatesthenumberoffalsenegativememorycontents.",
      "#memory_survey#ObjectiveEvaluation#memory_survey#ObjectiveEvaluation\nUsually,researchersleverageF1-scoretoevaluatethereferenceaccuracy,whichiscalculatedasF1=2·Precision·RecallPrecision+Recall,wheretheprecisionandrecallscoresarecalculatedasPrecision=TPTP+FN.\nTheTPrepresentsthenumberoftruepositivememorycontents,FPmeansthenumberoffalsepositivememorycontents,andFNindicatesthenumberoffalsenegativememorycontents.\nInpreviousworks,Luetal.\n[94]utilizeF1-scoretoevaluatetheretrievalprocessofthememory,andZhongetal.\n[6]focusonassessingwhetherrelatedmemorycanbesuccessfullyretrieved.\nTP+FPandRecall=TPResultCorrectnessandReferenceAccuracyarebothutilizedtoevaluatetheeffectivenessofthememorymodule.\nBeyondeffectiveness,efficiencyisalsoanimportantaspect,especiallyforreal-worldapplications.\nTherefore,wedescribetheevaluationofefficiencyasfollows.\nTime&HardwareCost.\nThetotaltimecostincludesthetimeleveragedformemoryadaptionandinference.\nTheadaptationtimereferstothetimeofmemorywritingandmemorymanagement,whiletheinferencetimeindicatesthetimelatencyofmemoryreading.\nInspecific,thedifferencefromthe21endtimetothestarttimeofmemoryoperationscanbeconsideredasthetimeconsumption.\nFormally,theaveragetimeconsumptionofeachtypeofoperationcanberepresentedas∆time=1MM(cid:88)i=1i−tstarttendi,whereMrepresentsthenumberoftheseoperations,tendimeanstheendtimeofthei-thoperation,andtstartindicatesthestarttimeofthatoperation.\nAsforthecomputationoverhead,itcanbeevaluatedibythepeakGPUmemoryallocation.\nInpreviousworks,Tacketal.\n[106]utilizethepeakmemoryallocationandadaptationtimetoassesstheefficiencyofmemoryoperations.\nObjectiveevaluationoffersnumericstrategiestocomparedifferentmethodsofmemory,whichisimportanttobenchmarkthisfieldandpromotefuturedevelopments.\n6.\n2",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nInaddition,thegranularityoftheratingsshouldalsobecarefullydesigned.\nToocoarseratingsmaynoteffectivelydiscriminatethecapabilitiesofdifferentmemorymodules,whiletoofine-grainedonesmaybringmoreeffortfortheworkerstomakejudgments.\nIngeneral,subjectiveevaluationcanbeusedinawiderangeofscenarios,whereonejustneedstodefinetheevaluationaspectsandletrecruitedworkersmakejudgments.\nThismethodisusuallymoreexplainablesincetheworkerscanprovidethereasonsfortheirjudgments.\nHowever,subjectiveevaluationiscostlyduetotheneedtoemployhumanevaluators.\nAdditionally,differentgroupsofevaluatorsmayhavevariousbiases,makingtheresultsdifficulttoreproduceandcompare.\n6.\n1.\n2ObjectiveEvaluationInobjectiveevaluation,previousworkusuallydefinesnumericmetricstoevaluatetheeffectivenessandefficiencyofthememorymodule.\nResultCorrectness.\nThismetricmeasureswhethertheagentcansuccessfullyanswerpre-definedquestionsdirectlybasedonthememorymodule.\nForexample,thequestioncouldbe\"WheredidAlicegotoday?\n\"withtwochoices\"A:theSummerPalace\"and\"B:theGreatWall\".\nThen,theagentshouldchoosethecorrectanswerbasedontheproblemanditsmemory.\nTheagent-generatedanswerwillbecomparedwiththegroundtruth.\nFormally,theaccuracycanbecalculatedasCorrectness=1NN(cid:88)i=1I[ai=ˆai],whereNisthenumberofproblems,airepresentsthegroundtruthforthei-thproblem,ˆaimeanstheanswergivenbytheagent,andI[ai=ˆai]isthematchingfunctioncommonlyrepresentedasI[ai=ˆai]=(cid:26)10ifai=ˆai,ifai̸=ˆai.\nInpreviousworks,Huetal.\n[96]constructquestionsfrompasthistorieswithannotatedgroundtruthsandcalculatetheaccuracyofwhethertherecalledmemorycouldmatchthecorrectanswers.\nSimilarly,Packeretal.\n[100]generatequestionsandanswersthatcanonlybederivedfrompastsessions,andcomparetheresponsesfromtheagentswiththegroundtruthstocalculatetheaccuracy.\nReferenceAccuracy.\nThismetricevaluateswhethertheagentcandiscoverrelevantmemorycontentstoanswerthequestions.\nDifferentfromtheabovemetric,whichfocusesonthefinalresults,referenceaccuracycaresmoreabouttheintermediateinformationtosupporttheagent’sfinaldecisions.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThismetricevaluateswhethertheagentcandiscoverrelevantmemorycontentstoanswerthequestions.\nDifferentfromtheabovemetric,whichfocusesonthefinalresults,referenceaccuracycaresmoreabouttheintermediateinformationtosupporttheagent’sfinaldecisions.\nInspecific,itcomparestheretrievedmemorywiththepre-preparedgroundtruth.\nFortheaboveproblemof\"WheredidAlicegotoday?\n\",ifthememorycontentsinclude(A)\"AlicehadlunchwithfriendsatWangfujingtoday.\n\"and(B)\"Alicehadroastduckforlunch\",thenabettermemorymoduleshouldselect(A)asareferencetoanswerthequestion.\nUsually,researchersleverageF1-scoretoevaluatethereferenceaccuracy,whichiscalculatedasF1=2·Precision·RecallPrecision+Recall,wheretheprecisionandrecallscoresarecalculatedasPrecision=TPTP+FN.\nTheTPrepresentsthenumberoftruepositivememorycontents,FPmeansthenumberoffalsepositivememorycontents,andFNindicatesthenumberoffalsenegativememorycontents.\nInpreviousworks,Luetal.\n[94]utilizeF1-scoretoevaluatetheretrievalprocessofthememory,andZhongetal.\n[6]focusonassessingwhetherrelatedmemorycanbesuccessfullyretrieved.\nTP+FPandRecall=TPResultCorrectnessandReferenceAccuracyarebothutilizedtoevaluatetheeffectivenessofthememorymodule.\nBeyondeffectiveness,efficiencyisalsoanimportantaspect,especiallyforreal-worldapplications.\nTherefore,wedescribetheevaluationofefficiencyasfollows.\nTime&HardwareCost.\nThetotaltimecostincludesthetimeleveragedformemoryadaptionandinference.\nTheadaptationtimereferstothetimeofmemorywritingandmemorymanagement,whiletheinferencetimeindicatesthetimelatencyofmemoryreading.\nInspecific,thedifferencefromthe21endtimetothestarttimeofmemoryoperationscanbeconsideredasthetimeconsumption.\nFormally,theaveragetimeconsumptionofeachtypeofoperationcanberepresentedas∆time=1MM(cid:88)i=1i−tstarttendi,whereMrepresentsthenumberoftheseoperations,tendimeanstheendtimeofthei-thoperation,andtstartindicatesthestarttimeofthatoperation.\nAsforthecomputationoverhead,itcanbeevaluatedibythepeakGPUmemoryallocation.\nInpreviousworks,Tacketal.",
      "#memory_survey#Memory-basedLifelongLearning#memory_survey#Memory-basedLifelongLearning\nMemory-basedLifelongLearningLifelonglearningisanadvancedtopicinartificialintelligence,extendingthelearningcapabilitiesofagentsacrosstheirlife-longspan[173].\nAgentscancontinuouslyinteractwiththeirenvironment,persistentlyobserveenvironments,andacquireexternalknowledge,enablingamodeofenhancementlikehumans.\nThememoryofanagentiskeytoachievinglifelonglearning,asitneedstolearntostoreandapplythepastobservations.\nLifelonglearninginLLM-basedagentsholdssignificantpracticalvalue,suchasinlong-termsocialsimulationsandpersonalassistance.\nHowever,italsofacesseveralchallenges.\nFirstly,lifelonglearningistemporal,necessitatingthatanagent’smemorycapturestemporality.\nThistemporalitycouldcauseinteractionsbetweenmemories,suchasmemoryoverlap.\nFurthermore,duetotheextendedperiodoflifelonglearning,itneedstostoreavastamountofmemoriesandretrievethemwhenneeded,possiblyincorporatingacertainmechanismforforgetting.\n8.\n4"
    ],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThememorymoduleisanimportantcomponentforsuchapplications,whichhelpstoaccuratelysimulatehumandynamicbehaviors.\nInpreviousstudies,Kaiyaetal.\n[148]proposeaSummarize-and-Forgetmemorymechanismforbetterself-monitoringinsocialscenarios.\nGaoetal.\n[2]focusonsocialnetworksimulationsystems.\nEachagentinthesystemhasamemorypool,whichconsistsofdiverseusermessagesfromonlineplatformstoidentifytheuser.\nLietal.\n[163]maintainconversationcontexts,encompassingtheeconomicenvironmentandagentdecisionsfrompreviousmonths,inordertosimulatetheimpactofbroadmacroeconomictrendsonagents’decision-makingandtomaketheagentsgraspmarketdynamics.\nLietal.\n[109]simulatethejob-seekingscenarioinhumansociety,wherethememoryofagentsincludesprofilesandgoalsinitiallyandisfurtherenrichedwithotherinformation,likedialoguesandpersonalreflections.\nHuaetal.\n[150]simulatethedecisionsandconsequencesoftheparticipatingcountriesinthewars,wheretheconversationsofagentsarecontinuouslymaintainedintomemory.\nThereareseveralinsightsindesigninganagent’smemoryforrole-playandsocialsimulation.\nFirst,thememoryshouldbeconsistentwiththeroles’characteristics,whichcanbeusedtoidentifyeachroleanddistinguishitfromtheothers.\nThisiscrucialforimprovingtherealismofrole-playandthediversityofsocialsimulation.\nSecond,thememoryshouldappropriatelyinfluencethesubsequent24actionsoftheagenttoensuretheconsistencyandrationalityofitsbehaviors.\nAdditionally,forhumanoidagents,theirmemorymechanismsshouldalignwiththefeaturesofhumanmemory,suchasforgettingandlong/short-termmemory,whichshouldrefertothetheoriesofcognitivepsychology.\n7.\n2PersonalAssistantLLM-basedagentsarewell-suitedforcreatingpersonalassistants,suchasagentscapableofengaginginlong-termconversationswithusers[94,101,153],aswellasthosetaskedwithautomaticallyseekinginformation[164].\nTheseagentsoftenneedtomemorizepreviousdialoguestomaintaintheconsistency,andremembercriticalstylesandeventstogeneratemorepersonalizedandrelevantresponses.\nLuetal.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nManypreviousstudieshaveexploredmethodsforconstructingrolememories[105,143,145–147].\nShaoetal.\n[105]constructthememoryofrolesbyexperienceuploading,whichutilizesSFTtoinjectmemoryintomodelparameters.\nLietal.\n[143]enhancelargelanguagemodelsforrole-playingviaanimprovedpromptandthecharactermemoryextractedfromscripts,whereuserqueriesand23Table4:Summarizationofmemory-enhancedagentsapplications.\nApplicationsModelsApplicationsModelsRole-playingSocialSimulationPersonalAssistantGameCharacter-LLM[105]ChatHaruhi[143]RoleLLM[145]NarrativePlay[146]CharacterGLM[147]GenerativeAgents[83]LyfeAgents[148]S3[2]MetaAgents[109]WarAgent[150]MemoryBank[6]RET-LLM[7]MemoChat[94]MemGPT[100]MPC[101]AutoGen[153]ChatDB[96]TiM[97]SCM[98]Voyager[99]GITM[93]JARVIS[159]LARP[161]CodeGenerationRecommendationMedicineFinanceScienceRTLFixer[142]GameGPT[144]ChatDev[1]MetaGPT[109]CodeAgent[114]RecAgent[95]InteRecAgent[108]RecMind[102]AgentCF[149]Huatuo[107]DoctorGLM[129]Radiology-GPT[132]Wangetal.\n[151]EHRAgent[152]ChatDoctor[115]InvestLM[113]TradingGPT[154]QuantAgent[155]FinMem[156]Koaetal.\n[157]Chemist-X[158]ChemDFM[160]MatChat[162]chatbot’sresponsesareconcatenatedtoformasequenceasmemory.\nWangetal.\n[145]infuserole-specificknowledgeandepisodememoriesintoLLM-basedagents,wherecontextQApairsareconcatenatedtoformepisodememory.\nZhaoetal.\n[146]aimtogeneratehuman-likeresponses,guidedbypersonalitytraitsextractedfromnarratives,whichcanbestoredandretrievedbyrelevanceandimportance.\nZhouetal.\n[147]generatecharacter-baseddialoguesfordifferentrolesandempowerLLM-basedagentswithcorrespondingstylesbySFT.\nSocialsimulationisbasicallyanextensionofrole-playing,whichfocusesmoreonmulti-agentmodeling.\nThememorymoduleisanimportantcomponentforsuchapplications,whichhelpstoaccuratelysimulatehumandynamicbehaviors.\nInpreviousstudies,Kaiyaetal.\n[148]proposeaSummarize-and-Forgetmemorymechanismforbetterself-monitoringinsocialscenarios.\nGaoetal.\n[2]focusonsocialnetworksimulationsystems.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nInfact,nearlyallthememory-equippedagentscanevaluatetheeffectofmemorybyablationstudies,comparingtheperformancebetweenwith/withoutmemorymodules.\nTheevaluationonspecificscenarioscanbetterreflectthesignificanceofmemoryforthedownstreamapplicationspractically.\n6.\n3DiscussionsComparedwithdirectevaluation,indirectevaluationviaspecifictaskscanbeeasiertoconduct,sincetherearealreadymanypublicbenchmarks.\nHowever,theperformanceontaskscanbeattributedtovariousfactors,andmemoryisonlyoneofthem,whichmaymaketheevaluationresultsbiased.\nBydirectevaluation,theeffectivenessofthememorymodulecanbeindependentlyevaluated,whichimprovesthereliabilityoftheevaluationresults.\nHowever,toourknowledge,therearenoopen-sourcedbenchmarkstailoredforthememorymodulesinLLM-basedagents.\n7Memory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1Role-playingandSocialSimulationRole-playingrepresentsaclassicapplicationofLLM-basedagents,wherememoryplaysacrucialroleinsidetheagents.\nItendowsroleswithdistinctcharacteristics,differentiatingthemfromoneanother.\nManypreviousstudieshaveexploredmethodsforconstructingrolememories[105,143,145–147].\nShaoetal.\n[105]constructthememoryofrolesbyexperienceuploading,whichutilizesSFTtoinjectmemoryintomodelparameters.\nLietal.",
      "#memory_survey#MemoryinHumanoidAgent#memory_survey#MemoryinHumanoidAgent\nMemoryinHumanoidAgentAhumanoidagentreferstoanagentdesignedtoexhibitbehaviorsconsistentwithhumans,therebyfacilitatingapplicationsinsocialsimulation,studiesofhumanbehavior,androle-playing.\nUnliketask-orientedagentswheregreatercapabilityistypicallypreferred,theproficiencyofahumanoidagentshouldcloselymimicthatofhumans.\nConsequently,thememoryofhumanoidagentsshouldalignwithhumancognitiveprocesses,adheringtopsychologicalprinciplessuchasmemorydistortionandforgetfulness.\nAdditionally,humanoidagentsshouldpossessknowledgeboundaries,meaningthattheirknowledgeshouldcorrespondtothatoftheentitytheyreplicate.\nForinstance,inrole-playingscenarios,anagentembodyingachildshouldnotpossessanunderstandingofadvancedmathematicalconceptsorothercomplexknowledgebeyondwhatistypicalforthatage[174].\n9",
      "#memory_survey#Memory-assistedAgent-EnvironmentInteraction#memory_survey#Memory-assistedAgent-EnvironmentInteraction\nForthenarrowmemorydefinition,theiterationonlyhappenswithinthesametrial,andthememoryisemptiedwhenthetrialisended.\nForthebroadmemorydefinition,theiterationhappensacrossdifferenttrialsoreventasks,aswellastheintegrationsofexternalknowledge.\nFortask(B)intheabovetoyexample,theagentcanconcludethatAliceenjoyswatchingsciencefictionmoviesintheevening,whichcanbeusedasadefaultruletomakerecommendationsforAliceinthefuture.\nMemoryReading.\nThisoperationaimstoobtainimportantinformationfromthememorytosupportthenextagentaction.\nItcorrespondstothethirdphaseoftheagent-environmentinteractionprocess.\nSupposeMktisthecontextofthenextaction,thenthememoryreadingoperationcanberepresentedby:tisthememorycontentsfortaskkatstept,ckˆMkt=R(Mkt,ckt+1),whereRisusuallyimplementedbycomputingthesimilaritybetweenMktisusedaspartsofthefinalprompttodrivetheagent’snextaction.\nFortask(B)intheabovetoyexample,whentheagentdecidesonthefinalrecommendedmoviein[Step3],itshouldfocusonthe“wanttowatch”listin[Step2]andselectonefromit.\ntandckt+1[82].\nˆMkBasedontheaboveoperations,wecanderiveaunifiedfunctionfortheevolvingprocessfrom{akt,okt}toakt+1,thatis:akt+1=LLM{R(P(Mkt−1,W({akt,okt})),ckt+1)},whereLLMisthelargelanguagemodel.\nThecompleteagent-environmentinteractionprocesscanbeeasilyobtainedbyiterativelyexpandingthisfunction(seeFigure3(b)foranintuitiveillustration).\nRemark.\nThisfunctionprovidesageneralformulationoftheagentmemorizingprocess.\nPreviousworksmayusedifferentspecifications.\nForexample,in[5],RandParesetasidenticalfunctions,andPonlytakeseffectattheendofatrial.\nInParketal.\n[83],Risimplementedbasedonthreecriteriaincludingsimilarity,timeinterval,andimportance,andPisrealizedbyareflectionprocesstoobtainmoreabstractthoughts.\nInthissection,wefocusontheoverallframeworkoftheagent’smemoryoperations.\nMoredetailedrealizationsofW,P,andRaredeferredinSection5.\n4"
    ],
    [
      "#memory_survey#NarrowDefinitionoftheAgentMemory#memory_survey#NarrowDefinitionoftheAgentMemory\nNarrowDefinitionoftheAgentMemoryInanarrowsense,thememoryoftheagentisonlyrelevanttothehistoricalinformationwithinthesametrial.\nFormally,foragiventask,thehistoricalinformationofthetrialbeforesteptisξt={a1,o1,a2,o2,.\n.\n.\n,at−1,ot−1},andthenthememoryisderivedbasedonξt.\nIntheabovetoyexample,fortask(A),theagentat[step3]needstoarrangethevisitingorderforAlice;atthistime,itsmemorycontainstheinformationabouttheselectedattractionsandarrivaltimein[step1]and[step2].\nFortask(B),theagenthastochooseamovieforAliceat[step3];atthistime,itsmemorycontainsthearrangedtimetowatchfilms.\n3.\n3",
      "#memory_survey#BroadDefinitionoftheAgentMemory#memory_survey#BroadDefinitionoftheAgentMemory\nBroadDefinitionoftheAgentMemory1,okt−1,ok1,.\n.\n.\n,akt={akInabroadsense,thememoryoftheagentcancomefrommuchwidersources,forexample,theinformationacrossdifferenttrialsandtheexternalknowledgebeyondtheagent-environmentinteractions.\nFormally,givenaseriesofsequentialtasks{T1,T2,.\n.\n.\n,TK},fortaskTk,thememoryinformationatsteptcomesfromthreesources:(1)thehistoricalinformationwithinthesametrial,thatis,ξkt−1},whereweaddsuperscriptktolabelthetaskindex.\n(2)Thehistoricalinformationacrossdifferenttrials,thatis,Ξk={ξ1,ξ2,.\n.\n.\n,ξk−1,ξk′},whereξj(j∈{1,.\n.\n.\n,k−1})representsthetrialsoftaskj1,andξk′denotesthepreviouslyexploredtrialsfortaskTk.\n(3)Externalknowledge,whichisrepresentedbyDkt.\nThememoryoftheagentisderivedbasedon(ξkt).\nIntheabovetoyexample,fortask(A),ifthereareseveralfailedtrials,thatis,thefeedbackfromAliceisnegative,thenthesetrialscanbeincorporatedintotheagent’smemorytoavoidfuturesimilarerrors(correspondingtoξk′).\nInaddition,fortask(B),theagentmayrecommendmoviesrelevanttotheattractionsthatAlicehasvisitedintask(A)tocaptureherrecentpreferences(correspondingto{ξ1,ξ2,.\n.\n.\n,ξk−1}).\nIntheagentdecisionprocess,ithasalsoreferredtothemagazineAttractionsinBeijingformakingtripplans,whichistheexternalknowledge(correspondingtoDkt,Ξk,Dkt)forthecurrenttaskTk.\n3.\n4",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.",
      "#memory_survey#PerspectiveofAgentApplications#memory_survey#PerspectiveofAgentApplications\nPerspectiveofAgentApplicationsInmanyapplications,memoryisanindispensablecomponentoftheagent.\nForexample,inaconver-sationalagent,thememorystoresinformationabouthistoricalconversations,whichisnecessaryfortheagenttogeneratethenextresponse.\nWithoutmemory,theagentdoesnotknowthecontext,andcannotcontinuetheconversation[94].\nInasimulationagent,memoryisofgreatimportancetomaketheagentconsistentlyfollowtheroleprofiles.\nWithoutmemory,theagentmayeasilystepoutoftheroleduringthesimulationprocess[95].\nBothoftheaboveexamplesshowthatthememoryisnotanoptionalcomponent,butisnecessaryfortheagentstoaccomplishgiventasks.\nIntheabovethreeperspectives,thefirstonerevealsthatthememorybuildsthecognitivebasisoftheagent.\nThesecondandthirdonesshowthatthememoryisnecessaryfortheagent’sevolvingprinciplesandapplications,whichprovideinsightsfordesigningagentswithmemorymechanisms.\n5",
      "#memory_survey#D:\\projects\\KAG\\kag\\examples\\memory_survey_test\\builder\\./data/memory_survey.pdf#memory_survey#D:\\projects\\KAG\\kag\\examples\\memory_survey_test\\builder\\./data/memory_survey.pdf\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n7.\n6ExpertSysteminSpecificDomains.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n7.\n7OtherApplications.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n8Limitations&FutureDirections8.\n1MoreAdvancesinParametricMemory.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n8.\n2MemoryinLLM-basedMulti-agentApplications.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n8.\n3Memory-basedLifelongLearning.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n8.\n4MemoryinHumanoidAgent.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n9Conclusion2323232325252526262627272728282831"
    ],
    [
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nIntheformerthreetypes,theyrecordtheinformationinsidetheagent-environmentinteractionloop,whilethelasttypeleveragesnaturallanguagestostoreinformationoutsidethatloop.\nCompleteInteractions.\nThismethodstoresalltheinformationoftheagent-environmentinteractionhistorybasedonlong-contextstrategies[116].\nFortheexampleinSection3.\n1,thememoryofthe14agentintask(A)afterstep2canbeimplementedbyconcatenatingalltheinformationbeforestep2,andthefinaltextualformmemoryis:\"Yourmemoryis[Step1](Agent).\n.\n.\n(OnlineTicketOffice).\n.\n.\n[Step2].\n.\n.\nPleaseinferbasedonyourmemory\".\nInthepreviouswork,differentmodelsstorethememoryinformationusingdifferentstrategies.\nForexample,inLongChat[116],theagentsfocusonunderstandingnaturallanguagesinlong-contextscenarios.\nItfine-tunesthefoundationmodelforbetteradaptingtomemorizecompleteinteractions.\nMemorySandbox[117]intendstoalleviatetheimpactofirrelevantmemoryinconversations.\nItdesignsatransparentandinteractivemethodtomanagethememoryofagents,whichremovesirrelevantmemorybeforeconcatenatingthemasaprompt.\nMoreover,someeffortsarededicatedtoenhancingthecapacityofLLMstohandlelongercontexts[118,119].\nWhilestoringalltheagent-environmentinteractionscanmaintaincomprehensiveinformation,obviouslimitationsexistintermsofcomputationalcost,inferencetime,andinferencerobustness.\nFirstly,thefast-growinglong-contextmemoryinpracticeresultsinhighcomputationalcostduringLLMinference,duetothequadraticgrowthofthetimecomplexityofattentioncomputationwithsequencelength.\nItthusrequiresmuchmorecomputingresourcesandsignificantlyincreasesinferencelatency,whichhindersitspracticaldeployment.\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.",
      "#memory_survey#MoreAdvancesinParametricMemory#memory_survey#MoreAdvancesinParametricMemory\nPresently,researcherscantransfervastamountsofdomainknowledgeintotheparametersofLLMsbySFT.\nHowever,itistime-consumingandrequiresextensivetextcorpus,makingitunsuitableforsituationalknowledge.\nOneviableapproachistoemploymeta-learningtoletmodelslearntomemorize.\nForexample,MEND[134]leveragesthemethodofmeta-learningtotrainacompactmodelthathastheabilitytoproduceadjustmentsfortheparametersofapre-trainedlanguagemodel.\nMoreover,thelackofinterpretabilityassociatedwithparametricmemorycanbeahindrance,especiallyindomainsrequiringhighlevelsoftrust,suchasmedicine.\nTherefore,enhancingthecredibilityandinterpretabilityofparametricmemoryisanurgentissuethatneedstobeaddressed.\n8.\n2",
      "#memory_survey#MemoryinParametricForm#memory_survey#MemoryinParametricForm\nMemoryinParametricFormAnalternativetypeofapproachesistorepresentmemoryinparametricform.\nTheydonottakeuptheextralengthofcontextinprompts,sotheyarenotconstrainedbythelengthlimitationsofLLMcontext.\nHowever,theparametricmemoryformisstillunder-researched,andwecategorizepreviousworksintotwotypes:fine-tuningmethodsandmemoryeditingmethods.\nFine-tuningMethods.\nIntegratingexternalknowledgeintothememoryofagentsisbeneficialforenrichingdomain-specificknowledgeontopofitsgeneralknowledge.\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\n1,thememoryofthe14agentintask(A)afterstep2canbeimplementedbyconcatenatingalltheinformationbeforestep2,andthefinaltextualformmemoryis:\"Yourmemoryis[Step1](Agent).\n.\n.\n(OnlineTicketOffice).\n.\n.\n[Step2].\n.\n.\nPleaseinferbasedonyourmemory\".\nInthepreviouswork,differentmodelsstorethememoryinformationusingdifferentstrategies.\nForexample,inLongChat[116],theagentsfocusonunderstandingnaturallanguagesinlong-contextscenarios.\nItfine-tunesthefoundationmodelforbetteradaptingtomemorizecompleteinteractions.\nMemorySandbox[117]intendstoalleviatetheimpactofirrelevantmemoryinconversations.\nItdesignsatransparentandinteractivemethodtomanagethememoryofagents,whichremovesirrelevantmemorybeforeconcatenatingthemasaprompt.\nMoreover,someeffortsarededicatedtoenhancingthecapacityofLLMstohandlelongercontexts[118,119].\nWhilestoringalltheagent-environmentinteractionscanmaintaincomprehensiveinformation,obviouslimitationsexistintermsofcomputationalcost,inferencetime,andinferencerobustness.\nFirstly,thefast-growinglong-contextmemoryinpracticeresultsinhighcomputationalcostduringLLMinference,duetothequadraticgrowthofthetimecomplexityofattentioncomputationwithsequencelength.\nItthusrequiresmuchmorecomputingresourcesandsignificantlyincreasesinferencelatency,whichhindersitspracticaldeployment.\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.",
      "#memory_survey#Memory-enhancedAgentApplications#memory_survey#Memory-enhancedAgentApplications\nMemory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1"
    ],
    [
      "#memory_survey#Memory-basedLifelongLearning#memory_survey#Memory-basedLifelongLearning\nMemory-basedLifelongLearningLifelonglearningisanadvancedtopicinartificialintelligence,extendingthelearningcapabilitiesofagentsacrosstheirlife-longspan[173].\nAgentscancontinuouslyinteractwiththeirenvironment,persistentlyobserveenvironments,andacquireexternalknowledge,enablingamodeofenhancementlikehumans.\nThememoryofanagentiskeytoachievinglifelonglearning,asitneedstolearntostoreandapplythepastobservations.\nLifelonglearninginLLM-basedagentsholdssignificantpracticalvalue,suchasinlong-termsocialsimulationsandpersonalassistance.\nHowever,italsofacesseveralchallenges.\nFirstly,lifelonglearningistemporal,necessitatingthatanagent’smemorycapturestemporality.\nThistemporalitycouldcauseinteractionsbetweenmemories,suchasmemoryoverlap.\nFurthermore,duetotheextendedperiodoflifelonglearning,itneedstostoreavastamountofmemoriesandretrievethemwhenneeded,possiblyincorporatingacertainmechanismforforgetting.\n8.\n4",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nIntheformerthreetypes,theyrecordtheinformationinsidetheagent-environmentinteractionloop,whilethelasttypeleveragesnaturallanguagestostoreinformationoutsidethatloop.\nCompleteInteractions.\nThismethodstoresalltheinformationoftheagent-environmentinteractionhistorybasedonlong-contextstrategies[116].\nFortheexampleinSection3.\n1,thememoryofthe14agentintask(A)afterstep2canbeimplementedbyconcatenatingalltheinformationbeforestep2,andthefinaltextualformmemoryis:\"Yourmemoryis[Step1](Agent).\n.\n.\n(OnlineTicketOffice).\n.\n.\n[Step2].\n.\n.\nPleaseinferbasedonyourmemory\".\nInthepreviouswork,differentmodelsstorethememoryinformationusingdifferentstrategies.\nForexample,inLongChat[116],theagentsfocusonunderstandingnaturallanguagesinlong-contextscenarios.\nItfine-tunesthefoundationmodelforbetteradaptingtomemorizecompleteinteractions.\nMemorySandbox[117]intendstoalleviatetheimpactofirrelevantmemoryinconversations.\nItdesignsatransparentandinteractivemethodtomanagethememoryofagents,whichremovesirrelevantmemorybeforeconcatenatingthemasaprompt.\nMoreover,someeffortsarededicatedtoenhancingthecapacityofLLMstohandlelongercontexts[118,119].\nWhilestoringalltheagent-environmentinteractionscanmaintaincomprehensiveinformation,obviouslimitationsexistintermsofcomputationalcost,inferencetime,andinferencerobustness.\nFirstly,thefast-growinglong-contextmemoryinpracticeresultsinhighcomputationalcostduringLLMinference,duetothequadraticgrowthofthetimecomplexityofattentioncomputationwithsequencelength.\nItthusrequiresmuchmorecomputingresourcesandsignificantlyincreasesinferencelatency,whichhindersitspracticaldeployment.\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\n2PersonalAssistantLLM-basedagentsarewell-suitedforcreatingpersonalassistants,suchasagentscapableofengaginginlong-termconversationswithusers[94,101,153],aswellasthosetaskedwithautomaticallyseekinginformation[164].\nTheseagentsoftenneedtomemorizepreviousdialoguestomaintaintheconsistency,andremembercriticalstylesandeventstogeneratemorepersonalizedandrelevantresponses.\nLuetal.\n[94]maintainthecontextconsistencyfordialoguesbysavingcontentsandinformationofconversations,whichhelpstofindproperrelevantinformationbyretrieval.\nLeeetal.\n[101]summarizeconversationstoextractimportantinformation,storeit,andretrieveitforfutureinference.\nPanetal.\n[164]focusoninformation-seekingtasks,whichdesignmemorymodulestostoreuser’scontextinformation,andempowerexternalknowledgewithtoolusage.\nWuetal.\n[153]retainimportantcontextasmemorytomaintainconversationconsistency.\nInsummary,mostmemoryimplementationsforpersonalassistantsadoptretrievalmethodsintextualform,becausetheyarebetteratfindingrelevantinformationfrompiecesofconversations.\nForthememorystorage,theagentshouldrememberthefactualinformationduringuser-agentinteractions,aswellasthepersonalstyleofusers,inordertogenerateresponsesthataretailoredtotheuser’ssituation.\nAdditionally,whenrecallingmemories,theagentshouldidentifyandretrievethememorythatisrelevanttothecurrentqueryandcontext.\nThisprinciplecanenabletheagenttocorrectlyunderstandtheuser’srequirement,andmaintaintheconsistencyinconversations.\n7.\n3Open-worldGameForgamesandopen-worldexploration,LLM-basedagentsalwaysmaintainpostobservationsastaskcontexts,andstoreexperiencesinprevioussuccessfultrials.\nByleveragingpastexperiences,agentscanavoidmakingthesamemistakesrepeatedlyandachieveahigh-levelunderstandingofenvironments,thusexploringmoreeffectively.\nSomeofthemcanacquireexternaldatabasesorAPIstoobtaingeneralknowledge[99,93,159,161].\nWangetal.\n[99]saveobtainedskillsintomemoryforfurtherusageinMinecraft.\nZhuetal.\n[93]storeandretrievesuccessfultrajectoriesasexamplesforsimilartasks,andutilizeexternalMinecraftWikibyAPIcalls.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nInaddition,cognitivepsychologyhasbeenstudiedforalongtime,somanyeffectivehumanmemorytheoriesandarchitectureshavebeenaccumulated,whichcansupportmoreadvancedcapabilitiesoftheagents[89].\n2https://en.\nwikipedia.\norg/wiki/Cognitive_psychology10Figure4:Anoverviewofthesources,forms,andoperationsofthememoryinLLM-basedagents.\n4.\n2PerspectiveofSelf-EvolutionToaccomplishdifferentpracticaltasks,agentshavetoself-evolveindynamicenvironments[90].\nIntheagent-environmentinteractionprocess,thememoryiskeytothefollowingaspects:(1)Experienceaccumulation.\nAnimportantfunctionofthememoryistorememberpasterrorplannings,inappropriatebehaviors,orfailedexperiences,soastomaketheagentmoreeffectiveforhandlingsimilartasksinthefuture[91].\nThisisextremelyimportantforenhancingthelearningefficiencyoftheagentintheself-evolvingprocess.\n(2)Environmentexploration.\nToautonomouslyevolveintheenvironment,theagentshavetoexploredifferentactionsandlearnfromthefeedback[92].\nByrememberinghistoricalinformation,thememorycanhelptobetterdecidewhenandhowtomakeexplorations,forexample,focusingmoreonpreviouslyfailedtrialsoractionswithlowerexploringfrequencies[93].\n(3)Knowledgeabstraction.\nAnotherimportantfunctionofthememoryistosummarizeandabstracthigh-levelinformationfromrawobservations,whichisthebasisfortheagenttobemoreadaptiveandgeneralizabletounseenenvironments[82].\nInsummary,self-evolutionisthebasiccharacteristicofLLM-basedagents,andmemoryisofkeyimportancetoself-evolution.\n4.\n3PerspectiveofAgentApplicationsInmanyapplications,memoryisanindispensablecomponentoftheagent.\nForexample,inaconver-sationalagent,thememorystoresinformationabouthistoricalconversations,whichisnecessaryfortheagenttogeneratethenextresponse.\nWithoutmemory,theagentdoesnotknowthecontext,andcannotcontinuetheconversation[94].\nInasimulationagent,memoryisofgreatimportancetomaketheagentconsistentlyfollowtheroleprofiles.\nWithoutmemory,theagentmayeasilystepoutoftheroleduringthesimulationprocess[95].",
      "#memory_survey#Long-contextApplications#memory_survey#Long-contextApplications\nLong-contextApplicationsBeyondtheabovegeneralapplications,inmanyscenarios,LLM-basedagentshavetomakedecisionsbasedonextremelylongprompts.\nInthesescenarios,thelongpromptsareusuallyregardedasthememorycontents,whichplayanimportantroleindrivingagentbehaviors.\n22Inpreviousworks,Huangetal.\n[19]organizeacomprehensivesurveyforlong-contextLLMs,whichprovidesasummaryofevaluationmetricsonlong-contextscenarios.\nMoreover,Shahametal.\n[138]proposeazero-shotbenchmarkforevaluatingagents’understandingoflong-contextnaturallanguages.\nAsforspecificlong-contexttasks,long-contextpassageretrievalisoneoftheimportanttasksforevaluatingthelong-contextabilityofagents.\nItrequiresagentstofindthecorrectparagraphinalongcontextthatcorrespondstothegivenquestionsordescriptions[139].\nLong-contextsummarizationisanotherrepresentativetask.\nItrequestsagentstoformulateaglobalunderstandingofthewholecontext,andsummarizesitaccordingtothedescriptions,wheresomemetricsonmatchingscoreslikeROUGEcanbeutilizedtocomparetheresultswithgroundtruths.\nTheevaluationoflong-contextapplicationsprovidesbroaderapproachestoassessthefunctionofmemoryinagents,focusingonpracticaldownstreamscenarios.\nThecomprehensivebenchmarks[138,140]alsoprovideanobjectiveassessmentfortheabilityoflong-contextunderstanding.\n6.\n2.\n4"
    ],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain.",
      "#memory_survey#ExternalKnowledge#memory_survey#ExternalKnowledge\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain.\nItfine-tunesanacquisitionprocesstoretrieveexternalknowledgefromWikipediaandmedicaldatabases.\nDiscussion.\nTheexternalknowledgecanbeobtainedfrombothprivateandpublicsources.\nItprovidesLLM-basedagentswithmuchknowledgebeyondtheirinternalenvironment,whichmightbedifficultorevenimpossiblefortheagenttoacquirebyagent-environmentinteractions.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nSomeofthemcanacquireexternaldatabasesorAPIstoobtaingeneralknowledge[99,93,159,161].\nWangetal.\n[99]saveobtainedskillsintomemoryforfurtherusageinMinecraft.\nZhuetal.\n[93]storeandretrievesuccessfultrajectoriesasexamplesforsimilartasks,andutilizeexternalMinecraftWikibyAPIcalls.\nWangetal.\n[159]constructmultimodalmemoryasaknowledgelibraryandprovideexamplesforpromptbyretrievinginteractiveexperiences.\nYanetal.\n[161]maintainworkingmemoryfordecision-making,saveandretrieverelevantpastexperiences,andimplementexternaldatasetsforgeneralknowledge.\nInsummary,nomatterinside-trialorcross-trialinformation,thekeyaspectofmemoryistoreflectonpastinteractionsanddrawexperiencesthatcanbeappliedtothesubsequentexploration.\nInadditiontoaccumulatingexperiencethroughself-involvingtrials,absorbingexternalknowledgeaspartoftheagent’smemoryisalsoanimportantwaytoenhancetheexploratorycapabilitiesoftheagent.\n7.\n4CodeGenerationInthescenarioofcodegeneration,LLM-basedagentscansearchrelevantinformationfromthememory,therebyobtainingmoreknowledgefordevelopment.\nTheycansavepreviousexperiencesforfutureproblems,andalsomaintaincontextinconversationaldevelopmentinterfaces[142,144,1,109].\nTsaietal.\n[142]constructanexternalnon-parametricmemorydatabase,whichstoresthecompilererrorsandhumanexpertinstructionsforautomaticsyntaxerrorfixing.\nIn[144],personalinformationwillbestoredinthememory,andhelpsinretainingcontextandknowledgefordecision-making.\nQianetal.\n[1]adoptmulti-agentstodevelopsoftware,whereeachrolemaintainsamemorytostorethepastconversationswithotherroles.\nLietal.\n[109]alsofocusonsoftwaredevelopment,andtheagentcanretrieveitshistoricalrecordspreservedinmemorywhenerrorsoccur.\nZhangetal.\n[114]cansearchrelevantinformationwhentheyfaceproblemsoncodegeneration.\nByleveragingexternalresources,theagentscanlearnfromcode-relatedknowledgeandstoreitintotheirmemory,therebyenhancingthecapabilitiesofcodegeneration.\nInaddition,thememorycanimprovethecontinuityandconsistencyincodegeneration.",
      "#memory_survey#Memory-enhancedAgentApplications#memory_survey#Memory-enhancedAgentApplications\nMemory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1"
    ],
    [
      "#memory_survey#ExternalKnowledge#memory_survey#ExternalKnowledge\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain.\nItfine-tunesanacquisitionprocesstoretrieveexternalknowledgefromWikipediaandmedicaldatabases.\nDiscussion.\nTheexternalknowledgecanbeobtainedfrombothprivateandpublicsources.\nItprovidesLLM-basedagentswithmuchknowledgebeyondtheirinternalenvironment,whichmightbedifficultorevenimpossiblefortheagenttoacquirebyagent-environmentinteractions.",
      "#memory_survey#ExternalKnowledge#memory_survey#ExternalKnowledge\nItshouldbenotedthattheinside-trialinformationnotonlyincludesagent-environmentinteractions,butalsocontainsinteractioncontexts,suchastimeandlocationinformation.\n12Discussion.\nTheinside-trialinformationisthemostobviousandintuitivesourcethatshouldbeleveragedtoconstructtheagent’smemorysinceitishighlyrelevanttothecurrenttaskthattheagenthastoaccomplish.\nHowever,relyingsolelyoninside-trialinformationmaypreventtheagentfromaccumulatingvaluableknowledgefromvarioustasksandlearningmoregeneralizableinformation.\nThus,manystudiesalsoexplorehowtoeffectivelyutilizetheinformationacrossdifferenttaskstobuildthememorymodule,whichisdetailedinthefollowingsections.\n5.\n1.\n2Cross-trialInformationForLLM-basedagents,theinformationaccumulatedacrossmultipletrialsintheenvironmentisalsoacrucialpartofthememory,typicallyincludingsuccessfulandfailedactionsandtheirinsights,suchasfailurereasons,commonactionpatternstosucceed,andsoon.\nRepresentativeStudies.\nOneofthemostprominentstudiesisReflexion[5],whichproposesverbalreinforcementlearningforLLM-basedagents.\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain.",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nMemoryinTextualFormTextualformiscurrentlythemainstreammethodtorepresentthememorycontents,whichisfeaturedinbetterinterpretability,easierimplementation,andfasterread-writeefficiency.\nInspecific,thetextualformcanbebothnon-structuredrepresentationslikerawnaturallanguagesandstructuredinformationsuchastuples,databases,andsoon.\nIngeneral,previousstudiesusethetextualformmemorytostorefourtypesofinformationincluding(1)completeagent-environmentinteractions,(2)recentagent-environmentinteractions,(3)retrievedagent-environmentinteractions,and(4)externalknowledge.\nIntheformerthreemethods,thememoryleveragesnaturallanguagestodescribetheinformationwithintheagent-environmentinteractionloop.\nIntheformerthreetypes,theyrecordtheinformationinsidetheagent-environmentinteractionloop,whilethelasttypeleveragesnaturallanguagestostoreinformationoutsidethatloop.\nCompleteInteractions.\nThismethodstoresalltheinformationoftheagent-environmentinteractionhistorybasedonlong-contextstrategies[116].\nFortheexampleinSection3.\n1,thememoryofthe14agentintask(A)afterstep2canbeimplementedbyconcatenatingalltheinformationbeforestep2,andthefinaltextualformmemoryis:\"Yourmemoryis[Step1](Agent).\n.\n.\n(OnlineTicketOffice).\n.\n.\n[Step2].\n.\n.\nPleaseinferbasedonyourmemory\".\nInthepreviouswork,differentmodelsstorethememoryinformationusingdifferentstrategies.\nForexample,inLongChat[116],theagentsfocusonunderstandingnaturallanguagesinlong-contextscenarios.\nItfine-tunesthefoundationmodelforbetteradaptingtomemorizecompleteinteractions.\nMemorySandbox[117]intendstoalleviatetheimpactofirrelevantmemoryinconversations.\nItdesignsatransparentandinteractivemethodtomanagethememoryofagents,whichremovesirrelevantmemorybeforeconcatenatingthemasaprompt.\nMoreover,someeffortsarededicatedtoenhancingthecapacityofLLMstohandlelongercontexts[118,119].\nWhilestoringalltheagent-environmentinteractionscanmaintaincomprehensiveinformation,obviouslimitationsexistintermsofcomputationalcost,inferencetime,andinferencerobustness."
    ],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\nWiththestrongcapabilityofLLMstosimulatehumanminds,theseoperationscanhelptheagentstobettergeneratehigh-levelinformationandinteractwithenvironments.\n18Table3:Summarizationofthememoryoperations.\nIfamodeldoesnothavespecialdesignsonthememoryoperations,weuse◦tolabelit,otherwise,itisdenotedby✓.\n×meansthatthememoryoperationsarenotdiscussedinthepaper.\nModelsWritingMergingReflectionForgettingReadingManagementMemoryBank[6]RET-LLM[7]ChatDB[96]TiM[97]SCM[98]Voyager[99]MemGPT[100]MemoChat[94]MPC[101]GenerativeAgents[83]RecMind[102]Retroformer[103]ExpeL[82]Synapse[91]GITM[93]ReAct[104]Reflexion[5]RecAgent[95]Character-LLM[105]MAC[106]Huatuo[107]ChatDev[1]InteRecAgent[108]MetaAgents[109]TPTU[110,111]MetaGPT[112]S3[2]InvestLM[113]✓✓✓✓✓✓✓✓✓✓◦✓✓✓◦◦✓✓✓✓✓✓✓✓◦✓✓✓✓××✓✓××××××✓✓×✓×✓✓×✓××✓×××××✓×✓××✓✓××✓×✓✓×✓×✓✓×✓×✓✓✓✓✓✓×✓××✓×××××✓×××××××✓××××××××✓×✓✓✓✓✓✓✓✓✓✓✓◦◦✓✓◦◦✓◦✓◦✓✓✓✓✓✓◦5.\n3.\n3MemoryReadingWhentheagentsrequireinformationforreasoninganddecision-making,thememoryreadingoperationwillextractrelatedinformationfrommemoryforusage.\nTherefore,howtoaccesstherelatedinformationforthecurrentstateisimportant.\nDuetothemassivequantityofmemoryentities,andthefactthatnotallofthemarepertinenttothecurrentstate,carefuldesignisrequiredtoextractusefulinformationbasedonrelevanceandothertask-orientatedfactors.\nRepresentativeStudies.\nInChatDB[96],thememoryreadingoperationisexecutedbytheSQLstatements.\nThesestatementswillbegeneratedbyagentsasaseriesofChain-of-Memoryinadvance.\nInMPC[101],theagentscanretrieverelevantmemoryfromthememorypool.\nThismethodalsoproposestoprovideChain-of-Thoughtexamplesforignoringcertainmemory.\nExpeL[82]utilizestheFaiss[124]vectorstoreasthepoolofmemory,andobtainsthetop-Ksuccessfultrajectoriesthatsharethehighestsimilarityscoreswiththecurrenttask.\nDiscussion.\nTosomeextent,thememoryreadingandwritingoperationsarecollaborative,andtheformsofmemorywritinggreatlyinfluencethemethodsofmemoryreading.\nFortheformsoftextual19Figure5:Anoverviewoftheevaluationmethodsofthememorymodule.",
      "#memory_survey#Introduction#memory_survey#Introduction\nIntroduction\"Withoutmemory,thereisnoculture.\nWithoutmemory,therewouldbenocivilization,nosociety,nofuture.\n\"ElieWiesel,1928-2016Recently,largelanguagemodels(LLMs)haveachievedremarkablesuccessinalargenumberofdomains,rangingfromartificialintelligenceandsoftwareengineeringtoeducationandsocialsci-ence[1–3].\nOriginalLLMsusuallyaccomplishdifferenttaskswithoutinteractingwithenvironments.\nHowever,toachievethefinalgoalofartificialgeneralintelligence(AGI),intelligentmachinesshouldbeabletoimprovethemselvesbyautonomouslyexploringandlearningfromtherealworld.\nForexample,ifatrip-planningagentintendstobookaticket,itshouldsendanorderrequesttotheticketwebsite,andobservetheresponsebeforetakingthenextaction.\nApersonalassistantagentshouldadjustitsbehaviorsaccordingtotheuser’sfeedback,providingpersonalizedresponsestoimproveuser’ssatisfaction.\nTofurtherpushtheboundaryofLLMstowardsAGI,recentyearshavewitnessedalargenumberofstudiesonLLM-basedagents[3,4],wherethekeyistoequipLLMswithadditionalmodulestoenhancetheirself-evolvingcapabilityinreal-worldenvironments.\nAmongalltheaddedmodules,memoryisakeycomponentthatdifferentiatestheagentsfromoriginalLLMs,makinganagenttrulyanagent(seeFigure1).\nItplaysanextremelyimportantroleindetermininghowtheagentaccumulatesknowledge,processeshistoricalexperience,retrievesinformativeknowledgetosupportitsactions,andsoon.\nAroundthememorymodule,peoplehavedevotedmuchefforttodesigningitsinformationsources,storageforms,andoperationmechanisms.\nForexample,Shinnetal.\n[5]incorporatebothin-trialandcross-trialinformationtobuildthememorymoduleforenhancingtheagent’sreasoningcapability.\nZhongetal.\n[6]storememoryinformationintheformofnaturallanguages,whichisexplainableandfriendlytotheusers.\nModarressietal.\n[7]designbothmemoryreadingandwritingoperationstointeractwithenvironmentsfortasksolving.\nWhilepreviousstudieshavedesignedmanypromisingmemorymodules,therestilllacksasystemicstudytoviewthememorymodulesfromaholisticperspective.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nManystudieschoosetostoretherawinformation,whileothersalsoputthesummaryoftherawinformationintothememorymodule.\nRepresentativeStudies.\nInTiM[97],therawinformationwillbeextractedastherelationbetweentwoentities,andstoredinastructureddatabase.\nWhenwritingintothedatabase,similarcontentswillbestoredinthesamegroup.\nInSCM[98],itdesignsamemorycontrollertodecidewhentoexecutetheoperations.\nThecontrollerservesasaguideforthewholememorymodule.\nInMemGPT[100],thememorywritingisentirelyself-directed.\nTheagentscanautonomouslyupdatethememorybasedonthecontexts.\nInMemoChat[94],theagentssummarizeeachconversationsegmentbyabstractingthemainlydiscussedtopicsandstoringthemaskeysforindexingmemorypieces.\nDiscussion.\nPreviousresearchindicatesthatdesigningthestrategyofinformationextractionduringthememorywritingoperationisvital[94].\nThisisbecausetheoriginalinformationiscommonlylengthyandnoisy.\nBesides,differentenvironmentsmayprovidevariousformsoffeedback,andhowtoextractandrepresenttheinformationasmemoryisalsosignificantformemorywriting.\n5.\n3.\n2MemoryManagementForhumanbeings,memoryinformationisconstantlyprocessedandabstractedinthebrains.\nThememoryintheagentcanalsobemanagedbyreflectingtogeneratehigher-levelmemories,mergingredundantmemoryentries,andforgettingunimportant,earlymemories.\nRepresentativeStudies.\nInMemoryBank[6],theagentsprocessanddistilltheconversationsintoahigh-levelsummaryofdailyevents,similartohowhumansrecallkeyaspectsoftheirexperiences.\nThroughlong-terminteractions,theycontinuallyevaluateandrefinetheirknowledge,generatingdailyinsightsintopersonalitytraits.\nInVoyager[99],theagentsareabletorefinetheirmemorybasedonthefeedbackoftheenvironment.\nInGenerativeAgents[83],theagentscanreflecttogethigher-levelinformation,wheretheabstractthoughtsaregeneratedfromagents.\nThereflectionprocesswillbeactivatedwhenthereareaccumulatedeventsthatareenoughtoaddress.\nForGITM[93],inordertoestablishcommonreferenceplansforvarioussituations,keyactionsfrommultipleplansarefurthersummarizedinthememorymodule.\nDiscussion.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nThesestatementswillbegeneratedbyagentsasaseriesofChain-of-Memoryinadvance.\nInMPC[101],theagentscanretrieverelevantmemoryfromthememorypool.\nThismethodalsoproposestoprovideChain-of-Thoughtexamplesforignoringcertainmemory.\nExpeL[82]utilizestheFaiss[124]vectorstoreasthepoolofmemory,andobtainsthetop-Ksuccessfultrajectoriesthatsharethehighestsimilarityscoreswiththecurrenttask.\nDiscussion.\nTosomeextent,thememoryreadingandwritingoperationsarecollaborative,andtheformsofmemorywritinggreatlyinfluencethemethodsofmemoryreading.\nFortheformsoftextual19Figure5:Anoverviewoftheevaluationmethodsofthememorymodule.\nmemory,mostpreviousworksusethetextsimilarityandotherauxiliaryinformationforreading.\nFortheformsofparametricmemory,existingmodelsmayjustutilizetheupdatedparametersforinference,whichcanbeseenasanimplicitreadingprocess.\n6",
      "#memory_survey#Memory-basedLifelongLearning#memory_survey#Memory-basedLifelongLearning\nMemory-basedLifelongLearningLifelonglearningisanadvancedtopicinartificialintelligence,extendingthelearningcapabilitiesofagentsacrosstheirlife-longspan[173].\nAgentscancontinuouslyinteractwiththeirenvironment,persistentlyobserveenvironments,andacquireexternalknowledge,enablingamodeofenhancementlikehumans.\nThememoryofanagentiskeytoachievinglifelonglearning,asitneedstolearntostoreandapplythepastobservations.\nLifelonglearninginLLM-basedagentsholdssignificantpracticalvalue,suchasinlong-termsocialsimulationsandpersonalassistance.\nHowever,italsofacesseveralchallenges.\nFirstly,lifelonglearningistemporal,necessitatingthatanagent’smemorycapturestemporality.\nThistemporalitycouldcauseinteractionsbetweenmemories,suchasmemoryoverlap.\nFurthermore,duetotheextendedperiodoflifelonglearning,itneedstostoreavastamountofmemoriesandretrievethemwhenneeded,possiblyincorporatingacertainmechanismforforgetting.\n8.\n4"
    ],
    [
      "#memory_survey#ExternalKnowledge#memory_survey#ExternalKnowledge\nTheexternalknowledgecanbeobtainedfrombothprivateandpublicsources.\nItprovidesLLM-basedagentswithmuchknowledgebeyondtheirinternalenvironment,whichmightbedifficultorevenimpossiblefortheagenttoacquirebyagent-environmentinteractions.\nMoreover,mostexternalknowledgecanbeacquiredbyaccessingtheAPIsofvarioustoolsdynamicallyinrealtimeaccordingtothetaskneeds,thusmitigatingtheproblemofoutdatedknowledge.\nIntegratingexternalknowledgeintothememoryofLLM-basedagentssignificantlyexpandstheirknowledgeboundaries,providingthemwithunlimited,up-to-date,andwell-foundedknowledgefordecision-making.\n5.\n2",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nMoreover,retrievalmethodstypicallystorehomogeneousinformationinsidetheenvironment,wherealltheinformationisinaconsistentform.\nForheterogeneousinformationoutsidetheenvironment,it’sdifficulttodirectlyapplythesamemethodformemorystorage.\nExternalKnowledge.\nToobtainmoreinformation,someagentsacquireexternalknowledgebyinvokingtools,withtheaimoftransformingadditionalrelevantknowledgeintotheirownmemoriesfordecision-making.\nForinstance,accessingexternalknowledgethroughApplicationProgrammingInterface(API)isacommonpractice[104,5].\nNowadays,abundantpublicinformation,suchasWikipediaandOpenWeatherMap4,areavailableonline(eitherfreeofchargeoronapayingbasis),andcanbeconvenientlyaccessedthroughAPIcalls.\nForinstance,in[Step2]oftask(A)oftheexampleinSection3.\n1,externalknowledgefromthedigitalmagazineisobtainedwithtoolmethods.\nInexistingmodels,Toolformer[125]proposestoteachLLMtousetools,whichcanacquireexternalknowledgeforbettersolvingtasks.\nFurthermore,ToolLLM[126]empowersLlama[127]withtheabilitytoutilizemoreAPIsinRapidAPI5andtoenablemulti-toolusage,whichprovidesageneralinterfacetoextendagents’ability.\nInTPTU[110],theagentsareincorporatedinbothtaskplanningandtoolusage,inordertotackleintricateproblems.\nThefollow-upwork[111]furtherimprovesitsabilityextensivelylikeretrieval.\nInToRA[128],theagentsarerequiredtosolvemathematicalproblems.\nTheyutilizeimitationlearningtoimprovetheirabilitytouseprogram-basedtools.\nTheabovemethodssignificantlyadvancethecapabilitiesofagentsbyallowingthemtoaccessexternalup-to-dateandreal-worldinformationfromdiversesources.\nHowever,thereliabilityofthisinformationcanbequestionableduetopotentialinaccuraciesandbiases[18].\nFurthermore,theintegrationoftoolsintoagentsdemandsacomprehensiveunderstandingtointerprettheretrievedinformationacrossvariouscontexts,whichcanincurhighercomputationalcostsandcomplicationsinaligningexternaldatawithinternaldecision-makingprocesses.",
      "#memory_survey#ExternalKnowledge#memory_survey#ExternalKnowledge\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain.\nItfine-tunesanacquisitionprocesstoretrieveexternalknowledgefromWikipediaandmedicaldatabases.\nDiscussion.\nTheexternalknowledgecanbeobtainedfrombothprivateandpublicsources.\nItprovidesLLM-basedagentswithmuchknowledgebeyondtheirinternalenvironment,whichmightbedifficultorevenimpossiblefortheagenttoacquirebyagent-environmentinteractions.",
      "#memory_survey#ExternalKnowledge#memory_survey#ExternalKnowledge\nItshouldbenotedthattheinside-trialinformationnotonlyincludesagent-environmentinteractions,butalsocontainsinteractioncontexts,suchastimeandlocationinformation.\n12Discussion.\nTheinside-trialinformationisthemostobviousandintuitivesourcethatshouldbeleveragedtoconstructtheagent’smemorysinceitishighlyrelevanttothecurrenttaskthattheagenthastoaccomplish.\nHowever,relyingsolelyoninside-trialinformationmaypreventtheagentfromaccumulatingvaluableknowledgefromvarioustasksandlearningmoregeneralizableinformation.\nThus,manystudiesalsoexplorehowtoeffectivelyutilizetheinformationacrossdifferenttaskstobuildthememorymodule,whichisdetailedinthefollowingsections.\n5.\n1.\n2Cross-trialInformationForLLM-basedagents,theinformationaccumulatedacrossmultipletrialsintheenvironmentisalsoacrucialpartofthememory,typicallyincludingsuccessfulandfailedactionsandtheirinsights,suchasfailurereasons,commonactionpatternstosucceed,andsoon.\nRepresentativeStudies.\nOneofthemostprominentstudiesisReflexion[5],whichproposesverbalreinforcementlearningforLLM-basedagents.\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.",
      "#memory_survey#Memory-basedLifelongLearning#memory_survey#Memory-basedLifelongLearning\nMemory-basedLifelongLearningLifelonglearningisanadvancedtopicinartificialintelligence,extendingthelearningcapabilitiesofagentsacrosstheirlife-longspan[173].\nAgentscancontinuouslyinteractwiththeirenvironment,persistentlyobserveenvironments,andacquireexternalknowledge,enablingamodeofenhancementlikehumans.\nThememoryofanagentiskeytoachievinglifelonglearning,asitneedstolearntostoreandapplythepastobservations.\nLifelonglearninginLLM-basedagentsholdssignificantpracticalvalue,suchasinlong-termsocialsimulationsandpersonalassistance.\nHowever,italsofacesseveralchallenges.\nFirstly,lifelonglearningistemporal,necessitatingthatanagent’smemorycapturestemporality.\nThistemporalitycouldcauseinteractionsbetweenmemories,suchasmemoryoverlap.\nFurthermore,duetotheextendedperiodoflifelonglearning,itneedstostoreavastamountofmemoriesandretrievethemwhenneeded,possiblyincorporatingacertainmechanismforforgetting.\n8.\n4"
    ],
    [
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.\nAnotherlimitationoffine-tuningliesinthecomputationalcostandtimeconsumption,aswellastherequirementofalargeamountofdata.\nTherefore,mostfine-tuningapproachesareappliedtoofflinescenarios,andcanseldomdealwithonlinescenarios,suchasfine-tuningwithagentobservationsandtrialexperiences.\nDuetothefrequentagent-environmentinteractions,itisunaffordableforthecostofbackpropagationtofine-tuneeverystepoftheonlineanddynamicinteractions.\nMemoryEditingMethods.",
      "#memory_survey#MemoryinParametricForm#memory_survey#MemoryinParametricForm\nMemoryinParametricFormAnalternativetypeofapproachesistorepresentmemoryinparametricform.\nTheydonottakeuptheextralengthofcontextinprompts,sotheyarenotconstrainedbythelengthlimitationsofLLMcontext.\nHowever,theparametricmemoryformisstillunder-researched,andwecategorizepreviousworksintotwotypes:fine-tuningmethodsandmemoryeditingmethods.\nFine-tuningMethods.\nIntegratingexternalknowledgeintothememoryofagentsisbeneficialforenrichingdomain-specificknowledgeontopofitsgeneralknowledge.\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.\nAnotherlimitationoffine-tuningliesinthecomputationalcostandtimeconsumption,aswellastherequirementofalargeamountofdata.\nTherefore,mostfine-tuningapproachesareappliedtoofflinescenarios,andcanseldomdealwithonlinescenarios,suchasfine-tuningwithagentobservationsandtrialexperiences.\nDuetothefrequentagent-environmentinteractions,itisunaffordableforthecostofbackpropagationtofine-tuneeverystepoftheonlineanddynamicinteractions.\nMemoryEditingMethods.\nApartfromthefine-tuningapproaches,anothertypeofmethodsforinfusingmemoryintomodelparametersisknowledgeediting[133,134].\nUnlikefine-tuningmethodsthatextractpatternsfromcertaindatasets,knowledgeeditingmethodsspecificallytargetandadjustonlythefactsthatneedtobechanged.\nItensuresthatunrelatedknowledgeremainsunaffected.\nKnowledgeeditingmethodsaremoresuitableforsmall-scalememoryadjustments.\nGenerally,theyhavelowercomputationalcosts,makingthemmoresuitableforonlinescenarios.",
      "#memory_survey#ExpertSysteminSpecificDomains#memory_survey#ExpertSysteminSpecificDomains\nExpertSysteminSpecificDomainsMedicineDomain.\nInthefieldofmedicine,mostofthepreviousworksempowerLLM-basedagentswithexternalknowledgeintheirmemory[107,129,132,151,115].\nWangetal.\n[107]fine-tuneLLaMA[127]withmedicalknowledgegraphCMeKG[165]inQAform,inordertoenhancetheirmedicaldomainknowledge.\nXiongetal.\n[129]adoptLoRA[131]toefficientlyfine-tuneonfoundationmodelsforhealthcare.\nWangetal.\n[151]empowerLLM-basedagentstoacquiretext-basedexternalknowledgeasreasoningreference.\nBesides,Shietal.\n[152]buildmemoryuponthemostrelevantsuccessfulcasesfrompastexperiences,andusesimilaritymetricfortheretrievalofrelevantquestionsinthemedicinedomain.\nFinanceDomain.\nSomepreviousworksalsoapplyLLM-basedagentsinthefinancedomain,whosememorycanstorefinancialknowledge[113],marketinformation[154,156],andsuccessfulexperi-ences[157,155].\nYangetal.\n[113]constructfinancialinvestmentdatasettofine-tuneLLaMA[127]toempowerknowledgeoninvestment.\nLietal.\n[154]designalayered-memorystructuretostoredifferenttypesofmarketinginformation.\nWangetal.\n[155]recordtheongoinginteractionlikeexchangesandinformationtoensureconsistentresponse,andrecordprioroutputsasexperiencesforretrievingrelevantexamplestoprovideadiverselearningcontextforagents.\nKoaetal.\n[157]storepastpricemovementandexplanations,andgeneratereflectionsonprevioustrials.\nYuetal.\n[156]adoptalayeredmemorymechanismtoprovideabundantinformationforreasoning.\nScience.\nInthedomainofscience,someexistingworksdesignLLM-basedagentswithalargeamountofknowledgeinmemorytosolveproblems[158,160,162].\nChenetal.\n[158]includemoleculedatabaseandonlineliteratureasexternalknowledgeformemoryinLLM-basedagents,andretrievethemwhentheyneedrelatedinformation.\nZhaoetal.\n[160]andChenetal.\n[162]empowerdomainknowledgebyfine-tuninginChemistryandstructuredmaterialsrespectively.\nTobuildanexpertsystembasedonagentsinaspecificverticaldomain,itisnecessarytoretainthedomain-specificknowledgeintheirmemory.\nHowever,thereareseveralchallenges.",
      "#memory_survey#ExternalKnowledge#memory_survey#ExternalKnowledge\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain.\nItfine-tunesanacquisitionprocesstoretrieveexternalknowledgefromWikipediaandmedicaldatabases.\nDiscussion.\nTheexternalknowledgecanbeobtainedfrombothprivateandpublicsources.\nItprovidesLLM-basedagentswithmuchknowledgebeyondtheirinternalenvironment,whichmightbedifficultorevenimpossiblefortheagenttoacquirebyagent-environmentinteractions."
    ],
    [
      "#memory_survey#MemoryinParametricForm#memory_survey#MemoryinParametricForm\nMemoryinParametricFormAnalternativetypeofapproachesistorepresentmemoryinparametricform.\nTheydonottakeuptheextralengthofcontextinprompts,sotheyarenotconstrainedbythelengthlimitationsofLLMcontext.\nHowever,theparametricmemoryformisstillunder-researched,andwecategorizepreviousworksintotwotypes:fine-tuningmethodsandmemoryeditingmethods.\nFine-tuningMethods.\nIntegratingexternalknowledgeintothememoryofagentsisbeneficialforenrichingdomain-specificknowledgeontopofitsgeneralknowledge.\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.\nAnotherlimitationoffine-tuningliesinthecomputationalcostandtimeconsumption,aswellastherequirementofalargeamountofdata.\nTherefore,mostfine-tuningapproachesareappliedtoofflinescenarios,andcanseldomdealwithonlinescenarios,suchasfine-tuningwithagentobservationsandtrialexperiences.\nDuetothefrequentagent-environmentinteractions,itisunaffordableforthecostofbackpropagationtofine-tuneeverystepoftheonlineanddynamicinteractions.\nMemoryEditingMethods.",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nMoreover,someeffortsarededicatedtoenhancingthecapacityofLLMstohandlelongercontexts[118,119].\nWhilestoringalltheagent-environmentinteractionscanmaintaincomprehensiveinformation,obviouslimitationsexistintermsofcomputationalcost,inferencetime,andinferencerobustness.\nFirstly,thefast-growinglong-contextmemoryinpracticeresultsinhighcomputationalcostduringLLMinference,duetothequadraticgrowthofthetimecomplexityofattentioncomputationwithsequencelength.\nItthusrequiresmuchmorecomputingresourcesandsignificantlyincreasesinferencelatency,whichhindersitspracticaldeployment.\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.\nThismethodstoresandmaintainsthemostrecentlyacquiredmemoriesusingnaturallanguages,therebyenhancingtheefficiencyofmemoryinformationutilizationaccordingtothePrincipleofLocality[121].\nIntask(B)oftheexampleinSection3.\n1,wecanjustrememberAlice’spreferencesintherecentthreeyears,andtruncatethedistantpart,wheretherecentthreeyearscanbeconsideredasthememorywindowsize.\nInpreviousstudies,therearevariousstrategiestostorerecenttextualmemories.\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nIntheformerthreetypes,theyrecordtheinformationinsidetheagent-environmentinteractionloop,whilethelasttypeleveragesnaturallanguagestostoreinformationoutsidethatloop.\nCompleteInteractions.\nThismethodstoresalltheinformationoftheagent-environmentinteractionhistorybasedonlong-contextstrategies[116].\nFortheexampleinSection3.\n1,thememoryofthe14agentintask(A)afterstep2canbeimplementedbyconcatenatingalltheinformationbeforestep2,andthefinaltextualformmemoryis:\"Yourmemoryis[Step1](Agent).\n.\n.\n(OnlineTicketOffice).\n.\n.\n[Step2].\n.\n.\nPleaseinferbasedonyourmemory\".\nInthepreviouswork,differentmodelsstorethememoryinformationusingdifferentstrategies.\nForexample,inLongChat[116],theagentsfocusonunderstandingnaturallanguagesinlong-contextscenarios.\nItfine-tunesthefoundationmodelforbetteradaptingtomemorizecompleteinteractions.\nMemorySandbox[117]intendstoalleviatetheimpactofirrelevantmemoryinconversations.\nItdesignsatransparentandinteractivemethodtomanagethememoryofagents,whichremovesirrelevantmemorybeforeconcatenatingthemasaprompt.\nMoreover,someeffortsarededicatedtoenhancingthecapacityofLLMstohandlelongercontexts[118,119].\nWhilestoringalltheagent-environmentinteractionscanmaintaincomprehensiveinformation,obviouslimitationsexistintermsofcomputationalcost,inferencetime,andinferencerobustness.\nFirstly,thefast-growinglong-contextmemoryinpracticeresultsinhighcomputationalcostduringLLMinference,duetothequadraticgrowthofthetimecomplexityofattentioncomputationwithsequencelength.\nItthusrequiresmuchmorecomputingresourcesandsignificantlyincreasesinferencelatency,whichhindersitspracticaldeployment.\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.",
      "#memory_survey#Memory-assistedAgent-EnvironmentInteraction#memory_survey#Memory-assistedAgent-EnvironmentInteraction\nForthenarrowmemorydefinition,theiterationonlyhappenswithinthesametrial,andthememoryisemptiedwhenthetrialisended.\nForthebroadmemorydefinition,theiterationhappensacrossdifferenttrialsoreventasks,aswellastheintegrationsofexternalknowledge.\nFortask(B)intheabovetoyexample,theagentcanconcludethatAliceenjoyswatchingsciencefictionmoviesintheevening,whichcanbeusedasadefaultruletomakerecommendationsforAliceinthefuture.\nMemoryReading.\nThisoperationaimstoobtainimportantinformationfromthememorytosupportthenextagentaction.\nItcorrespondstothethirdphaseoftheagent-environmentinteractionprocess.\nSupposeMktisthecontextofthenextaction,thenthememoryreadingoperationcanberepresentedby:tisthememorycontentsfortaskkatstept,ckˆMkt=R(Mkt,ckt+1),whereRisusuallyimplementedbycomputingthesimilaritybetweenMktisusedaspartsofthefinalprompttodrivetheagent’snextaction.\nFortask(B)intheabovetoyexample,whentheagentdecidesonthefinalrecommendedmoviein[Step3],itshouldfocusonthe“wanttowatch”listin[Step2]andselectonefromit.\ntandckt+1[82].\nˆMkBasedontheaboveoperations,wecanderiveaunifiedfunctionfortheevolvingprocessfrom{akt,okt}toakt+1,thatis:akt+1=LLM{R(P(Mkt−1,W({akt,okt})),ckt+1)},whereLLMisthelargelanguagemodel.\nThecompleteagent-environmentinteractionprocesscanbeeasilyobtainedbyiterativelyexpandingthisfunction(seeFigure3(b)foranintuitiveillustration).\nRemark.\nThisfunctionprovidesageneralformulationoftheagentmemorizingprocess.\nPreviousworksmayusedifferentspecifications.\nForexample,in[5],RandParesetasidenticalfunctions,andPonlytakeseffectattheendofatrial.\nInParketal.\n[83],Risimplementedbasedonthreecriteriaincludingsimilarity,timeinterval,andimportance,andPisrealizedbyareflectionprocesstoobtainmoreabstractthoughts.\nInthissection,wefocusontheoverallframeworkoftheagent’smemoryoperations.\nMoredetailedrealizationsofW,P,andRaredeferredinSection5.\n4"
    ],
    [
      "#memory_survey#ExternalKnowledge#memory_survey#ExternalKnowledge\nItshouldbenotedthattheinside-trialinformationnotonlyincludesagent-environmentinteractions,butalsocontainsinteractioncontexts,suchastimeandlocationinformation.\n12Discussion.\nTheinside-trialinformationisthemostobviousandintuitivesourcethatshouldbeleveragedtoconstructtheagent’smemorysinceitishighlyrelevanttothecurrenttaskthattheagenthastoaccomplish.\nHowever,relyingsolelyoninside-trialinformationmaypreventtheagentfromaccumulatingvaluableknowledgefromvarioustasksandlearningmoregeneralizableinformation.\nThus,manystudiesalsoexplorehowtoeffectivelyutilizetheinformationacrossdifferenttaskstobuildthememorymodule,whichisdetailedinthefollowingsections.\n5.\n1.\n2Cross-trialInformationForLLM-basedagents,theinformationaccumulatedacrossmultipletrialsintheenvironmentisalsoacrucialpartofthememory,typicallyincludingsuccessfulandfailedactionsandtheirinsights,suchasfailurereasons,commonactionpatternstosucceed,andsoon.\nRepresentativeStudies.\nOneofthemostprominentstudiesisReflexion[5],whichproposesverbalreinforcementlearningforLLM-basedagents.\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTiM[97]aimstoenhancetheagent’sreasoningcapabilitybyself-generatingmultiplethoughtsafteraccomplishingatask,whichisusedasthememorytoprovidemoregeneralizableinformation.\nVoyager[99]focusesonbuildinggameagentsbasedonMinecraft,wherethememorycontainsexecutablecodesofpreliminaryandbasicactionstoaccomplishatask.\nItshouldbenotedthattheinside-trialinformationnotonlyincludesagent-environmentinteractions,butalsocontainsinteractioncontexts,suchastimeandlocationinformation.\n12Discussion.\nTheinside-trialinformationisthemostobviousandintuitivesourcethatshouldbeleveragedtoconstructtheagent’smemorysinceitishighlyrelevanttothecurrenttaskthattheagenthastoaccomplish.\nHowever,relyingsolelyoninside-trialinformationmaypreventtheagentfromaccumulatingvaluableknowledgefromvarioustasksandlearningmoregeneralizableinformation.\nThus,manystudiesalsoexplorehowtoeffectivelyutilizetheinformationacrossdifferenttaskstobuildthememorymodule,whichisdetailedinthefollowingsections.\n5.\n1.\n2Cross-trialInformationForLLM-basedagents,theinformationaccumulatedacrossmultipletrialsintheenvironmentisalsoacrucialpartofthememory,typicallyincludingsuccessfulandfailedactionsandtheirinsights,suchasfailurereasons,commonactionpatternstosucceed,andsoon.\nRepresentativeStudies.\nOneofthemostprominentstudiesisReflexion[5],whichproposesverbalreinforcementlearningforLLM-basedagents.\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nThememoryofanagentisderivedfromthehistoricalbehaviorstoachieveatarget,forexample,thecollectionofrelevantpaperswhenresearchingonaspecifictopic.\nMemoChat[94]aimstochatwithhumans,wherethememoryoftheagentisderivedbasedontheconversationhistoryofadialoguesession.\nTiM[97]aimstoenhancetheagent’sreasoningcapabilitybyself-generatingmultiplethoughtsafteraccomplishingatask,whichisusedasthememorytoprovidemoregeneralizableinformation.\nVoyager[99]focusesonbuildinggameagentsbasedonMinecraft,wherethememorycontainsexecutablecodesofpreliminaryandbasicactionstoaccomplishatask.\nItshouldbenotedthattheinside-trialinformationnotonlyincludesagent-environmentinteractions,butalsocontainsinteractioncontexts,suchastimeandlocationinformation.\n12Discussion.\nTheinside-trialinformationisthemostobviousandintuitivesourcethatshouldbeleveragedtoconstructtheagent’smemorysinceitishighlyrelevanttothecurrenttaskthattheagenthastoaccomplish.\nHowever,relyingsolelyoninside-trialinformationmaypreventtheagentfromaccumulatingvaluableknowledgefromvarioustasksandlearningmoregeneralizableinformation.\nThus,manystudiesalsoexplorehowtoeffectivelyutilizetheinformationacrossdifferenttaskstobuildthememorymodule,whichisdetailedinthefollowingsections.\n5.\n1.\n2Cross-trialInformationForLLM-basedagents,theinformationaccumulatedacrossmultipletrialsintheenvironmentisalsoacrucialpartofthememory,typicallyincludingsuccessfulandfailedactionsandtheirinsights,suchasfailurereasons,commonactionpatternstosucceed,andsoon.\nRepresentativeStudies.\nOneofthemostprominentstudiesisReflexion[5],whichproposesverbalreinforcementlearningforLLM-basedagents.\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain."
    ],
    [
      "#memory_survey#MemoryinParametricForm#memory_survey#MemoryinParametricForm\nMemoryinParametricFormAnalternativetypeofapproachesistorepresentmemoryinparametricform.\nTheydonottakeuptheextralengthofcontextinprompts,sotheyarenotconstrainedbythelengthlimitationsofLLMcontext.\nHowever,theparametricmemoryformisstillunder-researched,andwecategorizepreviousworksintotwotypes:fine-tuningmethodsandmemoryeditingmethods.\nFine-tuningMethods.\nIntegratingexternalknowledgeintothememoryofagentsisbeneficialforenrichingdomain-specificknowledgeontopofitsgeneralknowledge.\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.\nAnotherlimitationoffine-tuningliesinthecomputationalcostandtimeconsumption,aswellastherequirementofalargeamountofdata.\nTherefore,mostfine-tuningapproachesareappliedtoofflinescenarios,andcanseldomdealwithonlinescenarios,suchasfine-tuningwithagentobservationsandtrialexperiences.\nDuetothefrequentagent-environmentinteractions,itisunaffordableforthecostofbackpropagationtofine-tuneeverystepoftheonlineanddynamicinteractions.\nMemoryEditingMethods.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTosystemicallysummarizethestudiesinthisfield,researchershavewrittenalotofsurveypapers.\nInthissection,webrieflyreviewthesesurveys(seeFigure2foranoverview),highlightingtheirmajorfocusesandcontributionstobetterpositionourstudy.\n2.\n1SurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.\n[70]presentthefirstcomprehensivesurveytosummarizethebackground,evolutionpaths,modelarchitectures,trainingmethodologies,andevaluationstrategiesofLLMs.\nHadietal.\n[71]andMinetal.\n[72]alsoconductLLMsurveysfromtheholisticview,which,however,providedifferenttaxonomiesandunderstandingsonLLMs.\nFollowingthesesurveys,peoplediveintospecificaspectsofLLMsandreviewthecorrespondingmilestonestudiesandkeytechnologies.\nTheseaspectscanbeclassifiedintofourcategoriesincludingthefundamentalproblems,evaluation,applications,andchallengesofLLMs.\nFundamentalproblems.\nThesurveysinthiscategoryaimtosummarizetechniquesthatcanbeleveragedtotacklefundamentalproblemsofLLMs.\nSpecifically,Zhangetal.\n[8]provideacomprehensivesurveyonthemethodsofsupervisedfine-tuning,whichisakeytechniqueforbettertrainingLLMs.\nShenetal.\n[9],Wangetal.\n[10]andLiuetal.\n[11]presentsurveysonthealignmentofLLMs,whichisakeyrequirementforLLMstoproduceoutputsconsistentwithhumanvalues.\nGaoetal.\n[12]proposeasurveyontheretrieval-augmentedgeneration(RAG)capabilityofLLMs,whichiskeytoprovidingLLMswithfactualandup-to-dateknowledgeandremovinghallucinations.\nQinetal.\n[18]summarizethestate-of-the-artmethodsonenablingLLMstoleverageexternaltools,whichisfundamentalforLLMstoexpandtheircapabilityindomainsthatrequirespecializedknowledge.\nWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16]andZhangetal.\n[17]presentsurveysonthedirectionofLLMknowledgeediting,whichisimportantforcustomizingLLMstosatisfyspecificrequirements.\nHuangetal.\n[19],Wangetal.\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\nFigure2:TheorganizationofrelatedsurveysonLLMsandLLM-basedagents.\n6Challenges.\nThesurveysinthiscategoryfocusontrustworthinessinLLMs,suchashallucination,bias,unfairness,explainability,security,andprivacy.\nHallucinationinLLMsreferstotheproblemthatLLMsmaygeneratemisconceptionsorfabrications,impactingtheirreliabilityfordownstreamapplications.\nZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Tonmoyetal.\n[58]andJiangetal.\n[59]summarizethemainstreammodelsforalleviatingthehallucinationprobleminLLMs.\nThebiasandunfairnessproblemsrefertothephenomenonthatLLMsmayunequallytreatdifferenthumansorobjectives,whichcanleadtothepropagationofsocietalstereotypesanddiscrimination.\nGallegosetal.\n[60],Koteketal.\n[61]andLietal.\n[62]comprehensivelydiscussthesechallengesandsummarizeexistingmethodsforalleviatingthem.\nTheproblemofexplainabilitymeansthattheinternalworkingmechanismsofLLMsarestillunclear.\nZhaoetal.\n[63]systematicallydiscussthisproblemandsummarizepreviouseffortsonimprovingtheexplainabilityofLLMs.\nSecurityandprivacyarealsochallengingproblems,whichhavebeencomprehensivelysurveyedinYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68]andDasetal.\n[69].\n2.\n2",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\nSurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.\n[70]presentthefirstcomprehensivesurveytosummarizethebackground,evolutionpaths,modelarchitectures,trainingmethodologies,andevaluationstrategiesofLLMs.\nHadietal.\n[71]andMinetal.\n[72]alsoconductLLMsurveysfromtheholisticview,which,however,providedifferenttaxonomiesandunderstandingsonLLMs.\nFollowingthesesurveys,peoplediveintospecificaspectsofLLMsandreviewthecorrespondingmilestonestudiesandkeytechnologies.\nTheseaspectscanbeclassifiedintofourcategoriesincludingthefundamentalproblems,evaluation,applications,andchallengesofLLMs.\nFundamentalproblems.\nThesurveysinthiscategoryaimtosummarizetechniquesthatcanbeleveragedtotacklefundamentalproblemsofLLMs.\nSpecifically,Zhangetal.\n[8]provideacomprehensivesurveyonthemethodsofsupervisedfine-tuning,whichisakeytechniqueforbettertrainingLLMs.\nShenetal.\n[9],Wangetal.\n[10]andLiuetal.\n[11]presentsurveysonthealignmentofLLMs,whichisakeyrequirementforLLMstoproduceoutputsconsistentwithhumanvalues.\nGaoetal.\n[12]proposeasurveyontheretrieval-augmentedgeneration(RAG)capabilityofLLMs,whichiskeytoprovidingLLMswithfactualandup-to-dateknowledgeandremovinghallucinations.\nQinetal.\n[18]summarizethestate-of-the-artmethodsonenablingLLMstoleverageexternaltools,whichisfundamentalforLLMstoexpandtheircapabilityindomainsthatrequirespecializedknowledge.\nWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16]andZhangetal.\n[17]presentsurveysonthedirectionofLLMknowledgeediting,whichisimportantforcustomizingLLMstosatisfyspecificrequirements.\nHuangetal.\n[19],Wangetal.\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal."
    ],
    [
      "#memory_survey#Memory-basedLifelongLearning#memory_survey#Memory-basedLifelongLearning\nMemory-basedLifelongLearningLifelonglearningisanadvancedtopicinartificialintelligence,extendingthelearningcapabilitiesofagentsacrosstheirlife-longspan[173].\nAgentscancontinuouslyinteractwiththeirenvironment,persistentlyobserveenvironments,andacquireexternalknowledge,enablingamodeofenhancementlikehumans.\nThememoryofanagentiskeytoachievinglifelonglearning,asitneedstolearntostoreandapplythepastobservations.\nLifelonglearninginLLM-basedagentsholdssignificantpracticalvalue,suchasinlong-termsocialsimulationsandpersonalassistance.\nHowever,italsofacesseveralchallenges.\nFirstly,lifelonglearningistemporal,necessitatingthatanagent’smemorycapturestemporality.\nThistemporalitycouldcauseinteractionsbetweenmemories,suchasmemoryoverlap.\nFurthermore,duetotheextendedperiodoflifelonglearning,itneedstostoreavastamountofmemoriesandretrievethemwhenneeded,possiblyincorporatingacertainmechanismforforgetting.\n8.\n4",
      "#memory_survey#Memory-enhancedAgentApplications#memory_survey#Memory-enhancedAgentApplications\nMemory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nThememoryofanagentisderivedfromthehistoricalbehaviorstoachieveatarget,forexample,thecollectionofrelevantpaperswhenresearchingonaspecifictopic.\nMemoChat[94]aimstochatwithhumans,wherethememoryoftheagentisderivedbasedontheconversationhistoryofadialoguesession.\nTiM[97]aimstoenhancetheagent’sreasoningcapabilitybyself-generatingmultiplethoughtsafteraccomplishingatask,whichisusedasthememorytoprovidemoregeneralizableinformation.\nVoyager[99]focusesonbuildinggameagentsbasedonMinecraft,wherethememorycontainsexecutablecodesofpreliminaryandbasicactionstoaccomplishatask.\nItshouldbenotedthattheinside-trialinformationnotonlyincludesagent-environmentinteractions,butalsocontainsinteractioncontexts,suchastimeandlocationinformation.\n12Discussion.\nTheinside-trialinformationisthemostobviousandintuitivesourcethatshouldbeleveragedtoconstructtheagent’smemorysinceitishighlyrelevanttothecurrenttaskthattheagenthastoaccomplish.\nHowever,relyingsolelyoninside-trialinformationmaypreventtheagentfromaccumulatingvaluableknowledgefromvarioustasksandlearningmoregeneralizableinformation.\nThus,manystudiesalsoexplorehowtoeffectivelyutilizetheinformationacrossdifferenttaskstobuildthememorymodule,whichisdetailedinthefollowingsections.\n5.\n1.\n2Cross-trialInformationForLLM-basedagents,theinformationaccumulatedacrossmultipletrialsintheenvironmentisalsoacrucialpartofthememory,typicallyincludingsuccessfulandfailedactionsandtheirinsights,suchasfailurereasons,commonactionpatternstosucceed,andsoon.\nRepresentativeStudies.\nOneofthemostprominentstudiesisReflexion[5],whichproposesverbalreinforcementlearningforLLM-basedagents.\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.",
      "#memory_survey#WhatistheMemoryofLLM-basedAgent#memory_survey#WhatistheMemoryofLLM-basedAgent\nWhatistheMemoryofLLM-basedAgentInteractingandlearningfromenvironmentsisabasicrequirementofLLM-basedagents.\nIntheagent-environmentinteractionprocess,therearethreekeyphases,thatis,(1)theagentperceivesinformationfromtheenvironment,andstoresitintothememory;(2)theagentprocessesthestoredinformationtomakeitmoreusable;and(3)theagenttakesthenextactionbasedontheprocessedmemoryinformation.\nInallthesephases,memoryplaysanextremelyimportantrole.\nInthefollowing,wefirstdefinethememoryoftheagentfrombothnarrowandbroadperspectives,andthen,detailtheexecutionprocessesoftheabovethreephasesbasedonthememorymodule.\n3.\n1",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain."
    ],
    [
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\nFigure2:TheorganizationofrelatedsurveysonLLMsandLLM-basedagents.\n6Challenges.\nThesurveysinthiscategoryfocusontrustworthinessinLLMs,suchashallucination,bias,unfairness,explainability,security,andprivacy.\nHallucinationinLLMsreferstotheproblemthatLLMsmaygeneratemisconceptionsorfabrications,impactingtheirreliabilityfordownstreamapplications.\nZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Tonmoyetal.\n[58]andJiangetal.\n[59]summarizethemainstreammodelsforalleviatingthehallucinationprobleminLLMs.\nThebiasandunfairnessproblemsrefertothephenomenonthatLLMsmayunequallytreatdifferenthumansorobjectives,whichcanleadtothepropagationofsocietalstereotypesanddiscrimination.\nGallegosetal.\n[60],Koteketal.\n[61]andLietal.\n[62]comprehensivelydiscussthesechallengesandsummarizeexistingmethodsforalleviatingthem.\nTheproblemofexplainabilitymeansthattheinternalworkingmechanismsofLLMsarestillunclear.\nZhaoetal.\n[63]systematicallydiscussthisproblemandsummarizepreviouseffortsonimprovingtheexplainabilityofLLMs.\nSecurityandprivacyarealsochallengingproblems,whichhavebeencomprehensivelysurveyedinYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68]andDasetal.\n[69].\n2.\n2",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal.\n[47]summarizetheapplicationsofLLMsinmedicine.\nLietal.\n[48]focusontheapplicationsofLLMsinfinance.\nHeetal.\n[49]reviewthemodelsonleveragingLLMstoimprovethedevelopmentofpsychology.\n5SupervisedFine-tuningZhangetal.\n[8].\nAlignmentShenetal.\n[9],Wangetal.\n[10],Liuetal.\n[11].\nRetrievalAugmentationGaoetal.\n[12].\nKnowledgeEditingWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16],Zhangetal.\n[17].\nFundamentalProblemsToolUsageQinetal.\n[18].\nLong-contextMultimodalEfficiencyHuangetal.\n[19],Wangetal.\n[20],Pawaretal.\n[21].\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24],Yinetal.\n[25].\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28,28],Xuetal.\n[29],Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32],Parketal.\n[33].\nEvaluationChangetal.\n[34],Guoetal.\n[35].\nInformationProcessingSoftwareEngineeringYangetal.\n[36],Zhuetal.\n[37],Xuetal.\n[38].\nFanetal.\n[39],Wangetal.\n[40],Zhengetal.\n[41].\nRoboticsZengetal.\n[42].\nApplicationsAutonomousDrivingCuietal.\n[43],Yangetal.\n[44].\nLLMs[70–73]MedecineFinancePsychologyHeetal.\n[45],Zhouetal.\n[46],Wangetal.\n[47].\nLietal.\n[48].\nHeetal.\n[49].\nRecommendationLietal.\n[50],Linetal.\n[51],Wangetal.\n[52].\nHallucinationZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Ton-moyetal.\n[58],Jiangetal.\n[59].\nChallengesBias&FairnessGallegosetal.\n[60],Koteketal.\n[61],Lietal.\n[62].\nExplainabilityZhaoetal.\n[63].\nSecurityYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68],Dasetal.\n[69].\nPlanningHuangetal.\n[74].\nFundamentalProblemsMemoryOurSurvey.\nMulti-agentsGuoetal.\n[75].\nLLM-basedAgent[3,4,77–80]EvaluationApplicationsChallengesLietal.\n[76].\nFigure2:TheorganizationofrelatedsurveysonLLMsandLLM-basedagents.\n6Challenges.\nThesurveysinthiscategoryfocusontrustworthinessinLLMs,suchashallucination,bias,unfairness,explainability,security,andprivacy.",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\nSurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.\n[70]presentthefirstcomprehensivesurveytosummarizethebackground,evolutionpaths,modelarchitectures,trainingmethodologies,andevaluationstrategiesofLLMs.\nHadietal.\n[71]andMinetal.\n[72]alsoconductLLMsurveysfromtheholisticview,which,however,providedifferenttaxonomiesandunderstandingsonLLMs.\nFollowingthesesurveys,peoplediveintospecificaspectsofLLMsandreviewthecorrespondingmilestonestudiesandkeytechnologies.\nTheseaspectscanbeclassifiedintofourcategoriesincludingthefundamentalproblems,evaluation,applications,andchallengesofLLMs.\nFundamentalproblems.\nThesurveysinthiscategoryaimtosummarizetechniquesthatcanbeleveragedtotacklefundamentalproblemsofLLMs.\nSpecifically,Zhangetal.\n[8]provideacomprehensivesurveyonthemethodsofsupervisedfine-tuning,whichisakeytechniqueforbettertrainingLLMs.\nShenetal.\n[9],Wangetal.\n[10]andLiuetal.\n[11]presentsurveysonthealignmentofLLMs,whichisakeyrequirementforLLMstoproduceoutputsconsistentwithhumanvalues.\nGaoetal.\n[12]proposeasurveyontheretrieval-augmentedgeneration(RAG)capabilityofLLMs,whichiskeytoprovidingLLMswithfactualandup-to-dateknowledgeandremovinghallucinations.\nQinetal.\n[18]summarizethestate-of-the-artmethodsonenablingLLMstoleverageexternaltools,whichisfundamentalforLLMstoexpandtheircapabilityindomainsthatrequirespecializedknowledge.\nWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16]andZhangetal.\n[17]presentsurveysonthedirectionofLLMknowledgeediting,whichisimportantforcustomizingLLMstosatisfyspecificrequirements.\nHuangetal.\n[19],Wangetal.\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTosystemicallysummarizethestudiesinthisfield,researchershavewrittenalotofsurveypapers.\nInthissection,webrieflyreviewthesesurveys(seeFigure2foranoverview),highlightingtheirmajorfocusesandcontributionstobetterpositionourstudy.\n2.\n1SurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.\n[70]presentthefirstcomprehensivesurveytosummarizethebackground,evolutionpaths,modelarchitectures,trainingmethodologies,andevaluationstrategiesofLLMs.\nHadietal.\n[71]andMinetal.\n[72]alsoconductLLMsurveysfromtheholisticview,which,however,providedifferenttaxonomiesandunderstandingsonLLMs.\nFollowingthesesurveys,peoplediveintospecificaspectsofLLMsandreviewthecorrespondingmilestonestudiesandkeytechnologies.\nTheseaspectscanbeclassifiedintofourcategoriesincludingthefundamentalproblems,evaluation,applications,andchallengesofLLMs.\nFundamentalproblems.\nThesurveysinthiscategoryaimtosummarizetechniquesthatcanbeleveragedtotacklefundamentalproblemsofLLMs.\nSpecifically,Zhangetal.\n[8]provideacomprehensivesurveyonthemethodsofsupervisedfine-tuning,whichisakeytechniqueforbettertrainingLLMs.\nShenetal.\n[9],Wangetal.\n[10]andLiuetal.\n[11]presentsurveysonthealignmentofLLMs,whichisakeyrequirementforLLMstoproduceoutputsconsistentwithhumanvalues.\nGaoetal.\n[12]proposeasurveyontheretrieval-augmentedgeneration(RAG)capabilityofLLMs,whichiskeytoprovidingLLMswithfactualandup-to-dateknowledgeandremovinghallucinations.\nQinetal.\n[18]summarizethestate-of-the-artmethodsonenablingLLMstoleverageexternaltools,whichisfundamentalforLLMstoexpandtheircapabilityindomainsthatrequirespecializedknowledge.\nWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16]andZhangetal.\n[17]presentsurveysonthedirectionofLLMknowledgeediting,whichisimportantforcustomizingLLMstosatisfyspecificrequirements.\nHuangetal.\n[19],Wangetal.\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68],Dasetal.\n[69].\nPlanningHuangetal.\n[74].\nFundamentalProblemsMemoryOurSurvey.\nMulti-agentsGuoetal.\n[75].\nLLM-basedAgent[3,4,77–80]EvaluationApplicationsChallengesLietal.\n[76].\nFigure2:TheorganizationofrelatedsurveysonLLMsandLLM-basedagents.\n6Challenges.\nThesurveysinthiscategoryfocusontrustworthinessinLLMs,suchashallucination,bias,unfairness,explainability,security,andprivacy.\nHallucinationinLLMsreferstotheproblemthatLLMsmaygeneratemisconceptionsorfabrications,impactingtheirreliabilityfordownstreamapplications.\nZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Tonmoyetal.\n[58]andJiangetal.\n[59]summarizethemainstreammodelsforalleviatingthehallucinationprobleminLLMs.\nThebiasandunfairnessproblemsrefertothephenomenonthatLLMsmayunequallytreatdifferenthumansorobjectives,whichcanleadtothepropagationofsocietalstereotypesanddiscrimination.\nGallegosetal.\n[60],Koteketal.\n[61]andLietal.\n[62]comprehensivelydiscussthesechallengesandsummarizeexistingmethodsforalleviatingthem.\nTheproblemofexplainabilitymeansthattheinternalworkingmechanismsofLLMsarestillunclear.\nZhaoetal.\n[63]systematicallydiscussthisproblemandsummarizepreviouseffortsonimprovingtheexplainabilityofLLMs.\nSecurityandprivacyarealsochallengingproblems,whichhavebeencomprehensivelysurveyedinYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68]andDasetal.\n[69].\n2.\n2SurveysonLargeLanguageModel-basedAgentsBasedonthecapabilityofLLMs,peoplehaveconductedalotofstudiesonbuildingLLM-basedagents,whichcanautonomouslyperceiveenvironments,takeactions,accumulateknowledge,andevolvethemselves.\nInthisfield,Wangetal.\n[3]presentthefirstsurveypapertosystematicallysummarizeLLM-basedagentsfromtheperspectivesofagentconstruction,agentapplication,andagentevaluation.\nXietal.\n[4],Zhaoetal.\n[77],Chengetal.\n[78]andGeetal.\n[80]alsosummarizeLLM-basedagentstudiesfromtheoverallperspective,buttheyhavedifferentfocusesandtaxonomies,deliveringmorediverseunderstandingsonthisfield.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n31[53]YueZhang,YafuLi,LeyangCui,DengCai,LemaoLiu,TingchenFu,XintingHuang,EnboZhao,YuZhang,YulongChen,etal.\nSiren’ssongintheaiocean:asurveyonhallucinationinlargelanguagemodels.\narXivpreprintarXiv:2309.\n01219,2023.\n[54]LeiHuang,WeijiangYu,WeitaoMa,WeihongZhong,ZhangyinFeng,HaotianWang,Qian-glongChen,WeihuaPeng,XiaochengFeng,BingQin,etal.\nAsurveyonhallucinationinlargelanguagemodels:Principles,taxonomy,challenges,andopenquestions.\narXivpreprintarXiv:2311.\n05232,2023.\n[55]VipulaRawte,AmitSheth,andAmitavaDas.\nAsurveyofhallucinationinlargefoundationmodels.\narXivpreprintarXiv:2309.\n05922,2023.\n[56]HongbinYe,TongLiu,AijiaZhang,WeiHua,andWeiqiangJia.\nCognitivemirage:Areviewofhallucinationsinlargelanguagemodels.\narXivpreprintarXiv:2309.\n06794,2023.\n[57]ZiweiJi,NayeonLee,RitaFrieske,TiezhengYu,DanSu,YanXu,EtsukoIshii,YeJinBang,AndreaMadotto,andPascaleFung.\nSurveyofhallucinationinnaturallanguagegeneration.\nACMComputingSurveys,55(12):1–38,2023.\n[58]SMTonmoy,SMZaman,VinijaJain,AnkuRani,VipulaRawte,AmanChadha,andAmitavaDas.\nAcomprehensivesurveyofhallucinationmitigationtechniquesinlargelanguagemodels.\narXivpreprintarXiv:2401.\n01313,2024.\n[59]XuhuiJiang,YuxingTian,FengruiHua,ChengjinXu,YuanzhuoWang,andJianGuo.\nAsurveyonlargelanguagemodelhallucinationviaacreativityperspective.\narXivpreprintarXiv:2402.\n06647,2024.\n[60]IsabelOGallegos,RyanARossi,JoeBarrow,MdMehrabTanjim,SungchulKim,FranckDernoncourt,TongYu,RuiyiZhang,andNesreenKAhmed.\nBiasandfairnessinlargelanguagemodels:Asurvey.\narXivpreprintarXiv:2309.\n00770,2023.\n[61]HadasKotek,RikkerDockum,andDavidSun.\nGenderbiasandstereotypesinlargelanguagemodels.\nInProceedingsofTheACMCollectiveIntelligenceConference,pages12–24,2023.\n[62]YingjiLi,MengnanDu,RuiSong,XinWang,andYingWang.\nAsurveyonfairnessinlargelanguagemodels.\narXivpreprintarXiv:2308.\n10149,2023.\n[63]HaiyanZhao,HanjieChen,FanYang,NinghaoLiu,HuiqiDeng,HengyiCai,ShuaiqiangWang,DaweiYin,andMengnanDu.\nExplainabilityforlargelanguagemodels:Asurvey.\nACMTransactionsonIntelligentSystemsandTechnology,2023.",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32]andParketal.\n[33]systematicallyreviewthetechniquesofmodelcompression.\nDingetal.\n[81]andXuetal.\n[29]analyzeandconcludethestudiesonparameterefficientfine-tuning.\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28]andDingetal.\n[81]putmorefocusesontheefficiencyofresourceutilizationinageneralsense.\nEvaluation.\nThesurveysinthiscategoryfocusonhowtoevaluatethecapabilityofLLMs.\nSpecifi-cally,Changetal.\n[34]comprehensivelysummarizetheevaluationmethodsfromanoverallperspec-tive.\nItencompassesdifferentevaluationtasks,methods,andbenchmarks,whichserveascriticalpartsinassessingLLMperformances.\nGuoetal.\n[35]caremoreabouttheevaluationtargetsanddescribehowtoevaluatetheknowledge,alignment,andsafetycontrolcapabilitiesofLLMs,whichsupplementevaluationmetricsbeyondperformance.\nApplications.\nThesurveysinthiscategoryaimtosummarizemodelsthatleverageLLMstoimprovedifferentapplications.\nMoreconcretely,Zhuetal.\n[37]focusonthefieldofinformationretrieval(IR)andsummarizestudiesonLLM-basedqueryprocesses.\nXuetal.\n[38]paymoreattentiontoinformationextraction(IE)andprovidecomprehensivetaxonomiesforLLM-basedmodelsinthisfield.\nLietal.\n[50],Linetal.\n[51]andWangetal.\n[52]discusstheapplicationsofLLMsinthefieldofrecommendersystem,wheretheyutilizeagentstogeneratedataandproviderecommendations.\nFanetal.\n[39],Wangetal.\n[40],andZhengetal.\n[41]concentrateonhowLLMscanbenefitsoftwareengineering(SE)intermsofsoftwaredesign,development,andtesting.\nZengetal.\n[42]summarizeLLM-basedmethodsinthefieldofrobotics.\nCuietal.\n[43]andYangetal.\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal.",
      "#memory_survey#RelatedSurveys#memory_survey#RelatedSurveys\nRelatedSurveysInthepasttwoyears,LLMshaveattractedmuchattentionfromtheacademicandindustrycommu-nities.\nTosystemicallysummarizethestudiesinthisfield,researchershavewrittenalotofsurveypapers.\nInthissection,webrieflyreviewthesesurveys(seeFigure2foranoverview),highlightingtheirmajorfocusesandcontributionstobetterpositionourstudy.\n2.\n1",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[63]HaiyanZhao,HanjieChen,FanYang,NinghaoLiu,HuiqiDeng,HengyiCai,ShuaiqiangWang,DaweiYin,andMengnanDu.\nExplainabilityforlargelanguagemodels:Asurvey.\nACMTransactionsonIntelligentSystemsandTechnology,2023.\n[64]YifanYao,JinhaoDuan,KaidiXu,YuanfangCai,EricSun,andYueZhang.\nAsurveyonlargelanguagemodel(llm)securityandprivacy:Thegood,thebad,andtheugly.\narXivpreprintarXiv:2312.\n02003,1,2023.\n[65]ErfanShayegani,MdAbdullahAlMamun,YuFu,PedramZaree,YueDong,andNaelAbu-Ghazaleh.\nSurveyofvulnerabilitiesinlargelanguagemodelsrevealedbyadversarialattacks.\narXivpreprintarXiv:2310.\n10844,2023.\n[66]SethNeelandPeterChang.\nPrivacyissuesinlargelanguagemodels:Asurvey.\narXivpreprintarXiv:2312.\n06717,2023.\n[67]VictoriaSmith,AliShahinShamsabadi,CarolynAshurst,andAdrianWeller.\nIdentifyingandmitigatingprivacyrisksstemmingfromlanguagemodels:Asurvey.\narXivpreprintarXiv:2310.\n01424,2023.\n[68]ZhichenDong,ZhanhuiZhou,ChaoYang,JingShao,andYuQiao.\nAttacks,defensesandevaluationsforllmconversationsafety:Asurvey.\narXivpreprintarXiv:2402.\n09283,2024.\n[69]BadhanChandraDas,MHadiAmini,andYanzhaoWu.\nSecurityandprivacychallengesoflargelanguagemodels:Asurvey.\narXivpreprintarXiv:2402.\n00888,2024.\n[70]WayneXinZhao,KunZhou,JunyiLi,TianyiTang,XiaoleiWang,YupengHou,YingqianMin,BeichenZhang,JunjieZhang,ZicanDong,etal.\nAsurveyoflargelanguagemodels.\narXivpreprintarXiv:2303.\n18223,2023.\n32[71]MuhammadUsmanHadi,RizwanQureshi,AbbasShah,MuhammadIrfan,AnasZafar,MuhammadBilalShaikh,NaveedAkhtar,JiaWu,SeyedaliMirjalili,etal.\nAsurveyonlargelanguagemodels:Applications,challenges,limitations,andpracticalusage.\nAuthoreaPreprints,2023.\n[72]BonanMin,HayleyRoss,EliorSulem,AmirPouranBenVeyseh,ThienHuuNguyen,OscarSainz,EnekoAgirre,IlanaHeintz,andDanRoth.\nRecentadvancesinnaturallanguageprocessingvialargepre-trainedlanguagemodels:Asurvey.\nACMComputingSurveys,56(2):1–40,2023.\n[73]GrégoireMialon,RobertoDessì,MariaLomeli,ChristoforosNalmpantis,RamPasunuru,RobertaRaileanu,BaptisteRozière,TimoSchick,JaneDwivedi-Yu,AsliCelikyilmaz,etal.\nAugmentedlanguagemodels:asurvey.",
      "#memory_survey#Introduction#memory_survey#Introduction\n(2)WesystematicallysummarizeexistingstudiesondesigningandevaluatingthememorymoduleinLLM-basedagents,providingcleartaxonomiesandintuitiveinsights.\n(3)Wepresenttypicalagentapplicationstoshowtheimportanceofthememorymoduleindifferentscenarios.\n(4)Weanalyzethekeylimitationsofexistingmemorymodulesandshowpotentialsolutionsforinspiringfuturestudies.\nToourknowledge,thisisthefirstsurveyonthememorymechanismofLLM-basedagents.\nTherestofthissurveyisorganizedasfollows.\nFirst,weprovideasystematicalmeta-surveyforthefieldsofLLMsandLLM-basedagentsinSection2,categorizingdifferentsurveysandsummarizingtheirkeycontributions.\nThen,wediscusstheproblemsof“whatis”,“whydoweneed”and“howtoimplementandevaluate”thememorymoduleinLLM-basedagentsinSection3to6.\nNext,weshowtheapplicationsofmemory-enhancedagentsinSection7.\nThediscussionsofthelimitationsofexistingworkandfuturedirectionscomeatlastinSection8andSection9.\n42",
      "#memory_survey#Recommendation#memory_survey#Recommendation\n[40],andZhengetal.\n[41]concentrateonhowLLMscanbenefitsoftwareengineering(SE)intermsofsoftwaredesign,development,andtesting.\nZengetal.\n[42]summarizeLLM-basedmethodsinthefieldofrobotics.\nCuietal.\n[43]andYangetal.\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal.\n[47]summarizetheapplicationsofLLMsinmedicine.\nLietal.\n[48]focusontheapplicationsofLLMsinfinance.\nHeetal.\n[49]reviewthemodelsonleveragingLLMstoimprovethedevelopmentofpsychology.\n5SupervisedFine-tuningZhangetal.\n[8].\nAlignmentShenetal.\n[9],Wangetal.\n[10],Liuetal.\n[11].\nRetrievalAugmentationGaoetal.\n[12].\nKnowledgeEditingWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16],Zhangetal.\n[17].\nFundamentalProblemsToolUsageQinetal.\n[18].\nLong-contextMultimodalEfficiencyHuangetal.\n[19],Wangetal.\n[20],Pawaretal.\n[21].\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24],Yinetal.\n[25].\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28,28],Xuetal.\n[29],Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32],Parketal.\n[33].\nEvaluationChangetal.\n[34],Guoetal.\n[35].\nInformationProcessingSoftwareEngineeringYangetal.\n[36],Zhuetal.\n[37],Xuetal.\n[38].\nFanetal.\n[39],Wangetal.\n[40],Zhengetal.\n[41].\nRoboticsZengetal.\n[42].\nApplicationsAutonomousDrivingCuietal.\n[43],Yangetal.\n[44].\nLLMs[70–73]MedecineFinancePsychologyHeetal.\n[45],Zhouetal.\n[46],Wangetal.\n[47].\nLietal.\n[48].\nHeetal.\n[49].\nRecommendationLietal.\n[50],Linetal.\n[51],Wangetal.\n[52].\nHallucinationZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Ton-moyetal.\n[58],Jiangetal.\n[59].\nChallengesBias&FairnessGallegosetal.\n[60],Koteketal.\n[61],Lietal.\n[62].\nExplainabilityZhaoetal.\n[63].\nSecurityYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68],Dasetal.\n[69].\nPlanningHuangetal.\n[74].\nFundamentalProblemsMemoryOurSurvey.\nMulti-agentsGuoetal.\n[75].\nLLM-basedAgent[3,4,77–80]EvaluationApplicationsChallengesLietal.\n[76].",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[120]NelsonFLiu,KevinLin,JohnHewitt,AshwinParanjape,MicheleBevilacqua,FabioPetroni,andPercyLiang.\nLostinthemiddle:Howlanguagemodelsuselongcontexts.\narXivpreprintarXiv:2307.\n03172,2023.\n[121]PeterJDenning.\nThelocalityprinciple.\nCommunicationsoftheACM,48(7):19–24,2005.\n35[122]HermannEbbinghaus.\nMemory:Acontributiontoexperimentalpsychology,trans.\nHARuger&CEBussenius.\nTeachersCollege.\n[rWvH],1885.\n[123]JaapMJMurreandJoeriDros.\nReplicationandanalysisofebbinghaus’forgettingcurve.\nPloSone,10(7):e0120644,2015.\n[124]JeffJohnson,MatthijsDouze,andHervéJégou.\nBillion-scalesimilaritysearchwithgpus.\nIEEETransactionsonBigData,7(3):535–547,2019.\n[125]TimoSchick,JaneDwivedi-Yu,RobertoDessì,RobertaRaileanu,MariaLomeli,LukeZettle-moyer,NicolaCancedda,andThomasScialom.\nToolformer:Languagemodelscanteachthemselvestousetools.\narXivpreprintarXiv:2302.\n04761,2023.\n[126]YujiaQin,ShihaoLiang,YiningYe,KunlunZhu,LanYan,YaxiLu,YankaiLin,XinCong,XiangruTang,BillQian,etal.\nToolllm:Facilitatinglargelanguagemodelstomaster16000+real-worldapis.\narXivpreprintarXiv:2307.\n16789,2023.\n[127]HugoTouvron,ThibautLavril,GautierIzacard,XavierMartinet,Marie-AnneLachaux,Timo-théeLacroix,BaptisteRozière,NamanGoyal,EricHambro,FaisalAzhar,etal.\nLlama:Openandefficientfoundationlanguagemodels.\narXivpreprintarXiv:2302.\n13971,2023.\n[128]ZhibinGou,ZhihongShao,YeyunGong,YujiuYang,MinlieHuang,NanDuan,WeizhuChen,etal.\nTora:Atool-integratedreasoningagentformathematicalproblemsolving.\narXivpreprintarXiv:2309.\n17452,2023.\n[129]HonglinXiong,ShengWang,YitaoZhu,ZihaoZhao,YuxiaoLiu,QianWang,andDinggangShen.\nDoctorglm:Fine-tuningyourchinesedoctorisnotaherculeantask.\narXivpreprintarXiv:2304.\n01097,2023.\n[130]AohanZeng,XiaoLiu,ZhengxiaoDu,ZihanWang,HanyuLai,MingDing,ZhuoyiYang,YifanXu,WendiZheng,XiaoXia,etal.\nGlm-130b:Anopenbilingualpre-trainedmodel.\narXivpreprintarXiv:2210.\n02414,2022.\n[131]EdwardJHu,YelongShen,PhillipWallis,ZeyuanAllen-Zhu,YuanzhiLi,SheanWang,LuWang,andWeizhuChen.\nLora:Low-rankadaptationoflargelanguagemodels.\narXivpreprintarXiv:2106.\n09685,2021.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nForthememorydesign,wediscusspreviousworksfromthreedimensions,thatis,memorysources,memoryforms,andmemoryoperations.\nForthememoryevaluation,weintroducetwowidelyusedapproachesincludingdirectevaluationandindirectevaluationviaspecificagenttasks.\nNext,wediscussagentapplicationsincludingrole-playing,socialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,andexpertsystems,inordertoshowtheimportanceofthememorymoduleinpracticalscenarios.\nAtlast,weanalyzethelimitationsofexistingworkandhighlightsignificantfuturedirections.\nThemaincontributionsofthispapercanbesummarizedasfollows:(1)Weformallydefinethemem-orymoduleandcomprehensivelyanalyzeitsnecessityforLLM-basedagents.\n(2)WesystematicallysummarizeexistingstudiesondesigningandevaluatingthememorymoduleinLLM-basedagents,providingcleartaxonomiesandintuitiveinsights.\n(3)Wepresenttypicalagentapplicationstoshowtheimportanceofthememorymoduleindifferentscenarios.\n(4)Weanalyzethekeylimitationsofexistingmemorymodulesandshowpotentialsolutionsforinspiringfuturestudies.\nToourknowledge,thisisthefirstsurveyonthememorymechanismofLLM-basedagents.\nTherestofthissurveyisorganizedasfollows.\nFirst,weprovideasystematicalmeta-surveyforthefieldsofLLMsandLLM-basedagentsinSection2,categorizingdifferentsurveysandsummarizingtheirkeycontributions.\nThen,wediscusstheproblemsof“whatis”,“whydoweneed”and“howtoimplementandevaluate”thememorymoduleinLLM-basedagentsinSection3to6.\nNext,weshowtheapplicationsofmemory-enhancedagentsinSection7.\nThediscussionsofthelimitationsofexistingworkandfuturedirectionscomeatlastinSection8andSection9.\n42RelatedSurveysInthepasttwoyears,LLMshaveattractedmuchattentionfromtheacademicandindustrycommu-nities.\nTosystemicallysummarizethestudiesinthisfield,researchershavewrittenalotofsurveypapers.\nInthissection,webrieflyreviewthesesurveys(seeFigure2foranoverview),highlightingtheirmajorfocusesandcontributionstobetterpositionourstudy.\n2.\n1SurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.",
      "#memory_survey#MemoryinParametricForm#memory_survey#MemoryinParametricForm\nMEND[134]utilizestheideaofmeta-learningtotrainalightweightmodel,whichiscapableofgeneratingmodificationsformodelparametersofapre-trainedlanguagemodel.\nAPP[136]studieswhetheraddinganewfactleadstocatastrophicforgettingofexistingfacts.\nItfocusesontheimpactofneighborperturbationonmemoryaddition.\nMoreover,KnowledgeEditor[133]trainsahyper-networktopredictthemodificationofmodelpa-rameterswheninjectingmemorybasedonalearning-to-updateproblemformulation.\nWangetal.\n[137]proposeanewoptimizationtargettochangethepoisoningknowledgeofLLM,andmaintainthegeneralperformanceatthesametime.\nForLLM-basedagents,theagentscanchangebadmemorybyknowledgeediting,whichcanbeconsideredasatypeofforgettingmechanism.\nKnowledgeeditingmethodsprovideaninnovativewaytoupdatetheinformationstoredwithintheparametersofLLMs.\nByspecificallytargetingandadjustingthefacts,thesemethodscanensurethenon-targetedknowledgeunaffectedduringupdates,thusmitigatingtheissueofcatastrophicforgetting.\nMoreover,thetargetedadjustmentmechanismallowsformoreefficientandlessresource-intensiveupdates,makingknowledgeeditinganappealingchoiceforhigh-precisionandreal-timemodifications.\nHowever,despitethesepromisingdevelopments,computationalcostsofmeta-trainingandthepreservationofunrelatedmemoriesremainsignificantchallenges.\n5.\n2.\n3"
    ],
    [
      "#memory_survey#D:\\projects\\KAG\\kag\\examples\\memory_survey_test\\builder\\./data/memory_survey.pdf#memory_survey#D:\\projects\\KAG\\kag\\examples\\memory_survey_test\\builder\\./data/memory_survey.pdf\nPersonalassistant,game,codegeneration,……(Knowledge)Accordingtothepreviousworks,largelanguagemodelbasedagentsrefertoartificial……(Context)ThecurrenttopicisLLM-basedagent.\n“It”referstoLLM-basedagentsinthisconversation.\nSocialSimulationI'macompassionatephysicianspecializingincardiology,committedtoimprovingpatients'hearthealthandwell-being.\nI'maskillednursededicatedtopatientcare,ensuringcomfortandsupportinghealthwithempathyandexpertise.\nRole-playingI'maSmurf,andSmurfsareus!\nHaveyoueverhadadream?\nMagicisallaroundtheus!\nJarvis,wemustfirstlearntorun!\nWubalubadu.\nBdubWuckoop.\nI'mBatman,thelightsofcity.\n[IronMan]MynameisIronMan,alsoknownasTonyStark.\nIamthefounderofStarkIndustriesandamemberoftheAvengers.\nAsoneofthegeniusinventorsandbillionaire,Ihavecreatedthemostadvancedarmorintheworld,whichnotonlyprotectsmebutalsogivesmeincrediblestrengthandtheabilitytofly.\nOpen-worldGameSkills&KnowledgeHPMPSPCodeGenerationdefbubble_sort(arr):n=len(arr)#Traversethroughallarrayelementsforiinrange(n):#Lastielementsarealreadyinplaceforjinrange(0,n-i-1):#Traversethearrayfrom0ton-i-1#Swapiftheelementfoundisgreaterthanthenextelementifarr[j]>arr[j+1]:arr[j],arr[j+1]=arr[j+1],arr[j]returnarrSortthenumbersinascendingorder.\nBubblesortrepeatedlystepsthroughthelist,comparesadjacentelementsandswapsthemiftheyareinwrongorder.\nThepassthroughthelistisrepeateduntilthelistissorted.\nBubblesortcanreorderalistofnumbers.\nDevelopmentGroupRecommendationIwanttobuyadressforthegraduationparty.\n(Context)Shejustboughtanewbluedress.\nSoshemayneedawhiteaccessoriestomatchit.\n(PersonalPreference)Sheoftenbuysblueclothes.\nShevaluesthecost-effectivenessofitems,especiallyonclothes.\nShelikessmallthingswithlightcolors,suchasearpendants.\nYoumaylikethisbluedress.\nItisofgoodqualityandgreatprice.\nWouldyouliketobuyawaistbandforyourdress?\nGreat!\nIlikethisbuleone.\nIwillbuyitfortheparty.\nMedicineDavid,a38-year-oldmalewithahistoryofallergiesandsinusinfections,hasafamilyhistoryofdiabetesandhypertension.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.\nDuringmemoryreading,matchingscoresarecalculatedforeachmemoryentry,andthetop-Kentrieswillbeusedforthedecision-makingprocessofagents.\n15Inexistingstudies,mostagentsutilizeretrievalmethodstoprocessthememoryinformation.\nForexample,Parketal.\n[83]firstcalculatetherelevancebetweenthecurrentcontextandmemoryentriesbycosinesimilarity,andobtaintheimportanceandrecencyaccordingtoauxiliaryinformation.\nMemoryBank[6]employsadual-towerdenseretrievalmodeltofindrelatedinformationfrompastconversations.\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.\nDuringmemoryreading,matchingscoresarecalculatedforeachmemoryentry,andthetop-Kentrieswillbeusedforthedecision-makingprocessofagents.\n15Inexistingstudies,mostagentsutilizeretrievalmethodstoprocessthememoryinformation.\nForexample,Parketal.\n[83]firstcalculatetherelevancebetweenthecurrentcontextandmemoryentriesbycosinesimilarity,andobtaintheimportanceandrecencyaccordingtoauxiliaryinformation.\nMemoryBank[6]employsadual-towerdenseretrievalmodeltofindrelatedinformationfrompastconversations.\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage.\nItutilizesLocality-SensitiveHashing(LSH)toretrievetupleswithrelativeentriesinthedatabasetoprovidemoreinformation.\nInaddition,ChatDB[96]designstoutilizesymbolicmemory,andproposestogenerateSQLstatementstoretrievefromdatabasetoobtainstoredinformation.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\n[40],andZhengetal.\n[41]concentrateonhowLLMscanbenefitsoftwareengineering(SE)intermsofsoftwaredesign,development,andtesting.\nZengetal.\n[42]summarizeLLM-basedmethodsinthefieldofrobotics.\nCuietal.\n[43]andYangetal.\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal.\n[47]summarizetheapplicationsofLLMsinmedicine.\nLietal.\n[48]focusontheapplicationsofLLMsinfinance.\nHeetal.\n[49]reviewthemodelsonleveragingLLMstoimprovethedevelopmentofpsychology.\n5SupervisedFine-tuningZhangetal.\n[8].\nAlignmentShenetal.\n[9],Wangetal.\n[10],Liuetal.\n[11].\nRetrievalAugmentationGaoetal.\n[12].\nKnowledgeEditingWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16],Zhangetal.\n[17].\nFundamentalProblemsToolUsageQinetal.\n[18].\nLong-contextMultimodalEfficiencyHuangetal.\n[19],Wangetal.\n[20],Pawaretal.\n[21].\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24],Yinetal.\n[25].\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28,28],Xuetal.\n[29],Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32],Parketal.\n[33].\nEvaluationChangetal.\n[34],Guoetal.\n[35].\nInformationProcessingSoftwareEngineeringYangetal.\n[36],Zhuetal.\n[37],Xuetal.\n[38].\nFanetal.\n[39],Wangetal.\n[40],Zhengetal.\n[41].\nRoboticsZengetal.\n[42].\nApplicationsAutonomousDrivingCuietal.\n[43],Yangetal.\n[44].\nLLMs[70–73]MedecineFinancePsychologyHeetal.\n[45],Zhouetal.\n[46],Wangetal.\n[47].\nLietal.\n[48].\nHeetal.\n[49].\nRecommendationLietal.\n[50],Linetal.\n[51],Wangetal.\n[52].\nHallucinationZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Ton-moyetal.\n[58],Jiangetal.\n[59].\nChallengesBias&FairnessGallegosetal.\n[60],Koteketal.\n[61],Lietal.\n[62].\nExplainabilityZhaoetal.\n[63].\nSecurityYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68],Dasetal.\n[69].\nPlanningHuangetal.\n[74].\nFundamentalProblemsMemoryOurSurvey.\nMulti-agentsGuoetal.\n[75].\nLLM-basedAgent[3,4,77–80]EvaluationApplicationsChallengesLietal.\n[76].",
      "#memory_survey#Recommendation#memory_survey#Recommendation\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32]andParketal.\n[33]systematicallyreviewthetechniquesofmodelcompression.\nDingetal.\n[81]andXuetal.\n[29]analyzeandconcludethestudiesonparameterefficientfine-tuning.\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28]andDingetal.\n[81]putmorefocusesontheefficiencyofresourceutilizationinageneralsense.\nEvaluation.\nThesurveysinthiscategoryfocusonhowtoevaluatethecapabilityofLLMs.\nSpecifi-cally,Changetal.\n[34]comprehensivelysummarizetheevaluationmethodsfromanoverallperspec-tive.\nItencompassesdifferentevaluationtasks,methods,andbenchmarks,whichserveascriticalpartsinassessingLLMperformances.\nGuoetal.\n[35]caremoreabouttheevaluationtargetsanddescribehowtoevaluatetheknowledge,alignment,andsafetycontrolcapabilitiesofLLMs,whichsupplementevaluationmetricsbeyondperformance.\nApplications.\nThesurveysinthiscategoryaimtosummarizemodelsthatleverageLLMstoimprovedifferentapplications.\nMoreconcretely,Zhuetal.\n[37]focusonthefieldofinformationretrieval(IR)andsummarizestudiesonLLM-basedqueryprocesses.\nXuetal.\n[38]paymoreattentiontoinformationextraction(IE)andprovidecomprehensivetaxonomiesforLLM-basedmodelsinthisfield.\nLietal.\n[50],Linetal.\n[51]andWangetal.\n[52]discusstheapplicationsofLLMsinthefieldofrecommendersystem,wheretheyutilizeagentstogeneratedataandproviderecommendations.\nFanetal.\n[39],Wangetal.\n[40],andZhengetal.\n[41]concentrateonhowLLMscanbenefitsoftwareengineering(SE)intermsofsoftwaredesign,development,andtesting.\nZengetal.\n[42]summarizeLLM-basedmethodsinthefieldofrobotics.\nCuietal.\n[43]andYangetal.",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.\nDuringmemoryreading,matchingscoresarecalculatedforeachmemoryentry,andthetop-Kentrieswillbeusedforthedecision-makingprocessofagents.\n15Inexistingstudies,mostagentsutilizeretrievalmethodstoprocessthememoryinformation.\nForexample,Parketal.\n[83]firstcalculatetherelevancebetweenthecurrentcontextandmemoryentriesbycosinesimilarity,andobtaintheimportanceandrecencyaccordingtoauxiliaryinformation.\nMemoryBank[6]employsadual-towerdenseretrievalmodeltofindrelatedinformationfrompastconversations.\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage.\nItutilizesLocality-SensitiveHashing(LSH)toretrievetupleswithrelativeentriesinthedatabasetoprovidemoreinformation.\nInaddition,ChatDB[96]designstoutilizesymbolicmemory,andproposestogenerateSQLstatementstoretrievefromdatabasetoobtainstoredinformation.\nTheretrievalmethodsconsiderablydependontheaccuracyandefficiencyofobtainingexpectedinformation.\nAninaccurateretrievalstrategycanpotentiallyacquireunrelatedinformationthatisunhelpfulforagentinference.\nAndaheavyretrievalsystemcanleadtolargecomputationalcostsandlongtimelatency,especiallywhenhandlingmassiveinformation.\nMoreover,retrievalmethodstypicallystorehomogeneousinformationinsidetheenvironment,wherealltheinformationisinaconsistentform.\nForheterogeneousinformationoutsidetheenvironment,it’sdifficulttodirectlyapplythesamemethodformemorystorage.\nExternalKnowledge.",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nWiththestrongcapabilityofLLMstosimulatehumanminds,theseoperationscanhelptheagentstobettergeneratehigh-levelinformationandinteractwithenvironments.\n18Table3:Summarizationofthememoryoperations.\nIfamodeldoesnothavespecialdesignsonthememoryoperations,weuse◦tolabelit,otherwise,itisdenotedby✓.\n×meansthatthememoryoperationsarenotdiscussedinthepaper.\nModelsWritingMergingReflectionForgettingReadingManagementMemoryBank[6]RET-LLM[7]ChatDB[96]TiM[97]SCM[98]Voyager[99]MemGPT[100]MemoChat[94]MPC[101]GenerativeAgents[83]RecMind[102]Retroformer[103]ExpeL[82]Synapse[91]GITM[93]ReAct[104]Reflexion[5]RecAgent[95]Character-LLM[105]MAC[106]Huatuo[107]ChatDev[1]InteRecAgent[108]MetaAgents[109]TPTU[110,111]MetaGPT[112]S3[2]InvestLM[113]✓✓✓✓✓✓✓✓✓✓◦✓✓✓◦◦✓✓✓✓✓✓✓✓◦✓✓✓✓××✓✓××××××✓✓×✓×✓✓×✓××✓×××××✓×✓××✓✓××✓×✓✓×✓×✓✓×✓×✓✓✓✓✓✓×✓××✓×××××✓×××××××✓××××××××✓×✓✓✓✓✓✓✓✓✓✓✓◦◦✓✓◦◦✓◦✓◦✓✓✓✓✓✓◦5.\n3.\n3MemoryReadingWhentheagentsrequireinformationforreasoninganddecision-making,thememoryreadingoperationwillextractrelatedinformationfrommemoryforusage.\nTherefore,howtoaccesstherelatedinformationforthecurrentstateisimportant.\nDuetothemassivequantityofmemoryentities,andthefactthatnotallofthemarepertinenttothecurrentstate,carefuldesignisrequiredtoextractusefulinformationbasedonrelevanceandothertask-orientatedfactors.\nRepresentativeStudies.\nInChatDB[96],thememoryreadingoperationisexecutedbytheSQLstatements.\nThesestatementswillbegeneratedbyagentsasaseriesofChain-of-Memoryinadvance.\nInMPC[101],theagentscanretrieverelevantmemoryfromthememorypool.\nThismethodalsoproposestoprovideChain-of-Thoughtexamplesforignoringcertainmemory.\nExpeL[82]utilizestheFaiss[124]vectorstoreasthepoolofmemory,andobtainsthetop-Ksuccessfultrajectoriesthatsharethehighestsimilarityscoreswiththecurrenttask.\nDiscussion.\nTosomeextent,thememoryreadingandwritingoperationsarecollaborative,andtheformsofmemorywritinggreatlyinfluencethemethodsofmemoryreading.\nFortheformsoftextual19Figure5:Anoverviewoftheevaluationmethodsofthememorymodule.",
      "#memory_survey#IndirectEvaluation#memory_survey#IndirectEvaluation\nIndirectEvaluationBesidestheabovemethodthatdirectlyevaluatesthememorymodule,evaluatingviataskcompletionisalsoapopularevaluationstrategy.\nTheintuitionbehindthistypeofapproachesisthatiftheagentcansuccessfullycompleteataskthathighlydependsonmemory,itsuggeststhatthedesignedmemorymoduleiseffective.\nInthefollowingparts,wepresentseveralrepresentativetasksthatareleveragedtoevaluatethememorymoduleinindirectways.\n6.\n2.\n1",
      "#memory_survey#BasicKnowledge#memory_survey#BasicKnowledge\nIntheabovedefinitions,taskandenvironmentarethemostcoarse-grainedconcepts,whilestepisthemostfine-grainedone.\nTheytogetherdescribethecompleteagent-environmentinteractionprocess.\nAToyExample.\nBasedontheabovedefinitions,weshowatoyexampleanduseitthroughoutthepapertoprovidemoreintuitions.\nInthisexample,theagenthastwotasks:(A)MakingatripplanforAliceinBeijingfrom5/1/2024to5/3/2024,wheretheagenthasto(i)buyaround-tripflightticket,(ii)determineseveralattractionsaccordingtoAlice’spreferences,and(iii)arrangethevisitingorderoftheseattractions.\n(B)RecommendingamovieforAliceon5/10/2024,wheretheagenthasto(i)determinethetimethatAliceisfreetowatchmovies,and(ii)selectamovieaccordingtoAlice’swatchingpreference.\nForeachtask,wepresentapotentialtrialinthefollowing(alsoillustratedinFigure3(a)).\nFortask(A),thetrialis:[Step1]Agent:IneedtobookflightticketsfromShanghaitoBeijingon5/1/2024,andfromBeijingtoShanghaion5/3/2024throughtheonlineticketoffice.\nEnvironment(OnlineTicketOffice):Theorderhasbeenconfirmed.\nThedepartureflighttakesoffat9:00AM,andyourticketnumberisEK240501SX9021.\nThereturningflighttakesoffat4:30PM,andyourticketnumberisLG240503FN6317.\nPleasearriveattheairportontimeforyourflight.\n[Step2]Agent:IhaveacquiredexternalknowledgefromthemagazineAttractionsinBeijing.\nItshowsthattheGreatWall,theForbiddenCityandtheSummerPalacearefamous.\nAccordingtoAlice’spreferences,Ithinksheprefersancientarchitecture,soIdeterminetheForbiddenCityandtheSummerPalaceasthedestinations.\nEnvironment(Alice):Welldone!\n[Step3]Agent:Now,IneedtoarrangethevisitingorderforAlice.\nAccordingtotheinformationabove,IrecommendvisitingtheSummerPalaceaftershearrivesinBeijingbecauseitissuitabletospendawholeafternoonthereandwatchthesunset.\nThen,shecangototheForbiddenCitythenextday,whichwouldgiveherplentyoftime.\nFinally,shecanreturntoShanghaionthethirddayandtakearest.\nEnvironment(Alice):Ilovethisplan.\nThanks!",
      "#memory_survey#CodeGeneration#memory_survey#CodeGeneration\nCodeGeneration.\n7.\n5",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nThesestatementswillbegeneratedbyagentsasaseriesofChain-of-Memoryinadvance.\nInMPC[101],theagentscanretrieverelevantmemoryfromthememorypool.\nThismethodalsoproposestoprovideChain-of-Thoughtexamplesforignoringcertainmemory.\nExpeL[82]utilizestheFaiss[124]vectorstoreasthepoolofmemory,andobtainsthetop-Ksuccessfultrajectoriesthatsharethehighestsimilarityscoreswiththecurrenttask.\nDiscussion.\nTosomeextent,thememoryreadingandwritingoperationsarecollaborative,andtheformsofmemorywritinggreatlyinfluencethemethodsofmemoryreading.\nFortheformsoftextual19Figure5:Anoverviewoftheevaluationmethodsofthememorymodule.\nmemory,mostpreviousworksusethetextsimilarityandotherauxiliaryinformationforreading.\nFortheformsofparametricmemory,existingmodelsmayjustutilizetheupdatedparametersforinference,whichcanbeseenasanimplicitreadingprocess.\n6",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal.\n[47]summarizetheapplicationsofLLMsinmedicine.\nLietal.\n[48]focusontheapplicationsofLLMsinfinance.\nHeetal.\n[49]reviewthemodelsonleveragingLLMstoimprovethedevelopmentofpsychology.\n5SupervisedFine-tuningZhangetal.\n[8].\nAlignmentShenetal.\n[9],Wangetal.\n[10],Liuetal.\n[11].\nRetrievalAugmentationGaoetal.\n[12].\nKnowledgeEditingWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16],Zhangetal.\n[17].\nFundamentalProblemsToolUsageQinetal.\n[18].\nLong-contextMultimodalEfficiencyHuangetal.\n[19],Wangetal.\n[20],Pawaretal.\n[21].\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24],Yinetal.\n[25].\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28,28],Xuetal.\n[29],Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32],Parketal.\n[33].\nEvaluationChangetal.\n[34],Guoetal.\n[35].\nInformationProcessingSoftwareEngineeringYangetal.\n[36],Zhuetal.\n[37],Xuetal.\n[38].\nFanetal.\n[39],Wangetal.\n[40],Zhengetal.\n[41].\nRoboticsZengetal.\n[42].\nApplicationsAutonomousDrivingCuietal.\n[43],Yangetal.\n[44].\nLLMs[70–73]MedecineFinancePsychologyHeetal.\n[45],Zhouetal.\n[46],Wangetal.\n[47].\nLietal.\n[48].\nHeetal.\n[49].\nRecommendationLietal.\n[50],Linetal.\n[51],Wangetal.\n[52].\nHallucinationZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Ton-moyetal.\n[58],Jiangetal.\n[59].\nChallengesBias&FairnessGallegosetal.\n[60],Koteketal.\n[61],Lietal.\n[62].\nExplainabilityZhaoetal.\n[63].\nSecurityYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68],Dasetal.\n[69].\nPlanningHuangetal.\n[74].\nFundamentalProblemsMemoryOurSurvey.\nMulti-agentsGuoetal.\n[75].\nLLM-basedAgent[3,4,77–80]EvaluationApplicationsChallengesLietal.\n[76].\nFigure2:TheorganizationofrelatedsurveysonLLMsandLLM-basedagents.\n6Challenges.\nThesurveysinthiscategoryfocusontrustworthinessinLLMs,suchashallucination,bias,unfairness,explainability,security,andprivacy.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage.\nItutilizesLocality-SensitiveHashing(LSH)toretrievetupleswithrelativeentriesinthedatabasetoprovidemoreinformation.\nInaddition,ChatDB[96]designstoutilizesymbolicmemory,andproposestogenerateSQLstatementstoretrievefromdatabasetoobtainstoredinformation.\nTheretrievalmethodsconsiderablydependontheaccuracyandefficiencyofobtainingexpectedinformation.\nAninaccurateretrievalstrategycanpotentiallyacquireunrelatedinformationthatisunhelpfulforagentinference.\nAndaheavyretrievalsystemcanleadtolargecomputationalcostsandlongtimelatency,especiallywhenhandlingmassiveinformation.\nMoreover,retrievalmethodstypicallystorehomogeneousinformationinsidetheenvironment,wherealltheinformationisinaconsistentform.\nForheterogeneousinformationoutsidetheenvironment,it’sdifficulttodirectlyapplythesamemethodformemorystorage.\nExternalKnowledge.\nToobtainmoreinformation,someagentsacquireexternalknowledgebyinvokingtools,withtheaimoftransformingadditionalrelevantknowledgeintotheirownmemoriesfordecision-making.\nForinstance,accessingexternalknowledgethroughApplicationProgrammingInterface(API)isacommonpractice[104,5].\nNowadays,abundantpublicinformation,suchasWikipediaandOpenWeatherMap4,areavailableonline(eitherfreeofchargeoronapayingbasis),andcanbeconvenientlyaccessedthroughAPIcalls.\nForinstance,in[Step2]oftask(A)oftheexampleinSection3.\n1,externalknowledgefromthedigitalmagazineisobtainedwithtoolmethods.\nInexistingmodels,Toolformer[125]proposestoteachLLMtousetools,whichcanacquireexternalknowledgeforbettersolvingtasks.\nFurthermore,ToolLLM[126]empowersLlama[127]withtheabilitytoutilizemoreAPIsinRapidAPI5andtoenablemulti-toolusage,whichprovidesageneralinterfacetoextendagents’ability.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.\nThismethodstoresandmaintainsthemostrecentlyacquiredmemoriesusingnaturallanguages,therebyenhancingtheefficiencyofmemoryinformationutilizationaccordingtothePrincipleofLocality[121].\nIntask(B)oftheexampleinSection3.\n1,wecanjustrememberAlice’spreferencesintherecentthreeyears,andtruncatethedistantpart,wheretherecentthreeyearscanbeconsideredasthememorywindowsize.\nInpreviousstudies,therearevariousstrategiestostorerecenttextualmemories.\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories."
    ],
    [
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.\nAnotherlimitationoffine-tuningliesinthecomputationalcostandtimeconsumption,aswellastherequirementofalargeamountofdata.\nTherefore,mostfine-tuningapproachesareappliedtoofflinescenarios,andcanseldomdealwithonlinescenarios,suchasfine-tuningwithagentobservationsandtrialexperiences.\nDuetothefrequentagent-environmentinteractions,itisunaffordableforthecostofbackpropagationtofine-tuneeverystepoftheonlineanddynamicinteractions.\nMemoryEditingMethods.",
      "#memory_survey#MemoryinParametricForm#memory_survey#MemoryinParametricForm\nMemoryinParametricFormAnalternativetypeofapproachesistorepresentmemoryinparametricform.\nTheydonottakeuptheextralengthofcontextinprompts,sotheyarenotconstrainedbythelengthlimitationsofLLMcontext.\nHowever,theparametricmemoryformisstillunder-researched,andwecategorizepreviousworksintotwotypes:fine-tuningmethodsandmemoryeditingmethods.\nFine-tuningMethods.\nIntegratingexternalknowledgeintothememoryofagentsisbeneficialforenrichingdomain-specificknowledgeontopofitsgeneralknowledge.\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThefollow-upwork[111]furtherimprovesitsabilityextensivelylikeretrieval.\nInToRA[128],theagentsarerequiredtosolvemathematicalproblems.\nTheyutilizeimitationlearningtoimprovetheirabilitytouseprogram-basedtools.\nTheabovemethodssignificantlyadvancethecapabilitiesofagentsbyallowingthemtoaccessexternalup-to-dateandreal-worldinformationfromdiversesources.\nHowever,thereliabilityofthisinformationcanbequestionableduetopotentialinaccuraciesandbiases[18].\nFurthermore,theintegrationoftoolsintoagentsdemandsacomprehensiveunderstandingtointerprettheretrievedinformationacrossvariouscontexts,whichcanincurhighercomputationalcostsandcomplicationsinaligningexternaldatawithinternaldecision-makingprocesses.\nAdditionally,utilizingexternalAPIsbringsforthconcernsregardingprivacy,datasecurity,andcompliancewithusagepolicies,necessitatingrigorousmanagementandoversight[18].\n5.\n2.\n2MemoryinParametricFormAnalternativetypeofapproachesistorepresentmemoryinparametricform.\nTheydonottakeuptheextralengthofcontextinprompts,sotheyarenotconstrainedbythelengthlimitationsofLLMcontext.\nHowever,theparametricmemoryformisstillunder-researched,andwecategorizepreviousworksintotwotypes:fine-tuningmethodsandmemoryeditingmethods.\nFine-tuningMethods.\nIntegratingexternalknowledgeintothememoryofagentsisbeneficialforenrichingdomain-specificknowledgeontopofitsgeneralknowledge.\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.",
      "#memory_survey#Memory-enhancedAgentApplications#memory_survey#Memory-enhancedAgentApplications\nMemory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nInexistingmodels,Toolformer[125]proposestoteachLLMtousetools,whichcanacquireexternalknowledgeforbettersolvingtasks.\nFurthermore,ToolLLM[126]empowersLlama[127]withtheabilitytoutilizemoreAPIsinRapidAPI5andtoenablemulti-toolusage,whichprovidesageneralinterfacetoextendagents’ability.\nInTPTU[110],theagentsareincorporatedinbothtaskplanningandtoolusage,inordertotackleintricateproblems.\nThefollow-upwork[111]furtherimprovesitsabilityextensivelylikeretrieval.\nInToRA[128],theagentsarerequiredtosolvemathematicalproblems.\nTheyutilizeimitationlearningtoimprovetheirabilitytouseprogram-basedtools.\nTheabovemethodssignificantlyadvancethecapabilitiesofagentsbyallowingthemtoaccessexternalup-to-dateandreal-worldinformationfromdiversesources.\nHowever,thereliabilityofthisinformationcanbequestionableduetopotentialinaccuraciesandbiases[18].\nFurthermore,theintegrationoftoolsintoagentsdemandsacomprehensiveunderstandingtointerprettheretrievedinformationacrossvariouscontexts,whichcanincurhighercomputationalcostsandcomplicationsinaligningexternaldatawithinternaldecision-makingprocesses.\nAdditionally,utilizingexternalAPIsbringsforthconcernsregardingprivacy,datasecurity,andcompliancewithusagepolicies,necessitatingrigorousmanagementandoversight[18].\n5.\n2.\n2MemoryinParametricFormAnalternativetypeofapproachesistorepresentmemoryinparametricform.\nTheydonottakeuptheextralengthofcontextinprompts,sotheyarenotconstrainedbythelengthlimitationsofLLMcontext.\nHowever,theparametricmemoryformisstillunder-researched,andwecategorizepreviousworksintotwotypes:fine-tuningmethodsandmemoryeditingmethods.\nFine-tuningMethods.\nIntegratingexternalknowledgeintothememoryofagentsisbeneficialforenrichingdomain-specificknowledgeontopofitsgeneralknowledge.\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3."
    ],
    [
      "#memory_survey#Memory-enhancedAgentApplications#memory_survey#Memory-enhancedAgentApplications\nMemory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1",
      "#memory_survey#WhyWeNeedtheMemoryinLLM-basedAgent#memory_survey#WhyWeNeedtheMemoryinLLM-basedAgent\nWhyWeNeedtheMemoryinLLM-basedAgentAbove,wehaveintroducedwhatisthememoryofLLM-basedagents.\nBeforecomprehensivelypresentinghowtoimplementit,inthissection,webrieflyshowwhymemoryisnecessaryforbuildingLLM-basedagents,whereweexpandourdiscussionfromthreeperspectivesincludingcognitivepsychology,self-evolution,andagentapplications.\n4.\n1",
      "#memory_survey#PerspectiveofCognitivePsychology#memory_survey#PerspectiveofCognitivePsychology\nPerspectiveofCognitivePsychologyCognitivepsychologyisthescientificstudyofhumanmentalprocessessuchasattention,languageuse,memory,perception,problem-solving,creativity,andreasoning2.\nAmongtheseprocesses,memoryiswidelyrecognizedasanextremelyimportantone[84].\nItisfundamentalforhumanstolearnknowledgebyaccumulatingimportantinformationandabstractinghigh-levelconcepts[85],formsocialnormsbyrememberingculturalvaluesandindividualexperiences[86],takereasonablebehaviorsbyimaginingthepotentialpositiveandnegativeconsequences[87],andamongothers.\nAmajorgoalofLLM-basedagentsistoreplacehumansforaccomplishingdifferenttasks.\nTomakeagentsbehavelikehumans,followinghuman’sworkingmechanismstodesigntheagentsisanaturalandessentialchoice[88].\nSincememoryisimportantforhumans,designingmemorymodulesisalsosignificantfortheagents.\nInaddition,cognitivepsychologyhasbeenstudiedforalongtime,somanyeffectivehumanmemorytheoriesandarchitectureshavebeenaccumulated,whichcansupportmoreadvancedcapabilitiesoftheagents[89].\n2https://en.\nwikipedia.\norg/wiki/Cognitive_psychology10Figure4:Anoverviewofthesources,forms,andoperationsofthememoryinLLM-basedagents.\n4.\n2",
      "#memory_survey#WhatistheMemoryofLLM-basedAgent#memory_survey#WhatistheMemoryofLLM-basedAgent\nWhatistheMemoryofLLM-basedAgentInteractingandlearningfromenvironmentsisabasicrequirementofLLM-basedagents.\nIntheagent-environmentinteractionprocess,therearethreekeyphases,thatis,(1)theagentperceivesinformationfromtheenvironment,andstoresitintothememory;(2)theagentprocessesthestoredinformationtomakeitmoreusable;and(3)theagenttakesthenextactionbasedontheprocessedmemoryinformation.\nInallthesephases,memoryplaysanextremelyimportantrole.\nInthefollowing,wefirstdefinethememoryoftheagentfrombothnarrowandbroadperspectives,andthen,detailtheexecutionprocessesoftheabovethreephasesbasedonthememorymodule.\n3.\n1",
      "#memory_survey#Memory-assistedAgent-EnvironmentInteraction#memory_survey#Memory-assistedAgent-EnvironmentInteraction\nForthenarrowmemorydefinition,theiterationonlyhappenswithinthesametrial,andthememoryisemptiedwhenthetrialisended.\nForthebroadmemorydefinition,theiterationhappensacrossdifferenttrialsoreventasks,aswellastheintegrationsofexternalknowledge.\nFortask(B)intheabovetoyexample,theagentcanconcludethatAliceenjoyswatchingsciencefictionmoviesintheevening,whichcanbeusedasadefaultruletomakerecommendationsforAliceinthefuture.\nMemoryReading.\nThisoperationaimstoobtainimportantinformationfromthememorytosupportthenextagentaction.\nItcorrespondstothethirdphaseoftheagent-environmentinteractionprocess.\nSupposeMktisthecontextofthenextaction,thenthememoryreadingoperationcanberepresentedby:tisthememorycontentsfortaskkatstept,ckˆMkt=R(Mkt,ckt+1),whereRisusuallyimplementedbycomputingthesimilaritybetweenMktisusedaspartsofthefinalprompttodrivetheagent’snextaction.\nFortask(B)intheabovetoyexample,whentheagentdecidesonthefinalrecommendedmoviein[Step3],itshouldfocusonthe“wanttowatch”listin[Step2]andselectonefromit.\ntandckt+1[82].\nˆMkBasedontheaboveoperations,wecanderiveaunifiedfunctionfortheevolvingprocessfrom{akt,okt}toakt+1,thatis:akt+1=LLM{R(P(Mkt−1,W({akt,okt})),ckt+1)},whereLLMisthelargelanguagemodel.\nThecompleteagent-environmentinteractionprocesscanbeeasilyobtainedbyiterativelyexpandingthisfunction(seeFigure3(b)foranintuitiveillustration).\nRemark.\nThisfunctionprovidesageneralformulationoftheagentmemorizingprocess.\nPreviousworksmayusedifferentspecifications.\nForexample,in[5],RandParesetasidenticalfunctions,andPonlytakeseffectattheendofatrial.\nInParketal.\n[83],Risimplementedbasedonthreecriteriaincludingsimilarity,timeinterval,andimportance,andPisrealizedbyareflectionprocesstoobtainmoreabstractthoughts.\nInthissection,wefocusontheoverallframeworkoftheagent’smemoryoperations.\nMoredetailedrealizationsofW,P,andRaredeferredinSection5.\n4"
    ],
    [
      "#memory_survey#ObjectiveEvaluation#memory_survey#ObjectiveEvaluation\nUsually,researchersleverageF1-scoretoevaluatethereferenceaccuracy,whichiscalculatedasF1=2·Precision·RecallPrecision+Recall,wheretheprecisionandrecallscoresarecalculatedasPrecision=TPTP+FN.\nTheTPrepresentsthenumberoftruepositivememorycontents,FPmeansthenumberoffalsepositivememorycontents,andFNindicatesthenumberoffalsenegativememorycontents.\nInpreviousworks,Luetal.\n[94]utilizeF1-scoretoevaluatetheretrievalprocessofthememory,andZhongetal.\n[6]focusonassessingwhetherrelatedmemorycanbesuccessfullyretrieved.\nTP+FPandRecall=TPResultCorrectnessandReferenceAccuracyarebothutilizedtoevaluatetheeffectivenessofthememorymodule.\nBeyondeffectiveness,efficiencyisalsoanimportantaspect,especiallyforreal-worldapplications.\nTherefore,wedescribetheevaluationofefficiencyasfollows.\nTime&HardwareCost.\nThetotaltimecostincludesthetimeleveragedformemoryadaptionandinference.\nTheadaptationtimereferstothetimeofmemorywritingandmemorymanagement,whiletheinferencetimeindicatesthetimelatencyofmemoryreading.\nInspecific,thedifferencefromthe21endtimetothestarttimeofmemoryoperationscanbeconsideredasthetimeconsumption.\nFormally,theaveragetimeconsumptionofeachtypeofoperationcanberepresentedas∆time=1MM(cid:88)i=1i−tstarttendi,whereMrepresentsthenumberoftheseoperations,tendimeanstheendtimeofthei-thoperation,andtstartindicatesthestarttimeofthatoperation.\nAsforthecomputationoverhead,itcanbeevaluatedibythepeakGPUmemoryallocation.\nInpreviousworks,Tacketal.\n[106]utilizethepeakmemoryallocationandadaptationtimetoassesstheefficiencyofmemoryoperations.\nObjectiveevaluationoffersnumericstrategiestocomparedifferentmethodsofmemory,whichisimportanttobenchmarkthisfieldandpromotefuturedevelopments.\n6.\n2",
      "#memory_survey#ObjectiveEvaluation#memory_survey#ObjectiveEvaluation\nObjectiveEvaluationInobjectiveevaluation,previousworkusuallydefinesnumericmetricstoevaluatetheeffectivenessandefficiencyofthememorymodule.\nResultCorrectness.\nThismetricmeasureswhethertheagentcansuccessfullyanswerpre-definedquestionsdirectlybasedonthememorymodule.\nForexample,thequestioncouldbe\"WheredidAlicegotoday?\n\"withtwochoices\"A:theSummerPalace\"and\"B:theGreatWall\".\nThen,theagentshouldchoosethecorrectanswerbasedontheproblemanditsmemory.\nTheagent-generatedanswerwillbecomparedwiththegroundtruth.\nFormally,theaccuracycanbecalculatedasCorrectness=1NN(cid:88)i=1I[ai=ˆai],whereNisthenumberofproblems,airepresentsthegroundtruthforthei-thproblem,ˆaimeanstheanswergivenbytheagent,andI[ai=ˆai]isthematchingfunctioncommonlyrepresentedasI[ai=ˆai]=(cid:26)10ifai=ˆai,ifai̸=ˆai.\nInpreviousworks,Huetal.\n[96]constructquestionsfrompasthistorieswithannotatedgroundtruthsandcalculatetheaccuracyofwhethertherecalledmemorycouldmatchthecorrectanswers.\nSimilarly,Packeretal.\n[100]generatequestionsandanswersthatcanonlybederivedfrompastsessions,andcomparetheresponsesfromtheagentswiththegroundtruthstocalculatetheaccuracy.\nReferenceAccuracy.\nThismetricevaluateswhethertheagentcandiscoverrelevantmemorycontentstoanswerthequestions.\nDifferentfromtheabovemetric,whichfocusesonthefinalresults,referenceaccuracycaresmoreabouttheintermediateinformationtosupporttheagent’sfinaldecisions.\nInspecific,itcomparestheretrievedmemorywiththepre-preparedgroundtruth.\nFortheaboveproblemof\"WheredidAlicegotoday?\n\",ifthememorycontentsinclude(A)\"AlicehadlunchwithfriendsatWangfujingtoday.\n\"and(B)\"Alicehadroastduckforlunch\",thenabettermemorymoduleshouldselect(A)asareferencetoanswerthequestion.\nUsually,researchersleverageF1-scoretoevaluatethereferenceaccuracy,whichiscalculatedasF1=2·Precision·RecallPrecision+Recall,wheretheprecisionandrecallscoresarecalculatedasPrecision=TPTP+FN.\nTheTPrepresentsthenumberoftruepositivememorycontents,FPmeansthenumberoffalsepositivememorycontents,andFNindicatesthenumberoffalsenegativememorycontents.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThismetricevaluateswhethertheagentcandiscoverrelevantmemorycontentstoanswerthequestions.\nDifferentfromtheabovemetric,whichfocusesonthefinalresults,referenceaccuracycaresmoreabouttheintermediateinformationtosupporttheagent’sfinaldecisions.\nInspecific,itcomparestheretrievedmemorywiththepre-preparedgroundtruth.\nFortheaboveproblemof\"WheredidAlicegotoday?\n\",ifthememorycontentsinclude(A)\"AlicehadlunchwithfriendsatWangfujingtoday.\n\"and(B)\"Alicehadroastduckforlunch\",thenabettermemorymoduleshouldselect(A)asareferencetoanswerthequestion.\nUsually,researchersleverageF1-scoretoevaluatethereferenceaccuracy,whichiscalculatedasF1=2·Precision·RecallPrecision+Recall,wheretheprecisionandrecallscoresarecalculatedasPrecision=TPTP+FN.\nTheTPrepresentsthenumberoftruepositivememorycontents,FPmeansthenumberoffalsepositivememorycontents,andFNindicatesthenumberoffalsenegativememorycontents.\nInpreviousworks,Luetal.\n[94]utilizeF1-scoretoevaluatetheretrievalprocessofthememory,andZhongetal.\n[6]focusonassessingwhetherrelatedmemorycanbesuccessfullyretrieved.\nTP+FPandRecall=TPResultCorrectnessandReferenceAccuracyarebothutilizedtoevaluatetheeffectivenessofthememorymodule.\nBeyondeffectiveness,efficiencyisalsoanimportantaspect,especiallyforreal-worldapplications.\nTherefore,wedescribetheevaluationofefficiencyasfollows.\nTime&HardwareCost.\nThetotaltimecostincludesthetimeleveragedformemoryadaptionandinference.\nTheadaptationtimereferstothetimeofmemorywritingandmemorymanagement,whiletheinferencetimeindicatesthetimelatencyofmemoryreading.\nInspecific,thedifferencefromthe21endtimetothestarttimeofmemoryoperationscanbeconsideredasthetimeconsumption.\nFormally,theaveragetimeconsumptionofeachtypeofoperationcanberepresentedas∆time=1MM(cid:88)i=1i−tstarttendi,whereMrepresentsthenumberoftheseoperations,tendimeanstheendtimeofthei-thoperation,andtstartindicatesthestarttimeofthatoperation.\nAsforthecomputationoverhead,itcanbeevaluatedibythepeakGPUmemoryallocation.\nInpreviousworks,Tacketal.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.\nDuringmemoryreading,matchingscoresarecalculatedforeachmemoryentry,andthetop-Kentrieswillbeusedforthedecision-makingprocessofagents.\n15Inexistingstudies,mostagentsutilizeretrievalmethodstoprocessthememoryinformation.\nForexample,Parketal.\n[83]firstcalculatetherelevancebetweenthecurrentcontextandmemoryentriesbycosinesimilarity,andobtaintheimportanceandrecencyaccordingtoauxiliaryinformation.\nMemoryBank[6]employsadual-towerdenseretrievalmodeltofindrelatedinformationfrompastconversations.\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.\nDuringmemoryreading,matchingscoresarecalculatedforeachmemoryentry,andthetop-Kentrieswillbeusedforthedecision-makingprocessofagents.\n15Inexistingstudies,mostagentsutilizeretrievalmethodstoprocessthememoryinformation.\nForexample,Parketal.\n[83]firstcalculatetherelevancebetweenthecurrentcontextandmemoryentriesbycosinesimilarity,andobtaintheimportanceandrecencyaccordingtoauxiliaryinformation.\nMemoryBank[6]employsadual-towerdenseretrievalmodeltofindrelatedinformationfrompastconversations.\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage.\nItutilizesLocality-SensitiveHashing(LSH)toretrievetupleswithrelativeentriesinthedatabasetoprovidemoreinformation.\nInaddition,ChatDB[96]designstoutilizesymbolicmemory,andproposestogenerateSQLstatementstoretrievefromdatabasetoobtainstoredinformation."
    ],
    [
      "#memory_survey#MemoryinLLM-basedMulti-agentApplications#memory_survey#MemoryinLLM-basedMulti-agentApplications\nMemoryinLLM-basedMulti-agentApplicationsTheexplorationofmemorymechanismswithinLLMshasburgeonedintothedynamicdomainofmulti-agentsystems(MAS),markingsignificantadvancementsintherealmsofsynchronization,communication,andthemanagementofinformationasymmetry.\nOnepivotalaspectthatemergesinthecooperativescenariosismemorysynchronizationamongagents.\nThisprocessisfundamentalforestablishingaunifiedknowledgebase,ensuringconsistencyindecision-makingacrossdifferentagents.\nForexample,Chenetal.\n[170]emphasizethesignificanceofintegratingsynchronizedmemorymodulesformulti-robotcollaboration.\nAnotherimportantaspectisthecommunicationamongagents,whichheavilyreliesonmemoryformaintainingcontextandinterpretingmessages.\nForexample,Mandietal.\n[171]illustratememory-drivencommunicationframeworksthatfosteracommonunderstandingamongagents.\nInadditiontocooperativescenarios,somestudiesalsofocusoncompetitivescenarios,andtheinformationasymmetrybecomesacrucialissue[172].\nLookingahead,theadvancementofmemoryinLLM-basedMASispoisedattheconfluenceoftechnologicalinnovationandstrategicapplication.\nItbeckonstheexplorationofnovelmemory27modulesthatcanfurtherenhanceagentsynchronization,enablemoreeffectivecommunication,andprovidestrategicadvantagesininformation-richenvironments.\nThedevelopmentofsuchmemorymodelswouldnotonlynecessitateaddressingthecurrentchallengesofmemoryintegrationandman-agement,butalsoexploretheuntappedpotentialsofmemoryinfacilitatingmorerobust,intelligent,andadaptableMAS.\nAsevidencedbypioneeringresearch,theevolvinglandscapeofLLM-basedMASsetsapromisingstageforfutureinnovationsinmemoryutilizationandmanagement.\nThisexplorationisexpectedtounravelnewdimensionsofmemoryintegration,pushingtheboundariesofwhatiscurrentlyachievableandsettingnewbenchmarksintherealmofMAS.\n8.\n3",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThememorymoduleisanimportantcomponentforsuchapplications,whichhelpstoaccuratelysimulatehumandynamicbehaviors.\nInpreviousstudies,Kaiyaetal.\n[148]proposeaSummarize-and-Forgetmemorymechanismforbetterself-monitoringinsocialscenarios.\nGaoetal.\n[2]focusonsocialnetworksimulationsystems.\nEachagentinthesystemhasamemorypool,whichconsistsofdiverseusermessagesfromonlineplatformstoidentifytheuser.\nLietal.\n[163]maintainconversationcontexts,encompassingtheeconomicenvironmentandagentdecisionsfrompreviousmonths,inordertosimulatetheimpactofbroadmacroeconomictrendsonagents’decision-makingandtomaketheagentsgraspmarketdynamics.\nLietal.\n[109]simulatethejob-seekingscenarioinhumansociety,wherethememoryofagentsincludesprofilesandgoalsinitiallyandisfurtherenrichedwithotherinformation,likedialoguesandpersonalreflections.\nHuaetal.\n[150]simulatethedecisionsandconsequencesoftheparticipatingcountriesinthewars,wheretheconversationsofagentsarecontinuouslymaintainedintomemory.\nThereareseveralinsightsindesigninganagent’smemoryforrole-playandsocialsimulation.\nFirst,thememoryshouldbeconsistentwiththeroles’characteristics,whichcanbeusedtoidentifyeachroleanddistinguishitfromtheothers.\nThisiscrucialforimprovingtherealismofrole-playandthediversityofsocialsimulation.\nSecond,thememoryshouldappropriatelyinfluencethesubsequent24actionsoftheagenttoensuretheconsistencyandrationalityofitsbehaviors.\nAdditionally,forhumanoidagents,theirmemorymechanismsshouldalignwiththefeaturesofhumanmemory,suchasforgettingandlong/short-termmemory,whichshouldrefertothetheoriesofcognitivepsychology.\n7.\n2PersonalAssistantLLM-basedagentsarewell-suitedforcreatingpersonalassistants,suchasagentscapableofengaginginlong-termconversationswithusers[94,101,153],aswellasthosetaskedwithautomaticallyseekinginformation[164].\nTheseagentsoftenneedtomemorizepreviousdialoguestomaintaintheconsistency,andremembercriticalstylesandeventstogeneratemorepersonalizedandrelevantresponses.\nLuetal.",
      "#memory_survey#PerspectiveofAgentApplications#memory_survey#PerspectiveofAgentApplications\nPerspectiveofAgentApplicationsInmanyapplications,memoryisanindispensablecomponentoftheagent.\nForexample,inaconver-sationalagent,thememorystoresinformationabouthistoricalconversations,whichisnecessaryfortheagenttogeneratethenextresponse.\nWithoutmemory,theagentdoesnotknowthecontext,andcannotcontinuetheconversation[94].\nInasimulationagent,memoryisofgreatimportancetomaketheagentconsistentlyfollowtheroleprofiles.\nWithoutmemory,theagentmayeasilystepoutoftheroleduringthesimulationprocess[95].\nBothoftheaboveexamplesshowthatthememoryisnotanoptionalcomponent,butisnecessaryfortheagentstoaccomplishgiventasks.\nIntheabovethreeperspectives,thefirstonerevealsthatthememorybuildsthecognitivebasisoftheagent.\nThesecondandthirdonesshowthatthememoryisnecessaryfortheagent’sevolvingprinciplesandapplications,whichprovideinsightsfordesigningagentswithmemorymechanisms.\n5",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nManystudieschoosetostoretherawinformation,whileothersalsoputthesummaryoftherawinformationintothememorymodule.\nRepresentativeStudies.\nInTiM[97],therawinformationwillbeextractedastherelationbetweentwoentities,andstoredinastructureddatabase.\nWhenwritingintothedatabase,similarcontentswillbestoredinthesamegroup.\nInSCM[98],itdesignsamemorycontrollertodecidewhentoexecutetheoperations.\nThecontrollerservesasaguideforthewholememorymodule.\nInMemGPT[100],thememorywritingisentirelyself-directed.\nTheagentscanautonomouslyupdatethememorybasedonthecontexts.\nInMemoChat[94],theagentssummarizeeachconversationsegmentbyabstractingthemainlydiscussedtopicsandstoringthemaskeysforindexingmemorypieces.\nDiscussion.\nPreviousresearchindicatesthatdesigningthestrategyofinformationextractionduringthememorywritingoperationisvital[94].\nThisisbecausetheoriginalinformationiscommonlylengthyandnoisy.\nBesides,differentenvironmentsmayprovidevariousformsoffeedback,andhowtoextractandrepresenttheinformationasmemoryisalsosignificantformemorywriting.\n5.\n3.\n2MemoryManagementForhumanbeings,memoryinformationisconstantlyprocessedandabstractedinthebrains.\nThememoryintheagentcanalsobemanagedbyreflectingtogeneratehigher-levelmemories,mergingredundantmemoryentries,andforgettingunimportant,earlymemories.\nRepresentativeStudies.\nInMemoryBank[6],theagentsprocessanddistilltheconversationsintoahigh-levelsummaryofdailyevents,similartohowhumansrecallkeyaspectsoftheirexperiences.\nThroughlong-terminteractions,theycontinuallyevaluateandrefinetheirknowledge,generatingdailyinsightsintopersonalitytraits.\nInVoyager[99],theagentsareabletorefinetheirmemorybasedonthefeedbackoftheenvironment.\nInGenerativeAgents[83],theagentscanreflecttogethigher-levelinformation,wheretheabstractthoughtsaregeneratedfromagents.\nThereflectionprocesswillbeactivatedwhenthereareaccumulatedeventsthatareenoughtoaddress.\nForGITM[93],inordertoestablishcommonreferenceplansforvarioussituations,keyactionsfrommultipleplansarefurthersummarizedinthememorymodule.\nDiscussion.",
      "#memory_survey#Conversation#memory_survey#Conversation\nConversationEngaginginconversationswithhumansisoneofthemostimportantapplicationsofagents,wherememoryplaysacrucialroleinthisprocess.\nBystoringcontextinformationinmemory,theagentsallowuserstoexperiencepersonalizedconversations,thusimprovingusers’satisfaction.\nTherefore,whenotherpartsoftheagentsaredetermined,theperformanceoftheconversationtaskscanreflecttheeffectivenessofdifferentmemorymodules.\nInthecontextofconversation,consistencyandengagementaretwocommonlyusedmethodstoevaluatetheeffectivenessoftheagents’memory.\nConsistencyreferstohowtheresponsefromagentsisconsistentwiththecontextbecausedramaticchangesshouldbeavoidedduringtheconversation.\nForexample,Luetal.\n[94]evaluatetheconsistencyofagentsoninteractivedialogues,usingGPT-4toscoreontheresponsesfromagents.\nEngagementreferstohowtheuserisengagedtocontinuetheconversation.\nItreflectsthequalityandattractionofagents’responses,aswellastheabilityofagentstocraftthepersonasforcurrentconversations.\nForexample,Leeetal.\n[101]assesstheengagingnessofresponsesbySCE-pscore,andPackeretal.\n[100]utilizeCSIMscoretoevaluatethememoryeffectonincreasingengagementofusers.\n6.\n2.\n2"
    ],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain.",
      "#memory_survey#ExternalKnowledge#memory_survey#ExternalKnowledge\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain.\nItfine-tunesanacquisitionprocesstoretrieveexternalknowledgefromWikipediaandmedicaldatabases.\nDiscussion.\nTheexternalknowledgecanbeobtainedfrombothprivateandpublicsources.\nItprovidesLLM-basedagentswithmuchknowledgebeyondtheirinternalenvironment,whichmightbedifficultorevenimpossiblefortheagenttoacquirebyagent-environmentinteractions.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.",
      "#memory_survey#Memory-enhancedAgentApplications#memory_survey#Memory-enhancedAgentApplications\nMemory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nThememoryofanagentisderivedfromthehistoricalbehaviorstoachieveatarget,forexample,thecollectionofrelevantpaperswhenresearchingonaspecifictopic.\nMemoChat[94]aimstochatwithhumans,wherethememoryoftheagentisderivedbasedontheconversationhistoryofadialoguesession.\nTiM[97]aimstoenhancetheagent’sreasoningcapabilitybyself-generatingmultiplethoughtsafteraccomplishingatask,whichisusedasthememorytoprovidemoregeneralizableinformation.\nVoyager[99]focusesonbuildinggameagentsbasedonMinecraft,wherethememorycontainsexecutablecodesofpreliminaryandbasicactionstoaccomplishatask.\nItshouldbenotedthattheinside-trialinformationnotonlyincludesagent-environmentinteractions,butalsocontainsinteractioncontexts,suchastimeandlocationinformation.\n12Discussion.\nTheinside-trialinformationisthemostobviousandintuitivesourcethatshouldbeleveragedtoconstructtheagent’smemorysinceitishighlyrelevanttothecurrenttaskthattheagenthastoaccomplish.\nHowever,relyingsolelyoninside-trialinformationmaypreventtheagentfromaccumulatingvaluableknowledgefromvarioustasksandlearningmoregeneralizableinformation.\nThus,manystudiesalsoexplorehowtoeffectivelyutilizetheinformationacrossdifferenttaskstobuildthememorymodule,whichisdetailedinthefollowingsections.\n5.\n1.\n2Cross-trialInformationForLLM-basedagents,theinformationaccumulatedacrossmultipletrialsintheenvironmentisalsoacrucialpartofthememory,typicallyincludingsuccessfulandfailedactionsandtheirinsights,suchasfailurereasons,commonactionpatternstosucceed,andsoon.\nRepresentativeStudies.\nOneofthemostprominentstudiesisReflexion[5],whichproposesverbalreinforcementlearningforLLM-basedagents.\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks."
    ],
    [
      "#memory_survey#Memory-enhancedAgentApplications#memory_survey#Memory-enhancedAgentApplications\nMemory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nInfact,nearlyallthememory-equippedagentscanevaluatetheeffectofmemorybyablationstudies,comparingtheperformancebetweenwith/withoutmemorymodules.\nTheevaluationonspecificscenarioscanbetterreflectthesignificanceofmemoryforthedownstreamapplicationspractically.\n6.\n3DiscussionsComparedwithdirectevaluation,indirectevaluationviaspecifictaskscanbeeasiertoconduct,sincetherearealreadymanypublicbenchmarks.\nHowever,theperformanceontaskscanbeattributedtovariousfactors,andmemoryisonlyoneofthem,whichmaymaketheevaluationresultsbiased.\nBydirectevaluation,theeffectivenessofthememorymodulecanbeindependentlyevaluated,whichimprovesthereliabilityoftheevaluationresults.\nHowever,toourknowledge,therearenoopen-sourcedbenchmarkstailoredforthememorymodulesinLLM-basedagents.\n7Memory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1Role-playingandSocialSimulationRole-playingrepresentsaclassicapplicationofLLM-basedagents,wherememoryplaysacrucialroleinsidetheagents.\nItendowsroleswithdistinctcharacteristics,differentiatingthemfromoneanother.\nManypreviousstudieshaveexploredmethodsforconstructingrolememories[105,143,145–147].\nShaoetal.\n[105]constructthememoryofrolesbyexperienceuploading,whichutilizesSFTtoinjectmemoryintomodelparameters.\nLietal.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThememorymoduleisanimportantcomponentforsuchapplications,whichhelpstoaccuratelysimulatehumandynamicbehaviors.\nInpreviousstudies,Kaiyaetal.\n[148]proposeaSummarize-and-Forgetmemorymechanismforbetterself-monitoringinsocialscenarios.\nGaoetal.\n[2]focusonsocialnetworksimulationsystems.\nEachagentinthesystemhasamemorypool,whichconsistsofdiverseusermessagesfromonlineplatformstoidentifytheuser.\nLietal.\n[163]maintainconversationcontexts,encompassingtheeconomicenvironmentandagentdecisionsfrompreviousmonths,inordertosimulatetheimpactofbroadmacroeconomictrendsonagents’decision-makingandtomaketheagentsgraspmarketdynamics.\nLietal.\n[109]simulatethejob-seekingscenarioinhumansociety,wherethememoryofagentsincludesprofilesandgoalsinitiallyandisfurtherenrichedwithotherinformation,likedialoguesandpersonalreflections.\nHuaetal.\n[150]simulatethedecisionsandconsequencesoftheparticipatingcountriesinthewars,wheretheconversationsofagentsarecontinuouslymaintainedintomemory.\nThereareseveralinsightsindesigninganagent’smemoryforrole-playandsocialsimulation.\nFirst,thememoryshouldbeconsistentwiththeroles’characteristics,whichcanbeusedtoidentifyeachroleanddistinguishitfromtheothers.\nThisiscrucialforimprovingtherealismofrole-playandthediversityofsocialsimulation.\nSecond,thememoryshouldappropriatelyinfluencethesubsequent24actionsoftheagenttoensuretheconsistencyandrationalityofitsbehaviors.\nAdditionally,forhumanoidagents,theirmemorymechanismsshouldalignwiththefeaturesofhumanmemory,suchasforgettingandlong/short-termmemory,whichshouldrefertothetheoriesofcognitivepsychology.\n7.\n2PersonalAssistantLLM-basedagentsarewell-suitedforcreatingpersonalassistants,suchasagentscapableofengaginginlong-termconversationswithusers[94,101,153],aswellasthosetaskedwithautomaticallyseekinginformation[164].\nTheseagentsoftenneedtomemorizepreviousdialoguestomaintaintheconsistency,andremembercriticalstylesandeventstogeneratemorepersonalizedandrelevantresponses.\nLuetal.",
      "#memory_survey#PerspectiveofAgentApplications#memory_survey#PerspectiveofAgentApplications\nPerspectiveofAgentApplicationsInmanyapplications,memoryisanindispensablecomponentoftheagent.\nForexample,inaconver-sationalagent,thememorystoresinformationabouthistoricalconversations,whichisnecessaryfortheagenttogeneratethenextresponse.\nWithoutmemory,theagentdoesnotknowthecontext,andcannotcontinuetheconversation[94].\nInasimulationagent,memoryisofgreatimportancetomaketheagentconsistentlyfollowtheroleprofiles.\nWithoutmemory,theagentmayeasilystepoutoftheroleduringthesimulationprocess[95].\nBothoftheaboveexamplesshowthatthememoryisnotanoptionalcomponent,butisnecessaryfortheagentstoaccomplishgiventasks.\nIntheabovethreeperspectives,thefirstonerevealsthatthememorybuildsthecognitivebasisoftheagent.\nThesecondandthirdonesshowthatthememoryisnecessaryfortheagent’sevolvingprinciplesandapplications,whichprovideinsightsfordesigningagentswithmemorymechanisms.\n5",
      "#memory_survey#Multi-sourceQuestion-answering#memory_survey#Multi-sourceQuestion-answering\nMulti-sourceQuestion-answeringMulti-sourcequesting-answeringcancomprehensivelyevaluatethememorizedinformationfrommultiplesources,includinginside-trialinformation,cross-trialinformation,andexternalknowledge.\nItfocusesontheintegrationofmemoryutilizationfromvariouscontentsandsources.\nInpreviousworks,Yaoetal.\n[104]evaluatethememorythatintegratesinformationfromthetasktrialandtheexternalknowledgefromWikipedia.\nThen,Shinnetal.\n[5]andYaoetal.\n[103]furtherincludethecross-trialinformationofthesametask,wherethememoryispermittedtoobtainmoreexperiencesfrompreviousfailedtrials.\nMoreover,Packeretal.\n[100]allowagentstoutilizethememoryfrommulti-documentinformationforquestion-answering.\nByevaluatingmulti-sourcequestion-answeringtasks,thememoryofagentscanbeexaminedonthecapabilityofcontentintegrationfromvarioussources.\nItalsorevealstheissueofthememorycontradictionduetomultipleinformationsources,andtheproblemofupdatedknowledge,whichcanpotentiallyaffecttheperformanceofthememorymodule.\n6.\n2.\n3"
    ],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\n1,thememoryofthe14agentintask(A)afterstep2canbeimplementedbyconcatenatingalltheinformationbeforestep2,andthefinaltextualformmemoryis:\"Yourmemoryis[Step1](Agent).\n.\n.\n(OnlineTicketOffice).\n.\n.\n[Step2].\n.\n.\nPleaseinferbasedonyourmemory\".\nInthepreviouswork,differentmodelsstorethememoryinformationusingdifferentstrategies.\nForexample,inLongChat[116],theagentsfocusonunderstandingnaturallanguagesinlong-contextscenarios.\nItfine-tunesthefoundationmodelforbetteradaptingtomemorizecompleteinteractions.\nMemorySandbox[117]intendstoalleviatetheimpactofirrelevantmemoryinconversations.\nItdesignsatransparentandinteractivemethodtomanagethememoryofagents,whichremovesirrelevantmemorybeforeconcatenatingthemasaprompt.\nMoreover,someeffortsarededicatedtoenhancingthecapacityofLLMstohandlelongercontexts[118,119].\nWhilestoringalltheagent-environmentinteractionscanmaintaincomprehensiveinformation,obviouslimitationsexistintermsofcomputationalcost,inferencetime,andinferencerobustness.\nFirstly,thefast-growinglong-contextmemoryinpracticeresultsinhighcomputationalcostduringLLMinference,duetothequadraticgrowthofthetimecomplexityofattentioncomputationwithsequencelength.\nItthusrequiresmuchmorecomputingresourcesandsignificantlyincreasesinferencelatency,whichhindersitspracticaldeployment.\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.\nThismethodstoresandmaintainsthemostrecentlyacquiredmemoriesusingnaturallanguages,therebyenhancingtheefficiencyofmemoryinformationutilizationaccordingtothePrincipleofLocality[121].\nIntask(B)oftheexampleinSection3.\n1,wecanjustrememberAlice’spreferencesintherecentthreeyears,andtruncatethedistantpart,wheretherecentthreeyearscanbeconsideredasthememorywindowsize.\nInpreviousstudies,therearevariousstrategiestostorerecenttextualmemories.\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nMoreover,someeffortsarededicatedtoenhancingthecapacityofLLMstohandlelongercontexts[118,119].\nWhilestoringalltheagent-environmentinteractionscanmaintaincomprehensiveinformation,obviouslimitationsexistintermsofcomputationalcost,inferencetime,andinferencerobustness.\nFirstly,thefast-growinglong-contextmemoryinpracticeresultsinhighcomputationalcostduringLLMinference,duetothequadraticgrowthofthetimecomplexityofattentioncomputationwithsequencelength.\nItthusrequiresmuchmorecomputingresourcesandsignificantlyincreasesinferencelatency,whichhindersitspracticaldeployment.\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.\nThismethodstoresandmaintainsthemostrecentlyacquiredmemoriesusingnaturallanguages,therebyenhancingtheefficiencyofmemoryinformationutilizationaccordingtothePrincipleofLocality[121].\nIntask(B)oftheexampleinSection3.\n1,wecanjustrememberAlice’spreferencesintherecentthreeyears,andtruncatethedistantpart,wheretherecentthreeyearscanbeconsideredasthememorywindowsize.\nInpreviousstudies,therearevariousstrategiestostorerecenttextualmemories.\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nIntheformerthreetypes,theyrecordtheinformationinsidetheagent-environmentinteractionloop,whilethelasttypeleveragesnaturallanguagestostoreinformationoutsidethatloop.\nCompleteInteractions.\nThismethodstoresalltheinformationoftheagent-environmentinteractionhistorybasedonlong-contextstrategies[116].\nFortheexampleinSection3.\n1,thememoryofthe14agentintask(A)afterstep2canbeimplementedbyconcatenatingalltheinformationbeforestep2,andthefinaltextualformmemoryis:\"Yourmemoryis[Step1](Agent).\n.\n.\n(OnlineTicketOffice).\n.\n.\n[Step2].\n.\n.\nPleaseinferbasedonyourmemory\".\nInthepreviouswork,differentmodelsstorethememoryinformationusingdifferentstrategies.\nForexample,inLongChat[116],theagentsfocusonunderstandingnaturallanguagesinlong-contextscenarios.\nItfine-tunesthefoundationmodelforbetteradaptingtomemorizecompleteinteractions.\nMemorySandbox[117]intendstoalleviatetheimpactofirrelevantmemoryinconversations.\nItdesignsatransparentandinteractivemethodtomanagethememoryofagents,whichremovesirrelevantmemorybeforeconcatenatingthemasaprompt.\nMoreover,someeffortsarededicatedtoenhancingthecapacityofLLMstohandlelongercontexts[118,119].\nWhilestoringalltheagent-environmentinteractionscanmaintaincomprehensiveinformation,obviouslimitationsexistintermsofcomputationalcost,inferencetime,andinferencerobustness.\nFirstly,thefast-growinglong-contextmemoryinpracticeresultsinhighcomputationalcostduringLLMinference,duetothequadraticgrowthofthetimecomplexityofattentioncomputationwithsequencelength.\nItthusrequiresmuchmorecomputingresourcesandsignificantlyincreasesinferencelatency,whichhindersitspracticaldeployment.\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.",
      "#memory_survey#Memory-assistedAgent-EnvironmentInteraction#memory_survey#Memory-assistedAgent-EnvironmentInteraction\nForthenarrowmemorydefinition,theiterationonlyhappenswithinthesametrial,andthememoryisemptiedwhenthetrialisended.\nForthebroadmemorydefinition,theiterationhappensacrossdifferenttrialsoreventasks,aswellastheintegrationsofexternalknowledge.\nFortask(B)intheabovetoyexample,theagentcanconcludethatAliceenjoyswatchingsciencefictionmoviesintheevening,whichcanbeusedasadefaultruletomakerecommendationsforAliceinthefuture.\nMemoryReading.\nThisoperationaimstoobtainimportantinformationfromthememorytosupportthenextagentaction.\nItcorrespondstothethirdphaseoftheagent-environmentinteractionprocess.\nSupposeMktisthecontextofthenextaction,thenthememoryreadingoperationcanberepresentedby:tisthememorycontentsfortaskkatstept,ckˆMkt=R(Mkt,ckt+1),whereRisusuallyimplementedbycomputingthesimilaritybetweenMktisusedaspartsofthefinalprompttodrivetheagent’snextaction.\nFortask(B)intheabovetoyexample,whentheagentdecidesonthefinalrecommendedmoviein[Step3],itshouldfocusonthe“wanttowatch”listin[Step2]andselectonefromit.\ntandckt+1[82].\nˆMkBasedontheaboveoperations,wecanderiveaunifiedfunctionfortheevolvingprocessfrom{akt,okt}toakt+1,thatis:akt+1=LLM{R(P(Mkt−1,W({akt,okt})),ckt+1)},whereLLMisthelargelanguagemodel.\nThecompleteagent-environmentinteractionprocesscanbeeasilyobtainedbyiterativelyexpandingthisfunction(seeFigure3(b)foranintuitiveillustration).\nRemark.\nThisfunctionprovidesageneralformulationoftheagentmemorizingprocess.\nPreviousworksmayusedifferentspecifications.\nForexample,in[5],RandParesetasidenticalfunctions,andPonlytakeseffectattheendofatrial.\nInParketal.\n[83],Risimplementedbasedonthreecriteriaincludingsimilarity,timeinterval,andimportance,andPisrealizedbyareflectionprocesstoobtainmoreabstractthoughts.\nInthissection,wefocusontheoverallframeworkoftheagent’smemoryoperations.\nMoredetailedrealizationsofW,P,andRaredeferredinSection5.\n4"
    ],
    [
      "#memory_survey#Memory-basedLifelongLearning#memory_survey#Memory-basedLifelongLearning\nMemory-basedLifelongLearningLifelonglearningisanadvancedtopicinartificialintelligence,extendingthelearningcapabilitiesofagentsacrosstheirlife-longspan[173].\nAgentscancontinuouslyinteractwiththeirenvironment,persistentlyobserveenvironments,andacquireexternalknowledge,enablingamodeofenhancementlikehumans.\nThememoryofanagentiskeytoachievinglifelonglearning,asitneedstolearntostoreandapplythepastobservations.\nLifelonglearninginLLM-basedagentsholdssignificantpracticalvalue,suchasinlong-termsocialsimulationsandpersonalassistance.\nHowever,italsofacesseveralchallenges.\nFirstly,lifelonglearningistemporal,necessitatingthatanagent’smemorycapturestemporality.\nThistemporalitycouldcauseinteractionsbetweenmemories,suchasmemoryoverlap.\nFurthermore,duetotheextendedperiodoflifelonglearning,itneedstostoreavastamountofmemoriesandretrievethemwhenneeded,possiblyincorporatingacertainmechanismforforgetting.\n8.\n4",
      "#memory_survey#Memory-enhancedAgentApplications#memory_survey#Memory-enhancedAgentApplications\nMemory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1",
      "#memory_survey#WhyWeNeedtheMemoryinLLM-basedAgent#memory_survey#WhyWeNeedtheMemoryinLLM-basedAgent\nWhyWeNeedtheMemoryinLLM-basedAgentAbove,wehaveintroducedwhatisthememoryofLLM-basedagents.\nBeforecomprehensivelypresentinghowtoimplementit,inthissection,webrieflyshowwhymemoryisnecessaryforbuildingLLM-basedagents,whereweexpandourdiscussionfromthreeperspectivesincludingcognitivepsychology,self-evolution,andagentapplications.\n4.\n1",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nIntheformerthreetypes,theyrecordtheinformationinsidetheagent-environmentinteractionloop,whilethelasttypeleveragesnaturallanguagestostoreinformationoutsidethatloop.\nCompleteInteractions.\nThismethodstoresalltheinformationoftheagent-environmentinteractionhistorybasedonlong-contextstrategies[116].\nFortheexampleinSection3.\n1,thememoryofthe14agentintask(A)afterstep2canbeimplementedbyconcatenatingalltheinformationbeforestep2,andthefinaltextualformmemoryis:\"Yourmemoryis[Step1](Agent).\n.\n.\n(OnlineTicketOffice).\n.\n.\n[Step2].\n.\n.\nPleaseinferbasedonyourmemory\".\nInthepreviouswork,differentmodelsstorethememoryinformationusingdifferentstrategies.\nForexample,inLongChat[116],theagentsfocusonunderstandingnaturallanguagesinlong-contextscenarios.\nItfine-tunesthefoundationmodelforbetteradaptingtomemorizecompleteinteractions.\nMemorySandbox[117]intendstoalleviatetheimpactofirrelevantmemoryinconversations.\nItdesignsatransparentandinteractivemethodtomanagethememoryofagents,whichremovesirrelevantmemorybeforeconcatenatingthemasaprompt.\nMoreover,someeffortsarededicatedtoenhancingthecapacityofLLMstohandlelongercontexts[118,119].\nWhilestoringalltheagent-environmentinteractionscanmaintaincomprehensiveinformation,obviouslimitationsexistintermsofcomputationalcost,inferencetime,andinferencerobustness.\nFirstly,thefast-growinglong-contextmemoryinpracticeresultsinhighcomputationalcostduringLLMinference,duetothequadraticgrowthofthetimecomplexityofattentioncomputationwithsequencelength.\nItthusrequiresmuchmorecomputingresourcesandsignificantlyincreasesinferencelatency,whichhindersitspracticaldeployment.\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.",
      "#memory_survey#Memory-assistedAgent-EnvironmentInteraction#memory_survey#Memory-assistedAgent-EnvironmentInteraction\nForthenarrowmemorydefinition,theiterationonlyhappenswithinthesametrial,andthememoryisemptiedwhenthetrialisended.\nForthebroadmemorydefinition,theiterationhappensacrossdifferenttrialsoreventasks,aswellastheintegrationsofexternalknowledge.\nFortask(B)intheabovetoyexample,theagentcanconcludethatAliceenjoyswatchingsciencefictionmoviesintheevening,whichcanbeusedasadefaultruletomakerecommendationsforAliceinthefuture.\nMemoryReading.\nThisoperationaimstoobtainimportantinformationfromthememorytosupportthenextagentaction.\nItcorrespondstothethirdphaseoftheagent-environmentinteractionprocess.\nSupposeMktisthecontextofthenextaction,thenthememoryreadingoperationcanberepresentedby:tisthememorycontentsfortaskkatstept,ckˆMkt=R(Mkt,ckt+1),whereRisusuallyimplementedbycomputingthesimilaritybetweenMktisusedaspartsofthefinalprompttodrivetheagent’snextaction.\nFortask(B)intheabovetoyexample,whentheagentdecidesonthefinalrecommendedmoviein[Step3],itshouldfocusonthe“wanttowatch”listin[Step2]andselectonefromit.\ntandckt+1[82].\nˆMkBasedontheaboveoperations,wecanderiveaunifiedfunctionfortheevolvingprocessfrom{akt,okt}toakt+1,thatis:akt+1=LLM{R(P(Mkt−1,W({akt,okt})),ckt+1)},whereLLMisthelargelanguagemodel.\nThecompleteagent-environmentinteractionprocesscanbeeasilyobtainedbyiterativelyexpandingthisfunction(seeFigure3(b)foranintuitiveillustration).\nRemark.\nThisfunctionprovidesageneralformulationoftheagentmemorizingprocess.\nPreviousworksmayusedifferentspecifications.\nForexample,in[5],RandParesetasidenticalfunctions,andPonlytakeseffectattheendofatrial.\nInParketal.\n[83],Risimplementedbasedonthreecriteriaincludingsimilarity,timeinterval,andimportance,andPisrealizedbyareflectionprocesstoobtainmoreabstractthoughts.\nInthissection,wefocusontheoverallframeworkoftheagent’smemoryoperations.\nMoredetailedrealizationsofW,P,andRaredeferredinSection5.\n4"
    ],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain.",
      "#memory_survey#Memory-enhancedAgentApplications#memory_survey#Memory-enhancedAgentApplications\nMemory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1",
      "#memory_survey#ExternalKnowledge#memory_survey#ExternalKnowledge\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain.\nItfine-tunesanacquisitionprocesstoretrieveexternalknowledgefromWikipediaandmedicaldatabases.\nDiscussion.\nTheexternalknowledgecanbeobtainedfrombothprivateandpublicsources.\nItprovidesLLM-basedagentswithmuchknowledgebeyondtheirinternalenvironment,whichmightbedifficultorevenimpossiblefortheagenttoacquirebyagent-environmentinteractions.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nSomeofthemcanacquireexternaldatabasesorAPIstoobtaingeneralknowledge[99,93,159,161].\nWangetal.\n[99]saveobtainedskillsintomemoryforfurtherusageinMinecraft.\nZhuetal.\n[93]storeandretrievesuccessfultrajectoriesasexamplesforsimilartasks,andutilizeexternalMinecraftWikibyAPIcalls.\nWangetal.\n[159]constructmultimodalmemoryasaknowledgelibraryandprovideexamplesforpromptbyretrievinginteractiveexperiences.\nYanetal.\n[161]maintainworkingmemoryfordecision-making,saveandretrieverelevantpastexperiences,andimplementexternaldatasetsforgeneralknowledge.\nInsummary,nomatterinside-trialorcross-trialinformation,thekeyaspectofmemoryistoreflectonpastinteractionsanddrawexperiencesthatcanbeappliedtothesubsequentexploration.\nInadditiontoaccumulatingexperiencethroughself-involvingtrials,absorbingexternalknowledgeaspartoftheagent’smemoryisalsoanimportantwaytoenhancetheexploratorycapabilitiesoftheagent.\n7.\n4CodeGenerationInthescenarioofcodegeneration,LLM-basedagentscansearchrelevantinformationfromthememory,therebyobtainingmoreknowledgefordevelopment.\nTheycansavepreviousexperiencesforfutureproblems,andalsomaintaincontextinconversationaldevelopmentinterfaces[142,144,1,109].\nTsaietal.\n[142]constructanexternalnon-parametricmemorydatabase,whichstoresthecompilererrorsandhumanexpertinstructionsforautomaticsyntaxerrorfixing.\nIn[144],personalinformationwillbestoredinthememory,andhelpsinretainingcontextandknowledgefordecision-making.\nQianetal.\n[1]adoptmulti-agentstodevelopsoftware,whereeachrolemaintainsamemorytostorethepastconversationswithotherroles.\nLietal.\n[109]alsofocusonsoftwaredevelopment,andtheagentcanretrieveitshistoricalrecordspreservedinmemorywhenerrorsoccur.\nZhangetal.\n[114]cansearchrelevantinformationwhentheyfaceproblemsoncodegeneration.\nByleveragingexternalresources,theagentscanlearnfromcode-relatedknowledgeandstoreitintotheirmemory,therebyenhancingthecapabilitiesofcodegeneration.\nInaddition,thememorycanimprovethecontinuityandconsistencyincodegeneration."
    ],
    [
      "#memory_survey#ExternalKnowledge#memory_survey#ExternalKnowledge\nItshouldbenotedthattheinside-trialinformationnotonlyincludesagent-environmentinteractions,butalsocontainsinteractioncontexts,suchastimeandlocationinformation.\n12Discussion.\nTheinside-trialinformationisthemostobviousandintuitivesourcethatshouldbeleveragedtoconstructtheagent’smemorysinceitishighlyrelevanttothecurrenttaskthattheagenthastoaccomplish.\nHowever,relyingsolelyoninside-trialinformationmaypreventtheagentfromaccumulatingvaluableknowledgefromvarioustasksandlearningmoregeneralizableinformation.\nThus,manystudiesalsoexplorehowtoeffectivelyutilizetheinformationacrossdifferenttaskstobuildthememorymodule,whichisdetailedinthefollowingsections.\n5.\n1.\n2Cross-trialInformationForLLM-basedagents,theinformationaccumulatedacrossmultipletrialsintheenvironmentisalsoacrucialpartofthememory,typicallyincludingsuccessfulandfailedactionsandtheirinsights,suchasfailurereasons,commonactionpatternstosucceed,andsoon.\nRepresentativeStudies.\nOneofthemostprominentstudiesisReflexion[5],whichproposesverbalreinforcementlearningforLLM-basedagents.\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nThememoryofanagentisderivedfromthehistoricalbehaviorstoachieveatarget,forexample,thecollectionofrelevantpaperswhenresearchingonaspecifictopic.\nMemoChat[94]aimstochatwithhumans,wherethememoryoftheagentisderivedbasedontheconversationhistoryofadialoguesession.\nTiM[97]aimstoenhancetheagent’sreasoningcapabilitybyself-generatingmultiplethoughtsafteraccomplishingatask,whichisusedasthememorytoprovidemoregeneralizableinformation.\nVoyager[99]focusesonbuildinggameagentsbasedonMinecraft,wherethememorycontainsexecutablecodesofpreliminaryandbasicactionstoaccomplishatask.\nItshouldbenotedthattheinside-trialinformationnotonlyincludesagent-environmentinteractions,butalsocontainsinteractioncontexts,suchastimeandlocationinformation.\n12Discussion.\nTheinside-trialinformationisthemostobviousandintuitivesourcethatshouldbeleveragedtoconstructtheagent’smemorysinceitishighlyrelevanttothecurrenttaskthattheagenthastoaccomplish.\nHowever,relyingsolelyoninside-trialinformationmaypreventtheagentfromaccumulatingvaluableknowledgefromvarioustasksandlearningmoregeneralizableinformation.\nThus,manystudiesalsoexplorehowtoeffectivelyutilizetheinformationacrossdifferenttaskstobuildthememorymodule,whichisdetailedinthefollowingsections.\n5.\n1.\n2Cross-trialInformationForLLM-basedagents,theinformationaccumulatedacrossmultipletrialsintheenvironmentisalsoacrucialpartofthememory,typicallyincludingsuccessfulandfailedactionsandtheirinsights,suchasfailurereasons,commonactionpatternstosucceed,andsoon.\nRepresentativeStudies.\nOneofthemostprominentstudiesisReflexion[5],whichproposesverbalreinforcementlearningforLLM-basedagents.\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTiM[97]aimstoenhancetheagent’sreasoningcapabilitybyself-generatingmultiplethoughtsafteraccomplishingatask,whichisusedasthememorytoprovidemoregeneralizableinformation.\nVoyager[99]focusesonbuildinggameagentsbasedonMinecraft,wherethememorycontainsexecutablecodesofpreliminaryandbasicactionstoaccomplishatask.\nItshouldbenotedthattheinside-trialinformationnotonlyincludesagent-environmentinteractions,butalsocontainsinteractioncontexts,suchastimeandlocationinformation.\n12Discussion.\nTheinside-trialinformationisthemostobviousandintuitivesourcethatshouldbeleveragedtoconstructtheagent’smemorysinceitishighlyrelevanttothecurrenttaskthattheagenthastoaccomplish.\nHowever,relyingsolelyoninside-trialinformationmaypreventtheagentfromaccumulatingvaluableknowledgefromvarioustasksandlearningmoregeneralizableinformation.\nThus,manystudiesalsoexplorehowtoeffectivelyutilizetheinformationacrossdifferenttaskstobuildthememorymodule,whichisdetailedinthefollowingsections.\n5.\n1.\n2Cross-trialInformationForLLM-basedagents,theinformationaccumulatedacrossmultipletrialsintheenvironmentisalsoacrucialpartofthememory,typicallyincludingsuccessfulandfailedactionsandtheirinsights,suchasfailurereasons,commonactionpatternstosucceed,andsoon.\nRepresentativeStudies.\nOneofthemostprominentstudiesisReflexion[5],whichproposesverbalreinforcementlearningforLLM-basedagents.\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain."
    ],
    [
      "#memory_survey#Conversation#memory_survey#Conversation\nConversationEngaginginconversationswithhumansisoneofthemostimportantapplicationsofagents,wherememoryplaysacrucialroleinthisprocess.\nBystoringcontextinformationinmemory,theagentsallowuserstoexperiencepersonalizedconversations,thusimprovingusers’satisfaction.\nTherefore,whenotherpartsoftheagentsaredetermined,theperformanceoftheconversationtaskscanreflecttheeffectivenessofdifferentmemorymodules.\nInthecontextofconversation,consistencyandengagementaretwocommonlyusedmethodstoevaluatetheeffectivenessoftheagents’memory.\nConsistencyreferstohowtheresponsefromagentsisconsistentwiththecontextbecausedramaticchangesshouldbeavoidedduringtheconversation.\nForexample,Luetal.\n[94]evaluatetheconsistencyofagentsoninteractivedialogues,usingGPT-4toscoreontheresponsesfromagents.\nEngagementreferstohowtheuserisengagedtocontinuetheconversation.\nItreflectsthequalityandattractionofagents’responses,aswellastheabilityofagentstocraftthepersonasforcurrentconversations.\nForexample,Leeetal.\n[101]assesstheengagingnessofresponsesbySCE-pscore,andPackeretal.\n[100]utilizeCSIMscoretoevaluatethememoryeffectonincreasingengagementofusers.\n6.\n2.\n2",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[17]NingyuZhang,YunzhiYao,BozhongTian,PengWang,ShuminDeng,MengruWang,ZekunXi,ShengyuMao,JintianZhang,YuanshengNi,etal.\nAcomprehensivestudyofknowledgeeditingforlargelanguagemodels.\narXivpreprintarXiv:2401.\n01286,2024.\n[18]YujiaQin,ShengdingHu,YankaiLin,WeizeChen,NingDing,GanquCui,ZheniZeng,YufeiHuang,ChaojunXiao,ChiHan,etal.\nToollearningwithfoundationmodels.\narXivpreprintarXiv:2304.\n08354,2023.\n[19]YunpengHuang,JingweiXu,ZixuJiang,JunyuLai,ZenanLi,YuanYao,TaolueChen,LijuanYang,ZhouXin,andXiaoxingMa.\nAdvancingtransformerarchitectureinlong-contextlargelanguagemodels:Acomprehensivesurvey.\narXivpreprintarXiv:2311.\n12351,2023.\n29[20]XindiWang,MahsaSalmani,ParsaOmidi,XiangyuRen,MehdiRezagholizadeh,andAr-maghanEshaghi.\nBeyondthelimits:Asurveyoftechniquestoextendthecontextlengthinlargelanguagemodels.\narXivpreprintarXiv:2402.\n02244,2024.\n[21]SauravPawar,SMTonmoy,SMZaman,VinijaJain,AmanChadha,andAmitavaDas.\nThewhat,why,andhowofcontextlengthextensiontechniquesinlargelanguagemodels–adetailedsurvey.\narXivpreprintarXiv:2401.\n07872,2024.\n[22]JiayangWu,WenshengGan,ZefengChen,ShichengWan,andSYuPhilip.\nMultimodallargelanguagemodels:Asurvey.\nIn2023IEEEInternationalConferenceonBigData(BigData),pages2247–2256.\nIEEE,2023.\n[23]ShezhengSong,XiaopengLi,andShashaLi.\nHowtobridgethegapbetweenmodalities:Acomprehensivesurveyonmultimodallargelanguagemodel.\narXivpreprintarXiv:2311.\n07594,2023.\n[24]DavideCaffagni,FedericoCocchi,LucaBarsellotti,NicholasMoratelli,SaraSarto,LorenzoBaraldi,MarcellaCornia,andRitaCucchiara.\nThe(r)evolutionofmultimodallargelanguagemodels:Asurvey.\narXivpreprintarXiv:2402.\n12451,2024.\n[25]ShukangYin,ChaoyouFu,SiruiZhao,KeLi,XingSun,TongXu,andEnhongChen.\nAsurveyonmultimodallargelanguagemodels.\narXivpreprintarXiv:2306.\n13549,2023.\n[26]GuangjiBai,ZhengChai,ChenLing,ShiyuWang,JiayingLu,NanZhang,TingweiShi,ZiyangYu,MengdanZhu,YifeiZhang,etal.\nBeyondefficiency:Asystematicsurveyofresource-efficientlargelanguagemodels.\narXivpreprintarXiv:2401.\n00625,2024.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\narXivpreprintarXiv:2210.\n02414,2022.\n[131]EdwardJHu,YelongShen,PhillipWallis,ZeyuanAllen-Zhu,YuanzhiLi,SheanWang,LuWang,andWeizhuChen.\nLora:Low-rankadaptationoflargelanguagemodels.\narXivpreprintarXiv:2106.\n09685,2021.\n[132]ZhengliangLiu,AoxiaoZhong,YiweiLi,LongtaoYang,ChaoJu,ZihaoWu,ChongMa,PengShu,ChengChen,SekeunKim,etal.\nRadiology-gpt:Alargelanguagemodelforradiology.\narXivpreprintarXiv:2306.\n08666,2023.\n[133]NicolaDeCao,WilkerAziz,andIvanTitov.\nEditingfactualknowledgeinlanguagemodels.\narXivpreprintarXiv:2104.\n08164,2021.\n[134]EricMitchell,CharlesLin,AntoineBosselut,ChelseaFinn,andChristopherDManning.\nFastmodeleditingatscale.\narXivpreprintarXiv:2110.\n11309,2021.\n[135]ShengyuMao,NingyuZhang,XiaohanWang,MengruWang,YunzhiYao,YongJiang,PengjunXie,FeiHuang,andHuajunChen.\nEditingpersonalityforlargelanguagemodels.\n2023.\n[136]Jun-YuMa,Jia-ChenGu,NingyuZhang,andZhen-HuaLing.\nNeighboringperturbationsofknowledgeeditingonlargelanguagemodels.\narXivpreprintarXiv:2401.\n17623,2024.\n[137]MengruWang,NingyuZhang,ZiwenXu,ZekunXi,ShuminDeng,YunzhiYao,QishenZhang,LinyiYang,JindongWang,andHuajunChen.\nDetoxifyinglargelanguagemodelsviaknowledgeediting.\narXivpreprintarXiv:2403.\n14472,2024.\n[138]UriShaham,MaorIvgi,AviaEfrat,JonathanBerant,andOmerLevy.\nZeroscrolls:Azero-shotbenchmarkforlongtextunderstanding.\narXivpreprintarXiv:2305.\n14196,2023.\n[139]YushiBai,XinLv,JiajieZhang,HongchangLyu,JiankaiTang,ZhidianHuang,ZhengxiaoDu,XiaoLiu,AohanZeng,LeiHou,etal.\nLongbench:Abilingual,multitaskbenchmarkforlongcontextunderstanding.\narXivpreprintarXiv:2308.\n14508,2023.\n36[140]DachengLi,RulinShao,AnzeXie,YingSheng,LianminZheng,JosephGonzalez,IonStoica,XuezheMa,andHaoZhang.\nHowlongcancontextlengthofopen-sourcellmstrulypromise?\nInNeurIPS2023WorkshoponInstructionTuningandInstructionFollowing,2023.\n[141]MohitShridhar,XingdiYuan,Marc-AlexandreCôté,YonatanBisk,AdamTrischler,andMatthewHausknecht.\nAlfworld:Aligningtextandembodiedenvironmentsforinteractivelearning.\narXivpreprintarXiv:2010.\n03768,2020.\n[142]YunDaTsai,MingjieLiu,andHaoxingRen.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[44]ZhenjieYang,XiaosongJia,HongyangLi,andJunchiYan.\nAsurveyoflargelanguagemodelsforautonomousdriving.\narXivpreprintarXiv:2311.\n01043,2023.\n[45]KaiHe,RuiMao,QikaLin,YuchengRuan,XiangLan,MenglingFeng,andErikCambria.\nAsurveyoflargelanguagemodelsforhealthcare:fromdata,technology,andapplicationstoaccountabilityandethics.\narXivpreprintarXiv:2310.\n05694,2023.\n[46]HongjianZhou,BoyangGu,XinyuZou,YiruLi,SamSChen,PeilinZhou,JunlingLiu,YiningHua,ChengfengMao,XianWu,etal.\nAsurveyoflargelanguagemodelsinmedicine:Progress,application,andchallenge.\narXivpreprintarXiv:2311.\n05112,2023.\n[47]BenyouWang,QianqianXie,JiahuanPei,ZhihongChen,PrayagTiwari,ZhaoLi,andJieFu.\nPre-trainedlanguagemodelsinbiomedicaldomain:Asystematicsurvey.\nACMComputingSurveys,56(3):1–52,2023.\n[48]YinhengLi,ShaofeiWang,HanDing,andHangChen.\nLargelanguagemodelsinfinance:Asurvey.\nInProceedingsoftheFourthACMInternationalConferenceonAIinFinance,pages374–382,2023.\n[49]TianyuHe,GuanghuiFu,YijingYu,FanWang,JianqiangLi,QingZhao,ChangweiSong,HongzhiQi,DanLuo,HuijingZou,etal.\nTowardsapsychologicalgeneralistai:Asur-veyofcurrentapplicationsoflargelanguagemodelsandfutureprospects.\narXivpreprintarXiv:2312.\n04578,2023.\n[50]LeiLi,YongfengZhang,DugangLiu,andLiChen.\nLargelanguagemodelsforgenerativerecommendation:Asurveyandvisionarydiscussions.\narXivpreprintarXiv:2309.\n01157,2023.\n[51]JianghaoLin,XinyiDai,YunjiaXi,WeiwenLiu,BoChen,XiangyangLi,ChenxuZhu,HuifengGuo,YongYu,RuimingTang,etal.\nHowcanrecommendersystemsbenefitfromlargelanguagemodels:Asurvey.\narXivpreprintarXiv:2306.\n05817,2023.\n[52]WenjieWang,XinyuLin,FuliFeng,XiangnanHe,andTat-SengChua.\nGenerativerecommen-dation:Towardsnext-generationrecommenderparadigm.\narXivpreprintarXiv:2304.\n03516,2023.\n31[53]YueZhang,YafuLi,LeyangCui,DengCai,LemaoLiu,TingchenFu,XintingHuang,EnboZhao,YuZhang,YulongChen,etal.\nSiren’ssongintheaiocean:asurveyonhallucinationinlargelanguagemodels.\narXivpreprintarXiv:2309.\n01219,2023.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n31[53]YueZhang,YafuLi,LeyangCui,DengCai,LemaoLiu,TingchenFu,XintingHuang,EnboZhao,YuZhang,YulongChen,etal.\nSiren’ssongintheaiocean:asurveyonhallucinationinlargelanguagemodels.\narXivpreprintarXiv:2309.\n01219,2023.\n[54]LeiHuang,WeijiangYu,WeitaoMa,WeihongZhong,ZhangyinFeng,HaotianWang,Qian-glongChen,WeihuaPeng,XiaochengFeng,BingQin,etal.\nAsurveyonhallucinationinlargelanguagemodels:Principles,taxonomy,challenges,andopenquestions.\narXivpreprintarXiv:2311.\n05232,2023.\n[55]VipulaRawte,AmitSheth,andAmitavaDas.\nAsurveyofhallucinationinlargefoundationmodels.\narXivpreprintarXiv:2309.\n05922,2023.\n[56]HongbinYe,TongLiu,AijiaZhang,WeiHua,andWeiqiangJia.\nCognitivemirage:Areviewofhallucinationsinlargelanguagemodels.\narXivpreprintarXiv:2309.\n06794,2023.\n[57]ZiweiJi,NayeonLee,RitaFrieske,TiezhengYu,DanSu,YanXu,EtsukoIshii,YeJinBang,AndreaMadotto,andPascaleFung.\nSurveyofhallucinationinnaturallanguagegeneration.\nACMComputingSurveys,55(12):1–38,2023.\n[58]SMTonmoy,SMZaman,VinijaJain,AnkuRani,VipulaRawte,AmanChadha,andAmitavaDas.\nAcomprehensivesurveyofhallucinationmitigationtechniquesinlargelanguagemodels.\narXivpreprintarXiv:2401.\n01313,2024.\n[59]XuhuiJiang,YuxingTian,FengruiHua,ChengjinXu,YuanzhuoWang,andJianGuo.\nAsurveyonlargelanguagemodelhallucinationviaacreativityperspective.\narXivpreprintarXiv:2402.\n06647,2024.\n[60]IsabelOGallegos,RyanARossi,JoeBarrow,MdMehrabTanjim,SungchulKim,FranckDernoncourt,TongYu,RuiyiZhang,andNesreenKAhmed.\nBiasandfairnessinlargelanguagemodels:Asurvey.\narXivpreprintarXiv:2309.\n00770,2023.\n[61]HadasKotek,RikkerDockum,andDavidSun.\nGenderbiasandstereotypesinlargelanguagemodels.\nInProceedingsofTheACMCollectiveIntelligenceConference,pages12–24,2023.\n[62]YingjiLi,MengnanDu,RuiSong,XinWang,andYingWang.\nAsurveyonfairnessinlargelanguagemodels.\narXivpreprintarXiv:2308.\n10149,2023.\n[63]HaiyanZhao,HanjieChen,FanYang,NinghaoLiu,HuiqiDeng,HengyiCai,ShuaiqiangWang,DaweiYin,andMengnanDu.\nExplainabilityforlargelanguagemodels:Asurvey.\nACMTransactionsonIntelligentSystemsandTechnology,2023.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nFormally,theaveragetimeconsumptionofeachtypeofoperationcanberepresentedas∆time=1MM(cid:88)i=1i−tstarttendi,whereMrepresentsthenumberoftheseoperations,tendimeanstheendtimeofthei-thoperation,andtstartindicatesthestarttimeofthatoperation.\nAsforthecomputationoverhead,itcanbeevaluatedibythepeakGPUmemoryallocation.\nInpreviousworks,Tacketal.\n[106]utilizethepeakmemoryallocationandadaptationtimetoassesstheefficiencyofmemoryoperations.\nObjectiveevaluationoffersnumericstrategiestocomparedifferentmethodsofmemory,whichisimportanttobenchmarkthisfieldandpromotefuturedevelopments.\n6.\n2IndirectEvaluationBesidestheabovemethodthatdirectlyevaluatesthememorymodule,evaluatingviataskcompletionisalsoapopularevaluationstrategy.\nTheintuitionbehindthistypeofapproachesisthatiftheagentcansuccessfullycompleteataskthathighlydependsonmemory,itsuggeststhatthedesignedmemorymoduleiseffective.\nInthefollowingparts,wepresentseveralrepresentativetasksthatareleveragedtoevaluatethememorymoduleinindirectways.\n6.\n2.\n1ConversationEngaginginconversationswithhumansisoneofthemostimportantapplicationsofagents,wherememoryplaysacrucialroleinthisprocess.\nBystoringcontextinformationinmemory,theagentsallowuserstoexperiencepersonalizedconversations,thusimprovingusers’satisfaction.\nTherefore,whenotherpartsoftheagentsaredetermined,theperformanceoftheconversationtaskscanreflecttheeffectivenessofdifferentmemorymodules.\nInthecontextofconversation,consistencyandengagementaretwocommonlyusedmethodstoevaluatetheeffectivenessoftheagents’memory.\nConsistencyreferstohowtheresponsefromagentsisconsistentwiththecontextbecausedramaticchangesshouldbeavoidedduringtheconversation.\nForexample,Luetal.\n[94]evaluatetheconsistencyofagentsoninteractivedialogues,usingGPT-4toscoreontheresponsesfromagents.\nEngagementreferstohowtheuserisengagedtocontinuetheconversation.\nItreflectsthequalityandattractionofagents’responses,aswellastheabilityofagentstocraftthepersonasforcurrentconversations.\nForexample,Leeetal.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[167]ZhangchengQiang,WeiqingWang,andKerryTaylor.\nAgent-om:Leveraginglargelanguagemodelsforontologymatching.\narXivpreprintarXiv:2312.\n00326,2023.\n[168]LichengWen,DaochengFu,XinLi,XinyuCai,TaoMa,PinlongCai,MinDou,BotianShi,LiangHe,andYuQiao.\nDilu:Aknowledge-drivenapproachtoautonomousdrivingwithlargelanguagemodels.\narXivpreprintarXiv:2309.\n16292,2023.\n[169]ZhitaoWang,WeiWang,ZiraoLi,LongWang,CanYi,XinjieXu,LuyangCao,HanjingSu,ShouzhiChen,andJunZhou.\nXuat-copilot:Multi-agentcollaborativesystemforautomateduseracceptancetestingwithlargelanguagemodel.\narXivpreprintarXiv:2401.\n02705,2024.\n[170]YongchaoChen,JacobArkin,YangZhang,NicholasRoy,andChuchuFan.\nScalablemulti-robotcollaborationwithlargelanguagemodels:Centralizedordecentralizedsystems?\narXivpreprintarXiv:2309.\n15943,2023.\n[171]ZhaoMandi,ShreeyaJain,andShuranSong.\nRoco:Dialecticmulti-robotcollaborationwithlargelanguagemodels.\narXivpreprintarXiv:2307.\n04738,2023.\n[172]JonathanLight,MinCai,ShengShen,andZiniuHu.\nFromtexttotactic:Evaluatingllmsplayingthegameofavalon.\narXivpreprintarXiv:2310.\n05036,2023.\n38[173]BingLiu.\nLifelongmachinelearning:aparadigmforcontinuouslearning.\nFrontiersofComputerScience,11:359–361,2017.\n[174]GatiVAher,RosaIArriaga,andAdamTaumanKalai.\nUsinglargelanguagemodelstosimulatemultiplehumansandreplicatehumansubjectstudies.\nInInternationalConferenceonMachineLearning,pages337–371.\nPMLR,2023.\n39",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[141]MohitShridhar,XingdiYuan,Marc-AlexandreCôté,YonatanBisk,AdamTrischler,andMatthewHausknecht.\nAlfworld:Aligningtextandembodiedenvironmentsforinteractivelearning.\narXivpreprintarXiv:2010.\n03768,2020.\n[142]YunDaTsai,MingjieLiu,andHaoxingRen.\nRtlfixer:Automaticallyfixingrtlsyntaxerrorswithlargelanguagemodels.\narXivpreprintarXiv:2311.\n16543,2023.\n[143]ChengLi,ZiangLeng,ChenxiYan,JunyiShen,HaoWang,WeishiMi,YayingFei,XiaoyangFeng,SongYan,HaoShengWang,etal.\nChatharuhi:Revivinganimecharacterinrealityvialargelanguagemodel.\narXivpreprintarXiv:2308.\n09597,2023.\n[144]DakeChen,HanbinWang,YunhaoHuo,YuzhaoLi,andHaoyangZhang.\nGamegpt:Multi-agentcollaborativeframeworkforgamedevelopment.\narXivpreprintarXiv:2310.\n08067,2023.\n[145]ZekunMooreWang,ZhongyuanPeng,HaoranQue,JiahengLiu,WangchunshuZhou,YuhanWu,HongchengGuo,RuitongGan,ZehaoNi,ManZhang,etal.\nRolellm:Benchmarking,eliciting,andenhancingrole-playingabilitiesoflargelanguagemodels.\narXivpreprintarXiv:2310.\n00746,2023.\n[146]RuncongZhao,WenjiaZhang,JiazhengLi,LixingZhu,YanranLi,YulanHe,andLinGui.\nNarrativeplay:Interactivenarrativeunderstanding.\narXivpreprintarXiv:2310.\n01459,2023.\n[147]JinfengZhou,ZhuangChen,DazhenWan,BosiWen,YiSong,JifanYu,YongkangHuang,Lib-iaoPeng,JiamingYang,XiyaoXiao,etal.\nCharacterglm:Customizingchineseconversationalaicharacterswithlargelanguagemodels.\narXivpreprintarXiv:2311.\n16832,2023.\n[148]ZhaoKaiya,MichelangeloNaim,JovanaKondic,ManuelCortes,JiaxinGe,ShuyingLuo,GuangyuRobertYang,andAndrewAhn.\nLyfeagents:Generativeagentsforlow-costreal-timesocialinteractions.\narXivpreprintarXiv:2310.\n02172,2023.\n[149]JunjieZhang,YupengHou,RuobingXie,WenqiSun,JulianMcAuley,WayneXinZhao,LeyuLin,andJi-RongWen.\nAgentcf:Collaborativelearningwithautonomouslanguageagentsforrecommendersystems.\narXivpreprintarXiv:2310.\n09233,2023.\n[150]WenyueHua,LizhouFan,LingyaoLi,KaiMei,JianchaoJi,YingqiangGe,LibbyHemphill,andYongfengZhang.\nWarandpeace(waragent):Largelanguagemodel-basedmulti-agentsimulationofworldwars.\narXivpreprintarXiv:2311.\n17227,2023.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[120]NelsonFLiu,KevinLin,JohnHewitt,AshwinParanjape,MicheleBevilacqua,FabioPetroni,andPercyLiang.\nLostinthemiddle:Howlanguagemodelsuselongcontexts.\narXivpreprintarXiv:2307.\n03172,2023.\n[121]PeterJDenning.\nThelocalityprinciple.\nCommunicationsoftheACM,48(7):19–24,2005.\n35[122]HermannEbbinghaus.\nMemory:Acontributiontoexperimentalpsychology,trans.\nHARuger&CEBussenius.\nTeachersCollege.\n[rWvH],1885.\n[123]JaapMJMurreandJoeriDros.\nReplicationandanalysisofebbinghaus’forgettingcurve.\nPloSone,10(7):e0120644,2015.\n[124]JeffJohnson,MatthijsDouze,andHervéJégou.\nBillion-scalesimilaritysearchwithgpus.\nIEEETransactionsonBigData,7(3):535–547,2019.\n[125]TimoSchick,JaneDwivedi-Yu,RobertoDessì,RobertaRaileanu,MariaLomeli,LukeZettle-moyer,NicolaCancedda,andThomasScialom.\nToolformer:Languagemodelscanteachthemselvestousetools.\narXivpreprintarXiv:2302.\n04761,2023.\n[126]YujiaQin,ShihaoLiang,YiningYe,KunlunZhu,LanYan,YaxiLu,YankaiLin,XinCong,XiangruTang,BillQian,etal.\nToolllm:Facilitatinglargelanguagemodelstomaster16000+real-worldapis.\narXivpreprintarXiv:2307.\n16789,2023.\n[127]HugoTouvron,ThibautLavril,GautierIzacard,XavierMartinet,Marie-AnneLachaux,Timo-théeLacroix,BaptisteRozière,NamanGoyal,EricHambro,FaisalAzhar,etal.\nLlama:Openandefficientfoundationlanguagemodels.\narXivpreprintarXiv:2302.\n13971,2023.\n[128]ZhibinGou,ZhihongShao,YeyunGong,YujiuYang,MinlieHuang,NanDuan,WeizhuChen,etal.\nTora:Atool-integratedreasoningagentformathematicalproblemsolving.\narXivpreprintarXiv:2309.\n17452,2023.\n[129]HonglinXiong,ShengWang,YitaoZhu,ZihaoZhao,YuxiaoLiu,QianWang,andDinggangShen.\nDoctorglm:Fine-tuningyourchinesedoctorisnotaherculeantask.\narXivpreprintarXiv:2304.\n01097,2023.\n[130]AohanZeng,XiaoLiu,ZhengxiaoDu,ZihanWang,HanyuLai,MingDing,ZhuoyiYang,YifanXu,WendiZheng,XiaoXia,etal.\nGlm-130b:Anopenbilingualpre-trainedmodel.\narXivpreprintarXiv:2210.\n02414,2022.\n[131]EdwardJHu,YelongShen,PhillipWallis,ZeyuanAllen-Zhu,YuanzhiLi,SheanWang,LuWang,andWeizhuChen.\nLora:Low-rankadaptationoflargelanguagemodels.\narXivpreprintarXiv:2106.\n09685,2021.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[26]GuangjiBai,ZhengChai,ChenLing,ShiyuWang,JiayingLu,NanZhang,TingweiShi,ZiyangYu,MengdanZhu,YifeiZhang,etal.\nBeyondefficiency:Asystematicsurveyofresource-efficientlargelanguagemodels.\narXivpreprintarXiv:2401.\n00625,2024.\n[27]ZhongweiWan,XinWang,CheLiu,SamiulAlam,YuZheng,ZhongnanQu,ShenYan,YiZhu,QuanluZhang,MosharafChowdhury,etal.\nEfficientlargelanguagemodels:Asurvey.\narXivpreprintarXiv:2312.\n03863,1,2023.\n[28]XupengMiao,GabrieleOliaro,ZhihaoZhang,XinhaoCheng,HongyiJin,TianqiChen,andZhihaoJia.\nTowardsefficientgenerativelargelanguagemodelserving:Asurveyfromalgorithmstosystems.\narXivpreprintarXiv:2312.\n15234,2023.\n[29]LinglingXu,HaoranXie,Si-ZhaoJoeQin,XiaohuiTao,andFuLeeWang.\nParameter-efficientfine-tuningmethodsforpretrainedlanguagemodels:Acriticalreviewandassessment.\narXivpreprintarXiv:2312.\n12148,2023.\n[30]XunyuZhu,JianLi,YongLiu,CanMa,andWeipingWang.\nAsurveyonmodelcompressionforlargelanguagemodels.\narXivpreprintarXiv:2308.\n07633,2023.\n[31]CanwenXuandJulianMcAuley.\nAsurveyonmodelcompressionandaccelerationforpretrainedlanguagemodels.\nInProceedingsoftheAAAIConferenceonArtificialIntelligence,volume37,pages10566–10575,2023.\n[32]WenxiaoWang,WeiChen,YicongLuo,YongliuLong,ZhengkaiLin,LiyeZhang,BinbinLin,DengCai,andXiaofeiHe.\nModelcompressionandefficientinferenceforlargelanguagemodels:Asurvey.\narXivpreprintarXiv:2402.\n09748,2024.\n[33]SeungcheolPark,JaehyeonChoi,SojinLee,andUKang.\nAcomprehensivesurveyofcompressionalgorithmsforlanguagemodels.\narXivpreprintarXiv:2401.\n15347,2024.\n[34]YupengChang,XuWang,JindongWang,YuanWu,LinyiYang,KaijieZhu,HaoChen,XiaoyuanYi,CunxiangWang,YidongWang,etal.\nAsurveyonevaluationoflargelanguagemodels.\nACMTransactionsonIntelligentSystemsandTechnology,2023.\n[35]ZishanGuo,RenrenJin,ChuangLiu,YufeiHuang,DanShi,LinhaoYu,YanLiu,JiaxuanLi,BojianXiong,DeyiXiong,etal.\nEvaluatinglargelanguagemodels:Acomprehensivesurvey.\narXivpreprintarXiv:2310.\n19736,2023.\n[36]JingfengYang,HongyeJin,RuixiangTang,XiaotianHan,QizhangFeng,HaomingJiang,BingYin,andXiaHu."
    ],
    [],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\nForbothsimulatingusersinrecommendersystemsandcapturingtheirpreferences,retainingper-sonalizedinformationthroughmemoryisessential.\nAcriticalchallengeliesinhowtoalignthepersonalizedinformationandfeedbackwithLLMs,andstorethemintothememoryofagents.\nItisalsoanimportanttaskforbridgingthegapbetweenconventionalrecommendationmodelsandLLMs.\n7.\n6",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nByleveragingexternalresources,theagentscanlearnfromcode-relatedknowledgeandstoreitintotheirmemory,therebyenhancingthecapabilitiesofcodegeneration.\nInaddition,thememorycanimprovethecontinuityandconsistencyincodegeneration.\nByintegratingcontextualmemory,theagentcanbetterunderstandtherequirementsforsoftwaredevelopment,therebyenhancingthecoherenceofthegeneratedcode.\nFurthermore,thememoryisalsocrucialfortheiterativeoptimizationofcode,asitcanidentifythedeveloper’stargetsbasedonthehistories.\n257.\n5RecommendationInthefieldofrecommendation,somepreviousworksfocusonsimulatingusersinrecommendersystems[95,108],wherethememorycanrepresenttheuserprofilesandhistoriesintherealworld.\nOtherstrytoimprovetheperformanceofrecommendation,orprovideotherformatsofrecommendationinterfaces[149,102].\nWangetal.\n[95]simulateuserbehaviorsinrecommendationscenariostogeneratedataforrecommendersystems,andtheagentsstorepastobservationsandinsightsintoahierarchicalmemory.\nInHuangetal.\n[108],thememoryinLLM-basedagentscanarchivetheuser’sconversationalhistoryoverextendedperiods,aswellascapturethemostrecentdialoguespertinenttothecurrentprompt,tosimulateinteractiverecommendersystems.\nItalsousesanactor-criticreflectiontoimprovetherobustnessofagents.\nItemagentsanduseragentsareequippedwithdifferentmemoriesin[149],whereitemagentsareendowedwithdynamicmemorymodulesdesignedtocaptureandpreserveinformationpertinenttotheirintrinsicattributesandtheinclinationsoftheiradopters.\nForuseragents,theadaptivememoryupdatingmechanismplaysapivotalroleinaligningtheagents’operationswithuserbehaviorsandpreferences.\nWangetal.\n[102]memorizeindividualizeduserinformationlikereviewsorratingsforitems,andacquiredomain-specificknowledgeandreal-timeinformationbywebsearchingtools.\nForbothsimulatingusersinrecommendersystemsandcapturingtheirpreferences,retainingper-sonalizedinformationthroughmemoryisessential.\nAcriticalchallengeliesinhowtoalignthepersonalizedinformationandfeedbackwithLLMs,andstorethemintothememoryofagents.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nManypreviousstudieshaveexploredmethodsforconstructingrolememories[105,143,145–147].\nShaoetal.\n[105]constructthememoryofrolesbyexperienceuploading,whichutilizesSFTtoinjectmemoryintomodelparameters.\nLietal.\n[143]enhancelargelanguagemodelsforrole-playingviaanimprovedpromptandthecharactermemoryextractedfromscripts,whereuserqueriesand23Table4:Summarizationofmemory-enhancedagentsapplications.\nApplicationsModelsApplicationsModelsRole-playingSocialSimulationPersonalAssistantGameCharacter-LLM[105]ChatHaruhi[143]RoleLLM[145]NarrativePlay[146]CharacterGLM[147]GenerativeAgents[83]LyfeAgents[148]S3[2]MetaAgents[109]WarAgent[150]MemoryBank[6]RET-LLM[7]MemoChat[94]MemGPT[100]MPC[101]AutoGen[153]ChatDB[96]TiM[97]SCM[98]Voyager[99]GITM[93]JARVIS[159]LARP[161]CodeGenerationRecommendationMedicineFinanceScienceRTLFixer[142]GameGPT[144]ChatDev[1]MetaGPT[109]CodeAgent[114]RecAgent[95]InteRecAgent[108]RecMind[102]AgentCF[149]Huatuo[107]DoctorGLM[129]Radiology-GPT[132]Wangetal.\n[151]EHRAgent[152]ChatDoctor[115]InvestLM[113]TradingGPT[154]QuantAgent[155]FinMem[156]Koaetal.\n[157]Chemist-X[158]ChemDFM[160]MatChat[162]chatbot’sresponsesareconcatenatedtoformasequenceasmemory.\nWangetal.\n[145]infuserole-specificknowledgeandepisodememoriesintoLLM-basedagents,wherecontextQApairsareconcatenatedtoformepisodememory.\nZhaoetal.\n[146]aimtogeneratehuman-likeresponses,guidedbypersonalitytraitsextractedfromnarratives,whichcanbestoredandretrievedbyrelevanceandimportance.\nZhouetal.\n[147]generatecharacter-baseddialoguesfordifferentrolesandempowerLLM-basedagentswithcorrespondingstylesbySFT.\nSocialsimulationisbasicallyanextensionofrole-playing,whichfocusesmoreonmulti-agentmodeling.\nThememorymoduleisanimportantcomponentforsuchapplications,whichhelpstoaccuratelysimulatehumandynamicbehaviors.\nInpreviousstudies,Kaiyaetal.\n[148]proposeaSummarize-and-Forgetmemorymechanismforbetterself-monitoringinsocialscenarios.\nGaoetal.\n[2]focusonsocialnetworksimulationsystems.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThememorymoduleisanimportantcomponentforsuchapplications,whichhelpstoaccuratelysimulatehumandynamicbehaviors.\nInpreviousstudies,Kaiyaetal.\n[148]proposeaSummarize-and-Forgetmemorymechanismforbetterself-monitoringinsocialscenarios.\nGaoetal.\n[2]focusonsocialnetworksimulationsystems.\nEachagentinthesystemhasamemorypool,whichconsistsofdiverseusermessagesfromonlineplatformstoidentifytheuser.\nLietal.\n[163]maintainconversationcontexts,encompassingtheeconomicenvironmentandagentdecisionsfrompreviousmonths,inordertosimulatetheimpactofbroadmacroeconomictrendsonagents’decision-makingandtomaketheagentsgraspmarketdynamics.\nLietal.\n[109]simulatethejob-seekingscenarioinhumansociety,wherethememoryofagentsincludesprofilesandgoalsinitiallyandisfurtherenrichedwithotherinformation,likedialoguesandpersonalreflections.\nHuaetal.\n[150]simulatethedecisionsandconsequencesoftheparticipatingcountriesinthewars,wheretheconversationsofagentsarecontinuouslymaintainedintomemory.\nThereareseveralinsightsindesigninganagent’smemoryforrole-playandsocialsimulation.\nFirst,thememoryshouldbeconsistentwiththeroles’characteristics,whichcanbeusedtoidentifyeachroleanddistinguishitfromtheothers.\nThisiscrucialforimprovingtherealismofrole-playandthediversityofsocialsimulation.\nSecond,thememoryshouldappropriatelyinfluencethesubsequent24actionsoftheagenttoensuretheconsistencyandrationalityofitsbehaviors.\nAdditionally,forhumanoidagents,theirmemorymechanismsshouldalignwiththefeaturesofhumanmemory,suchasforgettingandlong/short-termmemory,whichshouldrefertothetheoriesofcognitivepsychology.\n7.\n2PersonalAssistantLLM-basedagentsarewell-suitedforcreatingpersonalassistants,suchasagentscapableofengaginginlong-termconversationswithusers[94,101,153],aswellasthosetaskedwithautomaticallyseekinginformation[164].\nTheseagentsoftenneedtomemorizepreviousdialoguestomaintaintheconsistency,andremembercriticalstylesandeventstogeneratemorepersonalizedandrelevantresponses.\nLuetal.",
      "#memory_survey#Memory-assistedAgent-EnvironmentInteraction#memory_survey#Memory-assistedAgent-EnvironmentInteraction\nForthenarrowmemorydefinition,theiterationonlyhappenswithinthesametrial,andthememoryisemptiedwhenthetrialisended.\nForthebroadmemorydefinition,theiterationhappensacrossdifferenttrialsoreventasks,aswellastheintegrationsofexternalknowledge.\nFortask(B)intheabovetoyexample,theagentcanconcludethatAliceenjoyswatchingsciencefictionmoviesintheevening,whichcanbeusedasadefaultruletomakerecommendationsforAliceinthefuture.\nMemoryReading.\nThisoperationaimstoobtainimportantinformationfromthememorytosupportthenextagentaction.\nItcorrespondstothethirdphaseoftheagent-environmentinteractionprocess.\nSupposeMktisthecontextofthenextaction,thenthememoryreadingoperationcanberepresentedby:tisthememorycontentsfortaskkatstept,ckˆMkt=R(Mkt,ckt+1),whereRisusuallyimplementedbycomputingthesimilaritybetweenMktisusedaspartsofthefinalprompttodrivetheagent’snextaction.\nFortask(B)intheabovetoyexample,whentheagentdecidesonthefinalrecommendedmoviein[Step3],itshouldfocusonthe“wanttowatch”listin[Step2]andselectonefromit.\ntandckt+1[82].\nˆMkBasedontheaboveoperations,wecanderiveaunifiedfunctionfortheevolvingprocessfrom{akt,okt}toakt+1,thatis:akt+1=LLM{R(P(Mkt−1,W({akt,okt})),ckt+1)},whereLLMisthelargelanguagemodel.\nThecompleteagent-environmentinteractionprocesscanbeeasilyobtainedbyiterativelyexpandingthisfunction(seeFigure3(b)foranintuitiveillustration).\nRemark.\nThisfunctionprovidesageneralformulationoftheagentmemorizingprocess.\nPreviousworksmayusedifferentspecifications.\nForexample,in[5],RandParesetasidenticalfunctions,andPonlytakeseffectattheendofatrial.\nInParketal.\n[83],Risimplementedbasedonthreecriteriaincludingsimilarity,timeinterval,andimportance,andPisrealizedbyareflectionprocesstoobtainmoreabstractthoughts.\nInthissection,wefocusontheoverallframeworkoftheagent’smemoryoperations.\nMoredetailedrealizationsofW,P,andRaredeferredinSection5.\n4"
    ],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.\nDuringmemoryreading,matchingscoresarecalculatedforeachmemoryentry,andthetop-Kentrieswillbeusedforthedecision-makingprocessofagents.\n15Inexistingstudies,mostagentsutilizeretrievalmethodstoprocessthememoryinformation.\nForexample,Parketal.\n[83]firstcalculatetherelevancebetweenthecurrentcontextandmemoryentriesbycosinesimilarity,andobtaintheimportanceandrecencyaccordingtoauxiliaryinformation.\nMemoryBank[6]employsadual-towerdenseretrievalmodeltofindrelatedinformationfrompastconversations.\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage.\nItutilizesLocality-SensitiveHashing(LSH)toretrievetupleswithrelativeentriesinthedatabasetoprovidemoreinformation.\nInaddition,ChatDB[96]designstoutilizesymbolicmemory,andproposestogenerateSQLstatementstoretrievefromdatabasetoobtainstoredinformation.",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.\nDuringmemoryreading,matchingscoresarecalculatedforeachmemoryentry,andthetop-Kentrieswillbeusedforthedecision-makingprocessofagents.\n15Inexistingstudies,mostagentsutilizeretrievalmethodstoprocessthememoryinformation.\nForexample,Parketal.\n[83]firstcalculatetherelevancebetweenthecurrentcontextandmemoryentriesbycosinesimilarity,andobtaintheimportanceandrecencyaccordingtoauxiliaryinformation.\nMemoryBank[6]employsadual-towerdenseretrievalmodeltofindrelatedinformationfrompastconversations.\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage.\nItutilizesLocality-SensitiveHashing(LSH)toretrievetupleswithrelativeentriesinthedatabasetoprovidemoreinformation.\nInaddition,ChatDB[96]designstoutilizesymbolicmemory,andproposestogenerateSQLstatementstoretrievefromdatabasetoobtainstoredinformation.\nTheretrievalmethodsconsiderablydependontheaccuracyandefficiencyofobtainingexpectedinformation.\nAninaccurateretrievalstrategycanpotentiallyacquireunrelatedinformationthatisunhelpfulforagentinference.\nAndaheavyretrievalsystemcanleadtolargecomputationalcostsandlongtimelatency,especiallywhenhandlingmassiveinformation.\nMoreover,retrievalmethodstypicallystorehomogeneousinformationinsidetheenvironment,wherealltheinformationisinaconsistentform.\nForheterogeneousinformationoutsidetheenvironment,it’sdifficulttodirectlyapplythesamemethodformemorystorage.\nExternalKnowledge.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nItutilizesLocality-SensitiveHashing(LSH)toretrievetupleswithrelativeentriesinthedatabasetoprovidemoreinformation.\nInaddition,ChatDB[96]designstoutilizesymbolicmemory,andproposestogenerateSQLstatementstoretrievefromdatabasetoobtainstoredinformation.\nTheretrievalmethodsconsiderablydependontheaccuracyandefficiencyofobtainingexpectedinformation.\nAninaccurateretrievalstrategycanpotentiallyacquireunrelatedinformationthatisunhelpfulforagentinference.\nAndaheavyretrievalsystemcanleadtolargecomputationalcostsandlongtimelatency,especiallywhenhandlingmassiveinformation.\nMoreover,retrievalmethodstypicallystorehomogeneousinformationinsidetheenvironment,wherealltheinformationisinaconsistentform.\nForheterogeneousinformationoutsidetheenvironment,it’sdifficulttodirectlyapplythesamemethodformemorystorage.\nExternalKnowledge.\nToobtainmoreinformation,someagentsacquireexternalknowledgebyinvokingtools,withtheaimoftransformingadditionalrelevantknowledgeintotheirownmemoriesfordecision-making.\nForinstance,accessingexternalknowledgethroughApplicationProgrammingInterface(API)isacommonpractice[104,5].\nNowadays,abundantpublicinformation,suchasWikipediaandOpenWeatherMap4,areavailableonline(eitherfreeofchargeoronapayingbasis),andcanbeconvenientlyaccessedthroughAPIcalls.\nForinstance,in[Step2]oftask(A)oftheexampleinSection3.\n1,externalknowledgefromthedigitalmagazineisobtainedwithtoolmethods.\nInexistingmodels,Toolformer[125]proposestoteachLLMtousetools,whichcanacquireexternalknowledgeforbettersolvingtasks.\nFurthermore,ToolLLM[126]empowersLlama[127]withtheabilitytoutilizemoreAPIsinRapidAPI5andtoenablemulti-toolusage,whichprovidesageneralinterfacetoextendagents’ability.\nInTPTU[110],theagentsareincorporatedinbothtaskplanningandtoolusage,inordertotackleintricateproblems.\nThefollow-upwork[111]furtherimprovesitsabilityextensivelylikeretrieval.\nInToRA[128],theagentsarerequiredtosolvemathematicalproblems.\nTheyutilizeimitationlearningtoimprovetheirabilitytouseprogram-basedtools.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage.\nItutilizesLocality-SensitiveHashing(LSH)toretrievetupleswithrelativeentriesinthedatabasetoprovidemoreinformation.\nInaddition,ChatDB[96]designstoutilizesymbolicmemory,andproposestogenerateSQLstatementstoretrievefromdatabasetoobtainstoredinformation.\nTheretrievalmethodsconsiderablydependontheaccuracyandefficiencyofobtainingexpectedinformation.\nAninaccurateretrievalstrategycanpotentiallyacquireunrelatedinformationthatisunhelpfulforagentinference.\nAndaheavyretrievalsystemcanleadtolargecomputationalcostsandlongtimelatency,especiallywhenhandlingmassiveinformation.\nMoreover,retrievalmethodstypicallystorehomogeneousinformationinsidetheenvironment,wherealltheinformationisinaconsistentform.\nForheterogeneousinformationoutsidetheenvironment,it’sdifficulttodirectlyapplythesamemethodformemorystorage.\nExternalKnowledge.\nToobtainmoreinformation,someagentsacquireexternalknowledgebyinvokingtools,withtheaimoftransformingadditionalrelevantknowledgeintotheirownmemoriesfordecision-making.\nForinstance,accessingexternalknowledgethroughApplicationProgrammingInterface(API)isacommonpractice[104,5].\nNowadays,abundantpublicinformation,suchasWikipediaandOpenWeatherMap4,areavailableonline(eitherfreeofchargeoronapayingbasis),andcanbeconvenientlyaccessedthroughAPIcalls.\nForinstance,in[Step2]oftask(A)oftheexampleinSection3.\n1,externalknowledgefromthedigitalmagazineisobtainedwithtoolmethods.\nInexistingmodels,Toolformer[125]proposestoteachLLMtousetools,whichcanacquireexternalknowledgeforbettersolvingtasks.\nFurthermore,ToolLLM[126]empowersLlama[127]withtheabilitytoutilizemoreAPIsinRapidAPI5andtoenablemulti-toolusage,whichprovidesageneralinterfacetoextendagents’ability.",
      "#memory_survey#D:\\projects\\KAG\\kag\\examples\\memory_survey_test\\builder\\./data/memory_survey.pdf#memory_survey#D:\\projects\\KAG\\kag\\examples\\memory_survey_test\\builder\\./data/memory_survey.pdf\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n7.\n6ExpertSysteminSpecificDomains.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n7.\n7OtherApplications.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n8Limitations&FutureDirections8.\n1MoreAdvancesinParametricMemory.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n8.\n2MemoryinLLM-basedMulti-agentApplications.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n8.\n3Memory-basedLifelongLearning.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n8.\n4MemoryinHumanoidAgent.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n9Conclusion2323232325252526262627272728282831"
    ],
    [
      "#memory_survey#Memory-enhancedAgentApplications#memory_survey#Memory-enhancedAgentApplications\nMemory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal.\n[47]summarizetheapplicationsofLLMsinmedicine.\nLietal.\n[48]focusontheapplicationsofLLMsinfinance.\nHeetal.\n[49]reviewthemodelsonleveragingLLMstoimprovethedevelopmentofpsychology.\n5SupervisedFine-tuningZhangetal.\n[8].\nAlignmentShenetal.\n[9],Wangetal.\n[10],Liuetal.\n[11].\nRetrievalAugmentationGaoetal.\n[12].\nKnowledgeEditingWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16],Zhangetal.\n[17].\nFundamentalProblemsToolUsageQinetal.\n[18].\nLong-contextMultimodalEfficiencyHuangetal.\n[19],Wangetal.\n[20],Pawaretal.\n[21].\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24],Yinetal.\n[25].\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28,28],Xuetal.\n[29],Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32],Parketal.\n[33].\nEvaluationChangetal.\n[34],Guoetal.\n[35].\nInformationProcessingSoftwareEngineeringYangetal.\n[36],Zhuetal.\n[37],Xuetal.\n[38].\nFanetal.\n[39],Wangetal.\n[40],Zhengetal.\n[41].\nRoboticsZengetal.\n[42].\nApplicationsAutonomousDrivingCuietal.\n[43],Yangetal.\n[44].\nLLMs[70–73]MedecineFinancePsychologyHeetal.\n[45],Zhouetal.\n[46],Wangetal.\n[47].\nLietal.\n[48].\nHeetal.\n[49].\nRecommendationLietal.\n[50],Linetal.\n[51],Wangetal.\n[52].\nHallucinationZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Ton-moyetal.\n[58],Jiangetal.\n[59].\nChallengesBias&FairnessGallegosetal.\n[60],Koteketal.\n[61],Lietal.\n[62].\nExplainabilityZhaoetal.\n[63].\nSecurityYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68],Dasetal.\n[69].\nPlanningHuangetal.\n[74].\nFundamentalProblemsMemoryOurSurvey.\nMulti-agentsGuoetal.\n[75].\nLLM-basedAgent[3,4,77–80]EvaluationApplicationsChallengesLietal.\n[76].\nFigure2:TheorganizationofrelatedsurveysonLLMsandLLM-basedagents.\n6Challenges.\nThesurveysinthiscategoryfocusontrustworthinessinLLMs,suchashallucination,bias,unfairness,explainability,security,andprivacy.",
      "#memory_survey#HowtoImplementtheMemoryofLLM-basedAgent#memory_survey#HowtoImplementtheMemoryofLLM-basedAgent\nHowtoImplementtheMemoryofLLM-basedAgentInthissection,wediscusstheimplementationofthememorymodulefromthreeperspectives:memorysources,memoryforms,andmemoryoperations.\nMemorysourcesrefertowherethememorycontentscomefrom.\nMemoryformsfocusonhowtorepresentthememorycontents.\nMemoryoperationsaimtoprocessthememorycontents.\nThesethreeperspectivesprovideacomprehensivereviewofmemoryimplementationmethods,whichishelpfulforfutureresearch.\nForbetterdemonstration,wepresentanoverviewofimplementationmethodsinFigure4.\n5.\n1",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\nFigure2:TheorganizationofrelatedsurveysonLLMsandLLM-basedagents.\n6Challenges.\nThesurveysinthiscategoryfocusontrustworthinessinLLMs,suchashallucination,bias,unfairness,explainability,security,andprivacy.\nHallucinationinLLMsreferstotheproblemthatLLMsmaygeneratemisconceptionsorfabrications,impactingtheirreliabilityfordownstreamapplications.\nZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Tonmoyetal.\n[58]andJiangetal.\n[59]summarizethemainstreammodelsforalleviatingthehallucinationprobleminLLMs.\nThebiasandunfairnessproblemsrefertothephenomenonthatLLMsmayunequallytreatdifferenthumansorobjectives,whichcanleadtothepropagationofsocietalstereotypesanddiscrimination.\nGallegosetal.\n[60],Koteketal.\n[61]andLietal.\n[62]comprehensivelydiscussthesechallengesandsummarizeexistingmethodsforalleviatingthem.\nTheproblemofexplainabilitymeansthattheinternalworkingmechanismsofLLMsarestillunclear.\nZhaoetal.\n[63]systematicallydiscussthisproblemandsummarizepreviouseffortsonimprovingtheexplainabilityofLLMs.\nSecurityandprivacyarealsochallengingproblems,whichhavebeencomprehensivelysurveyedinYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68]andDasetal.\n[69].\n2.\n2",
      "#memory_survey#HowtoEvaluatetheMemoryinLLM-basedAgent#memory_survey#HowtoEvaluatetheMemoryinLLM-basedAgent\nHowtoEvaluatetheMemoryinLLM-basedAgentHowtoeffectivelyevaluatethememorymoduleremainsanopenproblem,wherediverseevaluationstrategieshavebeenproposedinpreviousworksaccordingtodifferentapplications.\nToclearlyshowthecommonideasofdifferentevaluationmethods,inthissection,wesummarizeageneralframework,whichincludestwobroadevaluationstrategies(seeFigure5foranoverview),thatis,(1)directevaluation,whichindependentlymeasuresthecapabilityofthememorymodule.\n(2)indirectevaluation,whichevaluatesthememorymoduleviaend-to-endagenttasks.\nIfthetaskscanbeeffectivelyaccomplished,thememorymoduleisdemonstratedtobeuseful.\n6.\n1",
      "#memory_survey#MemoryinLLM-basedMulti-agentApplications#memory_survey#MemoryinLLM-basedMulti-agentApplications\nMemoryinLLM-basedMulti-agentApplicationsTheexplorationofmemorymechanismswithinLLMshasburgeonedintothedynamicdomainofmulti-agentsystems(MAS),markingsignificantadvancementsintherealmsofsynchronization,communication,andthemanagementofinformationasymmetry.\nOnepivotalaspectthatemergesinthecooperativescenariosismemorysynchronizationamongagents.\nThisprocessisfundamentalforestablishingaunifiedknowledgebase,ensuringconsistencyindecision-makingacrossdifferentagents.\nForexample,Chenetal.\n[170]emphasizethesignificanceofintegratingsynchronizedmemorymodulesformulti-robotcollaboration.\nAnotherimportantaspectisthecommunicationamongagents,whichheavilyreliesonmemoryformaintainingcontextandinterpretingmessages.\nForexample,Mandietal.\n[171]illustratememory-drivencommunicationframeworksthatfosteracommonunderstandingamongagents.\nInadditiontocooperativescenarios,somestudiesalsofocusoncompetitivescenarios,andtheinformationasymmetrybecomesacrucialissue[172].\nLookingahead,theadvancementofmemoryinLLM-basedMASispoisedattheconfluenceoftechnologicalinnovationandstrategicapplication.\nItbeckonstheexplorationofnovelmemory27modulesthatcanfurtherenhanceagentsynchronization,enablemoreeffectivecommunication,andprovidestrategicadvantagesininformation-richenvironments.\nThedevelopmentofsuchmemorymodelswouldnotonlynecessitateaddressingthecurrentchallengesofmemoryintegrationandman-agement,butalsoexploretheuntappedpotentialsofmemoryinfacilitatingmorerobust,intelligent,andadaptableMAS.\nAsevidencedbypioneeringresearch,theevolvinglandscapeofLLM-basedMASsetsapromisingstageforfutureinnovationsinmemoryutilizationandmanagement.\nThisexplorationisexpectedtounravelnewdimensionsofmemoryintegration,pushingtheboundariesofwhatiscurrentlyachievableandsettingnewbenchmarksintherealmofMAS.\n8.\n3",
      "#memory_survey#Recommendation#memory_survey#Recommendation\n[40],andZhengetal.\n[41]concentrateonhowLLMscanbenefitsoftwareengineering(SE)intermsofsoftwaredesign,development,andtesting.\nZengetal.\n[42]summarizeLLM-basedmethodsinthefieldofrobotics.\nCuietal.\n[43]andYangetal.\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal.\n[47]summarizetheapplicationsofLLMsinmedicine.\nLietal.\n[48]focusontheapplicationsofLLMsinfinance.\nHeetal.\n[49]reviewthemodelsonleveragingLLMstoimprovethedevelopmentofpsychology.\n5SupervisedFine-tuningZhangetal.\n[8].\nAlignmentShenetal.\n[9],Wangetal.\n[10],Liuetal.\n[11].\nRetrievalAugmentationGaoetal.\n[12].\nKnowledgeEditingWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16],Zhangetal.\n[17].\nFundamentalProblemsToolUsageQinetal.\n[18].\nLong-contextMultimodalEfficiencyHuangetal.\n[19],Wangetal.\n[20],Pawaretal.\n[21].\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24],Yinetal.\n[25].\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28,28],Xuetal.\n[29],Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32],Parketal.\n[33].\nEvaluationChangetal.\n[34],Guoetal.\n[35].\nInformationProcessingSoftwareEngineeringYangetal.\n[36],Zhuetal.\n[37],Xuetal.\n[38].\nFanetal.\n[39],Wangetal.\n[40],Zhengetal.\n[41].\nRoboticsZengetal.\n[42].\nApplicationsAutonomousDrivingCuietal.\n[43],Yangetal.\n[44].\nLLMs[70–73]MedecineFinancePsychologyHeetal.\n[45],Zhouetal.\n[46],Wangetal.\n[47].\nLietal.\n[48].\nHeetal.\n[49].\nRecommendationLietal.\n[50],Linetal.\n[51],Wangetal.\n[52].\nHallucinationZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Ton-moyetal.\n[58],Jiangetal.\n[59].\nChallengesBias&FairnessGallegosetal.\n[60],Koteketal.\n[61],Lietal.\n[62].\nExplainabilityZhaoetal.\n[63].\nSecurityYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68],Dasetal.\n[69].\nPlanningHuangetal.\n[74].\nFundamentalProblemsMemoryOurSurvey.\nMulti-agentsGuoetal.\n[75].\nLLM-basedAgent[3,4,77–80]EvaluationApplicationsChallengesLietal.\n[76].",
      "#memory_survey#Introduction#memory_survey#Introduction\n(2)WesystematicallysummarizeexistingstudiesondesigningandevaluatingthememorymoduleinLLM-basedagents,providingcleartaxonomiesandintuitiveinsights.\n(3)Wepresenttypicalagentapplicationstoshowtheimportanceofthememorymoduleindifferentscenarios.\n(4)Weanalyzethekeylimitationsofexistingmemorymodulesandshowpotentialsolutionsforinspiringfuturestudies.\nToourknowledge,thisisthefirstsurveyonthememorymechanismofLLM-basedagents.\nTherestofthissurveyisorganizedasfollows.\nFirst,weprovideasystematicalmeta-surveyforthefieldsofLLMsandLLM-basedagentsinSection2,categorizingdifferentsurveysandsummarizingtheirkeycontributions.\nThen,wediscusstheproblemsof“whatis”,“whydoweneed”and“howtoimplementandevaluate”thememorymoduleinLLM-basedagentsinSection3to6.\nNext,weshowtheapplicationsofmemory-enhancedagentsinSection7.\nThediscussionsofthelimitationsofexistingworkandfuturedirectionscomeatlastinSection8andSection9.\n42",
      "#memory_survey#Recommendation#memory_survey#Recommendation\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32]andParketal.\n[33]systematicallyreviewthetechniquesofmodelcompression.\nDingetal.\n[81]andXuetal.\n[29]analyzeandconcludethestudiesonparameterefficientfine-tuning.\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28]andDingetal.\n[81]putmorefocusesontheefficiencyofresourceutilizationinageneralsense.\nEvaluation.\nThesurveysinthiscategoryfocusonhowtoevaluatethecapabilityofLLMs.\nSpecifi-cally,Changetal.\n[34]comprehensivelysummarizetheevaluationmethodsfromanoverallperspec-tive.\nItencompassesdifferentevaluationtasks,methods,andbenchmarks,whichserveascriticalpartsinassessingLLMperformances.\nGuoetal.\n[35]caremoreabouttheevaluationtargetsanddescribehowtoevaluatetheknowledge,alignment,andsafetycontrolcapabilitiesofLLMs,whichsupplementevaluationmetricsbeyondperformance.\nApplications.\nThesurveysinthiscategoryaimtosummarizemodelsthatleverageLLMstoimprovedifferentapplications.\nMoreconcretely,Zhuetal.\n[37]focusonthefieldofinformationretrieval(IR)andsummarizestudiesonLLM-basedqueryprocesses.\nXuetal.\n[38]paymoreattentiontoinformationextraction(IE)andprovidecomprehensivetaxonomiesforLLM-basedmodelsinthisfield.\nLietal.\n[50],Linetal.\n[51]andWangetal.\n[52]discusstheapplicationsofLLMsinthefieldofrecommendersystem,wheretheyutilizeagentstogeneratedataandproviderecommendations.\nFanetal.\n[39],Wangetal.\n[40],andZhengetal.\n[41]concentrateonhowLLMscanbenefitsoftwareengineering(SE)intermsofsoftwaredesign,development,andtesting.\nZengetal.\n[42]summarizeLLM-basedmethodsinthefieldofrobotics.\nCuietal.\n[43]andYangetal.",
      "#memory_survey#WhyWeNeedtheMemoryinLLM-basedAgent#memory_survey#WhyWeNeedtheMemoryinLLM-basedAgent\nWhyWeNeedtheMemoryinLLM-basedAgentAbove,wehaveintroducedwhatisthememoryofLLM-basedagents.\nBeforecomprehensivelypresentinghowtoimplementit,inthissection,webrieflyshowwhymemoryisnecessaryforbuildingLLM-basedagents,whereweexpandourdiscussionfromthreeperspectivesincludingcognitivepsychology,self-evolution,andagentapplications.\n4.\n1",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTosystemicallysummarizethestudiesinthisfield,researchershavewrittenalotofsurveypapers.\nInthissection,webrieflyreviewthesesurveys(seeFigure2foranoverview),highlightingtheirmajorfocusesandcontributionstobetterpositionourstudy.\n2.\n1SurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.\n[70]presentthefirstcomprehensivesurveytosummarizethebackground,evolutionpaths,modelarchitectures,trainingmethodologies,andevaluationstrategiesofLLMs.\nHadietal.\n[71]andMinetal.\n[72]alsoconductLLMsurveysfromtheholisticview,which,however,providedifferenttaxonomiesandunderstandingsonLLMs.\nFollowingthesesurveys,peoplediveintospecificaspectsofLLMsandreviewthecorrespondingmilestonestudiesandkeytechnologies.\nTheseaspectscanbeclassifiedintofourcategoriesincludingthefundamentalproblems,evaluation,applications,andchallengesofLLMs.\nFundamentalproblems.\nThesurveysinthiscategoryaimtosummarizetechniquesthatcanbeleveragedtotacklefundamentalproblemsofLLMs.\nSpecifically,Zhangetal.\n[8]provideacomprehensivesurveyonthemethodsofsupervisedfine-tuning,whichisakeytechniqueforbettertrainingLLMs.\nShenetal.\n[9],Wangetal.\n[10]andLiuetal.\n[11]presentsurveysonthealignmentofLLMs,whichisakeyrequirementforLLMstoproduceoutputsconsistentwithhumanvalues.\nGaoetal.\n[12]proposeasurveyontheretrieval-augmentedgeneration(RAG)capabilityofLLMs,whichiskeytoprovidingLLMswithfactualandup-to-dateknowledgeandremovinghallucinations.\nQinetal.\n[18]summarizethestate-of-the-artmethodsonenablingLLMstoleverageexternaltools,whichisfundamentalforLLMstoexpandtheircapabilityindomainsthatrequirespecializedknowledge.\nWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16]andZhangetal.\n[17]presentsurveysonthedirectionofLLMknowledgeediting,whichisimportantforcustomizingLLMstosatisfyspecificrequirements.\nHuangetal.\n[19],Wangetal.\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32]andParketal.\n[33]systematicallyreviewthetechniquesofmodelcompression.\nDingetal.\n[81]andXuetal.\n[29]analyzeandconcludethestudiesonparameterefficientfine-tuning.\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28]andDingetal.\n[81]putmorefocusesontheefficiencyofresourceutilizationinageneralsense.\nEvaluation.\nThesurveysinthiscategoryfocusonhowtoevaluatethecapabilityofLLMs.\nSpecifi-cally,Changetal.\n[34]comprehensivelysummarizetheevaluationmethodsfromanoverallperspec-tive.\nItencompassesdifferentevaluationtasks,methods,andbenchmarks,whichserveascriticalpartsinassessingLLMperformances.\nGuoetal.\n[35]caremoreabouttheevaluationtargetsanddescribehowtoevaluatetheknowledge,alignment,andsafetycontrolcapabilitiesofLLMs,whichsupplementevaluationmetricsbeyondperformance.\nApplications.\nThesurveysinthiscategoryaimtosummarizemodelsthatleverageLLMstoimprovedifferentapplications.\nMoreconcretely,Zhuetal.\n[37]focusonthefieldofinformationretrieval(IR)andsummarizestudiesonLLM-basedqueryprocesses.\nXuetal.\n[38]paymoreattentiontoinformationextraction(IE)andprovidecomprehensivetaxonomiesforLLM-basedmodelsinthisfield.\nLietal.\n[50],Linetal.\n[51]andWangetal.\n[52]discusstheapplicationsofLLMsinthefieldofrecommendersystem,wheretheyutilizeagentstogeneratedataandproviderecommendations.\nFanetal.\n[39],Wangetal.\n[40],andZhengetal.\n[41]concentrateonhowLLMscanbenefitsoftwareengineering(SE)intermsofsoftwaredesign,development,andtesting.\nZengetal.\n[42]summarizeLLM-basedmethodsinthefieldofrobotics.\nCuietal.\n[43]andYangetal.\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal.",
      "#memory_survey#Limitations&FutureDirections#memory_survey#Limitations&FutureDirections\nLimitations&FutureDirections8.\n1",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\nSurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.\n[70]presentthefirstcomprehensivesurveytosummarizethebackground,evolutionpaths,modelarchitectures,trainingmethodologies,andevaluationstrategiesofLLMs.\nHadietal.\n[71]andMinetal.\n[72]alsoconductLLMsurveysfromtheholisticview,which,however,providedifferenttaxonomiesandunderstandingsonLLMs.\nFollowingthesesurveys,peoplediveintospecificaspectsofLLMsandreviewthecorrespondingmilestonestudiesandkeytechnologies.\nTheseaspectscanbeclassifiedintofourcategoriesincludingthefundamentalproblems,evaluation,applications,andchallengesofLLMs.\nFundamentalproblems.\nThesurveysinthiscategoryaimtosummarizetechniquesthatcanbeleveragedtotacklefundamentalproblemsofLLMs.\nSpecifically,Zhangetal.\n[8]provideacomprehensivesurveyonthemethodsofsupervisedfine-tuning,whichisakeytechniqueforbettertrainingLLMs.\nShenetal.\n[9],Wangetal.\n[10]andLiuetal.\n[11]presentsurveysonthealignmentofLLMs,whichisakeyrequirementforLLMstoproduceoutputsconsistentwithhumanvalues.\nGaoetal.\n[12]proposeasurveyontheretrieval-augmentedgeneration(RAG)capabilityofLLMs,whichiskeytoprovidingLLMswithfactualandup-to-dateknowledgeandremovinghallucinations.\nQinetal.\n[18]summarizethestate-of-the-artmethodsonenablingLLMstoleverageexternaltools,whichisfundamentalforLLMstoexpandtheircapabilityindomainsthatrequirespecializedknowledge.\nWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16]andZhangetal.\n[17]presentsurveysonthedirectionofLLMknowledgeediting,whichisimportantforcustomizingLLMstosatisfyspecificrequirements.\nHuangetal.\n[19],Wangetal.\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal.",
      "#memory_survey#Introduction#memory_survey#Introduction\nIntroduction\"Withoutmemory,thereisnoculture.\nWithoutmemory,therewouldbenocivilization,nosociety,nofuture.\n\"ElieWiesel,1928-2016Recently,largelanguagemodels(LLMs)haveachievedremarkablesuccessinalargenumberofdomains,rangingfromartificialintelligenceandsoftwareengineeringtoeducationandsocialsci-ence[1–3].\nOriginalLLMsusuallyaccomplishdifferenttaskswithoutinteractingwithenvironments.\nHowever,toachievethefinalgoalofartificialgeneralintelligence(AGI),intelligentmachinesshouldbeabletoimprovethemselvesbyautonomouslyexploringandlearningfromtherealworld.\nForexample,ifatrip-planningagentintendstobookaticket,itshouldsendanorderrequesttotheticketwebsite,andobservetheresponsebeforetakingthenextaction.\nApersonalassistantagentshouldadjustitsbehaviorsaccordingtotheuser’sfeedback,providingpersonalizedresponsestoimproveuser’ssatisfaction.\nTofurtherpushtheboundaryofLLMstowardsAGI,recentyearshavewitnessedalargenumberofstudiesonLLM-basedagents[3,4],wherethekeyistoequipLLMswithadditionalmodulestoenhancetheirself-evolvingcapabilityinreal-worldenvironments.\nAmongalltheaddedmodules,memoryisakeycomponentthatdifferentiatestheagentsfromoriginalLLMs,makinganagenttrulyanagent(seeFigure1).\nItplaysanextremelyimportantroleindetermininghowtheagentaccumulatesknowledge,processeshistoricalexperience,retrievesinformativeknowledgetosupportitsactions,andsoon.\nAroundthememorymodule,peoplehavedevotedmuchefforttodesigningitsinformationsources,storageforms,andoperationmechanisms.\nForexample,Shinnetal.\n[5]incorporatebothin-trialandcross-trialinformationtobuildthememorymoduleforenhancingtheagent’sreasoningcapability.\nZhongetal.\n[6]storememoryinformationintheformofnaturallanguages,whichisexplainableandfriendlytotheusers.\nModarressietal.\n[7]designbothmemoryreadingandwritingoperationstointeractwithenvironmentsfortasksolving.\nWhilepreviousstudieshavedesignedmanypromisingmemorymodules,therestilllacksasystemicstudytoviewthememorymodulesfromaholisticperspective.",
      "#memory_survey#Discussions#memory_survey#Discussions\nDiscussionsComparedwithdirectevaluation,indirectevaluationviaspecifictaskscanbeeasiertoconduct,sincetherearealreadymanypublicbenchmarks.\nHowever,theperformanceontaskscanbeattributedtovariousfactors,andmemoryisonlyoneofthem,whichmaymaketheevaluationresultsbiased.\nBydirectevaluation,theeffectivenessofthememorymodulecanbeindependentlyevaluated,whichimprovesthereliabilityoftheevaluationresults.\nHowever,toourknowledge,therearenoopen-sourcedbenchmarkstailoredforthememorymodulesinLLM-basedagents.\n7",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nRecommendation.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n7.\n6ExpertSysteminSpecificDomains.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n7.\n7OtherApplications.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n8Limitations&FutureDirections8.\n1MoreAdvancesinParametricMemory.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n8.\n2MemoryinLLM-basedMulti-agentApplications.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n8.\n3Memory-basedLifelongLearning.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n8.\n4MemoryinHumanoidAgent.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n9Conclusion2323232325252526262627272728282831Introduction\"Withoutmemory,thereisnoculture.\nWithoutmemory,therewouldbenocivilization,nosociety,nofuture.\n\"ElieWiesel,1928-2016Recently,largelanguagemodels(LLMs)haveachievedremarkablesuccessinalargenumberofdomains,rangingfromartificialintelligenceandsoftwareengineeringtoeducationandsocialsci-ence[1–3].\nOriginalLLMsusuallyaccomplishdifferenttaskswithoutinteractingwithenvironments.\nHowever,toachievethefinalgoalofartificialgeneralintelligence(AGI),intelligentmachinesshouldbeabletoimprovethemselvesbyautonomouslyexploringandlearningfromtherealworld.\nForexample,ifatrip-planningagentintendstobookaticket,itshouldsendanorderrequesttotheticketwebsite,andobservetheresponsebeforetakingthenextaction.\nApersonalassistantagentshouldadjustitsbehaviorsaccordingtotheuser’sfeedback,providingpersonalizedresponsestoimproveuser’ssatisfaction.\nTofurtherpushtheboundaryofLLMstowardsAGI,recentyearshavewitnessedalargenumberofstudiesonLLM-basedagents[3,4],wherethekeyistoequipLLMswithadditionalmodulestoenhancetheirself-evolvingcapabilityinreal-worldenvironments.\nAmongalltheaddedmodules,memoryisakeycomponentthatdifferentiatestheagentsfromoriginalLLMs,makinganagenttrulyanagent(seeFigure1).\nItplaysanextremelyimportantroleindetermininghowtheagentaccumulatesknowledge,processeshistoricalexperience,retrievesinformativeknowledgetosupportitsactions,andsoon.",
      "#memory_survey#Memory-basedLifelongLearning#memory_survey#Memory-basedLifelongLearning\nMemory-basedLifelongLearningLifelonglearningisanadvancedtopicinartificialintelligence,extendingthelearningcapabilitiesofagentsacrosstheirlife-longspan[173].\nAgentscancontinuouslyinteractwiththeirenvironment,persistentlyobserveenvironments,andacquireexternalknowledge,enablingamodeofenhancementlikehumans.\nThememoryofanagentiskeytoachievinglifelonglearning,asitneedstolearntostoreandapplythepastobservations.\nLifelonglearninginLLM-basedagentsholdssignificantpracticalvalue,suchasinlong-termsocialsimulationsandpersonalassistance.\nHowever,italsofacesseveralchallenges.\nFirstly,lifelonglearningistemporal,necessitatingthatanagent’smemorycapturestemporality.\nThistemporalitycouldcauseinteractionsbetweenmemories,suchasmemoryoverlap.\nFurthermore,duetotheextendedperiodoflifelonglearning,itneedstostoreavastamountofmemoriesandretrievethemwhenneeded,possiblyincorporatingacertainmechanismforforgetting.\n8.\n4"
    ],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[141]MohitShridhar,XingdiYuan,Marc-AlexandreCôté,YonatanBisk,AdamTrischler,andMatthewHausknecht.\nAlfworld:Aligningtextandembodiedenvironmentsforinteractivelearning.\narXivpreprintarXiv:2010.\n03768,2020.\n[142]YunDaTsai,MingjieLiu,andHaoxingRen.\nRtlfixer:Automaticallyfixingrtlsyntaxerrorswithlargelanguagemodels.\narXivpreprintarXiv:2311.\n16543,2023.\n[143]ChengLi,ZiangLeng,ChenxiYan,JunyiShen,HaoWang,WeishiMi,YayingFei,XiaoyangFeng,SongYan,HaoShengWang,etal.\nChatharuhi:Revivinganimecharacterinrealityvialargelanguagemodel.\narXivpreprintarXiv:2308.\n09597,2023.\n[144]DakeChen,HanbinWang,YunhaoHuo,YuzhaoLi,andHaoyangZhang.\nGamegpt:Multi-agentcollaborativeframeworkforgamedevelopment.\narXivpreprintarXiv:2310.\n08067,2023.\n[145]ZekunMooreWang,ZhongyuanPeng,HaoranQue,JiahengLiu,WangchunshuZhou,YuhanWu,HongchengGuo,RuitongGan,ZehaoNi,ManZhang,etal.\nRolellm:Benchmarking,eliciting,andenhancingrole-playingabilitiesoflargelanguagemodels.\narXivpreprintarXiv:2310.\n00746,2023.\n[146]RuncongZhao,WenjiaZhang,JiazhengLi,LixingZhu,YanranLi,YulanHe,andLinGui.\nNarrativeplay:Interactivenarrativeunderstanding.\narXivpreprintarXiv:2310.\n01459,2023.\n[147]JinfengZhou,ZhuangChen,DazhenWan,BosiWen,YiSong,JifanYu,YongkangHuang,Lib-iaoPeng,JiamingYang,XiyaoXiao,etal.\nCharacterglm:Customizingchineseconversationalaicharacterswithlargelanguagemodels.\narXivpreprintarXiv:2311.\n16832,2023.\n[148]ZhaoKaiya,MichelangeloNaim,JovanaKondic,ManuelCortes,JiaxinGe,ShuyingLuo,GuangyuRobertYang,andAndrewAhn.\nLyfeagents:Generativeagentsforlow-costreal-timesocialinteractions.\narXivpreprintarXiv:2310.\n02172,2023.\n[149]JunjieZhang,YupengHou,RuobingXie,WenqiSun,JulianMcAuley,WayneXinZhao,LeyuLin,andJi-RongWen.\nAgentcf:Collaborativelearningwithautonomouslanguageagentsforrecommendersystems.\narXivpreprintarXiv:2310.\n09233,2023.\n[150]WenyueHua,LizhouFan,LingyaoLi,KaiMei,JianchaoJi,YingqiangGe,LibbyHemphill,andYongfengZhang.\nWarandpeace(waragent):Largelanguagemodel-basedmulti-agentsimulationofworldwars.\narXivpreprintarXiv:2311.\n17227,2023.",
      "#memory_survey#ExternalKnowledge#memory_survey#ExternalKnowledge\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain.\nItfine-tunesanacquisitionprocesstoretrieveexternalknowledgefromWikipediaandmedicaldatabases.\nDiscussion.\nTheexternalknowledgecanbeobtainedfrombothprivateandpublicsources.\nItprovidesLLM-basedagentswithmuchknowledgebeyondtheirinternalenvironment,whichmightbedifficultorevenimpossiblefortheagenttoacquirebyagent-environmentinteractions.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nManypreviousstudieshaveexploredmethodsforconstructingrolememories[105,143,145–147].\nShaoetal.\n[105]constructthememoryofrolesbyexperienceuploading,whichutilizesSFTtoinjectmemoryintomodelparameters.\nLietal.\n[143]enhancelargelanguagemodelsforrole-playingviaanimprovedpromptandthecharactermemoryextractedfromscripts,whereuserqueriesand23Table4:Summarizationofmemory-enhancedagentsapplications.\nApplicationsModelsApplicationsModelsRole-playingSocialSimulationPersonalAssistantGameCharacter-LLM[105]ChatHaruhi[143]RoleLLM[145]NarrativePlay[146]CharacterGLM[147]GenerativeAgents[83]LyfeAgents[148]S3[2]MetaAgents[109]WarAgent[150]MemoryBank[6]RET-LLM[7]MemoChat[94]MemGPT[100]MPC[101]AutoGen[153]ChatDB[96]TiM[97]SCM[98]Voyager[99]GITM[93]JARVIS[159]LARP[161]CodeGenerationRecommendationMedicineFinanceScienceRTLFixer[142]GameGPT[144]ChatDev[1]MetaGPT[109]CodeAgent[114]RecAgent[95]InteRecAgent[108]RecMind[102]AgentCF[149]Huatuo[107]DoctorGLM[129]Radiology-GPT[132]Wangetal.\n[151]EHRAgent[152]ChatDoctor[115]InvestLM[113]TradingGPT[154]QuantAgent[155]FinMem[156]Koaetal.\n[157]Chemist-X[158]ChemDFM[160]MatChat[162]chatbot’sresponsesareconcatenatedtoformasequenceasmemory.\nWangetal.\n[145]infuserole-specificknowledgeandepisodememoriesintoLLM-basedagents,wherecontextQApairsareconcatenatedtoformepisodememory.\nZhaoetal.\n[146]aimtogeneratehuman-likeresponses,guidedbypersonalitytraitsextractedfromnarratives,whichcanbestoredandretrievedbyrelevanceandimportance.\nZhouetal.\n[147]generatecharacter-baseddialoguesfordifferentrolesandempowerLLM-basedagentswithcorrespondingstylesbySFT.\nSocialsimulationisbasicallyanextensionofrole-playing,whichfocusesmoreonmulti-agentmodeling.\nThememorymoduleisanimportantcomponentforsuchapplications,whichhelpstoaccuratelysimulatehumandynamicbehaviors.\nInpreviousstudies,Kaiyaetal.\n[148]proposeaSummarize-and-Forgetmemorymechanismforbetterself-monitoringinsocialscenarios.\nGaoetal.\n[2]focusonsocialnetworksimulationsystems.",
      "#memory_survey#Conversation#memory_survey#Conversation\nConversationEngaginginconversationswithhumansisoneofthemostimportantapplicationsofagents,wherememoryplaysacrucialroleinthisprocess.\nBystoringcontextinformationinmemory,theagentsallowuserstoexperiencepersonalizedconversations,thusimprovingusers’satisfaction.\nTherefore,whenotherpartsoftheagentsaredetermined,theperformanceoftheconversationtaskscanreflecttheeffectivenessofdifferentmemorymodules.\nInthecontextofconversation,consistencyandengagementaretwocommonlyusedmethodstoevaluatetheeffectivenessoftheagents’memory.\nConsistencyreferstohowtheresponsefromagentsisconsistentwiththecontextbecausedramaticchangesshouldbeavoidedduringtheconversation.\nForexample,Luetal.\n[94]evaluatetheconsistencyofagentsoninteractivedialogues,usingGPT-4toscoreontheresponsesfromagents.\nEngagementreferstohowtheuserisengagedtocontinuetheconversation.\nItreflectsthequalityandattractionofagents’responses,aswellastheabilityofagentstocraftthepersonasforcurrentconversations.\nForexample,Leeetal.\n[101]assesstheengagingnessofresponsesbySCE-pscore,andPackeretal.\n[100]utilizeCSIMscoretoevaluatethememoryeffectonincreasingengagementofusers.\n6.\n2.\n2",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[150]WenyueHua,LizhouFan,LingyaoLi,KaiMei,JianchaoJi,YingqiangGe,LibbyHemphill,andYongfengZhang.\nWarandpeace(waragent):Largelanguagemodel-basedmulti-agentsimulationofworldwars.\narXivpreprintarXiv:2311.\n17227,2023.\n[151]HaochunWang,SendongZhao,ZewenQiang,ZijianLi,NuwaXi,YanruiDu,MuZhenCai,HaoqiangGuo,YuhanChen,HaomingXu,etal.\nKnowledge-tuninglargelanguagemodelswithstructuredmedicalknowledgebasesforreliableresponsegenerationinchinese.\narXivpreprintarXiv:2309.\n04175,2023.\n[152]WenqiShi,RanXu,YuchenZhuang,YueYu,JieyuZhang,HangWu,YuandaZhu,JoyceHo,CarlYang,andMayDWang.\nEhragent:Codeempowerslargelanguagemodelsforcomplextabularreasoningonelectronichealthrecords.\narXivpreprintarXiv:2401.\n07128,2024.\n[153]QingyunWu,GaganBansal,JieyuZhang,YiranWu,ShaokunZhang,ErkangZhu,BeibinLi,LiJiang,XiaoyunZhang,andChiWang.\nAutogen:Enablingnext-genllmapplicationsviamulti-agentconversationframework.\narXivpreprintarXiv:2308.\n08155,2023.\n[154]YangLi,YangyangYu,HaohangLi,ZhiChen,andKhaldounKhashanah.\nTradinggpt:Multi-agentsystemwithlayeredmemoryanddistinctcharactersforenhancedfinancialtradingperformance.\narXivpreprintarXiv:2309.\n03736,2023.\n[155]SaizhuoWang,HangYuan,LionelMNi,andJianGuo.\nQuantagent:Seekingholygrailintradingbyself-improvinglargelanguagemodel.\narXivpreprintarXiv:2402.\n03755,2024.\n37[156]YangyangYu,HaohangLi,ZhiChen,YuechenJiang,YangLi,DenghuiZhang,RongLiu,JordanWSuchow,andKhaldounKhashanah.\nFinmem:Aperformance-enhancedllmtradingagentwithlayeredmemoryandcharacterdesign.\narXive-prints,pagesarXiv–2311,2023.\n[157]KelvinJLKoa,YunshanMa,RitchieNg,andTat-SengChua.\nLearningtogenerateexplainablestockpredictionsusingself-reflectivelargelanguagemodels.\narXivpreprintarXiv:2402.\n03659,2024.\n[158]KexinChen,JunyouLi,KunyiWang,YuyangDu,JiahuiYu,JiaminLu,LanqingLi,JiezhongQiu,JianzhangPan,YiHuang,QunFang,PhengAnnHeng,andGuangyongChen.\nChemist-x:Largelanguagemodel-empoweredagentforreactionconditionrecommendationinchemicalsynthesis,2024.",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal.\n[47]summarizetheapplicationsofLLMsinmedicine.\nLietal.\n[48]focusontheapplicationsofLLMsinfinance.\nHeetal.\n[49]reviewthemodelsonleveragingLLMstoimprovethedevelopmentofpsychology.\n5SupervisedFine-tuningZhangetal.\n[8].\nAlignmentShenetal.\n[9],Wangetal.\n[10],Liuetal.\n[11].\nRetrievalAugmentationGaoetal.\n[12].\nKnowledgeEditingWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16],Zhangetal.\n[17].\nFundamentalProblemsToolUsageQinetal.\n[18].\nLong-contextMultimodalEfficiencyHuangetal.\n[19],Wangetal.\n[20],Pawaretal.\n[21].\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24],Yinetal.\n[25].\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28,28],Xuetal.\n[29],Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32],Parketal.\n[33].\nEvaluationChangetal.\n[34],Guoetal.\n[35].\nInformationProcessingSoftwareEngineeringYangetal.\n[36],Zhuetal.\n[37],Xuetal.\n[38].\nFanetal.\n[39],Wangetal.\n[40],Zhengetal.\n[41].\nRoboticsZengetal.\n[42].\nApplicationsAutonomousDrivingCuietal.\n[43],Yangetal.\n[44].\nLLMs[70–73]MedecineFinancePsychologyHeetal.\n[45],Zhouetal.\n[46],Wangetal.\n[47].\nLietal.\n[48].\nHeetal.\n[49].\nRecommendationLietal.\n[50],Linetal.\n[51],Wangetal.\n[52].\nHallucinationZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Ton-moyetal.\n[58],Jiangetal.\n[59].\nChallengesBias&FairnessGallegosetal.\n[60],Koteketal.\n[61],Lietal.\n[62].\nExplainabilityZhaoetal.\n[63].\nSecurityYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68],Dasetal.\n[69].\nPlanningHuangetal.\n[74].\nFundamentalProblemsMemoryOurSurvey.\nMulti-agentsGuoetal.\n[75].\nLLM-basedAgent[3,4,77–80]EvaluationApplicationsChallengesLietal.\n[76].\nFigure2:TheorganizationofrelatedsurveysonLLMsandLLM-basedagents.\n6Challenges.\nThesurveysinthiscategoryfocusontrustworthinessinLLMs,suchashallucination,bias,unfairness,explainability,security,andprivacy.",
      "#memory_survey#Memory-enhancedAgentApplications#memory_survey#Memory-enhancedAgentApplications\nMemory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68],Dasetal.\n[69].\nPlanningHuangetal.\n[74].\nFundamentalProblemsMemoryOurSurvey.\nMulti-agentsGuoetal.\n[75].\nLLM-basedAgent[3,4,77–80]EvaluationApplicationsChallengesLietal.\n[76].\nFigure2:TheorganizationofrelatedsurveysonLLMsandLLM-basedagents.\n6Challenges.\nThesurveysinthiscategoryfocusontrustworthinessinLLMs,suchashallucination,bias,unfairness,explainability,security,andprivacy.\nHallucinationinLLMsreferstotheproblemthatLLMsmaygeneratemisconceptionsorfabrications,impactingtheirreliabilityfordownstreamapplications.\nZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Tonmoyetal.\n[58]andJiangetal.\n[59]summarizethemainstreammodelsforalleviatingthehallucinationprobleminLLMs.\nThebiasandunfairnessproblemsrefertothephenomenonthatLLMsmayunequallytreatdifferenthumansorobjectives,whichcanleadtothepropagationofsocietalstereotypesanddiscrimination.\nGallegosetal.\n[60],Koteketal.\n[61]andLietal.\n[62]comprehensivelydiscussthesechallengesandsummarizeexistingmethodsforalleviatingthem.\nTheproblemofexplainabilitymeansthattheinternalworkingmechanismsofLLMsarestillunclear.\nZhaoetal.\n[63]systematicallydiscussthisproblemandsummarizepreviouseffortsonimprovingtheexplainabilityofLLMs.\nSecurityandprivacyarealsochallengingproblems,whichhavebeencomprehensivelysurveyedinYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68]andDasetal.\n[69].\n2.\n2SurveysonLargeLanguageModel-basedAgentsBasedonthecapabilityofLLMs,peoplehaveconductedalotofstudiesonbuildingLLM-basedagents,whichcanautonomouslyperceiveenvironments,takeactions,accumulateknowledge,andevolvethemselves.\nInthisfield,Wangetal.\n[3]presentthefirstsurveypapertosystematicallysummarizeLLM-basedagentsfromtheperspectivesofagentconstruction,agentapplication,andagentevaluation.\nXietal.\n[4],Zhaoetal.\n[77],Chengetal.\n[78]andGeetal.\n[80]alsosummarizeLLM-basedagentstudiesfromtheoverallperspective,buttheyhavedifferentfocusesandtaxonomies,deliveringmorediverseunderstandingsonthisfield.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\nACMComputingSurveys,56(2):1–40,2023.\n[73]GrégoireMialon,RobertoDessì,MariaLomeli,ChristoforosNalmpantis,RamPasunuru,RobertaRaileanu,BaptisteRozière,TimoSchick,JaneDwivedi-Yu,AsliCelikyilmaz,etal.\nAugmentedlanguagemodels:asurvey.\narXivpreprintarXiv:2302.\n07842,2023.\n[74]XuHuang,WeiwenLiu,XiaolongChen,XingmeiWang,HaoWang,DefuLian,YashengWang,RuimingTang,andEnhongChen.\nUnderstandingtheplanningofllmagents:Asurvey.\narXivpreprintarXiv:2402.\n02716,2024.\n[75]TaichengGuo,XiuyingChen,YaqiWang,RuidiChang,ShichaoPei,NiteshVChawla,OlafWiest,andXiangliangZhang.\nLargelanguagemodelbasedmulti-agents:Asurveyofprogressandchallenges.\narXivpreprintarXiv:2402.\n01680,2024.\n[76]YuanchunLi,HaoWen,WeijunWang,XiangyuLi,YizhenYuan,GuohongLiu,JiachengLiu,WenxingXu,XiangWang,YiSun,etal.\nPersonalllmagents:Insightsandsurveyaboutthecapability,efficiencyandsecurity.\narXivpreprintarXiv:2401.\n05459,2024.\n[77]PengyuZhao,ZijianJin,andNingCheng.\nAnin-depthsurveyoflargelanguagemodel-basedartificialintelligenceagents.\narXivpreprintarXiv:2309.\n14365,2023.\n[78]YuhengCheng,CeyaoZhang,ZhengwenZhang,XiangruiMeng,SiruiHong,WenhaoLi,ZihaoWang,ZekaiWang,FengYin,JunhuaZhao,etal.\nExploringlargelanguagemodelbasedintelligentagents:Definitions,methods,andprospects.\narXivpreprintarXiv:2401.\n03428,2024.\n[79]ZaneDurante,QiuyuanHuang,NaokiWake,RanGong,JaeSungPark,BidiptaSarkar,RohanTaori,YusukeNoda,DemetriTerzopoulos,YejinChoi,etal.\nAgentai:Surveyingthehorizonsofmultimodalinteraction.\narXivpreprintarXiv:2401.\n03568,2024.\n[80]YingqiangGe,YujieRen,WenyueHua,ShuyuanXu,JuntaoTan,andYongfengZhang.\nLlmasos(llmao),agentsasapps:Envisioningaios,agentsandtheaios-agentecosystem.\narXivpreprintarXiv:2312.\n03815,2023.\n[81]NingDing,YujiaQin,GuangYang,FuchaoWei,ZonghanYang,YushengSu,ShengdingHu,YulinChen,Chi-MinChan,WeizeChen,etal.\nDeltatuning:Acomprehensivestudyofparameterefficientmethodsforpre-trainedlanguagemodels.\narXivpreprintarXiv:2203.\n06904,2022.\n[82]AndrewZhao,DanielHuang,QuentinXu,MatthieuLin,Yong-JinLiu,andGaoHuang.\nExpel:Llmagentsareexperientiallearners.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\nGhostintheminecraft:Generallycapableagentsforopen-worldenviromentsvialargelanguagemodelswithtext-basedknowledgeandmemory.\narXivpreprintarXiv:2305.\n17144,2023.\n[94]JunruLu,SiyuAn,MingbaoLin,GabrielePergola,YulanHe,DiYin,XingSun,andYun-shengWu.\nMemochat:Tuningllmstousememosforconsistentlong-rangeopen-domainconversation.\narXivpreprintarXiv:2308.\n08239,2023.\n[95]LeiWang,JingsenZhang,HaoYang,ZhiyuanChen,JiakaiTang,ZeyuZhang,XuChen,YankaiLin,RuihuaSong,WayneXinZhao,JunXu,ZhichengDou,JunWang,andJi-RongWen.\nWhenlargelanguagemodelbasedagentmeetsuserbehavioranalysis:Anovelusersimulationparadigm,2023.\n[96]ChenxuHu,JieFu,ChenzhuangDu,SimianLuo,JunboZhao,andHangZhao.\nChatdb:Augmentingllmswithdatabasesastheirsymbolicmemory.\narXivpreprintarXiv:2306.\n03901,2023.\n[97]LeiLiu,XiaoyanYang,YueShen,BinbinHu,ZhiqiangZhang,JinjieGu,andGuannanZhang.\nThink-in-memory:Recallingandpost-thinkingenablellmswithlong-termmemory.\narXivpreprintarXiv:2311.\n08719,2023.\n[98]XinnianLiang,BingWang,HuiHuang,ShuangzhiWu,PeihaoWu,LuLu,ZejunMa,andZhoujunLi.\nUnleashinginfinite-lengthinputcapacityforlarge-scalelanguagemodelswithself-controlledmemorysystem.\narXivpreprintarXiv:2304.\n13343,2023.\n[99]GuanzhiWang,YuqiXie,YunfanJiang,AjayMandlekar,ChaoweiXiao,YukeZhu,LinxiFan,andAnimaAnandkumar.\nVoyager:Anopen-endedembodiedagentwithlargelanguagemodels.\narXivpreprintarXiv:2305.\n16291,2023.\n[100]CharlesPacker,VivianFang,ShishirGPatil,KevinLin,SarahWooders,andJosephEGonzalez.\nMemgpt:Towardsllmsasoperatingsystems.\narXivpreprintarXiv:2310.\n08560,2023.\n[101]GibbeumLee,VolkerHartmann,JonghoPark,DimitrisPapailiopoulos,andKangwookLee.\nPromptedllmsaschatbotmodulesforlongopen-domainconversation.\narXivpreprintarXiv:2305.\n04533,2023.\n[102]YanchengWang,ZiyanJiang,ZhengChen,FanYang,YingxueZhou,EunahCho,XingFan,XiaojiangHuang,YanbinLu,andYingzhenYang.\nRecmind:Largelanguagemodelpoweredagentforrecommendation.\narXivpreprintarXiv:2308.\n14296,2023.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[158]KexinChen,JunyouLi,KunyiWang,YuyangDu,JiahuiYu,JiaminLu,LanqingLi,JiezhongQiu,JianzhangPan,YiHuang,QunFang,PhengAnnHeng,andGuangyongChen.\nChemist-x:Largelanguagemodel-empoweredagentforreactionconditionrecommendationinchemicalsynthesis,2024.\n[159]ZihaoWang,ShaofeiCai,AnjiLiu,YonggangJin,JinbingHou,BoweiZhang,HaoweiLin,ZhaofengHe,ZilongZheng,YaodongYang,etal.\nJarvis-1:Open-worldmulti-taskagentswithmemory-augmentedmultimodallanguagemodels.\narXivpreprintarXiv:2311.\n05997,2023.\n[160]ZihanZhao,DaMa,LuChen,LiangtaiSun,ZihaoLi,HongshenXu,ZichenZhu,SuZhu,ShuaiFan,GuodongShen,etal.\nChemdfm:Dialoguefoundationmodelforchemistry.\narXivpreprintarXiv:2401.\n14818,2024.\n[161]MingYan,RuihaoLi,HaoZhang,HaoWang,ZhilanYang,andJiYan.\nLarp:Language-agentroleplayforopen-worldgames.\narXivpreprintarXiv:2312.\n17653,2023.\n[162]Zi-YiChen,Fan-KaiXie,MengWan,YangYuan,MiaoLiu,Zong-GuoWang,ShengMeng,andYan-GangWang.\nMatchat:Alargelanguagemodelandapplicationserviceplatformformaterialsscience.\nChinesePhysicsB,32(11):118104,2023.\n[163]NianLi,ChenGao,YongLi,andQingminLiao.\nLargelanguagemodel-empoweredagentsforsimulatingmacroeconomicactivities.\narXivpreprintarXiv:2310.\n10436,2023.\n[164]HaojiePan,ZepengZhai,HaoYuan,YaojiaLv,RuijiFu,MingLiu,ZhongyuanWang,andBingQin.\nKwaiagents:Generalizedinformation-seekingagentsystemwithlargelanguagemodels.\narXivpreprintarXiv:2312.\n04889,2023.\n[165]OdmaByambasuren,YunfeiYang,ZhifangSui,DamaiDai,BaobaoChang,SujianLi,andHongyingZan.\nPreliminarystudyontheconstructionofchinesemedicalknowledgegraph.\nJournalofChineseInformationProcessing,33(10):1–9,2019.\n[166]ZefanWang,ZichuanLiu,YingyingZhang,AoxiaoZhong,LuntingFan,LingfeiWu,andQingsongWen.\nRcagent:Cloudrootcauseanalysisbyautonomousagentswithtool-augmentedlargelanguagemodels.\narXivpreprintarXiv:2310.\n16340,2023.\n[167]ZhangchengQiang,WeiqingWang,andKerryTaylor.\nAgent-om:Leveraginglargelanguagemodelsforontologymatching.\narXivpreprintarXiv:2312.\n00326,2023.\n[168]LichengWen,DaochengFu,XinLi,XinyuCai,TaoMa,PinlongCai,MinDou,BotianShi,LiangHe,andYuQiao.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\n[40],andZhengetal.\n[41]concentrateonhowLLMscanbenefitsoftwareengineering(SE)intermsofsoftwaredesign,development,andtesting.\nZengetal.\n[42]summarizeLLM-basedmethodsinthefieldofrobotics.\nCuietal.\n[43]andYangetal.\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal.\n[47]summarizetheapplicationsofLLMsinmedicine.\nLietal.\n[48]focusontheapplicationsofLLMsinfinance.\nHeetal.\n[49]reviewthemodelsonleveragingLLMstoimprovethedevelopmentofpsychology.\n5SupervisedFine-tuningZhangetal.\n[8].\nAlignmentShenetal.\n[9],Wangetal.\n[10],Liuetal.\n[11].\nRetrievalAugmentationGaoetal.\n[12].\nKnowledgeEditingWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16],Zhangetal.\n[17].\nFundamentalProblemsToolUsageQinetal.\n[18].\nLong-contextMultimodalEfficiencyHuangetal.\n[19],Wangetal.\n[20],Pawaretal.\n[21].\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24],Yinetal.\n[25].\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28,28],Xuetal.\n[29],Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32],Parketal.\n[33].\nEvaluationChangetal.\n[34],Guoetal.\n[35].\nInformationProcessingSoftwareEngineeringYangetal.\n[36],Zhuetal.\n[37],Xuetal.\n[38].\nFanetal.\n[39],Wangetal.\n[40],Zhengetal.\n[41].\nRoboticsZengetal.\n[42].\nApplicationsAutonomousDrivingCuietal.\n[43],Yangetal.\n[44].\nLLMs[70–73]MedecineFinancePsychologyHeetal.\n[45],Zhouetal.\n[46],Wangetal.\n[47].\nLietal.\n[48].\nHeetal.\n[49].\nRecommendationLietal.\n[50],Linetal.\n[51],Wangetal.\n[52].\nHallucinationZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Ton-moyetal.\n[58],Jiangetal.\n[59].\nChallengesBias&FairnessGallegosetal.\n[60],Koteketal.\n[61],Lietal.\n[62].\nExplainabilityZhaoetal.\n[63].\nSecurityYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68],Dasetal.\n[69].\nPlanningHuangetal.\n[74].\nFundamentalProblemsMemoryOurSurvey.\nMulti-agentsGuoetal.\n[75].\nLLM-basedAgent[3,4,77–80]EvaluationApplicationsChallengesLietal.\n[76].",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[102]YanchengWang,ZiyanJiang,ZhengChen,FanYang,YingxueZhou,EunahCho,XingFan,XiaojiangHuang,YanbinLu,andYingzhenYang.\nRecmind:Largelanguagemodelpoweredagentforrecommendation.\narXivpreprintarXiv:2308.\n14296,2023.\n[103]WeiranYao,ShelbyHeinecke,JuanCarlosNiebles,ZhiweiLiu,YihaoFeng,LeXue,RitheshMurthy,ZeyuanChen,JianguoZhang,DevanshArpit,etal.\nRetroformer:Retrospectivelargelanguageagentswithpolicygradientoptimization.\narXivpreprintarXiv:2308.\n02151,2023.\n[104]ShunyuYao,JeffreyZhao,DianYu,NanDu,IzhakShafran,KarthikNarasimhan,andYuanCao.\nReact:Synergizingreasoningandactinginlanguagemodels.\narXivpreprintarXiv:2210.\n03629,2022.\n34[105]YunfanShao,LinyangLi,JunqiDai,andXipengQiu.\nCharacter-llm:Atrainableagentforrole-playing.\narXivpreprintarXiv:2310.\n10158,2023.\n[106]JihoonTack,JaehyungKim,EricMitchell,JinwooShin,YeeWhyeTeh,andJonathanRichardSchwarz.\nOnlineadaptationoflanguagemodelswithamemoryofamortizedcontexts.\narXivpreprintarXiv:2403.\n04317,2024.\n[107]HaochunWang,ChiLiu,NuwaXi,ZewenQiang,SendongZhao,BingQin,andTingLiu.\nHu-atuo:Tuningllamamodelwithchinesemedicalknowledge.\narXivpreprintarXiv:2304.\n06975,2023.\n[108]XuHuang,JianxunLian,YuxuanLei,JingYao,DefuLian,andXingXie.\nRecommenderaiagent:Integratinglargelanguagemodelsforinteractiverecommendations.\narXivpreprintarXiv:2308.\n16505,2023.\n[109]YuanLi,YixuanZhang,andLichaoSun.\nMetaagents:Simulatinginteractionsofhumanbehaviorsforllm-basedtask-orientedcoordinationviacollaborativegenerativeagents.\narXivpreprintarXiv:2310.\n06500,2023.\n[110]JingqingRuan,YihongChen,BinZhang,ZhiweiXu,TianpengBao,GuoqingDu,ShiweiShi,HangyuMao,XingyuZeng,andRuiZhao.\nTptu:Taskplanningandtoolusageoflargelanguagemodel-basedaiagents.\narXivpreprintarXiv:2308.\n03427,2023.\n[111]YilunKong,JingqingRuan,YihongChen,BinZhang,TianpengBao,ShiweiShi,GuoqingDu,XiaoruHu,HangyuMao,ZiyueLi,etal.\nTptu-v2:Boostingtaskplanningandtoolusageoflargelanguagemodel-basedagentsinreal-worldsystems.\narXivpreprintarXiv:2311.\n11315,2023.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThememorymoduleisanimportantcomponentforsuchapplications,whichhelpstoaccuratelysimulatehumandynamicbehaviors.\nInpreviousstudies,Kaiyaetal.\n[148]proposeaSummarize-and-Forgetmemorymechanismforbetterself-monitoringinsocialscenarios.\nGaoetal.\n[2]focusonsocialnetworksimulationsystems.\nEachagentinthesystemhasamemorypool,whichconsistsofdiverseusermessagesfromonlineplatformstoidentifytheuser.\nLietal.\n[163]maintainconversationcontexts,encompassingtheeconomicenvironmentandagentdecisionsfrompreviousmonths,inordertosimulatetheimpactofbroadmacroeconomictrendsonagents’decision-makingandtomaketheagentsgraspmarketdynamics.\nLietal.\n[109]simulatethejob-seekingscenarioinhumansociety,wherethememoryofagentsincludesprofilesandgoalsinitiallyandisfurtherenrichedwithotherinformation,likedialoguesandpersonalreflections.\nHuaetal.\n[150]simulatethedecisionsandconsequencesoftheparticipatingcountriesinthewars,wheretheconversationsofagentsarecontinuouslymaintainedintomemory.\nThereareseveralinsightsindesigninganagent’smemoryforrole-playandsocialsimulation.\nFirst,thememoryshouldbeconsistentwiththeroles’characteristics,whichcanbeusedtoidentifyeachroleanddistinguishitfromtheothers.\nThisiscrucialforimprovingtherealismofrole-playandthediversityofsocialsimulation.\nSecond,thememoryshouldappropriatelyinfluencethesubsequent24actionsoftheagenttoensuretheconsistencyandrationalityofitsbehaviors.\nAdditionally,forhumanoidagents,theirmemorymechanismsshouldalignwiththefeaturesofhumanmemory,suchasforgettingandlong/short-termmemory,whichshouldrefertothetheoriesofcognitivepsychology.\n7.\n2PersonalAssistantLLM-basedagentsarewell-suitedforcreatingpersonalassistants,suchasagentscapableofengaginginlong-termconversationswithusers[94,101,153],aswellasthosetaskedwithautomaticallyseekinginformation[164].\nTheseagentsoftenneedtomemorizepreviousdialoguestomaintaintheconsistency,andremembercriticalstylesandeventstogeneratemorepersonalizedandrelevantresponses.\nLuetal.",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\nFigure2:TheorganizationofrelatedsurveysonLLMsandLLM-basedagents.\n6Challenges.\nThesurveysinthiscategoryfocusontrustworthinessinLLMs,suchashallucination,bias,unfairness,explainability,security,andprivacy.\nHallucinationinLLMsreferstotheproblemthatLLMsmaygeneratemisconceptionsorfabrications,impactingtheirreliabilityfordownstreamapplications.\nZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Tonmoyetal.\n[58]andJiangetal.\n[59]summarizethemainstreammodelsforalleviatingthehallucinationprobleminLLMs.\nThebiasandunfairnessproblemsrefertothephenomenonthatLLMsmayunequallytreatdifferenthumansorobjectives,whichcanleadtothepropagationofsocietalstereotypesanddiscrimination.\nGallegosetal.\n[60],Koteketal.\n[61]andLietal.\n[62]comprehensivelydiscussthesechallengesandsummarizeexistingmethodsforalleviatingthem.\nTheproblemofexplainabilitymeansthattheinternalworkingmechanismsofLLMsarestillunclear.\nZhaoetal.\n[63]systematicallydiscussthisproblemandsummarizepreviouseffortsonimprovingtheexplainabilityofLLMs.\nSecurityandprivacyarealsochallengingproblems,whichhavebeencomprehensivelysurveyedinYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68]andDasetal.\n[69].\n2.\n2",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.\nAnotherlimitationoffine-tuningliesinthecomputationalcostandtimeconsumption,aswellastherequirementofalargeamountofdata.\nTherefore,mostfine-tuningapproachesareappliedtoofflinescenarios,andcanseldomdealwithonlinescenarios,suchasfine-tuningwithagentobservationsandtrialexperiences.\nDuetothefrequentagent-environmentinteractions,itisunaffordableforthecostofbackpropagationtofine-tuneeverystepoftheonlineanddynamicinteractions.\nMemoryEditingMethods."
    ],
    [
      "#memory_survey#ExternalKnowledge#memory_survey#ExternalKnowledge\nItshouldbenotedthattheinside-trialinformationnotonlyincludesagent-environmentinteractions,butalsocontainsinteractioncontexts,suchastimeandlocationinformation.\n12Discussion.\nTheinside-trialinformationisthemostobviousandintuitivesourcethatshouldbeleveragedtoconstructtheagent’smemorysinceitishighlyrelevanttothecurrenttaskthattheagenthastoaccomplish.\nHowever,relyingsolelyoninside-trialinformationmaypreventtheagentfromaccumulatingvaluableknowledgefromvarioustasksandlearningmoregeneralizableinformation.\nThus,manystudiesalsoexplorehowtoeffectivelyutilizetheinformationacrossdifferenttaskstobuildthememorymodule,whichisdetailedinthefollowingsections.\n5.\n1.\n2Cross-trialInformationForLLM-basedagents,theinformationaccumulatedacrossmultipletrialsintheenvironmentisalsoacrucialpartofthememory,typicallyincludingsuccessfulandfailedactionsandtheirinsights,suchasfailurereasons,commonactionpatternstosucceed,andsoon.\nRepresentativeStudies.\nOneofthemostprominentstudiesisReflexion[5],whichproposesverbalreinforcementlearningforLLM-basedagents.\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTiM[97]aimstoenhancetheagent’sreasoningcapabilitybyself-generatingmultiplethoughtsafteraccomplishingatask,whichisusedasthememorytoprovidemoregeneralizableinformation.\nVoyager[99]focusesonbuildinggameagentsbasedonMinecraft,wherethememorycontainsexecutablecodesofpreliminaryandbasicactionstoaccomplishatask.\nItshouldbenotedthattheinside-trialinformationnotonlyincludesagent-environmentinteractions,butalsocontainsinteractioncontexts,suchastimeandlocationinformation.\n12Discussion.\nTheinside-trialinformationisthemostobviousandintuitivesourcethatshouldbeleveragedtoconstructtheagent’smemorysinceitishighlyrelevanttothecurrenttaskthattheagenthastoaccomplish.\nHowever,relyingsolelyoninside-trialinformationmaypreventtheagentfromaccumulatingvaluableknowledgefromvarioustasksandlearningmoregeneralizableinformation.\nThus,manystudiesalsoexplorehowtoeffectivelyutilizetheinformationacrossdifferenttaskstobuildthememorymodule,whichisdetailedinthefollowingsections.\n5.\n1.\n2Cross-trialInformationForLLM-basedagents,theinformationaccumulatedacrossmultipletrialsintheenvironmentisalsoacrucialpartofthememory,typicallyincludingsuccessfulandfailedactionsandtheirinsights,suchasfailurereasons,commonactionpatternstosucceed,andsoon.\nRepresentativeStudies.\nOneofthemostprominentstudiesisReflexion[5],whichproposesverbalreinforcementlearningforLLM-basedagents.\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nThememoryofanagentisderivedfromthehistoricalbehaviorstoachieveatarget,forexample,thecollectionofrelevantpaperswhenresearchingonaspecifictopic.\nMemoChat[94]aimstochatwithhumans,wherethememoryoftheagentisderivedbasedontheconversationhistoryofadialoguesession.\nTiM[97]aimstoenhancetheagent’sreasoningcapabilitybyself-generatingmultiplethoughtsafteraccomplishingatask,whichisusedasthememorytoprovidemoregeneralizableinformation.\nVoyager[99]focusesonbuildinggameagentsbasedonMinecraft,wherethememorycontainsexecutablecodesofpreliminaryandbasicactionstoaccomplishatask.\nItshouldbenotedthattheinside-trialinformationnotonlyincludesagent-environmentinteractions,butalsocontainsinteractioncontexts,suchastimeandlocationinformation.\n12Discussion.\nTheinside-trialinformationisthemostobviousandintuitivesourcethatshouldbeleveragedtoconstructtheagent’smemorysinceitishighlyrelevanttothecurrenttaskthattheagenthastoaccomplish.\nHowever,relyingsolelyoninside-trialinformationmaypreventtheagentfromaccumulatingvaluableknowledgefromvarioustasksandlearningmoregeneralizableinformation.\nThus,manystudiesalsoexplorehowtoeffectivelyutilizetheinformationacrossdifferenttaskstobuildthememorymodule,whichisdetailedinthefollowingsections.\n5.\n1.\n2Cross-trialInformationForLLM-basedagents,theinformationaccumulatedacrossmultipletrialsintheenvironmentisalsoacrucialpartofthememory,typicallyincludingsuccessfulandfailedactionsandtheirinsights,suchasfailurereasons,commonactionpatternstosucceed,andsoon.\nRepresentativeStudies.\nOneofthemostprominentstudiesisReflexion[5],whichproposesverbalreinforcementlearningforLLM-basedagents.\nItderivestheexperiencesfrompasttrialsinverbalform,andappliestheminsubsequenttrialstoimprovetheperformanceofthesametask.\nFurthermore,Retroformer[103]fine-tunesthereflectionmodel,enablingtheagenttoextractcross-trialinformationfrompasttrialsmoreeffectively.\nInSynapse[91],theagentsfocusonsolvingthecomputercontroltasks.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\n2PersonalAssistantLLM-basedagentsarewell-suitedforcreatingpersonalassistants,suchasagentscapableofengaginginlong-termconversationswithusers[94,101,153],aswellasthosetaskedwithautomaticallyseekinginformation[164].\nTheseagentsoftenneedtomemorizepreviousdialoguestomaintaintheconsistency,andremembercriticalstylesandeventstogeneratemorepersonalizedandrelevantresponses.\nLuetal.\n[94]maintainthecontextconsistencyfordialoguesbysavingcontentsandinformationofconversations,whichhelpstofindproperrelevantinformationbyretrieval.\nLeeetal.\n[101]summarizeconversationstoextractimportantinformation,storeit,andretrieveitforfutureinference.\nPanetal.\n[164]focusoninformation-seekingtasks,whichdesignmemorymodulestostoreuser’scontextinformation,andempowerexternalknowledgewithtoolusage.\nWuetal.\n[153]retainimportantcontextasmemorytomaintainconversationconsistency.\nInsummary,mostmemoryimplementationsforpersonalassistantsadoptretrievalmethodsintextualform,becausetheyarebetteratfindingrelevantinformationfrompiecesofconversations.\nForthememorystorage,theagentshouldrememberthefactualinformationduringuser-agentinteractions,aswellasthepersonalstyleofusers,inordertogenerateresponsesthataretailoredtotheuser’ssituation.\nAdditionally,whenrecallingmemories,theagentshouldidentifyandretrievethememorythatisrelevanttothecurrentqueryandcontext.\nThisprinciplecanenabletheagenttocorrectlyunderstandtheuser’srequirement,andmaintaintheconsistencyinconversations.\n7.\n3Open-worldGameForgamesandopen-worldexploration,LLM-basedagentsalwaysmaintainpostobservationsastaskcontexts,andstoreexperiencesinprevioussuccessfultrials.\nByleveragingpastexperiences,agentscanavoidmakingthesamemistakesrepeatedlyandachieveahigh-levelunderstandingofenvironments,thusexploringmoreeffectively.\nSomeofthemcanacquireexternaldatabasesorAPIstoobtaingeneralknowledge[99,93,159,161].\nWangetal.\n[99]saveobtainedskillsintomemoryforfurtherusageinMinecraft.\nZhuetal.\n[93]storeandretrievesuccessfultrajectoriesasexamplesforsimilartasks,andutilizeexternalMinecraftWikibyAPIcalls."
    ],
    [
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\nSurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.\n[70]presentthefirstcomprehensivesurveytosummarizethebackground,evolutionpaths,modelarchitectures,trainingmethodologies,andevaluationstrategiesofLLMs.\nHadietal.\n[71]andMinetal.\n[72]alsoconductLLMsurveysfromtheholisticview,which,however,providedifferenttaxonomiesandunderstandingsonLLMs.\nFollowingthesesurveys,peoplediveintospecificaspectsofLLMsandreviewthecorrespondingmilestonestudiesandkeytechnologies.\nTheseaspectscanbeclassifiedintofourcategoriesincludingthefundamentalproblems,evaluation,applications,andchallengesofLLMs.\nFundamentalproblems.\nThesurveysinthiscategoryaimtosummarizetechniquesthatcanbeleveragedtotacklefundamentalproblemsofLLMs.\nSpecifically,Zhangetal.\n[8]provideacomprehensivesurveyonthemethodsofsupervisedfine-tuning,whichisakeytechniqueforbettertrainingLLMs.\nShenetal.\n[9],Wangetal.\n[10]andLiuetal.\n[11]presentsurveysonthealignmentofLLMs,whichisakeyrequirementforLLMstoproduceoutputsconsistentwithhumanvalues.\nGaoetal.\n[12]proposeasurveyontheretrieval-augmentedgeneration(RAG)capabilityofLLMs,whichiskeytoprovidingLLMswithfactualandup-to-dateknowledgeandremovinghallucinations.\nQinetal.\n[18]summarizethestate-of-the-artmethodsonenablingLLMstoleverageexternaltools,whichisfundamentalforLLMstoexpandtheircapabilityindomainsthatrequirespecializedknowledge.\nWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16]andZhangetal.\n[17]presentsurveysonthedirectionofLLMknowledgeediting,whichisimportantforcustomizingLLMstosatisfyspecificrequirements.\nHuangetal.\n[19],Wangetal.\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal.",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\nFigure2:TheorganizationofrelatedsurveysonLLMsandLLM-basedagents.\n6Challenges.\nThesurveysinthiscategoryfocusontrustworthinessinLLMs,suchashallucination,bias,unfairness,explainability,security,andprivacy.\nHallucinationinLLMsreferstotheproblemthatLLMsmaygeneratemisconceptionsorfabrications,impactingtheirreliabilityfordownstreamapplications.\nZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Tonmoyetal.\n[58]andJiangetal.\n[59]summarizethemainstreammodelsforalleviatingthehallucinationprobleminLLMs.\nThebiasandunfairnessproblemsrefertothephenomenonthatLLMsmayunequallytreatdifferenthumansorobjectives,whichcanleadtothepropagationofsocietalstereotypesanddiscrimination.\nGallegosetal.\n[60],Koteketal.\n[61]andLietal.\n[62]comprehensivelydiscussthesechallengesandsummarizeexistingmethodsforalleviatingthem.\nTheproblemofexplainabilitymeansthattheinternalworkingmechanismsofLLMsarestillunclear.\nZhaoetal.\n[63]systematicallydiscussthisproblemandsummarizepreviouseffortsonimprovingtheexplainabilityofLLMs.\nSecurityandprivacyarealsochallengingproblems,whichhavebeencomprehensivelysurveyedinYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68]andDasetal.\n[69].\n2.\n2",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTosystemicallysummarizethestudiesinthisfield,researchershavewrittenalotofsurveypapers.\nInthissection,webrieflyreviewthesesurveys(seeFigure2foranoverview),highlightingtheirmajorfocusesandcontributionstobetterpositionourstudy.\n2.\n1SurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.\n[70]presentthefirstcomprehensivesurveytosummarizethebackground,evolutionpaths,modelarchitectures,trainingmethodologies,andevaluationstrategiesofLLMs.\nHadietal.\n[71]andMinetal.\n[72]alsoconductLLMsurveysfromtheholisticview,which,however,providedifferenttaxonomiesandunderstandingsonLLMs.\nFollowingthesesurveys,peoplediveintospecificaspectsofLLMsandreviewthecorrespondingmilestonestudiesandkeytechnologies.\nTheseaspectscanbeclassifiedintofourcategoriesincludingthefundamentalproblems,evaluation,applications,andchallengesofLLMs.\nFundamentalproblems.\nThesurveysinthiscategoryaimtosummarizetechniquesthatcanbeleveragedtotacklefundamentalproblemsofLLMs.\nSpecifically,Zhangetal.\n[8]provideacomprehensivesurveyonthemethodsofsupervisedfine-tuning,whichisakeytechniqueforbettertrainingLLMs.\nShenetal.\n[9],Wangetal.\n[10]andLiuetal.\n[11]presentsurveysonthealignmentofLLMs,whichisakeyrequirementforLLMstoproduceoutputsconsistentwithhumanvalues.\nGaoetal.\n[12]proposeasurveyontheretrieval-augmentedgeneration(RAG)capabilityofLLMs,whichiskeytoprovidingLLMswithfactualandup-to-dateknowledgeandremovinghallucinations.\nQinetal.\n[18]summarizethestate-of-the-artmethodsonenablingLLMstoleverageexternaltools,whichisfundamentalforLLMstoexpandtheircapabilityindomainsthatrequirespecializedknowledge.\nWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16]andZhangetal.\n[17]presentsurveysonthedirectionofLLMknowledgeediting,whichisimportantforcustomizingLLMstosatisfyspecificrequirements.\nHuangetal.\n[19],Wangetal.\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32]andParketal.\n[33]systematicallyreviewthetechniquesofmodelcompression.\nDingetal.\n[81]andXuetal.\n[29]analyzeandconcludethestudiesonparameterefficientfine-tuning.\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28]andDingetal.\n[81]putmorefocusesontheefficiencyofresourceutilizationinageneralsense.\nEvaluation.\nThesurveysinthiscategoryfocusonhowtoevaluatethecapabilityofLLMs.\nSpecifi-cally,Changetal.\n[34]comprehensivelysummarizetheevaluationmethodsfromanoverallperspec-tive.\nItencompassesdifferentevaluationtasks,methods,andbenchmarks,whichserveascriticalpartsinassessingLLMperformances.\nGuoetal.\n[35]caremoreabouttheevaluationtargetsanddescribehowtoevaluatetheknowledge,alignment,andsafetycontrolcapabilitiesofLLMs,whichsupplementevaluationmetricsbeyondperformance.\nApplications.\nThesurveysinthiscategoryaimtosummarizemodelsthatleverageLLMstoimprovedifferentapplications.\nMoreconcretely,Zhuetal.\n[37]focusonthefieldofinformationretrieval(IR)andsummarizestudiesonLLM-basedqueryprocesses.\nXuetal.\n[38]paymoreattentiontoinformationextraction(IE)andprovidecomprehensivetaxonomiesforLLM-basedmodelsinthisfield.\nLietal.\n[50],Linetal.\n[51]andWangetal.\n[52]discusstheapplicationsofLLMsinthefieldofrecommendersystem,wheretheyutilizeagentstogeneratedataandproviderecommendations.\nFanetal.\n[39],Wangetal.\n[40],andZhengetal.\n[41]concentrateonhowLLMscanbenefitsoftwareengineering(SE)intermsofsoftwaredesign,development,andtesting.\nZengetal.\n[42]summarizeLLM-basedmethodsinthefieldofrobotics.\nCuietal.\n[43]andYangetal.\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal.",
      "#memory_survey#D:\\projects\\KAG\\kag\\examples\\memory_survey_test\\builder\\./data/memory_survey.pdf#memory_survey#D:\\projects\\KAG\\kag\\examples\\memory_survey_test\\builder\\./data/memory_survey.pdf\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n7.\n6ExpertSysteminSpecificDomains.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n7.\n7OtherApplications.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n8Limitations&FutureDirections8.\n1MoreAdvancesinParametricMemory.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n8.\n2MemoryinLLM-basedMulti-agentApplications.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n8.\n3Memory-basedLifelongLearning.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n8.\n4MemoryinHumanoidAgent.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n9Conclusion2323232325252526262627272728282831"
    ],
    [
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\nSurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.\n[70]presentthefirstcomprehensivesurveytosummarizethebackground,evolutionpaths,modelarchitectures,trainingmethodologies,andevaluationstrategiesofLLMs.\nHadietal.\n[71]andMinetal.\n[72]alsoconductLLMsurveysfromtheholisticview,which,however,providedifferenttaxonomiesandunderstandingsonLLMs.\nFollowingthesesurveys,peoplediveintospecificaspectsofLLMsandreviewthecorrespondingmilestonestudiesandkeytechnologies.\nTheseaspectscanbeclassifiedintofourcategoriesincludingthefundamentalproblems,evaluation,applications,andchallengesofLLMs.\nFundamentalproblems.\nThesurveysinthiscategoryaimtosummarizetechniquesthatcanbeleveragedtotacklefundamentalproblemsofLLMs.\nSpecifically,Zhangetal.\n[8]provideacomprehensivesurveyonthemethodsofsupervisedfine-tuning,whichisakeytechniqueforbettertrainingLLMs.\nShenetal.\n[9],Wangetal.\n[10]andLiuetal.\n[11]presentsurveysonthealignmentofLLMs,whichisakeyrequirementforLLMstoproduceoutputsconsistentwithhumanvalues.\nGaoetal.\n[12]proposeasurveyontheretrieval-augmentedgeneration(RAG)capabilityofLLMs,whichiskeytoprovidingLLMswithfactualandup-to-dateknowledgeandremovinghallucinations.\nQinetal.\n[18]summarizethestate-of-the-artmethodsonenablingLLMstoleverageexternaltools,whichisfundamentalforLLMstoexpandtheircapabilityindomainsthatrequirespecializedknowledge.\nWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16]andZhangetal.\n[17]presentsurveysonthedirectionofLLMknowledgeediting,whichisimportantforcustomizingLLMstosatisfyspecificrequirements.\nHuangetal.\n[19],Wangetal.\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTosystemicallysummarizethestudiesinthisfield,researchershavewrittenalotofsurveypapers.\nInthissection,webrieflyreviewthesesurveys(seeFigure2foranoverview),highlightingtheirmajorfocusesandcontributionstobetterpositionourstudy.\n2.\n1SurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.\n[70]presentthefirstcomprehensivesurveytosummarizethebackground,evolutionpaths,modelarchitectures,trainingmethodologies,andevaluationstrategiesofLLMs.\nHadietal.\n[71]andMinetal.\n[72]alsoconductLLMsurveysfromtheholisticview,which,however,providedifferenttaxonomiesandunderstandingsonLLMs.\nFollowingthesesurveys,peoplediveintospecificaspectsofLLMsandreviewthecorrespondingmilestonestudiesandkeytechnologies.\nTheseaspectscanbeclassifiedintofourcategoriesincludingthefundamentalproblems,evaluation,applications,andchallengesofLLMs.\nFundamentalproblems.\nThesurveysinthiscategoryaimtosummarizetechniquesthatcanbeleveragedtotacklefundamentalproblemsofLLMs.\nSpecifically,Zhangetal.\n[8]provideacomprehensivesurveyonthemethodsofsupervisedfine-tuning,whichisakeytechniqueforbettertrainingLLMs.\nShenetal.\n[9],Wangetal.\n[10]andLiuetal.\n[11]presentsurveysonthealignmentofLLMs,whichisakeyrequirementforLLMstoproduceoutputsconsistentwithhumanvalues.\nGaoetal.\n[12]proposeasurveyontheretrieval-augmentedgeneration(RAG)capabilityofLLMs,whichiskeytoprovidingLLMswithfactualandup-to-dateknowledgeandremovinghallucinations.\nQinetal.\n[18]summarizethestate-of-the-artmethodsonenablingLLMstoleverageexternaltools,whichisfundamentalforLLMstoexpandtheircapabilityindomainsthatrequirespecializedknowledge.\nWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16]andZhangetal.\n[17]presentsurveysonthedirectionofLLMknowledgeediting,whichisimportantforcustomizingLLMstosatisfyspecificrequirements.\nHuangetal.\n[19],Wangetal.\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32]andParketal.\n[33]systematicallyreviewthetechniquesofmodelcompression.\nDingetal.\n[81]andXuetal.\n[29]analyzeandconcludethestudiesonparameterefficientfine-tuning.\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28]andDingetal.\n[81]putmorefocusesontheefficiencyofresourceutilizationinageneralsense.\nEvaluation.\nThesurveysinthiscategoryfocusonhowtoevaluatethecapabilityofLLMs.\nSpecifi-cally,Changetal.\n[34]comprehensivelysummarizetheevaluationmethodsfromanoverallperspec-tive.\nItencompassesdifferentevaluationtasks,methods,andbenchmarks,whichserveascriticalpartsinassessingLLMperformances.\nGuoetal.\n[35]caremoreabouttheevaluationtargetsanddescribehowtoevaluatetheknowledge,alignment,andsafetycontrolcapabilitiesofLLMs,whichsupplementevaluationmetricsbeyondperformance.\nApplications.\nThesurveysinthiscategoryaimtosummarizemodelsthatleverageLLMstoimprovedifferentapplications.\nMoreconcretely,Zhuetal.\n[37]focusonthefieldofinformationretrieval(IR)andsummarizestudiesonLLM-basedqueryprocesses.\nXuetal.\n[38]paymoreattentiontoinformationextraction(IE)andprovidecomprehensivetaxonomiesforLLM-basedmodelsinthisfield.\nLietal.\n[50],Linetal.\n[51]andWangetal.\n[52]discusstheapplicationsofLLMsinthefieldofrecommendersystem,wheretheyutilizeagentstogeneratedataandproviderecommendations.\nFanetal.\n[39],Wangetal.\n[40],andZhengetal.\n[41]concentrateonhowLLMscanbenefitsoftwareengineering(SE)intermsofsoftwaredesign,development,andtesting.\nZengetal.\n[42]summarizeLLM-basedmethodsinthefieldofrobotics.\nCuietal.\n[43]andYangetal.\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32]andParketal.\n[33]systematicallyreviewthetechniquesofmodelcompression.\nDingetal.\n[81]andXuetal.\n[29]analyzeandconcludethestudiesonparameterefficientfine-tuning.\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28]andDingetal.\n[81]putmorefocusesontheefficiencyofresourceutilizationinageneralsense.\nEvaluation.\nThesurveysinthiscategoryfocusonhowtoevaluatethecapabilityofLLMs.\nSpecifi-cally,Changetal.\n[34]comprehensivelysummarizetheevaluationmethodsfromanoverallperspec-tive.\nItencompassesdifferentevaluationtasks,methods,andbenchmarks,whichserveascriticalpartsinassessingLLMperformances.\nGuoetal.\n[35]caremoreabouttheevaluationtargetsanddescribehowtoevaluatetheknowledge,alignment,andsafetycontrolcapabilitiesofLLMs,whichsupplementevaluationmetricsbeyondperformance.\nApplications.\nThesurveysinthiscategoryaimtosummarizemodelsthatleverageLLMstoimprovedifferentapplications.\nMoreconcretely,Zhuetal.\n[37]focusonthefieldofinformationretrieval(IR)andsummarizestudiesonLLM-basedqueryprocesses.\nXuetal.\n[38]paymoreattentiontoinformationextraction(IE)andprovidecomprehensivetaxonomiesforLLM-basedmodelsinthisfield.\nLietal.\n[50],Linetal.\n[51]andWangetal.\n[52]discusstheapplicationsofLLMsinthefieldofrecommendersystem,wheretheyutilizeagentstogeneratedataandproviderecommendations.\nFanetal.\n[39],Wangetal.\n[40],andZhengetal.\n[41]concentrateonhowLLMscanbenefitsoftwareengineering(SE)intermsofsoftwaredesign,development,andtesting.\nZengetal.\n[42]summarizeLLM-basedmethodsinthefieldofrobotics.\nCuietal.\n[43]andYangetal.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\n[40],andZhengetal.\n[41]concentrateonhowLLMscanbenefitsoftwareengineering(SE)intermsofsoftwaredesign,development,andtesting.\nZengetal.\n[42]summarizeLLM-basedmethodsinthefieldofrobotics.\nCuietal.\n[43]andYangetal.\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal.\n[47]summarizetheapplicationsofLLMsinmedicine.\nLietal.\n[48]focusontheapplicationsofLLMsinfinance.\nHeetal.\n[49]reviewthemodelsonleveragingLLMstoimprovethedevelopmentofpsychology.\n5SupervisedFine-tuningZhangetal.\n[8].\nAlignmentShenetal.\n[9],Wangetal.\n[10],Liuetal.\n[11].\nRetrievalAugmentationGaoetal.\n[12].\nKnowledgeEditingWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16],Zhangetal.\n[17].\nFundamentalProblemsToolUsageQinetal.\n[18].\nLong-contextMultimodalEfficiencyHuangetal.\n[19],Wangetal.\n[20],Pawaretal.\n[21].\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24],Yinetal.\n[25].\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28,28],Xuetal.\n[29],Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32],Parketal.\n[33].\nEvaluationChangetal.\n[34],Guoetal.\n[35].\nInformationProcessingSoftwareEngineeringYangetal.\n[36],Zhuetal.\n[37],Xuetal.\n[38].\nFanetal.\n[39],Wangetal.\n[40],Zhengetal.\n[41].\nRoboticsZengetal.\n[42].\nApplicationsAutonomousDrivingCuietal.\n[43],Yangetal.\n[44].\nLLMs[70–73]MedecineFinancePsychologyHeetal.\n[45],Zhouetal.\n[46],Wangetal.\n[47].\nLietal.\n[48].\nHeetal.\n[49].\nRecommendationLietal.\n[50],Linetal.\n[51],Wangetal.\n[52].\nHallucinationZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Ton-moyetal.\n[58],Jiangetal.\n[59].\nChallengesBias&FairnessGallegosetal.\n[60],Koteketal.\n[61],Lietal.\n[62].\nExplainabilityZhaoetal.\n[63].\nSecurityYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68],Dasetal.\n[69].\nPlanningHuangetal.\n[74].\nFundamentalProblemsMemoryOurSurvey.\nMulti-agentsGuoetal.\n[75].\nLLM-basedAgent[3,4,77–80]EvaluationApplicationsChallengesLietal.\n[76].",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\n[44]focusontheapplicationofautonomousdrivingandsummarizemodelsinthisdomainbasedonLLMsfromdifferentperspectives.\nBeyondtheabovedomainsinartificialintelligence,LLMshavealsobeenusedinnaturalandsocialscience.\nHeetal.\n[45],Zhouetal.\n[46]andWangetal.\n[47]summarizetheapplicationsofLLMsinmedicine.\nLietal.\n[48]focusontheapplicationsofLLMsinfinance.\nHeetal.\n[49]reviewthemodelsonleveragingLLMstoimprovethedevelopmentofpsychology.\n5SupervisedFine-tuningZhangetal.\n[8].\nAlignmentShenetal.\n[9],Wangetal.\n[10],Liuetal.\n[11].\nRetrievalAugmentationGaoetal.\n[12].\nKnowledgeEditingWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16],Zhangetal.\n[17].\nFundamentalProblemsToolUsageQinetal.\n[18].\nLong-contextMultimodalEfficiencyHuangetal.\n[19],Wangetal.\n[20],Pawaretal.\n[21].\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24],Yinetal.\n[25].\nBaietal.\n[26],Wanetal.\n[27],Miaoetal.\n[28,28],Xuetal.\n[29],Zhuetal.\n[30],XuandMcAuley[31],Wangetal.\n[32],Parketal.\n[33].\nEvaluationChangetal.\n[34],Guoetal.\n[35].\nInformationProcessingSoftwareEngineeringYangetal.\n[36],Zhuetal.\n[37],Xuetal.\n[38].\nFanetal.\n[39],Wangetal.\n[40],Zhengetal.\n[41].\nRoboticsZengetal.\n[42].\nApplicationsAutonomousDrivingCuietal.\n[43],Yangetal.\n[44].\nLLMs[70–73]MedecineFinancePsychologyHeetal.\n[45],Zhouetal.\n[46],Wangetal.\n[47].\nLietal.\n[48].\nHeetal.\n[49].\nRecommendationLietal.\n[50],Linetal.\n[51],Wangetal.\n[52].\nHallucinationZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Ton-moyetal.\n[58],Jiangetal.\n[59].\nChallengesBias&FairnessGallegosetal.\n[60],Koteketal.\n[61],Lietal.\n[62].\nExplainabilityZhaoetal.\n[63].\nSecurityYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68],Dasetal.\n[69].\nPlanningHuangetal.\n[74].\nFundamentalProblemsMemoryOurSurvey.\nMulti-agentsGuoetal.\n[75].\nLLM-basedAgent[3,4,77–80]EvaluationApplicationsChallengesLietal.\n[76].\nFigure2:TheorganizationofrelatedsurveysonLLMsandLLM-basedagents.\n6Challenges.\nThesurveysinthiscategoryfocusontrustworthinessinLLMs,suchashallucination,bias,unfairness,explainability,security,andprivacy.",
      "#memory_survey#RelatedSurveys#memory_survey#RelatedSurveys\nRelatedSurveysInthepasttwoyears,LLMshaveattractedmuchattentionfromtheacademicandindustrycommu-nities.\nTosystemicallysummarizethestudiesinthisfield,researchershavewrittenalotofsurveypapers.\nInthissection,webrieflyreviewthesesurveys(seeFigure2foranoverview),highlightingtheirmajorfocusesandcontributionstobetterpositionourstudy.\n2.\n1",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\nFigure2:TheorganizationofrelatedsurveysonLLMsandLLM-basedagents.\n6Challenges.\nThesurveysinthiscategoryfocusontrustworthinessinLLMs,suchashallucination,bias,unfairness,explainability,security,andprivacy.\nHallucinationinLLMsreferstotheproblemthatLLMsmaygeneratemisconceptionsorfabrications,impactingtheirreliabilityfordownstreamapplications.\nZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Tonmoyetal.\n[58]andJiangetal.\n[59]summarizethemainstreammodelsforalleviatingthehallucinationprobleminLLMs.\nThebiasandunfairnessproblemsrefertothephenomenonthatLLMsmayunequallytreatdifferenthumansorobjectives,whichcanleadtothepropagationofsocietalstereotypesanddiscrimination.\nGallegosetal.\n[60],Koteketal.\n[61]andLietal.\n[62]comprehensivelydiscussthesechallengesandsummarizeexistingmethodsforalleviatingthem.\nTheproblemofexplainabilitymeansthattheinternalworkingmechanismsofLLMsarestillunclear.\nZhaoetal.\n[63]systematicallydiscussthisproblemandsummarizepreviouseffortsonimprovingtheexplainabilityofLLMs.\nSecurityandprivacyarealsochallengingproblems,whichhavebeencomprehensivelysurveyedinYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68]andDasetal.\n[69].\n2.\n2",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nForthememorydesign,wediscusspreviousworksfromthreedimensions,thatis,memorysources,memoryforms,andmemoryoperations.\nForthememoryevaluation,weintroducetwowidelyusedapproachesincludingdirectevaluationandindirectevaluationviaspecificagenttasks.\nNext,wediscussagentapplicationsincludingrole-playing,socialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,andexpertsystems,inordertoshowtheimportanceofthememorymoduleinpracticalscenarios.\nAtlast,weanalyzethelimitationsofexistingworkandhighlightsignificantfuturedirections.\nThemaincontributionsofthispapercanbesummarizedasfollows:(1)Weformallydefinethemem-orymoduleandcomprehensivelyanalyzeitsnecessityforLLM-basedagents.\n(2)WesystematicallysummarizeexistingstudiesondesigningandevaluatingthememorymoduleinLLM-basedagents,providingcleartaxonomiesandintuitiveinsights.\n(3)Wepresenttypicalagentapplicationstoshowtheimportanceofthememorymoduleindifferentscenarios.\n(4)Weanalyzethekeylimitationsofexistingmemorymodulesandshowpotentialsolutionsforinspiringfuturestudies.\nToourknowledge,thisisthefirstsurveyonthememorymechanismofLLM-basedagents.\nTherestofthissurveyisorganizedasfollows.\nFirst,weprovideasystematicalmeta-surveyforthefieldsofLLMsandLLM-basedagentsinSection2,categorizingdifferentsurveysandsummarizingtheirkeycontributions.\nThen,wediscusstheproblemsof“whatis”,“whydoweneed”and“howtoimplementandevaluate”thememorymoduleinLLM-basedagentsinSection3to6.\nNext,weshowtheapplicationsofmemory-enhancedagentsinSection7.\nThediscussionsofthelimitationsofexistingworkandfuturedirectionscomeatlastinSection8andSection9.\n42RelatedSurveysInthepasttwoyears,LLMshaveattractedmuchattentionfromtheacademicandindustrycommu-nities.\nTosystemicallysummarizethestudiesinthisfield,researchershavewrittenalotofsurveypapers.\nInthissection,webrieflyreviewthesesurveys(seeFigure2foranoverview),highlightingtheirmajorfocusesandcontributionstobetterpositionourstudy.\n2.\n1SurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68],Dasetal.\n[69].\nPlanningHuangetal.\n[74].\nFundamentalProblemsMemoryOurSurvey.\nMulti-agentsGuoetal.\n[75].\nLLM-basedAgent[3,4,77–80]EvaluationApplicationsChallengesLietal.\n[76].\nFigure2:TheorganizationofrelatedsurveysonLLMsandLLM-basedagents.\n6Challenges.\nThesurveysinthiscategoryfocusontrustworthinessinLLMs,suchashallucination,bias,unfairness,explainability,security,andprivacy.\nHallucinationinLLMsreferstotheproblemthatLLMsmaygeneratemisconceptionsorfabrications,impactingtheirreliabilityfordownstreamapplications.\nZhangetal.\n[53],Huangetal.\n[54],Rawteetal.\n[55],Yeetal.\n[56],Jietal.\n[57],Tonmoyetal.\n[58]andJiangetal.\n[59]summarizethemainstreammodelsforalleviatingthehallucinationprobleminLLMs.\nThebiasandunfairnessproblemsrefertothephenomenonthatLLMsmayunequallytreatdifferenthumansorobjectives,whichcanleadtothepropagationofsocietalstereotypesanddiscrimination.\nGallegosetal.\n[60],Koteketal.\n[61]andLietal.\n[62]comprehensivelydiscussthesechallengesandsummarizeexistingmethodsforalleviatingthem.\nTheproblemofexplainabilitymeansthattheinternalworkingmechanismsofLLMsarestillunclear.\nZhaoetal.\n[63]systematicallydiscussthisproblemandsummarizepreviouseffortsonimprovingtheexplainabilityofLLMs.\nSecurityandprivacyarealsochallengingproblems,whichhavebeencomprehensivelysurveyedinYaoetal.\n[64],Shayeganietal.\n[65],NeelandChang[66],Smithetal.\n[67],Dongetal.\n[68]andDasetal.\n[69].\n2.\n2SurveysonLargeLanguageModel-basedAgentsBasedonthecapabilityofLLMs,peoplehaveconductedalotofstudiesonbuildingLLM-basedagents,whichcanautonomouslyperceiveenvironments,takeactions,accumulateknowledge,andevolvethemselves.\nInthisfield,Wangetal.\n[3]presentthefirstsurveypapertosystematicallysummarizeLLM-basedagentsfromtheperspectivesofagentconstruction,agentapplication,andagentevaluation.\nXietal.\n[4],Zhaoetal.\n[77],Chengetal.\n[78]andGeetal.\n[80]alsosummarizeLLM-basedagentstudiesfromtheoverallperspective,buttheyhavedifferentfocusesandtaxonomies,deliveringmorediverseunderstandingsonthisfield."
    ],
    [
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.\nThismethodstoresandmaintainsthemostrecentlyacquiredmemoriesusingnaturallanguages,therebyenhancingtheefficiencyofmemoryinformationutilizationaccordingtothePrincipleofLocality[121].\nIntask(B)oftheexampleinSection3.\n1,wecanjustrememberAlice’spreferencesintherecentthreeyears,andtruncatethedistantpart,wheretherecentthreeyearscanbeconsideredasthememorywindowsize.\nInpreviousstudies,therearevariousstrategiestostorerecenttextualmemories.\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nMoreover,someeffortsarededicatedtoenhancingthecapacityofLLMstohandlelongercontexts[118,119].\nWhilestoringalltheagent-environmentinteractionscanmaintaincomprehensiveinformation,obviouslimitationsexistintermsofcomputationalcost,inferencetime,andinferencerobustness.\nFirstly,thefast-growinglong-contextmemoryinpracticeresultsinhighcomputationalcostduringLLMinference,duetothequadraticgrowthofthetimecomplexityofattentioncomputationwithsequencelength.\nItthusrequiresmuchmorecomputingresourcesandsignificantlyincreasesinferencelatency,whichhindersitspracticaldeployment.\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.\nThismethodstoresandmaintainsthemostrecentlyacquiredmemoriesusingnaturallanguages,therebyenhancingtheefficiencyofmemoryinformationutilizationaccordingtothePrincipleofLocality[121].\nIntask(B)oftheexampleinSection3.\n1,wecanjustrememberAlice’spreferencesintherecentthreeyears,andtruncatethedistantpart,wheretherecentthreeyearscanbeconsideredasthememorywindowsize.\nInpreviousstudies,therearevariousstrategiestostorerecenttextualmemories.\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThismetricevaluateswhethertheagentcandiscoverrelevantmemorycontentstoanswerthequestions.\nDifferentfromtheabovemetric,whichfocusesonthefinalresults,referenceaccuracycaresmoreabouttheintermediateinformationtosupporttheagent’sfinaldecisions.\nInspecific,itcomparestheretrievedmemorywiththepre-preparedgroundtruth.\nFortheaboveproblemof\"WheredidAlicegotoday?\n\",ifthememorycontentsinclude(A)\"AlicehadlunchwithfriendsatWangfujingtoday.\n\"and(B)\"Alicehadroastduckforlunch\",thenabettermemorymoduleshouldselect(A)asareferencetoanswerthequestion.\nUsually,researchersleverageF1-scoretoevaluatethereferenceaccuracy,whichiscalculatedasF1=2·Precision·RecallPrecision+Recall,wheretheprecisionandrecallscoresarecalculatedasPrecision=TPTP+FN.\nTheTPrepresentsthenumberoftruepositivememorycontents,FPmeansthenumberoffalsepositivememorycontents,andFNindicatesthenumberoffalsenegativememorycontents.\nInpreviousworks,Luetal.\n[94]utilizeF1-scoretoevaluatetheretrievalprocessofthememory,andZhongetal.\n[6]focusonassessingwhetherrelatedmemorycanbesuccessfullyretrieved.\nTP+FPandRecall=TPResultCorrectnessandReferenceAccuracyarebothutilizedtoevaluatetheeffectivenessofthememorymodule.\nBeyondeffectiveness,efficiencyisalsoanimportantaspect,especiallyforreal-worldapplications.\nTherefore,wedescribetheevaluationofefficiencyasfollows.\nTime&HardwareCost.\nThetotaltimecostincludesthetimeleveragedformemoryadaptionandinference.\nTheadaptationtimereferstothetimeofmemorywritingandmemorymanagement,whiletheinferencetimeindicatesthetimelatencyofmemoryreading.\nInspecific,thedifferencefromthe21endtimetothestarttimeofmemoryoperationscanbeconsideredasthetimeconsumption.\nFormally,theaveragetimeconsumptionofeachtypeofoperationcanberepresentedas∆time=1MM(cid:88)i=1i−tstarttendi,whereMrepresentsthenumberoftheseoperations,tendimeanstheendtimeofthei-thoperation,andtstartindicatesthestarttimeofthatoperation.\nAsforthecomputationoverhead,itcanbeevaluatedibythepeakGPUmemoryallocation.\nInpreviousworks,Tacketal.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.\nThismethodstoresandmaintainsthemostrecentlyacquiredmemoriesusingnaturallanguages,therebyenhancingtheefficiencyofmemoryinformationutilizationaccordingtothePrincipleofLocality[121].\nIntask(B)oftheexampleinSection3.\n1,wecanjustrememberAlice’spreferencesintherecentthreeyears,andtruncatethedistantpart,wheretherecentthreeyearscanbeconsideredasthememorywindowsize.\nInpreviousstudies,therearevariousstrategiestostorerecenttextualmemories.\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.",
      "#memory_survey#ObjectiveEvaluation#memory_survey#ObjectiveEvaluation\nUsually,researchersleverageF1-scoretoevaluatethereferenceaccuracy,whichiscalculatedasF1=2·Precision·RecallPrecision+Recall,wheretheprecisionandrecallscoresarecalculatedasPrecision=TPTP+FN.\nTheTPrepresentsthenumberoftruepositivememorycontents,FPmeansthenumberoffalsepositivememorycontents,andFNindicatesthenumberoffalsenegativememorycontents.\nInpreviousworks,Luetal.\n[94]utilizeF1-scoretoevaluatetheretrievalprocessofthememory,andZhongetal.\n[6]focusonassessingwhetherrelatedmemorycanbesuccessfullyretrieved.\nTP+FPandRecall=TPResultCorrectnessandReferenceAccuracyarebothutilizedtoevaluatetheeffectivenessofthememorymodule.\nBeyondeffectiveness,efficiencyisalsoanimportantaspect,especiallyforreal-worldapplications.\nTherefore,wedescribetheevaluationofefficiencyasfollows.\nTime&HardwareCost.\nThetotaltimecostincludesthetimeleveragedformemoryadaptionandinference.\nTheadaptationtimereferstothetimeofmemorywritingandmemorymanagement,whiletheinferencetimeindicatesthetimelatencyofmemoryreading.\nInspecific,thedifferencefromthe21endtimetothestarttimeofmemoryoperationscanbeconsideredasthetimeconsumption.\nFormally,theaveragetimeconsumptionofeachtypeofoperationcanberepresentedas∆time=1MM(cid:88)i=1i−tstarttendi,whereMrepresentsthenumberoftheseoperations,tendimeanstheendtimeofthei-thoperation,andtstartindicatesthestarttimeofthatoperation.\nAsforthecomputationoverhead,itcanbeevaluatedibythepeakGPUmemoryallocation.\nInpreviousworks,Tacketal.\n[106]utilizethepeakmemoryallocationandadaptationtimetoassesstheefficiencyofmemoryoperations.\nObjectiveevaluationoffersnumericstrategiestocomparedifferentmethodsofmemory,whichisimportanttobenchmarkthisfieldandpromotefuturedevelopments.\n6.\n2"
    ],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\nItutilizesLocality-SensitiveHashing(LSH)toretrievetupleswithrelativeentriesinthedatabasetoprovidemoreinformation.\nInaddition,ChatDB[96]designstoutilizesymbolicmemory,andproposestogenerateSQLstatementstoretrievefromdatabasetoobtainstoredinformation.\nTheretrievalmethodsconsiderablydependontheaccuracyandefficiencyofobtainingexpectedinformation.\nAninaccurateretrievalstrategycanpotentiallyacquireunrelatedinformationthatisunhelpfulforagentinference.\nAndaheavyretrievalsystemcanleadtolargecomputationalcostsandlongtimelatency,especiallywhenhandlingmassiveinformation.\nMoreover,retrievalmethodstypicallystorehomogeneousinformationinsidetheenvironment,wherealltheinformationisinaconsistentform.\nForheterogeneousinformationoutsidetheenvironment,it’sdifficulttodirectlyapplythesamemethodformemorystorage.\nExternalKnowledge.\nToobtainmoreinformation,someagentsacquireexternalknowledgebyinvokingtools,withtheaimoftransformingadditionalrelevantknowledgeintotheirownmemoriesfordecision-making.\nForinstance,accessingexternalknowledgethroughApplicationProgrammingInterface(API)isacommonpractice[104,5].\nNowadays,abundantpublicinformation,suchasWikipediaandOpenWeatherMap4,areavailableonline(eitherfreeofchargeoronapayingbasis),andcanbeconvenientlyaccessedthroughAPIcalls.\nForinstance,in[Step2]oftask(A)oftheexampleinSection3.\n1,externalknowledgefromthedigitalmagazineisobtainedwithtoolmethods.\nInexistingmodels,Toolformer[125]proposestoteachLLMtousetools,whichcanacquireexternalknowledgeforbettersolvingtasks.\nFurthermore,ToolLLM[126]empowersLlama[127]withtheabilitytoutilizemoreAPIsinRapidAPI5andtoenablemulti-toolusage,whichprovidesageneralinterfacetoextendagents’ability.\nInTPTU[110],theagentsareincorporatedinbothtaskplanningandtoolusage,inordertotackleintricateproblems.\nThefollow-upwork[111]furtherimprovesitsabilityextensivelylikeretrieval.\nInToRA[128],theagentsarerequiredtosolvemathematicalproblems.\nTheyutilizeimitationlearningtoimprovetheirabilitytouseprogram-basedtools.",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nMoreover,retrievalmethodstypicallystorehomogeneousinformationinsidetheenvironment,wherealltheinformationisinaconsistentform.\nForheterogeneousinformationoutsidetheenvironment,it’sdifficulttodirectlyapplythesamemethodformemorystorage.\nExternalKnowledge.\nToobtainmoreinformation,someagentsacquireexternalknowledgebyinvokingtools,withtheaimoftransformingadditionalrelevantknowledgeintotheirownmemoriesfordecision-making.\nForinstance,accessingexternalknowledgethroughApplicationProgrammingInterface(API)isacommonpractice[104,5].\nNowadays,abundantpublicinformation,suchasWikipediaandOpenWeatherMap4,areavailableonline(eitherfreeofchargeoronapayingbasis),andcanbeconvenientlyaccessedthroughAPIcalls.\nForinstance,in[Step2]oftask(A)oftheexampleinSection3.\n1,externalknowledgefromthedigitalmagazineisobtainedwithtoolmethods.\nInexistingmodels,Toolformer[125]proposestoteachLLMtousetools,whichcanacquireexternalknowledgeforbettersolvingtasks.\nFurthermore,ToolLLM[126]empowersLlama[127]withtheabilitytoutilizemoreAPIsinRapidAPI5andtoenablemulti-toolusage,whichprovidesageneralinterfacetoextendagents’ability.\nInTPTU[110],theagentsareincorporatedinbothtaskplanningandtoolusage,inordertotackleintricateproblems.\nThefollow-upwork[111]furtherimprovesitsabilityextensivelylikeretrieval.\nInToRA[128],theagentsarerequiredtosolvemathematicalproblems.\nTheyutilizeimitationlearningtoimprovetheirabilitytouseprogram-basedtools.\nTheabovemethodssignificantlyadvancethecapabilitiesofagentsbyallowingthemtoaccessexternalup-to-dateandreal-worldinformationfromdiversesources.\nHowever,thereliabilityofthisinformationcanbequestionableduetopotentialinaccuraciesandbiases[18].\nFurthermore,theintegrationoftoolsintoagentsdemandsacomprehensiveunderstandingtointerprettheretrievedinformationacrossvariouscontexts,whichcanincurhighercomputationalcostsandcomplicationsinaligningexternaldatawithinternaldecision-makingprocesses.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nInexistingmodels,Toolformer[125]proposestoteachLLMtousetools,whichcanacquireexternalknowledgeforbettersolvingtasks.\nFurthermore,ToolLLM[126]empowersLlama[127]withtheabilitytoutilizemoreAPIsinRapidAPI5andtoenablemulti-toolusage,whichprovidesageneralinterfacetoextendagents’ability.\nInTPTU[110],theagentsareincorporatedinbothtaskplanningandtoolusage,inordertotackleintricateproblems.\nThefollow-upwork[111]furtherimprovesitsabilityextensivelylikeretrieval.\nInToRA[128],theagentsarerequiredtosolvemathematicalproblems.\nTheyutilizeimitationlearningtoimprovetheirabilitytouseprogram-basedtools.\nTheabovemethodssignificantlyadvancethecapabilitiesofagentsbyallowingthemtoaccessexternalup-to-dateandreal-worldinformationfromdiversesources.\nHowever,thereliabilityofthisinformationcanbequestionableduetopotentialinaccuraciesandbiases[18].\nFurthermore,theintegrationoftoolsintoagentsdemandsacomprehensiveunderstandingtointerprettheretrievedinformationacrossvariouscontexts,whichcanincurhighercomputationalcostsandcomplicationsinaligningexternaldatawithinternaldecision-makingprocesses.\nAdditionally,utilizingexternalAPIsbringsforthconcernsregardingprivacy,datasecurity,andcompliancewithusagepolicies,necessitatingrigorousmanagementandoversight[18].\n5.\n2.\n2MemoryinParametricFormAnalternativetypeofapproachesistorepresentmemoryinparametricform.\nTheydonottakeuptheextralengthofcontextinprompts,sotheyarenotconstrainedbythelengthlimitationsofLLMcontext.\nHowever,theparametricmemoryformisstillunder-researched,andwecategorizepreviousworksintotwotypes:fine-tuningmethodsandmemoryeditingmethods.\nFine-tuningMethods.\nIntegratingexternalknowledgeintothememoryofagentsisbeneficialforenrichingdomain-specificknowledgeontopofitsgeneralknowledge.\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThefollow-upwork[111]furtherimprovesitsabilityextensivelylikeretrieval.\nInToRA[128],theagentsarerequiredtosolvemathematicalproblems.\nTheyutilizeimitationlearningtoimprovetheirabilitytouseprogram-basedtools.\nTheabovemethodssignificantlyadvancethecapabilitiesofagentsbyallowingthemtoaccessexternalup-to-dateandreal-worldinformationfromdiversesources.\nHowever,thereliabilityofthisinformationcanbequestionableduetopotentialinaccuraciesandbiases[18].\nFurthermore,theintegrationoftoolsintoagentsdemandsacomprehensiveunderstandingtointerprettheretrievedinformationacrossvariouscontexts,whichcanincurhighercomputationalcostsandcomplicationsinaligningexternaldatawithinternaldecision-makingprocesses.\nAdditionally,utilizingexternalAPIsbringsforthconcernsregardingprivacy,datasecurity,andcompliancewithusagepolicies,necessitatingrigorousmanagementandoversight[18].\n5.\n2.\n2MemoryinParametricFormAnalternativetypeofapproachesistorepresentmemoryinparametricform.\nTheydonottakeuptheextralengthofcontextinprompts,sotheyarenotconstrainedbythelengthlimitationsofLLMcontext.\nHowever,theparametricmemoryformisstillunder-researched,andwecategorizepreviousworksintotwotypes:fine-tuningmethodsandmemoryeditingmethods.\nFine-tuningMethods.\nIntegratingexternalknowledgeintothememoryofagentsisbeneficialforenrichingdomain-specificknowledgeontopofitsgeneralknowledge.\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nTheirmemorycanrecordcross-trialinformationthroughsuccessfulexemplars,whichwouldbeusedasreferencesonsimilartrials.\nInExpeL[82],theagentsarerequiredtosolveacollectionofcomplexinteractivetaskswithintheenvironment.\nTheystoreandorganizecompletedtrajectories,andrecallsimilaronesforthenewtask.\nIntherecalledtrajectories,successfulcaseswillbecomparedwithfailedonestoidentifythepatternstosucceed.\nDiscussion.\nAccordingtotheaccumulatedmemoryofcross-trialinformation,theagentsareabletoaccumulateexperiences,whichisimportantfortheirevolution.\nBasedonthepastexperiences,theagentscanadjusttheiractionsbasedontheoverallfeedbackofthewholeprocess.\nIncontrasttotheinside-trialobservations,whichserveasshort-termmemory,thetrialexperiencescanbeconsideredaslong-termmemory.\nItutilizesfeedbackfromdifferenttrialstosupportawiderrangeofagenttrials,providingmoreprolongedexperientialsupportforagents.\nHowever,thelimitationliesinthefactthatbothinside-trialandcross-trialinformationrequiretheagentstopersonallyengageinagent-environmentinteractions,whereexternalexperiencesandknowledgearenotincluded.\n5.\n1.\n3ExternalKnowledgeAnimportantcharacteristicofLLM-basedagentsisthattheycanbedirectlycommunicatedandcon-trolledinnaturallanguages.\nAssuch,LLM-basedagentscaneasilyincorporateexternalknowledgeintextualforms(e.\ng.\n,Wikipedia3)tofacilitatetheirdecisions.\nRepresentativeStudies.\nInReAct[104],theagentsarerequiredtoanswerquestionsaboutgeneralknowledgebymultiplereasoningsteps.\nTheycanutilizeWikipediaAPIstoobtainexternalknowledgeiftheylackinformationduringthesesteps.\nGITM[93]intendstodesignagentsinMinecraft,whichcanexploreincomplexandsparse-rewardenvironments.\nTheagentsdrawfromtheonlineMinecraftWikiandcraftrecipestoprovideaninfinitesourceofknowledgefortheirnavigation.\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain."
    ],
    [
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nMoreover,someeffortsarededicatedtoenhancingthecapacityofLLMstohandlelongercontexts[118,119].\nWhilestoringalltheagent-environmentinteractionscanmaintaincomprehensiveinformation,obviouslimitationsexistintermsofcomputationalcost,inferencetime,andinferencerobustness.\nFirstly,thefast-growinglong-contextmemoryinpracticeresultsinhighcomputationalcostduringLLMinference,duetothequadraticgrowthofthetimecomplexityofattentioncomputationwithsequencelength.\nItthusrequiresmuchmorecomputingresourcesandsignificantlyincreasesinferencelatency,whichhindersitspracticaldeployment.\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.\nThismethodstoresandmaintainsthemostrecentlyacquiredmemoriesusingnaturallanguages,therebyenhancingtheefficiencyofmemoryinformationutilizationaccordingtothePrincipleofLocality[121].\nIntask(B)oftheexampleinSection3.\n1,wecanjustrememberAlice’spreferencesintherecentthreeyears,andtruncatethedistantpart,wheretherecentthreeyearscanbeconsideredasthememorywindowsize.\nInpreviousstudies,therearevariousstrategiestostorerecenttextualmemories.\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.",
      "#memory_survey#Long-contextApplications#memory_survey#Long-contextApplications\nLong-contextApplicationsBeyondtheabovegeneralapplications,inmanyscenarios,LLM-basedagentshavetomakedecisionsbasedonextremelylongprompts.\nInthesescenarios,thelongpromptsareusuallyregardedasthememorycontents,whichplayanimportantroleindrivingagentbehaviors.\n22Inpreviousworks,Huangetal.\n[19]organizeacomprehensivesurveyforlong-contextLLMs,whichprovidesasummaryofevaluationmetricsonlong-contextscenarios.\nMoreover,Shahametal.\n[138]proposeazero-shotbenchmarkforevaluatingagents’understandingoflong-contextnaturallanguages.\nAsforspecificlong-contexttasks,long-contextpassageretrievalisoneoftheimportanttasksforevaluatingthelong-contextabilityofagents.\nItrequiresagentstofindthecorrectparagraphinalongcontextthatcorrespondstothegivenquestionsordescriptions[139].\nLong-contextsummarizationisanotherrepresentativetask.\nItrequestsagentstoformulateaglobalunderstandingofthewholecontext,andsummarizesitaccordingtothedescriptions,wheresomemetricsonmatchingscoreslikeROUGEcanbeutilizedtocomparetheresultswithgroundtruths.\nTheevaluationoflong-contextapplicationsprovidesbroaderapproachestoassessthefunctionofmemoryinagents,focusingonpracticaldownstreamscenarios.\nThecomprehensivebenchmarks[138,140]alsoprovideanobjectiveassessmentfortheabilityoflong-contextunderstanding.\n6.\n2.\n4",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nIntheformerthreetypes,theyrecordtheinformationinsidetheagent-environmentinteractionloop,whilethelasttypeleveragesnaturallanguagestostoreinformationoutsidethatloop.\nCompleteInteractions.\nThismethodstoresalltheinformationoftheagent-environmentinteractionhistorybasedonlong-contextstrategies[116].\nFortheexampleinSection3.\n1,thememoryofthe14agentintask(A)afterstep2canbeimplementedbyconcatenatingalltheinformationbeforestep2,andthefinaltextualformmemoryis:\"Yourmemoryis[Step1](Agent).\n.\n.\n(OnlineTicketOffice).\n.\n.\n[Step2].\n.\n.\nPleaseinferbasedonyourmemory\".\nInthepreviouswork,differentmodelsstorethememoryinformationusingdifferentstrategies.\nForexample,inLongChat[116],theagentsfocusonunderstandingnaturallanguagesinlong-contextscenarios.\nItfine-tunesthefoundationmodelforbetteradaptingtomemorizecompleteinteractions.\nMemorySandbox[117]intendstoalleviatetheimpactofirrelevantmemoryinconversations.\nItdesignsatransparentandinteractivemethodtomanagethememoryofagents,whichremovesirrelevantmemorybeforeconcatenatingthemasaprompt.\nMoreover,someeffortsarededicatedtoenhancingthecapacityofLLMstohandlelongercontexts[118,119].\nWhilestoringalltheagent-environmentinteractionscanmaintaincomprehensiveinformation,obviouslimitationsexistintermsofcomputationalcost,inferencetime,andinferencerobustness.\nFirstly,thefast-growinglong-contextmemoryinpracticeresultsinhighcomputationalcostduringLLMinference,duetothequadraticgrowthofthetimecomplexityofattentioncomputationwithsequencelength.\nItthusrequiresmuchmorecomputingresourcesandsignificantlyincreasesinferencelatency,whichhindersitspracticaldeployment.\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.",
      "#memory_survey#SurveysonLargeLanguageModels#memory_survey#SurveysonLargeLanguageModels\nSurveysonLargeLanguageModelsInthefieldofLLMs,Zhaoetal.\n[70]presentthefirstcomprehensivesurveytosummarizethebackground,evolutionpaths,modelarchitectures,trainingmethodologies,andevaluationstrategiesofLLMs.\nHadietal.\n[71]andMinetal.\n[72]alsoconductLLMsurveysfromtheholisticview,which,however,providedifferenttaxonomiesandunderstandingsonLLMs.\nFollowingthesesurveys,peoplediveintospecificaspectsofLLMsandreviewthecorrespondingmilestonestudiesandkeytechnologies.\nTheseaspectscanbeclassifiedintofourcategoriesincludingthefundamentalproblems,evaluation,applications,andchallengesofLLMs.\nFundamentalproblems.\nThesurveysinthiscategoryaimtosummarizetechniquesthatcanbeleveragedtotacklefundamentalproblemsofLLMs.\nSpecifically,Zhangetal.\n[8]provideacomprehensivesurveyonthemethodsofsupervisedfine-tuning,whichisakeytechniqueforbettertrainingLLMs.\nShenetal.\n[9],Wangetal.\n[10]andLiuetal.\n[11]presentsurveysonthealignmentofLLMs,whichisakeyrequirementforLLMstoproduceoutputsconsistentwithhumanvalues.\nGaoetal.\n[12]proposeasurveyontheretrieval-augmentedgeneration(RAG)capabilityofLLMs,whichiskeytoprovidingLLMswithfactualandup-to-dateknowledgeandremovinghallucinations.\nQinetal.\n[18]summarizethestate-of-the-artmethodsonenablingLLMstoleverageexternaltools,whichisfundamentalforLLMstoexpandtheircapabilityindomainsthatrequirespecializedknowledge.\nWangetal.\n[13],Yaoetal.\n[14],Wangetal.\n[15],Fengetal.\n[16]andZhangetal.\n[17]presentsurveysonthedirectionofLLMknowledgeediting,whichisimportantforcustomizingLLMstosatisfyspecificrequirements.\nHuangetal.\n[19],Wangetal.\n[20]andPawaretal.\n[21]focusonlong-contextcapabilitiesofLLMs,whichiscriticalforLLMstoprocessmoreinformationateachtimeandenhancetheirapplicationscenarios.\nWuetal.\n[22],Songetal.\n[23],Caffagnietal.\n[24]andYinetal.\n[25]summarizemulti-modalLLMs,whichexpandsthecapabilityofLLMsfromtexttovisualandothermodalities.\nTheabovesurveysmainlyfocusontheeffectivenessofLLMs.\nAnotherimportantaspectofLLMsistheirtrainingandinferenceefficiency.\nTosummarizestudiesonthisaspect,Zhuetal.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\n1,thememoryofthe14agentintask(A)afterstep2canbeimplementedbyconcatenatingalltheinformationbeforestep2,andthefinaltextualformmemoryis:\"Yourmemoryis[Step1](Agent).\n.\n.\n(OnlineTicketOffice).\n.\n.\n[Step2].\n.\n.\nPleaseinferbasedonyourmemory\".\nInthepreviouswork,differentmodelsstorethememoryinformationusingdifferentstrategies.\nForexample,inLongChat[116],theagentsfocusonunderstandingnaturallanguagesinlong-contextscenarios.\nItfine-tunesthefoundationmodelforbetteradaptingtomemorizecompleteinteractions.\nMemorySandbox[117]intendstoalleviatetheimpactofirrelevantmemoryinconversations.\nItdesignsatransparentandinteractivemethodtomanagethememoryofagents,whichremovesirrelevantmemorybeforeconcatenatingthemasaprompt.\nMoreover,someeffortsarededicatedtoenhancingthecapacityofLLMstohandlelongercontexts[118,119].\nWhilestoringalltheagent-environmentinteractionscanmaintaincomprehensiveinformation,obviouslimitationsexistintermsofcomputationalcost,inferencetime,andinferencerobustness.\nFirstly,thefast-growinglong-contextmemoryinpracticeresultsinhighcomputationalcostduringLLMinference,duetothequadraticgrowthofthetimecomplexityofattentioncomputationwithsequencelength.\nItthusrequiresmuchmorecomputingresourcesandsignificantlyincreasesinferencelatency,whichhindersitspracticaldeployment.\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions."
    ],
    [
      "#memory_survey#ObjectiveEvaluation#memory_survey#ObjectiveEvaluation\nObjectiveEvaluationInobjectiveevaluation,previousworkusuallydefinesnumericmetricstoevaluatetheeffectivenessandefficiencyofthememorymodule.\nResultCorrectness.\nThismetricmeasureswhethertheagentcansuccessfullyanswerpre-definedquestionsdirectlybasedonthememorymodule.\nForexample,thequestioncouldbe\"WheredidAlicegotoday?\n\"withtwochoices\"A:theSummerPalace\"and\"B:theGreatWall\".\nThen,theagentshouldchoosethecorrectanswerbasedontheproblemanditsmemory.\nTheagent-generatedanswerwillbecomparedwiththegroundtruth.\nFormally,theaccuracycanbecalculatedasCorrectness=1NN(cid:88)i=1I[ai=ˆai],whereNisthenumberofproblems,airepresentsthegroundtruthforthei-thproblem,ˆaimeanstheanswergivenbytheagent,andI[ai=ˆai]isthematchingfunctioncommonlyrepresentedasI[ai=ˆai]=(cid:26)10ifai=ˆai,ifai̸=ˆai.\nInpreviousworks,Huetal.\n[96]constructquestionsfrompasthistorieswithannotatedgroundtruthsandcalculatetheaccuracyofwhethertherecalledmemorycouldmatchthecorrectanswers.\nSimilarly,Packeretal.\n[100]generatequestionsandanswersthatcanonlybederivedfrompastsessions,andcomparetheresponsesfromtheagentswiththegroundtruthstocalculatetheaccuracy.\nReferenceAccuracy.\nThismetricevaluateswhethertheagentcandiscoverrelevantmemorycontentstoanswerthequestions.\nDifferentfromtheabovemetric,whichfocusesonthefinalresults,referenceaccuracycaresmoreabouttheintermediateinformationtosupporttheagent’sfinaldecisions.\nInspecific,itcomparestheretrievedmemorywiththepre-preparedgroundtruth.\nFortheaboveproblemof\"WheredidAlicegotoday?\n\",ifthememorycontentsinclude(A)\"AlicehadlunchwithfriendsatWangfujingtoday.\n\"and(B)\"Alicehadroastduckforlunch\",thenabettermemorymoduleshouldselect(A)asareferencetoanswerthequestion.\nUsually,researchersleverageF1-scoretoevaluatethereferenceaccuracy,whichiscalculatedasF1=2·Precision·RecallPrecision+Recall,wheretheprecisionandrecallscoresarecalculatedasPrecision=TPTP+FN.\nTheTPrepresentsthenumberoftruepositivememorycontents,FPmeansthenumberoffalsepositivememorycontents,andFNindicatesthenumberoffalsenegativememorycontents.",
      "#memory_survey#ObjectiveEvaluation#memory_survey#ObjectiveEvaluation\nUsually,researchersleverageF1-scoretoevaluatethereferenceaccuracy,whichiscalculatedasF1=2·Precision·RecallPrecision+Recall,wheretheprecisionandrecallscoresarecalculatedasPrecision=TPTP+FN.\nTheTPrepresentsthenumberoftruepositivememorycontents,FPmeansthenumberoffalsepositivememorycontents,andFNindicatesthenumberoffalsenegativememorycontents.\nInpreviousworks,Luetal.\n[94]utilizeF1-scoretoevaluatetheretrievalprocessofthememory,andZhongetal.\n[6]focusonassessingwhetherrelatedmemorycanbesuccessfullyretrieved.\nTP+FPandRecall=TPResultCorrectnessandReferenceAccuracyarebothutilizedtoevaluatetheeffectivenessofthememorymodule.\nBeyondeffectiveness,efficiencyisalsoanimportantaspect,especiallyforreal-worldapplications.\nTherefore,wedescribetheevaluationofefficiencyasfollows.\nTime&HardwareCost.\nThetotaltimecostincludesthetimeleveragedformemoryadaptionandinference.\nTheadaptationtimereferstothetimeofmemorywritingandmemorymanagement,whiletheinferencetimeindicatesthetimelatencyofmemoryreading.\nInspecific,thedifferencefromthe21endtimetothestarttimeofmemoryoperationscanbeconsideredasthetimeconsumption.\nFormally,theaveragetimeconsumptionofeachtypeofoperationcanberepresentedas∆time=1MM(cid:88)i=1i−tstarttendi,whereMrepresentsthenumberoftheseoperations,tendimeanstheendtimeofthei-thoperation,andtstartindicatesthestarttimeofthatoperation.\nAsforthecomputationoverhead,itcanbeevaluatedibythepeakGPUmemoryallocation.\nInpreviousworks,Tacketal.\n[106]utilizethepeakmemoryallocationandadaptationtimetoassesstheefficiencyofmemoryoperations.\nObjectiveevaluationoffersnumericstrategiestocomparedifferentmethodsofmemory,whichisimportanttobenchmarkthisfieldandpromotefuturedevelopments.\n6.\n2",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThismetricevaluateswhethertheagentcandiscoverrelevantmemorycontentstoanswerthequestions.\nDifferentfromtheabovemetric,whichfocusesonthefinalresults,referenceaccuracycaresmoreabouttheintermediateinformationtosupporttheagent’sfinaldecisions.\nInspecific,itcomparestheretrievedmemorywiththepre-preparedgroundtruth.\nFortheaboveproblemof\"WheredidAlicegotoday?\n\",ifthememorycontentsinclude(A)\"AlicehadlunchwithfriendsatWangfujingtoday.\n\"and(B)\"Alicehadroastduckforlunch\",thenabettermemorymoduleshouldselect(A)asareferencetoanswerthequestion.\nUsually,researchersleverageF1-scoretoevaluatethereferenceaccuracy,whichiscalculatedasF1=2·Precision·RecallPrecision+Recall,wheretheprecisionandrecallscoresarecalculatedasPrecision=TPTP+FN.\nTheTPrepresentsthenumberoftruepositivememorycontents,FPmeansthenumberoffalsepositivememorycontents,andFNindicatesthenumberoffalsenegativememorycontents.\nInpreviousworks,Luetal.\n[94]utilizeF1-scoretoevaluatetheretrievalprocessofthememory,andZhongetal.\n[6]focusonassessingwhetherrelatedmemorycanbesuccessfullyretrieved.\nTP+FPandRecall=TPResultCorrectnessandReferenceAccuracyarebothutilizedtoevaluatetheeffectivenessofthememorymodule.\nBeyondeffectiveness,efficiencyisalsoanimportantaspect,especiallyforreal-worldapplications.\nTherefore,wedescribetheevaluationofefficiencyasfollows.\nTime&HardwareCost.\nThetotaltimecostincludesthetimeleveragedformemoryadaptionandinference.\nTheadaptationtimereferstothetimeofmemorywritingandmemorymanagement,whiletheinferencetimeindicatesthetimelatencyofmemoryreading.\nInspecific,thedifferencefromthe21endtimetothestarttimeofmemoryoperationscanbeconsideredasthetimeconsumption.\nFormally,theaveragetimeconsumptionofeachtypeofoperationcanberepresentedas∆time=1MM(cid:88)i=1i−tstarttendi,whereMrepresentsthenumberoftheseoperations,tendimeanstheendtimeofthei-thoperation,andtstartindicatesthestarttimeofthatoperation.\nAsforthecomputationoverhead,itcanbeevaluatedibythepeakGPUmemoryallocation.\nInpreviousworks,Tacketal.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nInaddition,thegranularityoftheratingsshouldalsobecarefullydesigned.\nToocoarseratingsmaynoteffectivelydiscriminatethecapabilitiesofdifferentmemorymodules,whiletoofine-grainedonesmaybringmoreeffortfortheworkerstomakejudgments.\nIngeneral,subjectiveevaluationcanbeusedinawiderangeofscenarios,whereonejustneedstodefinetheevaluationaspectsandletrecruitedworkersmakejudgments.\nThismethodisusuallymoreexplainablesincetheworkerscanprovidethereasonsfortheirjudgments.\nHowever,subjectiveevaluationiscostlyduetotheneedtoemployhumanevaluators.\nAdditionally,differentgroupsofevaluatorsmayhavevariousbiases,makingtheresultsdifficulttoreproduceandcompare.\n6.\n1.\n2ObjectiveEvaluationInobjectiveevaluation,previousworkusuallydefinesnumericmetricstoevaluatetheeffectivenessandefficiencyofthememorymodule.\nResultCorrectness.\nThismetricmeasureswhethertheagentcansuccessfullyanswerpre-definedquestionsdirectlybasedonthememorymodule.\nForexample,thequestioncouldbe\"WheredidAlicegotoday?\n\"withtwochoices\"A:theSummerPalace\"and\"B:theGreatWall\".\nThen,theagentshouldchoosethecorrectanswerbasedontheproblemanditsmemory.\nTheagent-generatedanswerwillbecomparedwiththegroundtruth.\nFormally,theaccuracycanbecalculatedasCorrectness=1NN(cid:88)i=1I[ai=ˆai],whereNisthenumberofproblems,airepresentsthegroundtruthforthei-thproblem,ˆaimeanstheanswergivenbytheagent,andI[ai=ˆai]isthematchingfunctioncommonlyrepresentedasI[ai=ˆai]=(cid:26)10ifai=ˆai,ifai̸=ˆai.\nInpreviousworks,Huetal.\n[96]constructquestionsfrompasthistorieswithannotatedgroundtruthsandcalculatetheaccuracyofwhethertherecalledmemorycouldmatchthecorrectanswers.\nSimilarly,Packeretal.\n[100]generatequestionsandanswersthatcanonlybederivedfrompastsessions,andcomparetheresponsesfromtheagentswiththegroundtruthstocalculatetheaccuracy.\nReferenceAccuracy.\nThismetricevaluateswhethertheagentcandiscoverrelevantmemorycontentstoanswerthequestions.\nDifferentfromtheabovemetric,whichfocusesonthefinalresults,referenceaccuracycaresmoreabouttheintermediateinformationtosupporttheagent’sfinaldecisions.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThisaspectreferstowhethertherecalledmemoryisnaturalandsuitableforthecurrentcontext.\nForexample,iftheagentismakingaplanforAlice’stravel,thememoryshouldberelatedtoherpreferencefortravelingratherthanworking.\nInpreviousworks,Modarressietal.\n[7]studywhetherthememorymodulecouldprovideproperreferencesamongtheever-changingknowledge.\nLiangetal.\n[98]presentsomeexamplestodemonstratetherelationbetweenthecurrentqueryandhistoricalmemory.\nZhongetal.\n[6]andLiuetal.\n[97]assessthecoherenceofresponsesthatintegratecontextandretrievedmemorybyscoringlabels.\nLeeetal.\n[101]focusonthecontradictionbetweentherecalledmemoryandcontexts.\nRationality.\nThisaspectaimstoevaluatewhethertherecalledmemoryisreasonable.\nForexample,iftheagentisaskedtoanswer\"WhereistheSummerPalace\",therecalledmemoryshouldbe\"TheSummerPalaceisinBeijing\"ratherthan\"TheSummerPalaceisontheMoon\".\nInpreviousworks,Leeetal.\n[101]askcrowdworkerstodirectlyscoretherationalityoftheretrievedmemory.\nZhongetal.\n[6]andLiuetal.\n[97]recruithumanevaluatorstocheckifthememorycontainsreasonableanswersforthecurrentquestion.\nAsforhowtoconducttheevaluationprocess,therearetwoimportantproblems.\nThefirstoneishowtoselectthehumanevaluators.\nIngeneral,theevaluatorsshouldbefamiliarwiththeevaluationtask,whichensuresthatthelabelingresultsareconvincingandreliable.\nInaddition,thebackgroundsoftheevaluatorsshouldbediversetoremovesubjectivebiasesofspecifichumangroups.\nThesecondproblemishowtolabeltheoutputsofthememorymodule.\nUsually,onecaneitherdirectlyscorethe20results[6]ormakecomparisonsbetweentwocandidates[95].\nTheformercanobtainabsoluteandquantitativeevaluationresults,whilethelattercanremovethelabelingnoiseswhenindependentlyscoringeachcandidate.\nInaddition,thegranularityoftheratingsshouldalsobecarefullydesigned.\nToocoarseratingsmaynoteffectivelydiscriminatethecapabilitiesofdifferentmemorymodules,whiletoofine-grainedonesmaybringmoreeffortfortheworkerstomakejudgments.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nThesestatementswillbegeneratedbyagentsasaseriesofChain-of-Memoryinadvance.\nInMPC[101],theagentscanretrieverelevantmemoryfromthememorypool.\nThismethodalsoproposestoprovideChain-of-Thoughtexamplesforignoringcertainmemory.\nExpeL[82]utilizestheFaiss[124]vectorstoreasthepoolofmemory,andobtainsthetop-Ksuccessfultrajectoriesthatsharethehighestsimilarityscoreswiththecurrenttask.\nDiscussion.\nTosomeextent,thememoryreadingandwritingoperationsarecollaborative,andtheformsofmemorywritinggreatlyinfluencethemethodsofmemoryreading.\nFortheformsoftextual19Figure5:Anoverviewoftheevaluationmethodsofthememorymodule.\nmemory,mostpreviousworksusethetextsimilarityandotherauxiliaryinformationforreading.\nFortheformsofparametricmemory,existingmodelsmayjustutilizetheupdatedparametersforinference,whichcanbeseenasanimplicitreadingprocess.\n6",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.\nDuringmemoryreading,matchingscoresarecalculatedforeachmemoryentry,andthetop-Kentrieswillbeusedforthedecision-makingprocessofagents.\n15Inexistingstudies,mostagentsutilizeretrievalmethodstoprocessthememoryinformation.\nForexample,Parketal.\n[83]firstcalculatetherelevancebetweenthecurrentcontextandmemoryentriesbycosinesimilarity,andobtaintheimportanceandrecencyaccordingtoauxiliaryinformation.\nMemoryBank[6]employsadual-towerdenseretrievalmodeltofindrelatedinformationfrompastconversations.\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage.",
      "#memory_survey#OtherTasks#memory_survey#OtherTasks\nOtherTasksInadditiontotheabovethreetypesofmajortasksforindirectevaluation,therearealsosomeothermetricsingeneraltasksthatcanrevealtheeffectivenessofthememorymodule.\nSuccessratereferstotheproportionoftasksthatagentscansuccessfullysolve.\nForYaoetal.\n[104],Shinnetal.\n[5]andZhaoetal.\n[82],theyassesshowmanyspacialtaskscanbecorrectlycompletedthroughreasoningandmemoryinAlfWorld[141].\nInZhuetal.\n[93],theyevaluatethesuccessrateofproducingdifferentitemsinMinecrafttoshowtheeffectofmemory.\nMoreover,Shinnetal.\n[5]measurethesuccessrateofpassedproblemsbygeneratedcodes,andZhengetal.\n[91]calculatethesuccessrateofcomputercontrolandaccuracyofelementselectiontoshowthefunctionoftrajectory-as-exemplarmemory.\nExplorationdegreetypicallyappearsinexploratorygames,whichreflectstheextentthatagentscanexploretheenvironment.\nForexample,Wangetal.\n[99]comparethenumbersofdistinctitemsexploredinMinecrafttoreflecttheskilllearninginmemory.\nInfact,nearlyallthememory-equippedagentscanevaluatetheeffectofmemorybyablationstudies,comparingtheperformancebetweenwith/withoutmemorymodules.\nTheevaluationonspecificscenarioscanbetterreflectthesignificanceofmemoryforthedownstreamapplicationspractically.\n6.\n3",
      "#memory_survey#SubjectiveEvaluation#memory_survey#SubjectiveEvaluation\nSubjectiveEvaluationInsubjectiveevaluation,therearetwokeyproblems,thatis,(1)whataspectsshouldbeevaluatedand(2)howtoconducttheevaluationprocess.\nTobeginwith,thefollowingtwoaspectsarethemostcommonperspectivesleveragedtoevaluatethememorymodule.\nCoherence.\nThisaspectreferstowhethertherecalledmemoryisnaturalandsuitableforthecurrentcontext.\nForexample,iftheagentismakingaplanforAlice’stravel,thememoryshouldberelatedtoherpreferencefortravelingratherthanworking.\nInpreviousworks,Modarressietal.\n[7]studywhetherthememorymodulecouldprovideproperreferencesamongtheever-changingknowledge.\nLiangetal.\n[98]presentsomeexamplestodemonstratetherelationbetweenthecurrentqueryandhistoricalmemory.\nZhongetal.\n[6]andLiuetal.\n[97]assessthecoherenceofresponsesthatintegratecontextandretrievedmemorybyscoringlabels.\nLeeetal.\n[101]focusonthecontradictionbetweentherecalledmemoryandcontexts.\nRationality.\nThisaspectaimstoevaluatewhethertherecalledmemoryisreasonable.\nForexample,iftheagentisaskedtoanswer\"WhereistheSummerPalace\",therecalledmemoryshouldbe\"TheSummerPalaceisinBeijing\"ratherthan\"TheSummerPalaceisontheMoon\".\nInpreviousworks,Leeetal.\n[101]askcrowdworkerstodirectlyscoretherationalityoftheretrievedmemory.\nZhongetal.\n[6]andLiuetal.\n[97]recruithumanevaluatorstocheckifthememorycontainsreasonableanswersforthecurrentquestion.\nAsforhowtoconducttheevaluationprocess,therearetwoimportantproblems.\nThefirstoneishowtoselectthehumanevaluators.\nIngeneral,theevaluatorsshouldbefamiliarwiththeevaluationtask,whichensuresthatthelabelingresultsareconvincingandreliable.\nInaddition,thebackgroundsoftheevaluatorsshouldbediversetoremovesubjectivebiasesofspecifichumangroups.\nThesecondproblemishowtolabeltheoutputsofthememorymodule.\nUsually,onecaneitherdirectlyscorethe20results[6]ormakecomparisonsbetweentwocandidates[95].\nTheformercanobtainabsoluteandquantitativeevaluationresults,whilethelattercanremovethelabelingnoiseswhenindependentlyscoringeachcandidate.\nInaddition,thegranularityoftheratingsshouldalsobecarefullydesigned.",
      "#memory_survey#SubjectiveEvaluation#memory_survey#SubjectiveEvaluation\nTheformercanobtainabsoluteandquantitativeevaluationresults,whilethelattercanremovethelabelingnoiseswhenindependentlyscoringeachcandidate.\nInaddition,thegranularityoftheratingsshouldalsobecarefullydesigned.\nToocoarseratingsmaynoteffectivelydiscriminatethecapabilitiesofdifferentmemorymodules,whiletoofine-grainedonesmaybringmoreeffortfortheworkerstomakejudgments.\nIngeneral,subjectiveevaluationcanbeusedinawiderangeofscenarios,whereonejustneedstodefinetheevaluationaspectsandletrecruitedworkersmakejudgments.\nThismethodisusuallymoreexplainablesincetheworkerscanprovidethereasonsfortheirjudgments.\nHowever,subjectiveevaluationiscostlyduetotheneedtoemployhumanevaluators.\nAdditionally,differentgroupsofevaluatorsmayhavevariousbiases,makingtheresultsdifficulttoreproduceandcompare.\n6.\n1.\n2",
      "#memory_survey#MemoryForms#memory_survey#MemoryForms\nMemoryFormsIngeneral,therearetwoformstorepresentthememorycontents:textualformandparametricform.\nIntextualform,theinformationisexplicitlyretainedandrecalledbynaturallanguages.\nInparametric3https://www.\nwikipedia.\norg13Table2:Summarizationofthememoryforms.\nWeuse✓and×tolabelwhetherornotthecorrespondingmemoryformisadoptedinthemodel.\nModelsMemoryBank[6]RET-LLM[7]ChatDB[96]TiM[97]SCM[98]Voyager[99]MemGPT[100]MemoChat[94]MPC[101]GenerativeAgents[83]RecMind[102]Retroformer[103]ExpeL[82]Synapse[91]GITM[93]ReAct[104]Reflexion[5]RecAgent[95]Character-LLM[105]MAC[106]Huatuo[107]ChatDev[1]InteRecAgent[108]MetaAgents[109]TPTU[110,111]MetaGPT[112]S3[2]InvestLM[113]TextualFormParametricFormCompleteRecentRetrievedExternalFine-tuningEditing××××××××××✓✓✓×✓✓✓×××✓✓××✓✓×✓××××✓×✓××××××××××✓✓×××✓×××××✓✓✓✓✓✓✓✓✓✓××✓✓✓××✓××××✓✓××✓××××××××××××✓✓×✓✓✓×××××✓×✓××××××××××××××✓××××××✓×✓××××××✓×××××××××××××××××××✓××××××××form,thememoryinformationisencodedintoparametersandimplicitlyinfluencestheagent’sactions.\nWesummarizepreviousworksonmemoryformswiththeirimplementationsinTable2.\n5.\n2.\n1",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.\nDuringmemoryreading,matchingscoresarecalculatedforeachmemoryentry,andthetop-Kentrieswillbeusedforthedecision-makingprocessofagents.\n15Inexistingstudies,mostagentsutilizeretrievalmethodstoprocessthememoryinformation.\nForexample,Parketal.\n[83]firstcalculatetherelevancebetweenthecurrentcontextandmemoryentriesbycosinesimilarity,andobtaintheimportanceandrecencyaccordingtoauxiliaryinformation.\nMemoryBank[6]employsadual-towerdenseretrievalmodeltofindrelatedinformationfrompastconversations.\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage.\nItutilizesLocality-SensitiveHashing(LSH)toretrievetupleswithrelativeentriesinthedatabasetoprovidemoreinformation.\nInaddition,ChatDB[96]designstoutilizesymbolicmemory,andproposestogenerateSQLstatementstoretrievefromdatabasetoobtainstoredinformation."
    ],
    [
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[63]HaiyanZhao,HanjieChen,FanYang,NinghaoLiu,HuiqiDeng,HengyiCai,ShuaiqiangWang,DaweiYin,andMengnanDu.\nExplainabilityforlargelanguagemodels:Asurvey.\nACMTransactionsonIntelligentSystemsandTechnology,2023.\n[64]YifanYao,JinhaoDuan,KaidiXu,YuanfangCai,EricSun,andYueZhang.\nAsurveyonlargelanguagemodel(llm)securityandprivacy:Thegood,thebad,andtheugly.\narXivpreprintarXiv:2312.\n02003,1,2023.\n[65]ErfanShayegani,MdAbdullahAlMamun,YuFu,PedramZaree,YueDong,andNaelAbu-Ghazaleh.\nSurveyofvulnerabilitiesinlargelanguagemodelsrevealedbyadversarialattacks.\narXivpreprintarXiv:2310.\n10844,2023.\n[66]SethNeelandPeterChang.\nPrivacyissuesinlargelanguagemodels:Asurvey.\narXivpreprintarXiv:2312.\n06717,2023.\n[67]VictoriaSmith,AliShahinShamsabadi,CarolynAshurst,andAdrianWeller.\nIdentifyingandmitigatingprivacyrisksstemmingfromlanguagemodels:Asurvey.\narXivpreprintarXiv:2310.\n01424,2023.\n[68]ZhichenDong,ZhanhuiZhou,ChaoYang,JingShao,andYuQiao.\nAttacks,defensesandevaluationsforllmconversationsafety:Asurvey.\narXivpreprintarXiv:2402.\n09283,2024.\n[69]BadhanChandraDas,MHadiAmini,andYanzhaoWu.\nSecurityandprivacychallengesoflargelanguagemodels:Asurvey.\narXivpreprintarXiv:2402.\n00888,2024.\n[70]WayneXinZhao,KunZhou,JunyiLi,TianyiTang,XiaoleiWang,YupengHou,YingqianMin,BeichenZhang,JunjieZhang,ZicanDong,etal.\nAsurveyoflargelanguagemodels.\narXivpreprintarXiv:2303.\n18223,2023.\n32[71]MuhammadUsmanHadi,RizwanQureshi,AbbasShah,MuhammadIrfan,AnasZafar,MuhammadBilalShaikh,NaveedAkhtar,JiaWu,SeyedaliMirjalili,etal.\nAsurveyonlargelanguagemodels:Applications,challenges,limitations,andpracticalusage.\nAuthoreaPreprints,2023.\n[72]BonanMin,HayleyRoss,EliorSulem,AmirPouranBenVeyseh,ThienHuuNguyen,OscarSainz,EnekoAgirre,IlanaHeintz,andDanRoth.\nRecentadvancesinnaturallanguageprocessingvialargepre-trainedlanguagemodels:Asurvey.\nACMComputingSurveys,56(2):1–40,2023.\n[73]GrégoireMialon,RobertoDessì,MariaLomeli,ChristoforosNalmpantis,RamPasunuru,RobertaRaileanu,BaptisteRozière,TimoSchick,JaneDwivedi-Yu,AsliCelikyilmaz,etal.\nAugmentedlanguagemodels:asurvey.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[167]ZhangchengQiang,WeiqingWang,andKerryTaylor.\nAgent-om:Leveraginglargelanguagemodelsforontologymatching.\narXivpreprintarXiv:2312.\n00326,2023.\n[168]LichengWen,DaochengFu,XinLi,XinyuCai,TaoMa,PinlongCai,MinDou,BotianShi,LiangHe,andYuQiao.\nDilu:Aknowledge-drivenapproachtoautonomousdrivingwithlargelanguagemodels.\narXivpreprintarXiv:2309.\n16292,2023.\n[169]ZhitaoWang,WeiWang,ZiraoLi,LongWang,CanYi,XinjieXu,LuyangCao,HanjingSu,ShouzhiChen,andJunZhou.\nXuat-copilot:Multi-agentcollaborativesystemforautomateduseracceptancetestingwithlargelanguagemodel.\narXivpreprintarXiv:2401.\n02705,2024.\n[170]YongchaoChen,JacobArkin,YangZhang,NicholasRoy,andChuchuFan.\nScalablemulti-robotcollaborationwithlargelanguagemodels:Centralizedordecentralizedsystems?\narXivpreprintarXiv:2309.\n15943,2023.\n[171]ZhaoMandi,ShreeyaJain,andShuranSong.\nRoco:Dialecticmulti-robotcollaborationwithlargelanguagemodels.\narXivpreprintarXiv:2307.\n04738,2023.\n[172]JonathanLight,MinCai,ShengShen,andZiniuHu.\nFromtexttotactic:Evaluatingllmsplayingthegameofavalon.\narXivpreprintarXiv:2310.\n05036,2023.\n38[173]BingLiu.\nLifelongmachinelearning:aparadigmforcontinuouslearning.\nFrontiersofComputerScience,11:359–361,2017.\n[174]GatiVAher,RosaIArriaga,andAdamTaumanKalai.\nUsinglargelanguagemodelstosimulatemultiplehumansandreplicatehumansubjectstudies.\nInInternationalConferenceonMachineLearning,pages337–371.\nPMLR,2023.\n39",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[120]NelsonFLiu,KevinLin,JohnHewitt,AshwinParanjape,MicheleBevilacqua,FabioPetroni,andPercyLiang.\nLostinthemiddle:Howlanguagemodelsuselongcontexts.\narXivpreprintarXiv:2307.\n03172,2023.\n[121]PeterJDenning.\nThelocalityprinciple.\nCommunicationsoftheACM,48(7):19–24,2005.\n35[122]HermannEbbinghaus.\nMemory:Acontributiontoexperimentalpsychology,trans.\nHARuger&CEBussenius.\nTeachersCollege.\n[rWvH],1885.\n[123]JaapMJMurreandJoeriDros.\nReplicationandanalysisofebbinghaus’forgettingcurve.\nPloSone,10(7):e0120644,2015.\n[124]JeffJohnson,MatthijsDouze,andHervéJégou.\nBillion-scalesimilaritysearchwithgpus.\nIEEETransactionsonBigData,7(3):535–547,2019.\n[125]TimoSchick,JaneDwivedi-Yu,RobertoDessì,RobertaRaileanu,MariaLomeli,LukeZettle-moyer,NicolaCancedda,andThomasScialom.\nToolformer:Languagemodelscanteachthemselvestousetools.\narXivpreprintarXiv:2302.\n04761,2023.\n[126]YujiaQin,ShihaoLiang,YiningYe,KunlunZhu,LanYan,YaxiLu,YankaiLin,XinCong,XiangruTang,BillQian,etal.\nToolllm:Facilitatinglargelanguagemodelstomaster16000+real-worldapis.\narXivpreprintarXiv:2307.\n16789,2023.\n[127]HugoTouvron,ThibautLavril,GautierIzacard,XavierMartinet,Marie-AnneLachaux,Timo-théeLacroix,BaptisteRozière,NamanGoyal,EricHambro,FaisalAzhar,etal.\nLlama:Openandefficientfoundationlanguagemodels.\narXivpreprintarXiv:2302.\n13971,2023.\n[128]ZhibinGou,ZhihongShao,YeyunGong,YujiuYang,MinlieHuang,NanDuan,WeizhuChen,etal.\nTora:Atool-integratedreasoningagentformathematicalproblemsolving.\narXivpreprintarXiv:2309.\n17452,2023.\n[129]HonglinXiong,ShengWang,YitaoZhu,ZihaoZhao,YuxiaoLiu,QianWang,andDinggangShen.\nDoctorglm:Fine-tuningyourchinesedoctorisnotaherculeantask.\narXivpreprintarXiv:2304.\n01097,2023.\n[130]AohanZeng,XiaoLiu,ZhengxiaoDu,ZihanWang,HanyuLai,MingDing,ZhuoyiYang,YifanXu,WendiZheng,XiaoXia,etal.\nGlm-130b:Anopenbilingualpre-trainedmodel.\narXivpreprintarXiv:2210.\n02414,2022.\n[131]EdwardJHu,YelongShen,PhillipWallis,ZeyuanAllen-Zhu,YuanzhiLi,SheanWang,LuWang,andWeizhuChen.\nLora:Low-rankadaptationoflargelanguagemodels.\narXivpreprintarXiv:2106.\n09685,2021.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[35]ZishanGuo,RenrenJin,ChuangLiu,YufeiHuang,DanShi,LinhaoYu,YanLiu,JiaxuanLi,BojianXiong,DeyiXiong,etal.\nEvaluatinglargelanguagemodels:Acomprehensivesurvey.\narXivpreprintarXiv:2310.\n19736,2023.\n[36]JingfengYang,HongyeJin,RuixiangTang,XiaotianHan,QizhangFeng,HaomingJiang,BingYin,andXiaHu.\nHarnessingthepowerofllmsinpractice:Asurveyonchatgptandbeyond.\narXivpreprintarXiv:2304.\n13712,2023.\n30[37]YutaoZhu,HuayingYuan,ShutingWang,JiongnanLiu,WenhanLiu,ChenlongDeng,ZhichengDou,andJi-RongWen.\nLargelanguagemodelsforinformationretrieval:Asurvey.\narXivpreprintarXiv:2308.\n07107,2023.\n[38]DerongXu,WeiChen,WenjunPeng,ChaoZhang,TongXu,XiangyuZhao,XianWu,YefengZheng,andEnhongChen.\nLargelanguagemodelsforgenerativeinformationextraction:Asurvey.\narXivpreprintarXiv:2312.\n17617,2023.\n[39]AngelaFan,BelizGokkaya,MarkHarman,MityaLyubarskiy,ShubhoSengupta,ShinYoo,andJieMZhang.\nLargelanguagemodelsforsoftwareengineering:Surveyandopenproblems.\narXivpreprintarXiv:2310.\n03533,2023.\n[40]JunjieWang,YuchaoHuang,ChunyangChen,ZheLiu,SongWang,andQingWang.\nSoftwaretestingwithlargelanguagemodels:Survey,landscape,andvision.\nIEEETransactionsonSoftwareEngineering,2024.\n[41]ZibinZheng,KaiwenNing,YanlinWang,JingwenZhang,DewuZheng,MingxiYe,andJiachiChen.\nAsurveyoflargelanguagemodelsforcode:Evolution,benchmarking,andfuturetrends.\narXivpreprintarXiv:2311.\n10372,2023.\n[42]FanlongZeng,WenshengGan,YonghengWang,NingLiu,andPhilipSYu.\nLargelanguagemodelsforrobotics:Asurvey.\narXivpreprintarXiv:2311.\n07226,2023.\n[43]CanCui,YunshengMa,XuCao,WenqianYe,YangZhou,KaizhaoLiang,JintaiChen,JuanwuLu,ZichongYang,Kuei-DaLiao,etal.\nAsurveyonmultimodallargelanguagemodelsforautonomousdriving.\nInProceedingsoftheIEEE/CVFWinterConferenceonApplicationsofComputerVision,pages958–979,2024.\n[44]ZhenjieYang,XiaosongJia,HongyangLi,andJunchiYan.\nAsurveyoflargelanguagemodelsforautonomousdriving.\narXivpreprintarXiv:2311.\n01043,2023.\n[45]KaiHe,RuiMao,QikaLin,YuchengRuan,XiangLan,MenglingFeng,andErikCambria.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\narXivpreprintarXiv:2210.\n02414,2022.\n[131]EdwardJHu,YelongShen,PhillipWallis,ZeyuanAllen-Zhu,YuanzhiLi,SheanWang,LuWang,andWeizhuChen.\nLora:Low-rankadaptationoflargelanguagemodels.\narXivpreprintarXiv:2106.\n09685,2021.\n[132]ZhengliangLiu,AoxiaoZhong,YiweiLi,LongtaoYang,ChaoJu,ZihaoWu,ChongMa,PengShu,ChengChen,SekeunKim,etal.\nRadiology-gpt:Alargelanguagemodelforradiology.\narXivpreprintarXiv:2306.\n08666,2023.\n[133]NicolaDeCao,WilkerAziz,andIvanTitov.\nEditingfactualknowledgeinlanguagemodels.\narXivpreprintarXiv:2104.\n08164,2021.\n[134]EricMitchell,CharlesLin,AntoineBosselut,ChelseaFinn,andChristopherDManning.\nFastmodeleditingatscale.\narXivpreprintarXiv:2110.\n11309,2021.\n[135]ShengyuMao,NingyuZhang,XiaohanWang,MengruWang,YunzhiYao,YongJiang,PengjunXie,FeiHuang,andHuajunChen.\nEditingpersonalityforlargelanguagemodels.\n2023.\n[136]Jun-YuMa,Jia-ChenGu,NingyuZhang,andZhen-HuaLing.\nNeighboringperturbationsofknowledgeeditingonlargelanguagemodels.\narXivpreprintarXiv:2401.\n17623,2024.\n[137]MengruWang,NingyuZhang,ZiwenXu,ZekunXi,ShuminDeng,YunzhiYao,QishenZhang,LinyiYang,JindongWang,andHuajunChen.\nDetoxifyinglargelanguagemodelsviaknowledgeediting.\narXivpreprintarXiv:2403.\n14472,2024.\n[138]UriShaham,MaorIvgi,AviaEfrat,JonathanBerant,andOmerLevy.\nZeroscrolls:Azero-shotbenchmarkforlongtextunderstanding.\narXivpreprintarXiv:2305.\n14196,2023.\n[139]YushiBai,XinLv,JiajieZhang,HongchangLyu,JiankaiTang,ZhidianHuang,ZhengxiaoDu,XiaoLiu,AohanZeng,LeiHou,etal.\nLongbench:Abilingual,multitaskbenchmarkforlongcontextunderstanding.\narXivpreprintarXiv:2308.\n14508,2023.\n36[140]DachengLi,RulinShao,AnzeXie,YingSheng,LianminZheng,JosephGonzalez,IonStoica,XuezheMa,andHaoZhang.\nHowlongcancontextlengthofopen-sourcellmstrulypromise?\nInNeurIPS2023WorkshoponInstructionTuningandInstructionFollowing,2023.\n[141]MohitShridhar,XingdiYuan,Marc-AlexandreCôté,YonatanBisk,AdamTrischler,andMatthewHausknecht.\nAlfworld:Aligningtextandembodiedenvironmentsforinteractivelearning.\narXivpreprintarXiv:2010.\n03768,2020.\n[142]YunDaTsai,MingjieLiu,andHaoxingRen.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[111]YilunKong,JingqingRuan,YihongChen,BinZhang,TianpengBao,ShiweiShi,GuoqingDu,XiaoruHu,HangyuMao,ZiyueLi,etal.\nTptu-v2:Boostingtaskplanningandtoolusageoflargelanguagemodel-basedagentsinreal-worldsystems.\narXivpreprintarXiv:2311.\n11315,2023.\n[112]SiruiHong,XiawuZheng,JonathanChen,YuhengCheng,JinlinWang,CeyaoZhang,ZiliWang,StevenKaShingYau,ZijuanLin,LiyangZhou,etal.\nMetagpt:Metaprogrammingformulti-agentcollaborativeframework.\narXivpreprintarXiv:2308.\n00352,2023.\n[113]YiYang,YixuanTang,andKarYanTam.\nInvestlm:Alargelanguagemodelforinvestmentusingfinancialdomaininstructiontuning.\narXivpreprintarXiv:2309.\n13064,2023.\n[114]KechiZhang,JiaLi,GeLi,XianjieShi,andZhiJin.\nCodeagent:Enhancingcodegenerationwithtool-integratedagentsystemsforreal-worldrepo-levelcodingchallenges.\narXivpreprintarXiv:2401.\n07339,2024.\n[115]LiYunxiang,LiZihan,ZhangKai,DanRuilong,andZhangYou.\nChatdoctor:Amedicalchatmodelfine-tunedonllamamodelusingmedicaldomainknowledge.\narXivpreprintarXiv:2303.\n14070,2023.\n[116]DachengLi,RulinShao,AnzeXie,YingSheng,LianminZheng,JosephGonzalez,IonStoica,XuezheMa,andHaoZhang.\nHowlongcancontextlengthofopen-sourcellmstrulypromise?\nInNeurIPS2023WorkshoponInstructionTuningandInstructionFollowing,2023.\n[117]ZihengHuang,SebastianGutierrez,HemanthKamana,andStephenMacNeil.\nMemorysandbox:Transparentandinteractivememorymanagementforconversationalagents.\nInAdjunctProceedingsofthe36thAnnualACMSymposiumonUserInterfaceSoftwareandTechnology,pages1–3,2023.\n[118]ArkaPal,DeepKarkhanis,ManleyRoberts,SamuelDooley,ArvindSundararajan,andSiddarthaNaidu.\nGiraffe:Adventuresinexpandingcontextlengthsinllms.\narXivpreprintarXiv:2308.\n10882,2023.\n[119]SzymonTworkowski,KonradStaniszewski,MikołajPacek,YuhuaiWu,HenrykMichalewski,andPiotrMiło´s.\nFocusedtransformer:Contrastivetrainingforcontextscaling,2023.\n[120]NelsonFLiu,KevinLin,JohnHewitt,AshwinParanjape,MicheleBevilacqua,FabioPetroni,andPercyLiang.\nLostinthemiddle:Howlanguagemodelsuselongcontexts.\narXivpreprintarXiv:2307.\n03172,2023.\n[121]PeterJDenning.\nThelocalityprinciple.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\n[141]MohitShridhar,XingdiYuan,Marc-AlexandreCôté,YonatanBisk,AdamTrischler,andMatthewHausknecht.\nAlfworld:Aligningtextandembodiedenvironmentsforinteractivelearning.\narXivpreprintarXiv:2010.\n03768,2020.\n[142]YunDaTsai,MingjieLiu,andHaoxingRen.\nRtlfixer:Automaticallyfixingrtlsyntaxerrorswithlargelanguagemodels.\narXivpreprintarXiv:2311.\n16543,2023.\n[143]ChengLi,ZiangLeng,ChenxiYan,JunyiShen,HaoWang,WeishiMi,YayingFei,XiaoyangFeng,SongYan,HaoShengWang,etal.\nChatharuhi:Revivinganimecharacterinrealityvialargelanguagemodel.\narXivpreprintarXiv:2308.\n09597,2023.\n[144]DakeChen,HanbinWang,YunhaoHuo,YuzhaoLi,andHaoyangZhang.\nGamegpt:Multi-agentcollaborativeframeworkforgamedevelopment.\narXivpreprintarXiv:2310.\n08067,2023.\n[145]ZekunMooreWang,ZhongyuanPeng,HaoranQue,JiahengLiu,WangchunshuZhou,YuhanWu,HongchengGuo,RuitongGan,ZehaoNi,ManZhang,etal.\nRolellm:Benchmarking,eliciting,andenhancingrole-playingabilitiesoflargelanguagemodels.\narXivpreprintarXiv:2310.\n00746,2023.\n[146]RuncongZhao,WenjiaZhang,JiazhengLi,LixingZhu,YanranLi,YulanHe,andLinGui.\nNarrativeplay:Interactivenarrativeunderstanding.\narXivpreprintarXiv:2310.\n01459,2023.\n[147]JinfengZhou,ZhuangChen,DazhenWan,BosiWen,YiSong,JifanYu,YongkangHuang,Lib-iaoPeng,JiamingYang,XiyaoXiao,etal.\nCharacterglm:Customizingchineseconversationalaicharacterswithlargelanguagemodels.\narXivpreprintarXiv:2311.\n16832,2023.\n[148]ZhaoKaiya,MichelangeloNaim,JovanaKondic,ManuelCortes,JiaxinGe,ShuyingLuo,GuangyuRobertYang,andAndrewAhn.\nLyfeagents:Generativeagentsforlow-costreal-timesocialinteractions.\narXivpreprintarXiv:2310.\n02172,2023.\n[149]JunjieZhang,YupengHou,RuobingXie,WenqiSun,JulianMcAuley,WayneXinZhao,LeyuLin,andJi-RongWen.\nAgentcf:Collaborativelearningwithautonomouslanguageagentsforrecommendersystems.\narXivpreprintarXiv:2310.\n09233,2023.\n[150]WenyueHua,LizhouFan,LingyaoLi,KaiMei,JianchaoJi,YingqiangGe,LibbyHemphill,andYongfengZhang.\nWarandpeace(waragent):Largelanguagemodel-basedmulti-agentsimulationofworldwars.\narXivpreprintarXiv:2311.\n17227,2023.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\nDeltatuning:Acomprehensivestudyofparameterefficientmethodsforpre-trainedlanguagemodels.\narXivpreprintarXiv:2203.\n06904,2022.\n[82]AndrewZhao,DanielHuang,QuentinXu,MatthieuLin,Yong-JinLiu,andGaoHuang.\nExpel:Llmagentsareexperientiallearners.\narXivpreprintarXiv:2308.\n10144,2023.\n[83]JoonSungPark,JosephO’Brien,CarrieJunCai,MeredithRingelMorris,PercyLiang,andMichaelSBernstein.\nGenerativeagents:Interactivesimulacraofhumanbehavior.\nInProceedingsofthe36thAnnualACMSymposiumonUserInterfaceSoftwareandTechnology,pages1–22,2023.\n[84]RobertLSolsoandJeromeKagan.\nCognitivepsychology.\nHoughtonMifflinHarcourtP,1979.\n[85]FergusIMCraikandRobertSLockhart.\nLevelsofprocessing:Aframeworkformemoryresearch.\nJournalofverballearningandverbalbehavior,11(6):671–684,1972.\n[86]SelmaLeydesdorff.\nMemorycultures:Memory,subjectivityandrecognition.\nRoutledge,2017.\n[87]PhilipNicholasJohnson-Laird.\nMentalmodels:Towardsacognitivescienceoflanguage,inference,andconsciousness.\nNumber6.\nHarvardUniversityPress,1983.\n33[88]JohnELaird.\nTheSoarcognitivearchitecture.\nMITpress,2019.\n[89]RonSun.\nDualityofthemind:Abottom-upapproachtowardcognition.\nPsychologyPress,2001.\n[90]RichardSSuttonandAndrewGBarto.\nReinforcementlearning:Anintroduction.\nMITpress,2018.\n[91]LongtaoZheng,RundongWang,XinrunWang,andBoAn.\nSynapse:Trajectory-as-exemplarInNeurIPS2023FoundationModelsforpromptingwithmemoryforcomputercontrol.\nDecisionMakingWorkshop,2023.\n[92]AliMontazeralghaem,HamedZamani,andJamesAllan.\nAreinforcementlearningframeworkforrelevancefeedback.\nInProceedingsofthe43rdinternationalacmsigirconferenceonresearchanddevelopmentininformationretrieval,pages59–68,2020.\n[93]XizhouZhu,YuntaoChen,HaoTian,ChenxinTao,WeijieSu,ChenyuYang,GaoHuang,BinLi,LeweiLu,XiaogangWang,etal.\nGhostintheminecraft:Generallycapableagentsforopen-worldenviromentsvialargelanguagemodelswithtext-basedknowledgeandmemory.\narXivpreprintarXiv:2305.\n17144,2023.\n[94]JunruLu,SiyuAn,MingbaoLin,GabrielePergola,YulanHe,DiYin,XingSun,andYun-shengWu.",
      "#memory_survey#Conclusion#memory_survey#Conclusion\nGhostintheminecraft:Generallycapableagentsforopen-worldenviromentsvialargelanguagemodelswithtext-basedknowledgeandmemory.\narXivpreprintarXiv:2305.\n17144,2023.\n[94]JunruLu,SiyuAn,MingbaoLin,GabrielePergola,YulanHe,DiYin,XingSun,andYun-shengWu.\nMemochat:Tuningllmstousememosforconsistentlong-rangeopen-domainconversation.\narXivpreprintarXiv:2308.\n08239,2023.\n[95]LeiWang,JingsenZhang,HaoYang,ZhiyuanChen,JiakaiTang,ZeyuZhang,XuChen,YankaiLin,RuihuaSong,WayneXinZhao,JunXu,ZhichengDou,JunWang,andJi-RongWen.\nWhenlargelanguagemodelbasedagentmeetsuserbehavioranalysis:Anovelusersimulationparadigm,2023.\n[96]ChenxuHu,JieFu,ChenzhuangDu,SimianLuo,JunboZhao,andHangZhao.\nChatdb:Augmentingllmswithdatabasesastheirsymbolicmemory.\narXivpreprintarXiv:2306.\n03901,2023.\n[97]LeiLiu,XiaoyanYang,YueShen,BinbinHu,ZhiqiangZhang,JinjieGu,andGuannanZhang.\nThink-in-memory:Recallingandpost-thinkingenablellmswithlong-termmemory.\narXivpreprintarXiv:2311.\n08719,2023.\n[98]XinnianLiang,BingWang,HuiHuang,ShuangzhiWu,PeihaoWu,LuLu,ZejunMa,andZhoujunLi.\nUnleashinginfinite-lengthinputcapacityforlarge-scalelanguagemodelswithself-controlledmemorysystem.\narXivpreprintarXiv:2304.\n13343,2023.\n[99]GuanzhiWang,YuqiXie,YunfanJiang,AjayMandlekar,ChaoweiXiao,YukeZhu,LinxiFan,andAnimaAnandkumar.\nVoyager:Anopen-endedembodiedagentwithlargelanguagemodels.\narXivpreprintarXiv:2305.\n16291,2023.\n[100]CharlesPacker,VivianFang,ShishirGPatil,KevinLin,SarahWooders,andJosephEGonzalez.\nMemgpt:Towardsllmsasoperatingsystems.\narXivpreprintarXiv:2310.\n08560,2023.\n[101]GibbeumLee,VolkerHartmann,JonghoPark,DimitrisPapailiopoulos,andKangwookLee.\nPromptedllmsaschatbotmodulesforlongopen-domainconversation.\narXivpreprintarXiv:2305.\n04533,2023.\n[102]YanchengWang,ZiyanJiang,ZhengChen,FanYang,YingxueZhou,EunahCho,XingFan,XiaojiangHuang,YanbinLu,andYingzhenYang.\nRecmind:Largelanguagemodelpoweredagentforrecommendation.\narXivpreprintarXiv:2308.\n14296,2023.",
      "#memory_survey#BasicKnowledge#memory_survey#BasicKnowledge\nBasicKnowledgeForclearpresentations,wefirstintroduceseveralimportantbackgroundknowledgeasfollows:Definition1(Task).\nTaskisthefinaltargetthattheagentneedstoachieve,forexample,bookingaflightticketforAlice,recommendingarestaurantforBob,andsoon.\nFormally,weuseTtorepresentataskandlabeldifferenttasksbysubscriptsinthefollowingcontents.\nDefinition2(Environment).\nInanarrowsense,environmentistheobjectthattheagentneedstointeractwithtoaccomplishthetask.\nFortheexamplesindefinition1,theenvironmentsareAliceandBob,whoprovidefeedbackontheagent’sactions.\nMorebroadly,environmentcanbeanycontextualfactorsthatinfluencetheagent’sdecisions,suchastheweatherwhenbookingflighttickets,thetimeandlocationwhenrecommendingrestaurants,etc.\nDefinition3(TrialandStep).\nToaccomplishatask,theagentneedstointeractwiththeenvironment.\nUsually,theagentfirsttakesanaction,andthentheenvironmentrespondstothisaction.\nAtlast,theagenttakesthenextactionbasedontheresponse.\nThisprocessiteratesuntilthetaskisfinished.\nThecompleteagent-environmentinteractionprocessiscalledatrial,andeachinteractionturniscalleda7Figure3:(a)Examplesofthepotentialtrialsintheagent-environmentinteractionprocess.\n(b)Illustrationofthememoryreading,writing,andmanagementprocesses,wheredottedlinesmeanthatthecross-trialinformationcanbeincorporatedintothememorymodule.\nstep.\nForeachtrial,theagentcantakemultiplestepstoformapotentialsolutiontothetask.\nForeachtask,theagentcanexploremultipletrialstoaccomplishthetask[5].\nFormally,atstept,weuseatandottorepresenttheagentactionandtheobservedenvironmentresponse,respectively.\nThen,aT-lengthtrialcanberepresentedasξT={a1,o1,a2,o2,.\n.\n.\n,oT,aT}.\nIntheabovedefinitions,taskandenvironmentarethemostcoarse-grainedconcepts,whilestepisthemostfine-grainedone.\nTheytogetherdescribethecompleteagent-environmentinteractionprocess.\nAToyExample.\nBasedontheabovedefinitions,weshowatoyexampleanduseitthroughoutthepapertoprovidemoreintuitions."
    ],
    [
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.\nAnotherlimitationoffine-tuningliesinthecomputationalcostandtimeconsumption,aswellastherequirementofalargeamountofdata.\nTherefore,mostfine-tuningapproachesareappliedtoofflinescenarios,andcanseldomdealwithonlinescenarios,suchasfine-tuningwithagentobservationsandtrialexperiences.\nDuetothefrequentagent-environmentinteractions,itisunaffordableforthecostofbackpropagationtofine-tuneeverystepoftheonlineanddynamicinteractions.\nMemoryEditingMethods.",
      "#memory_survey#MemoryinParametricForm#memory_survey#MemoryinParametricForm\nMemoryinParametricFormAnalternativetypeofapproachesistorepresentmemoryinparametricform.\nTheydonottakeuptheextralengthofcontextinprompts,sotheyarenotconstrainedbythelengthlimitationsofLLMcontext.\nHowever,theparametricmemoryformisstillunder-researched,andwecategorizepreviousworksintotwotypes:fine-tuningmethodsandmemoryeditingmethods.\nFine-tuningMethods.\nIntegratingexternalknowledgeintothememoryofagentsisbeneficialforenrichingdomain-specificknowledgeontopofitsgeneralknowledge.\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nItensuresthatunrelatedknowledgeremainsunaffected.\nKnowledgeeditingmethodsaremoresuitableforsmall-scalememoryadjustments.\nGenerally,theyhavelowercomputationalcosts,makingthemmoresuitableforonlinescenarios.\nInourexampleoftask(B),Alicealwayswatchesmoviesat9:00PMfromtheagent’smemory,butshemayrecentlychangeherworkandwouldnotbeemptyat9:00PM.\nIfso,therelatedmemory(suchasroutinesat9:00PM)shouldbeedited,whichcanbeimplementedbyknowledgeeditingmethods.\nInpreviousstudies,MAC[106]intendstodesignaneffectiveandefficientmemoryadaptationframeworkforonlinescenarios.\nItutilizesmeta-learningtosubstitutetheoptimizationstep.\nPer-sonalityEdit[135]focusesoneditingthepersonalityofLLMsandagents,whereitchangestheirtraitsbasedontheoriessuchasthebig-fivefactor.\nMEND[134]utilizestheideaofmeta-learningtotrainalightweightmodel,whichiscapableofgeneratingmodificationsformodelparametersofapre-trainedlanguagemodel.\nAPP[136]studieswhetheraddinganewfactleadstocatastrophicforgettingofexistingfacts.\nItfocusesontheimpactofneighborperturbationonmemoryaddition.\nMoreover,KnowledgeEditor[133]trainsahyper-networktopredictthemodificationofmodelpa-rameterswheninjectingmemorybasedonalearning-to-updateproblemformulation.\nWangetal.\n[137]proposeanewoptimizationtargettochangethepoisoningknowledgeofLLM,andmaintainthegeneralperformanceatthesametime.\nForLLM-basedagents,theagentscanchangebadmemorybyknowledgeediting,whichcanbeconsideredasatypeofforgettingmechanism.\nKnowledgeeditingmethodsprovideaninnovativewaytoupdatetheinformationstoredwithintheparametersofLLMs.\nByspecificallytargetingandadjustingthefacts,thesemethodscanensurethenon-targetedknowledgeunaffectedduringupdates,thusmitigatingtheissueofcatastrophicforgetting.\nMoreover,thetargetedadjustmentmechanismallowsformoreefficientandlessresource-intensiveupdates,makingknowledgeeditinganappealingchoiceforhigh-precisionandreal-timemodifications.\nHowever,despitethesepromisingdevelopments,computationalcostsofmeta-trainingandthepreservationofunrelatedmemoriesremainsignificantchallenges.\n5.\n2.",
      "#memory_survey#MemoryinParametricForm#memory_survey#MemoryinParametricForm\nMEND[134]utilizestheideaofmeta-learningtotrainalightweightmodel,whichiscapableofgeneratingmodificationsformodelparametersofapre-trainedlanguagemodel.\nAPP[136]studieswhetheraddinganewfactleadstocatastrophicforgettingofexistingfacts.\nItfocusesontheimpactofneighborperturbationonmemoryaddition.\nMoreover,KnowledgeEditor[133]trainsahyper-networktopredictthemodificationofmodelpa-rameterswheninjectingmemorybasedonalearning-to-updateproblemformulation.\nWangetal.\n[137]proposeanewoptimizationtargettochangethepoisoningknowledgeofLLM,andmaintainthegeneralperformanceatthesametime.\nForLLM-basedagents,theagentscanchangebadmemorybyknowledgeediting,whichcanbeconsideredasatypeofforgettingmechanism.\nKnowledgeeditingmethodsprovideaninnovativewaytoupdatetheinformationstoredwithintheparametersofLLMs.\nByspecificallytargetingandadjustingthefacts,thesemethodscanensurethenon-targetedknowledgeunaffectedduringupdates,thusmitigatingtheissueofcatastrophicforgetting.\nMoreover,thetargetedadjustmentmechanismallowsformoreefficientandlessresource-intensiveupdates,makingknowledgeeditinganappealingchoiceforhigh-precisionandreal-timemodifications.\nHowever,despitethesepromisingdevelopments,computationalcostsofmeta-trainingandthepreservationofunrelatedmemoriesremainsignificantchallenges.\n5.\n2.\n3",
      "#memory_survey#D:\\projects\\KAG\\kag\\examples\\memory_survey_test\\builder\\./data/memory_survey.pdf#memory_survey#D:\\projects\\KAG\\kag\\examples\\memory_survey_test\\builder\\./data/memory_survey.pdf\nASurveyontheMemoryMechanismofLargeLanguageModelbasedAgentsZeyuZhang1,XiaoheBo1,ChenMa1,RuiLi1,XuChen1,QuanyuDai2,JiemingZhu2,ZhenhuaDong2,Ji-RongWen11GaolingSchoolofArtificialIntelligence,RenminUniversityofChina,Beijing,China2HuaweiNoah’sArkLab,Chinazeyuzhang@ruc.\nedu.\ncn,xu.\nchen@ruc.\nedu.\ncnAbstractLargelanguagemodel(LLM)basedagentshaverecentlyattractedmuchattentionfromtheresearchandindustrycommunities.\nComparedwithoriginalLLMs,LLM-basedagentsarefeaturedintheirself-evolvingcapability,whichisthebasisforsolvingreal-worldproblemsthatneedlong-termandcomplexagent-environmentinteractions.\nThekeycomponenttosupportagent-environmentinteractionsisthememoryoftheagents.\nWhilepreviousstudieshaveproposedmanypromisingmem-orymechanisms,theyarescatteredindifferentpapers,andtherelacksasystemati-calreviewtosummarizeandcomparetheseworksfromaholisticperspective,fail-ingtoabstractcommonandeffectivedesigningpatternsforinspiringfuturestudies.\nTobridgethisgap,inthispaper,weproposeacomprehensivesurveyonthememorymechanismofLLM-basedagents.\nInspecific,wefirstdiscuss“whatis”and“whydoweneed”thememoryinLLM-basedagents.\nThen,wesystematicallyreviewpreviousstudiesonhowtodesignandevaluatethememorymodule.\nInaddition,wealsopresentmanyagentapplications,wherethememorymoduleplaysanimportantrole.\nAtlast,weanalyzethelimitationsofexistingworkandshowimportantfuturedirections.\nTokeepupwiththelatestadvancesinthisfield,wecreatearepositoryathttps://github.\ncom/nuster1128/LLM_Agent_Memory_Survey.\n4202rpA12]IA.\nsc[1v10531.\n4042:viXraFigure1:TheimportanceofthememorymoduleinLLM-basedagents.\nPreprint.\nUnderreview.\nPersonalAssistantPleasehelpmetoexplain“LLM-basedagent”.\nALLM-basedagentisatypeofartificial……Inwhichscenariosdoesithaveapplications?\nPersonalassistant,game,codegeneration,……(Knowledge)Accordingtothepreviousworks,largelanguagemodelbasedagentsrefertoartificial……(Context)ThecurrenttopicisLLM-basedagent.\n“It”referstoLLM-basedagentsinthisconversation."
    ],
    [
      "#memory_survey#PerspectiveofAgentApplications#memory_survey#PerspectiveofAgentApplications\nPerspectiveofAgentApplicationsInmanyapplications,memoryisanindispensablecomponentoftheagent.\nForexample,inaconver-sationalagent,thememorystoresinformationabouthistoricalconversations,whichisnecessaryfortheagenttogeneratethenextresponse.\nWithoutmemory,theagentdoesnotknowthecontext,andcannotcontinuetheconversation[94].\nInasimulationagent,memoryisofgreatimportancetomaketheagentconsistentlyfollowtheroleprofiles.\nWithoutmemory,theagentmayeasilystepoutoftheroleduringthesimulationprocess[95].\nBothoftheaboveexamplesshowthatthememoryisnotanoptionalcomponent,butisnecessaryfortheagentstoaccomplishgiventasks.\nIntheabovethreeperspectives,thefirstonerevealsthatthememorybuildsthecognitivebasisoftheagent.\nThesecondandthirdonesshowthatthememoryisnecessaryfortheagent’sevolvingprinciplesandapplications,whichprovideinsightsfordesigningagentswithmemorymechanisms.\n5",
      "#memory_survey#Introduction#memory_survey#Introduction\nIntroduction\"Withoutmemory,thereisnoculture.\nWithoutmemory,therewouldbenocivilization,nosociety,nofuture.\n\"ElieWiesel,1928-2016Recently,largelanguagemodels(LLMs)haveachievedremarkablesuccessinalargenumberofdomains,rangingfromartificialintelligenceandsoftwareengineeringtoeducationandsocialsci-ence[1–3].\nOriginalLLMsusuallyaccomplishdifferenttaskswithoutinteractingwithenvironments.\nHowever,toachievethefinalgoalofartificialgeneralintelligence(AGI),intelligentmachinesshouldbeabletoimprovethemselvesbyautonomouslyexploringandlearningfromtherealworld.\nForexample,ifatrip-planningagentintendstobookaticket,itshouldsendanorderrequesttotheticketwebsite,andobservetheresponsebeforetakingthenextaction.\nApersonalassistantagentshouldadjustitsbehaviorsaccordingtotheuser’sfeedback,providingpersonalizedresponsestoimproveuser’ssatisfaction.\nTofurtherpushtheboundaryofLLMstowardsAGI,recentyearshavewitnessedalargenumberofstudiesonLLM-basedagents[3,4],wherethekeyistoequipLLMswithadditionalmodulestoenhancetheirself-evolvingcapabilityinreal-worldenvironments.\nAmongalltheaddedmodules,memoryisakeycomponentthatdifferentiatestheagentsfromoriginalLLMs,makinganagenttrulyanagent(seeFigure1).\nItplaysanextremelyimportantroleindetermininghowtheagentaccumulatesknowledge,processeshistoricalexperience,retrievesinformativeknowledgetosupportitsactions,andsoon.\nAroundthememorymodule,peoplehavedevotedmuchefforttodesigningitsinformationsources,storageforms,andoperationmechanisms.\nForexample,Shinnetal.\n[5]incorporatebothin-trialandcross-trialinformationtobuildthememorymoduleforenhancingtheagent’sreasoningcapability.\nZhongetal.\n[6]storememoryinformationintheformofnaturallanguages,whichisexplainableandfriendlytotheusers.\nModarressietal.\n[7]designbothmemoryreadingandwritingoperationstointeractwithenvironmentsfortasksolving.\nWhilepreviousstudieshavedesignedmanypromisingmemorymodules,therestilllacksasystemicstudytoviewthememorymodulesfromaholisticperspective.",
      "#memory_survey#MemoryForms#memory_survey#MemoryForms\nMemoryFormsIngeneral,therearetwoformstorepresentthememorycontents:textualformandparametricform.\nIntextualform,theinformationisexplicitlyretainedandrecalledbynaturallanguages.\nInparametric3https://www.\nwikipedia.\norg13Table2:Summarizationofthememoryforms.\nWeuse✓and×tolabelwhetherornotthecorrespondingmemoryformisadoptedinthemodel.\nModelsMemoryBank[6]RET-LLM[7]ChatDB[96]TiM[97]SCM[98]Voyager[99]MemGPT[100]MemoChat[94]MPC[101]GenerativeAgents[83]RecMind[102]Retroformer[103]ExpeL[82]Synapse[91]GITM[93]ReAct[104]Reflexion[5]RecAgent[95]Character-LLM[105]MAC[106]Huatuo[107]ChatDev[1]InteRecAgent[108]MetaAgents[109]TPTU[110,111]MetaGPT[112]S3[2]InvestLM[113]TextualFormParametricFormCompleteRecentRetrievedExternalFine-tuningEditing××××××××××✓✓✓×✓✓✓×××✓✓××✓✓×✓××××✓×✓××××××××××✓✓×××✓×××××✓✓✓✓✓✓✓✓✓✓××✓✓✓××✓××××✓✓××✓××××××××××××✓✓×✓✓✓×××××✓×✓××××××××××××××✓××××××✓×✓××××××✓×××××××××××××××××××✓××××××××form,thememoryinformationisencodedintoparametersandimplicitlyinfluencestheagent’sactions.\nWesummarizepreviousworksonmemoryformswiththeirimplementationsinTable2.\n5.\n2.\n1",
      "#memory_survey#Memory-enhancedAgentApplications#memory_survey#Memory-enhancedAgentApplications\nMemory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1",
      "#memory_survey#OtherApplications#memory_survey#OtherApplications\nOtherApplicationsTherearesomeotherapplicationsofmemoryinLLM-basedagents.\nWangetal.\n[166]focusonthetaskofcloudrootcauseanalysis,usingmemorytostoreframeworkrules,taskrequirements,tools26documentation,few-shotexamples,andagentobservations.\nQiangetal.\n[167]solvetheproblemofontologymatching.\nTheagentssaveconversationaldialoguesandconstructarationaldatabaseforretrievingexternalknowledge.\nWenetal.\n[168]investigateautonomousdriving,whosememorymoduleisconstructedbyavectordatabaseandcontainstheexperiencesfrompastdrivingscenarios.\nWangetal.\n[169]proposetoimproveuseracceptancetesting,whichemploysaself-reflectionmechanism.\nAftereachtrial,theoperationagentsummarizestheconversationandupdatesthememorypool,untilthegoalofthecurrentstepisaccomplished.\nFordifferentapplications,thefocusofmemoryvaries,asitinherentlyservesthedownstreamtasks.\nTherefore,thedesignshouldalsoconsidertherequirementsoftasks.\n8",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThememorymoduleisanimportantcomponentforsuchapplications,whichhelpstoaccuratelysimulatehumandynamicbehaviors.\nInpreviousstudies,Kaiyaetal.\n[148]proposeaSummarize-and-Forgetmemorymechanismforbetterself-monitoringinsocialscenarios.\nGaoetal.\n[2]focusonsocialnetworksimulationsystems.\nEachagentinthesystemhasamemorypool,whichconsistsofdiverseusermessagesfromonlineplatformstoidentifytheuser.\nLietal.\n[163]maintainconversationcontexts,encompassingtheeconomicenvironmentandagentdecisionsfrompreviousmonths,inordertosimulatetheimpactofbroadmacroeconomictrendsonagents’decision-makingandtomaketheagentsgraspmarketdynamics.\nLietal.\n[109]simulatethejob-seekingscenarioinhumansociety,wherethememoryofagentsincludesprofilesandgoalsinitiallyandisfurtherenrichedwithotherinformation,likedialoguesandpersonalreflections.\nHuaetal.\n[150]simulatethedecisionsandconsequencesoftheparticipatingcountriesinthewars,wheretheconversationsofagentsarecontinuouslymaintainedintomemory.\nThereareseveralinsightsindesigninganagent’smemoryforrole-playandsocialsimulation.\nFirst,thememoryshouldbeconsistentwiththeroles’characteristics,whichcanbeusedtoidentifyeachroleanddistinguishitfromtheothers.\nThisiscrucialforimprovingtherealismofrole-playandthediversityofsocialsimulation.\nSecond,thememoryshouldappropriatelyinfluencethesubsequent24actionsoftheagenttoensuretheconsistencyandrationalityofitsbehaviors.\nAdditionally,forhumanoidagents,theirmemorymechanismsshouldalignwiththefeaturesofhumanmemory,suchasforgettingandlong/short-termmemory,whichshouldrefertothetheoriesofcognitivepsychology.\n7.\n2PersonalAssistantLLM-basedagentsarewell-suitedforcreatingpersonalassistants,suchasagentscapableofengaginginlong-termconversationswithusers[94,101,153],aswellasthosetaskedwithautomaticallyseekinginformation[164].\nTheseagentsoftenneedtomemorizepreviousdialoguestomaintaintheconsistency,andremembercriticalstylesandeventstogeneratemorepersonalizedandrelevantresponses.\nLuetal.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nCodeAgent[114]focusesontherepo-levelcodegenerationtask,whichcommonlyrequirescomplexdependenciesandextensivedocumentation.\nItdesignsawebsearchstrategyforacquiringrelatedexternalknowledge.\nChatDoctor[115]adaptsLLM-basedagentstothemedicaldomain.\nItfine-tunesanacquisitionprocesstoretrieveexternalknowledgefromWikipediaandmedicaldatabases.\nDiscussion.\nTheexternalknowledgecanbeobtainedfrombothprivateandpublicsources.\nItprovidesLLM-basedagentswithmuchknowledgebeyondtheirinternalenvironment,whichmightbedifficultorevenimpossiblefortheagenttoacquirebyagent-environmentinteractions.\nMoreover,mostexternalknowledgecanbeacquiredbyaccessingtheAPIsofvarioustoolsdynamicallyinrealtimeaccordingtothetaskneeds,thusmitigatingtheproblemofoutdatedknowledge.\nIntegratingexternalknowledgeintothememoryofLLM-basedagentssignificantlyexpandstheirknowledgeboundaries,providingthemwithunlimited,up-to-date,andwell-foundedknowledgefordecision-making.\n5.\n2MemoryFormsIngeneral,therearetwoformstorepresentthememorycontents:textualformandparametricform.\nIntextualform,theinformationisexplicitlyretainedandrecalledbynaturallanguages.\nInparametric3https://www.\nwikipedia.\norg13Table2:Summarizationofthememoryforms.\nWeuse✓and×tolabelwhetherornotthecorrespondingmemoryformisadoptedinthemodel.\nModelsMemoryBank[6]RET-LLM[7]ChatDB[96]TiM[97]SCM[98]Voyager[99]MemGPT[100]MemoChat[94]MPC[101]GenerativeAgents[83]RecMind[102]Retroformer[103]ExpeL[82]Synapse[91]GITM[93]ReAct[104]Reflexion[5]RecAgent[95]Character-LLM[105]MAC[106]Huatuo[107]ChatDev[1]InteRecAgent[108]MetaAgents[109]TPTU[110,111]MetaGPT[112]S3[2]InvestLM[113]TextualFormParametricFormCompleteRecentRetrievedExternalFine-tuningEditing××××××××××✓✓✓×✓✓✓×××✓✓××✓✓×✓××××✓×✓××××××××××✓✓×××✓×××××✓✓✓✓✓✓✓✓✓✓××✓✓✓××✓××××✓✓××✓××××××××××××✓✓×✓✓✓×××××✓×✓××××××××××××××✓××××××✓×✓××××××✓×××××××××××××××××××✓××××××××form,thememoryinformationisencodedintoparametersandimplicitlyinfluencestheagent’sactions.\nWesummarizepreviousworksonmemoryformswiththeirimplementationsinTable2.\n5.\n2.",
      "#memory_survey#WhyWeNeedtheMemoryinLLM-basedAgent#memory_survey#WhyWeNeedtheMemoryinLLM-basedAgent\nWhyWeNeedtheMemoryinLLM-basedAgentAbove,wehaveintroducedwhatisthememoryofLLM-basedagents.\nBeforecomprehensivelypresentinghowtoimplementit,inthissection,webrieflyshowwhymemoryisnecessaryforbuildingLLM-basedagents,whereweexpandourdiscussionfromthreeperspectivesincludingcognitivepsychology,self-evolution,andagentapplications.\n4.\n1",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nThesestatementswillbegeneratedbyagentsasaseriesofChain-of-Memoryinadvance.\nInMPC[101],theagentscanretrieverelevantmemoryfromthememorypool.\nThismethodalsoproposestoprovideChain-of-Thoughtexamplesforignoringcertainmemory.\nExpeL[82]utilizestheFaiss[124]vectorstoreasthepoolofmemory,andobtainsthetop-Ksuccessfultrajectoriesthatsharethehighestsimilarityscoreswiththecurrenttask.\nDiscussion.\nTosomeextent,thememoryreadingandwritingoperationsarecollaborative,andtheformsofmemorywritinggreatlyinfluencethemethodsofmemoryreading.\nFortheformsoftextual19Figure5:Anoverviewoftheevaluationmethodsofthememorymodule.\nmemory,mostpreviousworksusethetextsimilarityandotherauxiliaryinformationforreading.\nFortheformsofparametricmemory,existingmodelsmayjustutilizetheupdatedparametersforinference,whichcanbeseenasanimplicitreadingprocess.\n6",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nThecompleteagent-environmentinteractionprocesscanbeeasilyobtainedbyiterativelyexpandingthisfunction(seeFigure3(b)foranintuitiveillustration).\nRemark.\nThisfunctionprovidesageneralformulationoftheagentmemorizingprocess.\nPreviousworksmayusedifferentspecifications.\nForexample,in[5],RandParesetasidenticalfunctions,andPonlytakeseffectattheendofatrial.\nInParketal.\n[83],Risimplementedbasedonthreecriteriaincludingsimilarity,timeinterval,andimportance,andPisrealizedbyareflectionprocesstoobtainmoreabstractthoughts.\nInthissection,wefocusontheoverallframeworkoftheagent’smemoryoperations.\nMoredetailedrealizationsofW,P,andRaredeferredinSection5.\n4WhyWeNeedtheMemoryinLLM-basedAgentAbove,wehaveintroducedwhatisthememoryofLLM-basedagents.\nBeforecomprehensivelypresentinghowtoimplementit,inthissection,webrieflyshowwhymemoryisnecessaryforbuildingLLM-basedagents,whereweexpandourdiscussionfromthreeperspectivesincludingcognitivepsychology,self-evolution,andagentapplications.\n4.\n1PerspectiveofCognitivePsychologyCognitivepsychologyisthescientificstudyofhumanmentalprocessessuchasattention,languageuse,memory,perception,problem-solving,creativity,andreasoning2.\nAmongtheseprocesses,memoryiswidelyrecognizedasanextremelyimportantone[84].\nItisfundamentalforhumanstolearnknowledgebyaccumulatingimportantinformationandabstractinghigh-levelconcepts[85],formsocialnormsbyrememberingculturalvaluesandindividualexperiences[86],takereasonablebehaviorsbyimaginingthepotentialpositiveandnegativeconsequences[87],andamongothers.\nAmajorgoalofLLM-basedagentsistoreplacehumansforaccomplishingdifferenttasks.\nTomakeagentsbehavelikehumans,followinghuman’sworkingmechanismstodesigntheagentsisanaturalandessentialchoice[88].\nSincememoryisimportantforhumans,designingmemorymodulesisalsosignificantfortheagents.\nInaddition,cognitivepsychologyhasbeenstudiedforalongtime,somanyeffectivehumanmemorytheoriesandarchitectureshavebeenaccumulated,whichcansupportmoreadvancedcapabilitiesoftheagents[89].\n2https://en.\nwikipedia.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nInaddition,cognitivepsychologyhasbeenstudiedforalongtime,somanyeffectivehumanmemorytheoriesandarchitectureshavebeenaccumulated,whichcansupportmoreadvancedcapabilitiesoftheagents[89].\n2https://en.\nwikipedia.\norg/wiki/Cognitive_psychology10Figure4:Anoverviewofthesources,forms,andoperationsofthememoryinLLM-basedagents.\n4.\n2PerspectiveofSelf-EvolutionToaccomplishdifferentpracticaltasks,agentshavetoself-evolveindynamicenvironments[90].\nIntheagent-environmentinteractionprocess,thememoryiskeytothefollowingaspects:(1)Experienceaccumulation.\nAnimportantfunctionofthememoryistorememberpasterrorplannings,inappropriatebehaviors,orfailedexperiences,soastomaketheagentmoreeffectiveforhandlingsimilartasksinthefuture[91].\nThisisextremelyimportantforenhancingthelearningefficiencyoftheagentintheself-evolvingprocess.\n(2)Environmentexploration.\nToautonomouslyevolveintheenvironment,theagentshavetoexploredifferentactionsandlearnfromthefeedback[92].\nByrememberinghistoricalinformation,thememorycanhelptobetterdecidewhenandhowtomakeexplorations,forexample,focusingmoreonpreviouslyfailedtrialsoractionswithlowerexploringfrequencies[93].\n(3)Knowledgeabstraction.\nAnotherimportantfunctionofthememoryistosummarizeandabstracthigh-levelinformationfromrawobservations,whichisthebasisfortheagenttobemoreadaptiveandgeneralizabletounseenenvironments[82].\nInsummary,self-evolutionisthebasiccharacteristicofLLM-basedagents,andmemoryisofkeyimportancetoself-evolution.\n4.\n3PerspectiveofAgentApplicationsInmanyapplications,memoryisanindispensablecomponentoftheagent.\nForexample,inaconver-sationalagent,thememorystoresinformationabouthistoricalconversations,whichisnecessaryfortheagenttogeneratethenextresponse.\nWithoutmemory,theagentdoesnotknowthecontext,andcannotcontinuetheconversation[94].\nInasimulationagent,memoryisofgreatimportancetomaketheagentconsistentlyfollowtheroleprofiles.\nWithoutmemory,theagentmayeasilystepoutoftheroleduringthesimulationprocess[95].",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nWithoutmemory,theagentdoesnotknowthecontext,andcannotcontinuetheconversation[94].\nInasimulationagent,memoryisofgreatimportancetomaketheagentconsistentlyfollowtheroleprofiles.\nWithoutmemory,theagentmayeasilystepoutoftheroleduringthesimulationprocess[95].\nBothoftheaboveexamplesshowthatthememoryisnotanoptionalcomponent,butisnecessaryfortheagentstoaccomplishgiventasks.\nIntheabovethreeperspectives,thefirstonerevealsthatthememorybuildsthecognitivebasisoftheagent.\nThesecondandthirdonesshowthatthememoryisnecessaryfortheagent’sevolvingprinciplesandapplications,whichprovideinsightsfordesigningagentswithmemorymechanisms.\n5HowtoImplementtheMemoryofLLM-basedAgentInthissection,wediscusstheimplementationofthememorymodulefromthreeperspectives:memorysources,memoryforms,andmemoryoperations.\nMemorysourcesrefertowherethememorycontentscomefrom.\nMemoryformsfocusonhowtorepresentthememorycontents.\nMemoryoperationsaimtoprocessthememorycontents.\nThesethreeperspectivesprovideacomprehensivereviewofmemoryimplementationmethods,whichishelpfulforfutureresearch.\nForbetterdemonstration,wepresentanoverviewofimplementationmethodsinFigure4.\n5.\n1MemorySourcesInpreviousworks,thememorycontentsmaycomefromdifferentsources.\nBasedonourformulationinSection3,thesesourcescanbeclassifiedintothreecategories,thatis,theinformationinsideatrial,theinformationacrossdifferenttrials,andtheexternalknowledge.\nTheformertwoaredynamically11Table1:Summarizationofthememorysources.\nWeuse✓and×tolabelwhetherornotthecorrespondingsourceisadoptedinthemodel.",
      "#memory_survey#MemoryinHumanoidAgent#memory_survey#MemoryinHumanoidAgent\nMemoryinHumanoidAgentAhumanoidagentreferstoanagentdesignedtoexhibitbehaviorsconsistentwithhumans,therebyfacilitatingapplicationsinsocialsimulation,studiesofhumanbehavior,androle-playing.\nUnliketask-orientedagentswheregreatercapabilityistypicallypreferred,theproficiencyofahumanoidagentshouldcloselymimicthatofhumans.\nConsequently,thememoryofhumanoidagentsshouldalignwithhumancognitiveprocesses,adheringtopsychologicalprinciplessuchasmemorydistortionandforgetfulness.\nAdditionally,humanoidagentsshouldpossessknowledgeboundaries,meaningthattheirknowledgeshouldcorrespondtothatoftheentitytheyreplicate.\nForinstance,inrole-playingscenarios,anagentembodyingachildshouldnotpossessanunderstandingofadvancedmathematicalconceptsorothercomplexknowledgebeyondwhatistypicalforthatage[174].\n9",
      "#memory_survey#Introduction#memory_survey#Introduction\n[7]designbothmemoryreadingandwritingoperationstointeractwithenvironmentsfortasksolving.\nWhilepreviousstudieshavedesignedmanypromisingmemorymodules,therestilllacksasystemicstudytoviewthememorymodulesfromaholisticperspective.\nTobridgethisgap,inthispaper,wecomprehensivelyreviewpreviousstudiestopresentcleartaxonomiesandkeyprinciplesfordesigningandevaluatingthememorymodule.\nInspecific,wediscussthreekeyproblemsincluding:(1)whatisthememoryofLLM-basedagents?\n(2)whydoweneedthememoryinLLM-basedagents?\nand(3)howtoimplementandevaluatethememoryinLLM-basedagents?\nTobeginwith,wedetailtheconceptsofmemoryinLLM-basedagents,providingbothnarrowandbroaddefinitions.\nThen,weanalyzethenecessityofmemoryinLLM-basedagents,showingitsimportancefromthreeperspectivesincludingcognitivepsychology,self-evolution,andagentapplications.\nBasedontheproblemsof“what”and“why”,wepresentcommonlyusedstrategiestodesignandevaluatethememorymodules.\nForthememorydesign,wediscusspreviousworksfromthreedimensions,thatis,memorysources,memoryforms,andmemoryoperations.\nForthememoryevaluation,weintroducetwowidelyusedapproachesincludingdirectevaluationandindirectevaluationviaspecificagenttasks.\nNext,wediscussagentapplicationsincludingrole-playing,socialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,andexpertsystems,inordertoshowtheimportanceofthememorymoduleinpracticalscenarios.\nAtlast,weanalyzethelimitationsofexistingworkandhighlightsignificantfuturedirections.\nThemaincontributionsofthispapercanbesummarizedasfollows:(1)Weformallydefinethemem-orymoduleandcomprehensivelyanalyzeitsnecessityforLLM-basedagents.\n(2)WesystematicallysummarizeexistingstudiesondesigningandevaluatingthememorymoduleinLLM-basedagents,providingcleartaxonomiesandintuitiveinsights.\n(3)Wepresenttypicalagentapplicationstoshowtheimportanceofthememorymoduleindifferentscenarios.\n(4)Weanalyzethekeylimitationsofexistingmemorymodulesandshowpotentialsolutionsforinspiringfuturestudies.",
      "#memory_survey#MemoryinLLM-basedMulti-agentApplications#memory_survey#MemoryinLLM-basedMulti-agentApplications\nMemoryinLLM-basedMulti-agentApplicationsTheexplorationofmemorymechanismswithinLLMshasburgeonedintothedynamicdomainofmulti-agentsystems(MAS),markingsignificantadvancementsintherealmsofsynchronization,communication,andthemanagementofinformationasymmetry.\nOnepivotalaspectthatemergesinthecooperativescenariosismemorysynchronizationamongagents.\nThisprocessisfundamentalforestablishingaunifiedknowledgebase,ensuringconsistencyindecision-makingacrossdifferentagents.\nForexample,Chenetal.\n[170]emphasizethesignificanceofintegratingsynchronizedmemorymodulesformulti-robotcollaboration.\nAnotherimportantaspectisthecommunicationamongagents,whichheavilyreliesonmemoryformaintainingcontextandinterpretingmessages.\nForexample,Mandietal.\n[171]illustratememory-drivencommunicationframeworksthatfosteracommonunderstandingamongagents.\nInadditiontocooperativescenarios,somestudiesalsofocusoncompetitivescenarios,andtheinformationasymmetrybecomesacrucialissue[172].\nLookingahead,theadvancementofmemoryinLLM-basedMASispoisedattheconfluenceoftechnologicalinnovationandstrategicapplication.\nItbeckonstheexplorationofnovelmemory27modulesthatcanfurtherenhanceagentsynchronization,enablemoreeffectivecommunication,andprovidestrategicadvantagesininformation-richenvironments.\nThedevelopmentofsuchmemorymodelswouldnotonlynecessitateaddressingthecurrentchallengesofmemoryintegrationandman-agement,butalsoexploretheuntappedpotentialsofmemoryinfacilitatingmorerobust,intelligent,andadaptableMAS.\nAsevidencedbypioneeringresearch,theevolvinglandscapeofLLM-basedMASsetsapromisingstageforfutureinnovationsinmemoryutilizationandmanagement.\nThisexplorationisexpectedtounravelnewdimensionsofmemoryintegration,pushingtheboundariesofwhatiscurrentlyachievableandsettingnewbenchmarksintherealmofMAS.\n8.\n3",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nManystudieschoosetostoretherawinformation,whileothersalsoputthesummaryoftherawinformationintothememorymodule.\nRepresentativeStudies.\nInTiM[97],therawinformationwillbeextractedastherelationbetweentwoentities,andstoredinastructureddatabase.\nWhenwritingintothedatabase,similarcontentswillbestoredinthesamegroup.\nInSCM[98],itdesignsamemorycontrollertodecidewhentoexecutetheoperations.\nThecontrollerservesasaguideforthewholememorymodule.\nInMemGPT[100],thememorywritingisentirelyself-directed.\nTheagentscanautonomouslyupdatethememorybasedonthecontexts.\nInMemoChat[94],theagentssummarizeeachconversationsegmentbyabstractingthemainlydiscussedtopicsandstoringthemaskeysforindexingmemorypieces.\nDiscussion.\nPreviousresearchindicatesthatdesigningthestrategyofinformationextractionduringthememorywritingoperationisvital[94].\nThisisbecausetheoriginalinformationiscommonlylengthyandnoisy.\nBesides,differentenvironmentsmayprovidevariousformsoffeedback,andhowtoextractandrepresenttheinformationasmemoryisalsosignificantformemorywriting.\n5.\n3.\n2MemoryManagementForhumanbeings,memoryinformationisconstantlyprocessedandabstractedinthebrains.\nThememoryintheagentcanalsobemanagedbyreflectingtogeneratehigher-levelmemories,mergingredundantmemoryentries,andforgettingunimportant,earlymemories.\nRepresentativeStudies.\nInMemoryBank[6],theagentsprocessanddistilltheconversationsintoahigh-levelsummaryofdailyevents,similartohowhumansrecallkeyaspectsoftheirexperiences.\nThroughlong-terminteractions,theycontinuallyevaluateandrefinetheirknowledge,generatingdailyinsightsintopersonalitytraits.\nInVoyager[99],theagentsareabletorefinetheirmemorybasedonthefeedbackoftheenvironment.\nInGenerativeAgents[83],theagentscanreflecttogethigher-levelinformation,wheretheabstractthoughtsaregeneratedfromagents.\nThereflectionprocesswillbeactivatedwhenthereareaccumulatedeventsthatareenoughtoaddress.\nForGITM[93],inordertoestablishcommonreferenceplansforvarioussituations,keyactionsfrommultipleplansarefurthersummarizedinthememorymodule.\nDiscussion.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\n1PerspectiveofCognitivePsychologyCognitivepsychologyisthescientificstudyofhumanmentalprocessessuchasattention,languageuse,memory,perception,problem-solving,creativity,andreasoning2.\nAmongtheseprocesses,memoryiswidelyrecognizedasanextremelyimportantone[84].\nItisfundamentalforhumanstolearnknowledgebyaccumulatingimportantinformationandabstractinghigh-levelconcepts[85],formsocialnormsbyrememberingculturalvaluesandindividualexperiences[86],takereasonablebehaviorsbyimaginingthepotentialpositiveandnegativeconsequences[87],andamongothers.\nAmajorgoalofLLM-basedagentsistoreplacehumansforaccomplishingdifferenttasks.\nTomakeagentsbehavelikehumans,followinghuman’sworkingmechanismstodesigntheagentsisanaturalandessentialchoice[88].\nSincememoryisimportantforhumans,designingmemorymodulesisalsosignificantfortheagents.\nInaddition,cognitivepsychologyhasbeenstudiedforalongtime,somanyeffectivehumanmemorytheoriesandarchitectureshavebeenaccumulated,whichcansupportmoreadvancedcapabilitiesoftheagents[89].\n2https://en.\nwikipedia.\norg/wiki/Cognitive_psychology10Figure4:Anoverviewofthesources,forms,andoperationsofthememoryinLLM-basedagents.\n4.\n2PerspectiveofSelf-EvolutionToaccomplishdifferentpracticaltasks,agentshavetoself-evolveindynamicenvironments[90].\nIntheagent-environmentinteractionprocess,thememoryiskeytothefollowingaspects:(1)Experienceaccumulation.\nAnimportantfunctionofthememoryistorememberpasterrorplannings,inappropriatebehaviors,orfailedexperiences,soastomaketheagentmoreeffectiveforhandlingsimilartasksinthefuture[91].\nThisisextremelyimportantforenhancingthelearningefficiencyoftheagentintheself-evolvingprocess.\n(2)Environmentexploration.\nToautonomouslyevolveintheenvironment,theagentshavetoexploredifferentactionsandlearnfromthefeedback[92].\nByrememberinghistoricalinformation,thememorycanhelptobetterdecidewhenandhowtomakeexplorations,forexample,focusingmoreonpreviouslyfailedtrialsoractionswithlowerexploringfrequencies[93].\n(3)Knowledgeabstraction.",
      "#memory_survey#Memory-basedLifelongLearning#memory_survey#Memory-basedLifelongLearning\nMemory-basedLifelongLearningLifelonglearningisanadvancedtopicinartificialintelligence,extendingthelearningcapabilitiesofagentsacrosstheirlife-longspan[173].\nAgentscancontinuouslyinteractwiththeirenvironment,persistentlyobserveenvironments,andacquireexternalknowledge,enablingamodeofenhancementlikehumans.\nThememoryofanagentiskeytoachievinglifelonglearning,asitneedstolearntostoreandapplythepastobservations.\nLifelonglearninginLLM-basedagentsholdssignificantpracticalvalue,suchasinlong-termsocialsimulationsandpersonalassistance.\nHowever,italsofacesseveralchallenges.\nFirstly,lifelonglearningistemporal,necessitatingthatanagent’smemorycapturestemporality.\nThistemporalitycouldcauseinteractionsbetweenmemories,suchasmemoryoverlap.\nFurthermore,duetotheextendedperiodoflifelonglearning,itneedstostoreavastamountofmemoriesandretrievethemwhenneeded,possiblyincorporatingacertainmechanismforforgetting.\n8.\n4",
      "#memory_survey#Memory-assistedAgent-EnvironmentInteraction#memory_survey#Memory-assistedAgent-EnvironmentInteraction\nForthenarrowmemorydefinition,theiterationonlyhappenswithinthesametrial,andthememoryisemptiedwhenthetrialisended.\nForthebroadmemorydefinition,theiterationhappensacrossdifferenttrialsoreventasks,aswellastheintegrationsofexternalknowledge.\nFortask(B)intheabovetoyexample,theagentcanconcludethatAliceenjoyswatchingsciencefictionmoviesintheevening,whichcanbeusedasadefaultruletomakerecommendationsforAliceinthefuture.\nMemoryReading.\nThisoperationaimstoobtainimportantinformationfromthememorytosupportthenextagentaction.\nItcorrespondstothethirdphaseoftheagent-environmentinteractionprocess.\nSupposeMktisthecontextofthenextaction,thenthememoryreadingoperationcanberepresentedby:tisthememorycontentsfortaskkatstept,ckˆMkt=R(Mkt,ckt+1),whereRisusuallyimplementedbycomputingthesimilaritybetweenMktisusedaspartsofthefinalprompttodrivetheagent’snextaction.\nFortask(B)intheabovetoyexample,whentheagentdecidesonthefinalrecommendedmoviein[Step3],itshouldfocusonthe“wanttowatch”listin[Step2]andselectonefromit.\ntandckt+1[82].\nˆMkBasedontheaboveoperations,wecanderiveaunifiedfunctionfortheevolvingprocessfrom{akt,okt}toakt+1,thatis:akt+1=LLM{R(P(Mkt−1,W({akt,okt})),ckt+1)},whereLLMisthelargelanguagemodel.\nThecompleteagent-environmentinteractionprocesscanbeeasilyobtainedbyiterativelyexpandingthisfunction(seeFigure3(b)foranintuitiveillustration).\nRemark.\nThisfunctionprovidesageneralformulationoftheagentmemorizingprocess.\nPreviousworksmayusedifferentspecifications.\nForexample,in[5],RandParesetasidenticalfunctions,andPonlytakeseffectattheendofatrial.\nInParketal.\n[83],Risimplementedbasedonthreecriteriaincludingsimilarity,timeinterval,andimportance,andPisrealizedbyareflectionprocesstoobtainmoreabstractthoughts.\nInthissection,wefocusontheoverallframeworkoftheagent’smemoryoperations.\nMoredetailedrealizationsofW,P,andRaredeferredinSection5.\n4"
    ],
    [
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nMoreover,someeffortsarededicatedtoenhancingthecapacityofLLMstohandlelongercontexts[118,119].\nWhilestoringalltheagent-environmentinteractionscanmaintaincomprehensiveinformation,obviouslimitationsexistintermsofcomputationalcost,inferencetime,andinferencerobustness.\nFirstly,thefast-growinglong-contextmemoryinpracticeresultsinhighcomputationalcostduringLLMinference,duetothequadraticgrowthofthetimecomplexityofattentioncomputationwithsequencelength.\nItthusrequiresmuchmorecomputingresourcesandsignificantlyincreasesinferencelatency,whichhindersitspracticaldeployment.\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.\nThismethodstoresandmaintainsthemostrecentlyacquiredmemoriesusingnaturallanguages,therebyenhancingtheefficiencyofmemoryinformationutilizationaccordingtothePrincipleofLocality[121].\nIntask(B)oftheexampleinSection3.\n1,wecanjustrememberAlice’spreferencesintherecentthreeyears,andtruncatethedistantpart,wheretherecentthreeyearscanbeconsideredasthememorywindowsize.\nInpreviousstudies,therearevariousstrategiestostorerecenttextualmemories.\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.\nThismethodstoresandmaintainsthemostrecentlyacquiredmemoriesusingnaturallanguages,therebyenhancingtheefficiencyofmemoryinformationutilizationaccordingtothePrincipleofLocality[121].\nIntask(B)oftheexampleinSection3.\n1,wecanjustrememberAlice’spreferencesintherecentthreeyears,andtruncatethedistantpart,wheretherecentthreeyearscanbeconsideredasthememorywindowsize.\nInpreviousstudies,therearevariousstrategiestostorerecenttextualmemories.\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.\nThismethodstoresandmaintainsthemostrecentlyacquiredmemoriesusingnaturallanguages,therebyenhancingtheefficiencyofmemoryinformationutilizationaccordingtothePrincipleofLocality[121].\nIntask(B)oftheexampleinSection3.\n1,wecanjustrememberAlice’spreferencesintherecentthreeyears,andtruncatethedistantpart,wheretherecentthreeyearscanbeconsideredasthememorywindowsize.\nInpreviousstudies,therearevariousstrategiestostorerecenttextualmemories.\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.",
      "#memory_survey#D:\\projects\\KAG\\kag\\examples\\memory_survey_test\\builder\\./data/memory_survey.pdf#memory_survey#D:\\projects\\KAG\\kag\\examples\\memory_survey_test\\builder\\./data/memory_survey.pdf\nPersonalassistant,game,codegeneration,……(Knowledge)Accordingtothepreviousworks,largelanguagemodelbasedagentsrefertoartificial……(Context)ThecurrenttopicisLLM-basedagent.\n“It”referstoLLM-basedagentsinthisconversation.\nSocialSimulationI'macompassionatephysicianspecializingincardiology,committedtoimprovingpatients'hearthealthandwell-being.\nI'maskillednursededicatedtopatientcare,ensuringcomfortandsupportinghealthwithempathyandexpertise.\nRole-playingI'maSmurf,andSmurfsareus!\nHaveyoueverhadadream?\nMagicisallaroundtheus!\nJarvis,wemustfirstlearntorun!\nWubalubadu.\nBdubWuckoop.\nI'mBatman,thelightsofcity.\n[IronMan]MynameisIronMan,alsoknownasTonyStark.\nIamthefounderofStarkIndustriesandamemberoftheAvengers.\nAsoneofthegeniusinventorsandbillionaire,Ihavecreatedthemostadvancedarmorintheworld,whichnotonlyprotectsmebutalsogivesmeincrediblestrengthandtheabilitytofly.\nOpen-worldGameSkills&KnowledgeHPMPSPCodeGenerationdefbubble_sort(arr):n=len(arr)#Traversethroughallarrayelementsforiinrange(n):#Lastielementsarealreadyinplaceforjinrange(0,n-i-1):#Traversethearrayfrom0ton-i-1#Swapiftheelementfoundisgreaterthanthenextelementifarr[j]>arr[j+1]:arr[j],arr[j+1]=arr[j+1],arr[j]returnarrSortthenumbersinascendingorder.\nBubblesortrepeatedlystepsthroughthelist,comparesadjacentelementsandswapsthemiftheyareinwrongorder.\nThepassthroughthelistisrepeateduntilthelistissorted.\nBubblesortcanreorderalistofnumbers.\nDevelopmentGroupRecommendationIwanttobuyadressforthegraduationparty.\n(Context)Shejustboughtanewbluedress.\nSoshemayneedawhiteaccessoriestomatchit.\n(PersonalPreference)Sheoftenbuysblueclothes.\nShevaluesthecost-effectivenessofitems,especiallyonclothes.\nShelikessmallthingswithlightcolors,suchasearpendants.\nYoumaylikethisbluedress.\nItisofgoodqualityandgreatprice.\nWouldyouliketobuyawaistbandforyourdress?\nGreat!\nIlikethisbuleone.\nIwillbuyitfortheparty.\nMedicineDavid,a38-year-oldmalewithahistoryofallergiesandsinusinfections,hasafamilyhistoryofdiabetesandhypertension."
    ],
    [
      "#memory_survey#Memory-enhancedAgentApplications#memory_survey#Memory-enhancedAgentApplications\nMemory-enhancedAgentApplicationsRecently,LLM-basedagentshavebeeninvestigatedacrossawidevarietyofscenarios,facilitatingsocietaladvancement.\nIngeneral,mostLLM-basedagentsareequippedwithmemorymodules.\nHowever,thespecificeffectsundertakenbythesememorycomponents,theparticularinformationtheystore,andtheimplementationmethodstheyuse,varyacrossdifferentapplications.\nInordertoprovideinsightsforthedesignofmemoryfunctionalitiesinLLM-basedagents,inthissection,wereviewandsummarizehowmemorymechanismsaremanifestedinLLM-basedagentsacrossvariousapplicationscenarios.\nInspecific,wecategorizethemintoseveralclasses:role-playingandsocialsimulation,personalassistant,open-worldgames,codegeneration,recommendation,expertsystemsinspecificdomains,andotherapplications.\nThesummarizationisshowninTable4.\n7.\n1",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nByleveragingexternalresources,theagentscanlearnfromcode-relatedknowledgeandstoreitintotheirmemory,therebyenhancingthecapabilitiesofcodegeneration.\nInaddition,thememorycanimprovethecontinuityandconsistencyincodegeneration.\nByintegratingcontextualmemory,theagentcanbetterunderstandtherequirementsforsoftwaredevelopment,therebyenhancingthecoherenceofthegeneratedcode.\nFurthermore,thememoryisalsocrucialfortheiterativeoptimizationofcode,asitcanidentifythedeveloper’stargetsbasedonthehistories.\n257.\n5RecommendationInthefieldofrecommendation,somepreviousworksfocusonsimulatingusersinrecommendersystems[95,108],wherethememorycanrepresenttheuserprofilesandhistoriesintherealworld.\nOtherstrytoimprovetheperformanceofrecommendation,orprovideotherformatsofrecommendationinterfaces[149,102].\nWangetal.\n[95]simulateuserbehaviorsinrecommendationscenariostogeneratedataforrecommendersystems,andtheagentsstorepastobservationsandinsightsintoahierarchicalmemory.\nInHuangetal.\n[108],thememoryinLLM-basedagentscanarchivetheuser’sconversationalhistoryoverextendedperiods,aswellascapturethemostrecentdialoguespertinenttothecurrentprompt,tosimulateinteractiverecommendersystems.\nItalsousesanactor-criticreflectiontoimprovetherobustnessofagents.\nItemagentsanduseragentsareequippedwithdifferentmemoriesin[149],whereitemagentsareendowedwithdynamicmemorymodulesdesignedtocaptureandpreserveinformationpertinenttotheirintrinsicattributesandtheinclinationsoftheiradopters.\nForuseragents,theadaptivememoryupdatingmechanismplaysapivotalroleinaligningtheagents’operationswithuserbehaviorsandpreferences.\nWangetal.\n[102]memorizeindividualizeduserinformationlikereviewsorratingsforitems,andacquiredomain-specificknowledgeandreal-timeinformationbywebsearchingtools.\nForbothsimulatingusersinrecommendersystemsandcapturingtheirpreferences,retainingper-sonalizedinformationthroughmemoryisessential.\nAcriticalchallengeliesinhowtoalignthepersonalizedinformationandfeedbackwithLLMs,andstorethemintothememoryofagents.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\n1,thememoryofthe14agentintask(A)afterstep2canbeimplementedbyconcatenatingalltheinformationbeforestep2,andthefinaltextualformmemoryis:\"Yourmemoryis[Step1](Agent).\n.\n.\n(OnlineTicketOffice).\n.\n.\n[Step2].\n.\n.\nPleaseinferbasedonyourmemory\".\nInthepreviouswork,differentmodelsstorethememoryinformationusingdifferentstrategies.\nForexample,inLongChat[116],theagentsfocusonunderstandingnaturallanguagesinlong-contextscenarios.\nItfine-tunesthefoundationmodelforbetteradaptingtomemorizecompleteinteractions.\nMemorySandbox[117]intendstoalleviatetheimpactofirrelevantmemoryinconversations.\nItdesignsatransparentandinteractivemethodtomanagethememoryofagents,whichremovesirrelevantmemorybeforeconcatenatingthemasaprompt.\nMoreover,someeffortsarededicatedtoenhancingthecapacityofLLMstohandlelongercontexts[118,119].\nWhilestoringalltheagent-environmentinteractionscanmaintaincomprehensiveinformation,obviouslimitationsexistintermsofcomputationalcost,inferencetime,andinferencerobustness.\nFirstly,thefast-growinglong-contextmemoryinpracticeresultsinhighcomputationalcostduringLLMinference,duetothequadraticgrowthofthetimecomplexityofattentioncomputationwithsequencelength.\nItthusrequiresmuchmorecomputingresourcesandsignificantlyincreasesinferencelatency,whichhindersitspracticaldeployment.\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nInaddition,cognitivepsychologyhasbeenstudiedforalongtime,somanyeffectivehumanmemorytheoriesandarchitectureshavebeenaccumulated,whichcansupportmoreadvancedcapabilitiesoftheagents[89].\n2https://en.\nwikipedia.\norg/wiki/Cognitive_psychology10Figure4:Anoverviewofthesources,forms,andoperationsofthememoryinLLM-basedagents.\n4.\n2PerspectiveofSelf-EvolutionToaccomplishdifferentpracticaltasks,agentshavetoself-evolveindynamicenvironments[90].\nIntheagent-environmentinteractionprocess,thememoryiskeytothefollowingaspects:(1)Experienceaccumulation.\nAnimportantfunctionofthememoryistorememberpasterrorplannings,inappropriatebehaviors,orfailedexperiences,soastomaketheagentmoreeffectiveforhandlingsimilartasksinthefuture[91].\nThisisextremelyimportantforenhancingthelearningefficiencyoftheagentintheself-evolvingprocess.\n(2)Environmentexploration.\nToautonomouslyevolveintheenvironment,theagentshavetoexploredifferentactionsandlearnfromthefeedback[92].\nByrememberinghistoricalinformation,thememorycanhelptobetterdecidewhenandhowtomakeexplorations,forexample,focusingmoreonpreviouslyfailedtrialsoractionswithlowerexploringfrequencies[93].\n(3)Knowledgeabstraction.\nAnotherimportantfunctionofthememoryistosummarizeandabstracthigh-levelinformationfromrawobservations,whichisthebasisfortheagenttobemoreadaptiveandgeneralizabletounseenenvironments[82].\nInsummary,self-evolutionisthebasiccharacteristicofLLM-basedagents,andmemoryisofkeyimportancetoself-evolution.\n4.\n3PerspectiveofAgentApplicationsInmanyapplications,memoryisanindispensablecomponentoftheagent.\nForexample,inaconver-sationalagent,thememorystoresinformationabouthistoricalconversations,whichisnecessaryfortheagenttogeneratethenextresponse.\nWithoutmemory,theagentdoesnotknowthecontext,andcannotcontinuetheconversation[94].\nInasimulationagent,memoryisofgreatimportancetomaketheagentconsistentlyfollowtheroleprofiles.\nWithoutmemory,theagentmayeasilystepoutoftheroleduringthesimulationprocess[95].",
      "#memory_survey#Memory-assistedAgent-EnvironmentInteraction#memory_survey#Memory-assistedAgent-EnvironmentInteraction\nForthenarrowmemorydefinition,theiterationonlyhappenswithinthesametrial,andthememoryisemptiedwhenthetrialisended.\nForthebroadmemorydefinition,theiterationhappensacrossdifferenttrialsoreventasks,aswellastheintegrationsofexternalknowledge.\nFortask(B)intheabovetoyexample,theagentcanconcludethatAliceenjoyswatchingsciencefictionmoviesintheevening,whichcanbeusedasadefaultruletomakerecommendationsforAliceinthefuture.\nMemoryReading.\nThisoperationaimstoobtainimportantinformationfromthememorytosupportthenextagentaction.\nItcorrespondstothethirdphaseoftheagent-environmentinteractionprocess.\nSupposeMktisthecontextofthenextaction,thenthememoryreadingoperationcanberepresentedby:tisthememorycontentsfortaskkatstept,ckˆMkt=R(Mkt,ckt+1),whereRisusuallyimplementedbycomputingthesimilaritybetweenMktisusedaspartsofthefinalprompttodrivetheagent’snextaction.\nFortask(B)intheabovetoyexample,whentheagentdecidesonthefinalrecommendedmoviein[Step3],itshouldfocusonthe“wanttowatch”listin[Step2]andselectonefromit.\ntandckt+1[82].\nˆMkBasedontheaboveoperations,wecanderiveaunifiedfunctionfortheevolvingprocessfrom{akt,okt}toakt+1,thatis:akt+1=LLM{R(P(Mkt−1,W({akt,okt})),ckt+1)},whereLLMisthelargelanguagemodel.\nThecompleteagent-environmentinteractionprocesscanbeeasilyobtainedbyiterativelyexpandingthisfunction(seeFigure3(b)foranintuitiveillustration).\nRemark.\nThisfunctionprovidesageneralformulationoftheagentmemorizingprocess.\nPreviousworksmayusedifferentspecifications.\nForexample,in[5],RandParesetasidenticalfunctions,andPonlytakeseffectattheendofatrial.\nInParketal.\n[83],Risimplementedbasedonthreecriteriaincludingsimilarity,timeinterval,andimportance,andPisrealizedbyareflectionprocesstoobtainmoreabstractthoughts.\nInthissection,wefocusontheoverallframeworkoftheagent’smemoryoperations.\nMoredetailedrealizationsofW,P,andRaredeferredinSection5.\n4"
    ],
    [
      "#memory_survey#MemoryinParametricForm#memory_survey#MemoryinParametricForm\nMEND[134]utilizestheideaofmeta-learningtotrainalightweightmodel,whichiscapableofgeneratingmodificationsformodelparametersofapre-trainedlanguagemodel.\nAPP[136]studieswhetheraddinganewfactleadstocatastrophicforgettingofexistingfacts.\nItfocusesontheimpactofneighborperturbationonmemoryaddition.\nMoreover,KnowledgeEditor[133]trainsahyper-networktopredictthemodificationofmodelpa-rameterswheninjectingmemorybasedonalearning-to-updateproblemformulation.\nWangetal.\n[137]proposeanewoptimizationtargettochangethepoisoningknowledgeofLLM,andmaintainthegeneralperformanceatthesametime.\nForLLM-basedagents,theagentscanchangebadmemorybyknowledgeediting,whichcanbeconsideredasatypeofforgettingmechanism.\nKnowledgeeditingmethodsprovideaninnovativewaytoupdatetheinformationstoredwithintheparametersofLLMs.\nByspecificallytargetingandadjustingthefacts,thesemethodscanensurethenon-targetedknowledgeunaffectedduringupdates,thusmitigatingtheissueofcatastrophicforgetting.\nMoreover,thetargetedadjustmentmechanismallowsformoreefficientandlessresource-intensiveupdates,makingknowledgeeditinganappealingchoiceforhigh-precisionandreal-timemodifications.\nHowever,despitethesepromisingdevelopments,computationalcostsofmeta-trainingandthepreservationofunrelatedmemoriesremainsignificantchallenges.\n5.\n2.\n3",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.\nAnotherlimitationoffine-tuningliesinthecomputationalcostandtimeconsumption,aswellastherequirementofalargeamountofdata.\nTherefore,mostfine-tuningapproachesareappliedtoofflinescenarios,andcanseldomdealwithonlinescenarios,suchasfine-tuningwithagentobservationsandtrialexperiences.\nDuetothefrequentagent-environmentinteractions,itisunaffordableforthecostofbackpropagationtofine-tuneeverystepoftheonlineanddynamicinteractions.\nMemoryEditingMethods.",
      "#memory_survey#MemoryinParametricForm#memory_survey#MemoryinParametricForm\nMemoryinParametricFormAnalternativetypeofapproachesistorepresentmemoryinparametricform.\nTheydonottakeuptheextralengthofcontextinprompts,sotheyarenotconstrainedbythelengthlimitationsofLLMcontext.\nHowever,theparametricmemoryformisstillunder-researched,andwecategorizepreviousworksintotwotypes:fine-tuningmethodsandmemoryeditingmethods.\nFine-tuningMethods.\nIntegratingexternalknowledgeintothememoryofagentsisbeneficialforenrichingdomain-specificknowledgeontopofitsgeneralknowledge.\nToinfusethedomainknowledgeintoLLMs,supervisedfine-tuningisacommonapproach,whichempowersagentswiththememoryofdomainexperts.\nItsignificantlyimprovestheagent’sabilitytoaccomplishdomain-specifictasks.\nIntask(A)oftheexampleinSection3.\n1,theexternalknowledgeofattractionsfrommagazinescanbefine-tunedintotheparametersofLLMspriortothistask.\n4https://openweathermap.\norg5https://rapidapi.\ncom/hub16Inpreviousworks,Character-LLM[105]focusesontherole-playcircumstance.\nItutilizessupervisedfine-tuningstrategieswithrole-relateddata(e.\ng.\n,experiences),toendowagentswiththespecifictraitsandcharacteristicsoftherole.\nHuatuo[107]intendstoempoweragentswithprofessionalabilityinthebiomedicaldomain.\nIttriestofine-tuneLlama[127]onChinesemedicalknowledgebases.\nBesides,inordertocreateartificialdoctors,DoctorGLM[129]fine-tunesChatGLM[130]withLoRA[131],andRadiology-GPT[132]improvesdomainknowledgeonradiologyanalysisbysupervisedfine-tuningonanannotatedradiologydataset.\nMoreover,InvestLM[113]collectsinvestmentdataandfine-tunesittoimprovedomain-specificabilitiesonfinancialinvestment.\nThefine-tuningmethodscaneffectivelybridgethegapbetweengeneralagentsandspecializedagents.\nItimprovesthecapabilityofagentsonthetasksthatrequirehighaccuracyandreliabilityondomain-specificinformation.\nNevertheless,fine-tuningLLMsforspecificdomainscouldpotentiallyleadtooverfitting,anditalsoraisesconcernsaboutcatastrophicforgetting,whereLLMsmayforgettheoriginalknowledgebecauseofupdatingtheirparameters.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nItensuresthatunrelatedknowledgeremainsunaffected.\nKnowledgeeditingmethodsaremoresuitableforsmall-scalememoryadjustments.\nGenerally,theyhavelowercomputationalcosts,makingthemmoresuitableforonlinescenarios.\nInourexampleoftask(B),Alicealwayswatchesmoviesat9:00PMfromtheagent’smemory,butshemayrecentlychangeherworkandwouldnotbeemptyat9:00PM.\nIfso,therelatedmemory(suchasroutinesat9:00PM)shouldbeedited,whichcanbeimplementedbyknowledgeeditingmethods.\nInpreviousstudies,MAC[106]intendstodesignaneffectiveandefficientmemoryadaptationframeworkforonlinescenarios.\nItutilizesmeta-learningtosubstitutetheoptimizationstep.\nPer-sonalityEdit[135]focusesoneditingthepersonalityofLLMsandagents,whereitchangestheirtraitsbasedontheoriessuchasthebig-fivefactor.\nMEND[134]utilizestheideaofmeta-learningtotrainalightweightmodel,whichiscapableofgeneratingmodificationsformodelparametersofapre-trainedlanguagemodel.\nAPP[136]studieswhetheraddinganewfactleadstocatastrophicforgettingofexistingfacts.\nItfocusesontheimpactofneighborperturbationonmemoryaddition.\nMoreover,KnowledgeEditor[133]trainsahyper-networktopredictthemodificationofmodelpa-rameterswheninjectingmemorybasedonalearning-to-updateproblemformulation.\nWangetal.\n[137]proposeanewoptimizationtargettochangethepoisoningknowledgeofLLM,andmaintainthegeneralperformanceatthesametime.\nForLLM-basedagents,theagentscanchangebadmemorybyknowledgeediting,whichcanbeconsideredasatypeofforgettingmechanism.\nKnowledgeeditingmethodsprovideaninnovativewaytoupdatetheinformationstoredwithintheparametersofLLMs.\nByspecificallytargetingandadjustingthefacts,thesemethodscanensurethenon-targetedknowledgeunaffectedduringupdates,thusmitigatingtheissueofcatastrophicforgetting.\nMoreover,thetargetedadjustmentmechanismallowsformoreefficientandlessresource-intensiveupdates,makingknowledgeeditinganappealingchoiceforhigh-precisionandreal-timemodifications.\nHowever,despitethesepromisingdevelopments,computationalcostsofmeta-trainingandthepreservationofunrelatedmemoriesremainsignificantchallenges.\n5.\n2.",
      "#memory_survey#D:\\projects\\KAG\\kag\\examples\\memory_survey_test\\builder\\./data/memory_survey.pdf#memory_survey#D:\\projects\\KAG\\kag\\examples\\memory_survey_test\\builder\\./data/memory_survey.pdf\nASurveyontheMemoryMechanismofLargeLanguageModelbasedAgentsZeyuZhang1,XiaoheBo1,ChenMa1,RuiLi1,XuChen1,QuanyuDai2,JiemingZhu2,ZhenhuaDong2,Ji-RongWen11GaolingSchoolofArtificialIntelligence,RenminUniversityofChina,Beijing,China2HuaweiNoah’sArkLab,Chinazeyuzhang@ruc.\nedu.\ncn,xu.\nchen@ruc.\nedu.\ncnAbstractLargelanguagemodel(LLM)basedagentshaverecentlyattractedmuchattentionfromtheresearchandindustrycommunities.\nComparedwithoriginalLLMs,LLM-basedagentsarefeaturedintheirself-evolvingcapability,whichisthebasisforsolvingreal-worldproblemsthatneedlong-termandcomplexagent-environmentinteractions.\nThekeycomponenttosupportagent-environmentinteractionsisthememoryoftheagents.\nWhilepreviousstudieshaveproposedmanypromisingmem-orymechanisms,theyarescatteredindifferentpapers,andtherelacksasystemati-calreviewtosummarizeandcomparetheseworksfromaholisticperspective,fail-ingtoabstractcommonandeffectivedesigningpatternsforinspiringfuturestudies.\nTobridgethisgap,inthispaper,weproposeacomprehensivesurveyonthememorymechanismofLLM-basedagents.\nInspecific,wefirstdiscuss“whatis”and“whydoweneed”thememoryinLLM-basedagents.\nThen,wesystematicallyreviewpreviousstudiesonhowtodesignandevaluatethememorymodule.\nInaddition,wealsopresentmanyagentapplications,wherethememorymoduleplaysanimportantrole.\nAtlast,weanalyzethelimitationsofexistingworkandshowimportantfuturedirections.\nTokeepupwiththelatestadvancesinthisfield,wecreatearepositoryathttps://github.\ncom/nuster1128/LLM_Agent_Memory_Survey.\n4202rpA12]IA.\nsc[1v10531.\n4042:viXraFigure1:TheimportanceofthememorymoduleinLLM-basedagents.\nPreprint.\nUnderreview.\nPersonalAssistantPleasehelpmetoexplain“LLM-basedagent”.\nALLM-basedagentisatypeofartificial……Inwhichscenariosdoesithaveapplications?\nPersonalassistant,game,codegeneration,……(Knowledge)Accordingtothepreviousworks,largelanguagemodelbasedagentsrefertoartificial……(Context)ThecurrenttopicisLLM-basedagent.\n“It”referstoLLM-basedagentsinthisconversation."
    ],
    [
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.",
      "#memory_survey#Recommendation#memory_survey#Recommendation\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.\nThismethodstoresandmaintainsthemostrecentlyacquiredmemoriesusingnaturallanguages,therebyenhancingtheefficiencyofmemoryinformationutilizationaccordingtothePrincipleofLocality[121].\nIntask(B)oftheexampleinSection3.\n1,wecanjustrememberAlice’spreferencesintherecentthreeyears,andtruncatethedistantpart,wheretherecentthreeyearscanbeconsideredasthememorywindowsize.\nInpreviousstudies,therearevariousstrategiestostorerecenttextualmemories.\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.\nDuringmemoryreading,matchingscoresarecalculatedforeachmemoryentry,andthetop-Kentrieswillbeusedforthedecision-makingprocessofagents.\n15Inexistingstudies,mostagentsutilizeretrievalmethodstoprocessthememoryinformation.\nForexample,Parketal.\n[83]firstcalculatetherelevancebetweenthecurrentcontextandmemoryentriesbycosinesimilarity,andobtaintheimportanceandrecencyaccordingtoauxiliaryinformation.\nMemoryBank[6]employsadual-towerdenseretrievalmodeltofindrelatedinformationfrompastconversations.\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nWhat’smore,withitsfastgrowth,thememorylengthcaneasilyexceedtheupperboundofthesequencelengthduringLLM’spretraining,whichmakesatruncationofmemorynecessary.\nThus,itcanleadtoinformationlossduetotheincompletenessofagentmemory.\nLastbutnotleast,itcanleadtobiasesandunrobustnessinLLM’sinference.\nSpecifically,apreviousresearch[120]hasshownthat,thepositionsoftextsegmentsinalongcontextcangreatlyaffecttheirutilization,sothememoryinthelong-contextpromptcannotbetreatedequallyandstably.\nAllthesedrawbacksshowtheneedtodesignextramemorymodulesforLLM-basedagents,ratherthanstraightforwardlyconcatenatingalltheinformationintoaprompt.\nRecentInteractions.\nThismethodstoresandmaintainsthemostrecentlyacquiredmemoriesusingnaturallanguages,therebyenhancingtheefficiencyofmemoryinformationutilizationaccordingtothePrincipleofLocality[121].\nIntask(B)oftheexampleinSection3.\n1,wecanjustrememberAlice’spreferencesintherecentthreeyears,andtruncatethedistantpart,wheretherecentthreeyearscanbeconsideredasthememorywindowsize.\nInpreviousstudies,therearevariousstrategiestostorerecenttextualmemories.\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.",
      "#memory_survey#Memory-basedLifelongLearning#memory_survey#Memory-basedLifelongLearning\nMemory-basedLifelongLearningLifelonglearningisanadvancedtopicinartificialintelligence,extendingthelearningcapabilitiesofagentsacrosstheirlife-longspan[173].\nAgentscancontinuouslyinteractwiththeirenvironment,persistentlyobserveenvironments,andacquireexternalknowledge,enablingamodeofenhancementlikehumans.\nThememoryofanagentiskeytoachievinglifelonglearning,asitneedstolearntostoreandapplythepastobservations.\nLifelonglearninginLLM-basedagentsholdssignificantpracticalvalue,suchasinlong-termsocialsimulationsandpersonalassistance.\nHowever,italsofacesseveralchallenges.\nFirstly,lifelonglearningistemporal,necessitatingthatanagent’smemorycapturestemporality.\nThistemporalitycouldcauseinteractionsbetweenmemories,suchasmemoryoverlap.\nFurthermore,duetotheextendedperiodoflifelonglearning,itneedstostoreavastamountofmemoriesandretrievethemwhenneeded,possiblyincorporatingacertainmechanismforforgetting.\n8.\n4"
    ],
    [
      "#memory_survey#Recommendation#memory_survey#Recommendation\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.\nDuringmemoryreading,matchingscoresarecalculatedforeachmemoryentry,andthetop-Kentrieswillbeusedforthedecision-makingprocessofagents.\n15Inexistingstudies,mostagentsutilizeretrievalmethodstoprocessthememoryinformation.\nForexample,Parketal.\n[83]firstcalculatetherelevancebetweenthecurrentcontextandmemoryentriesbycosinesimilarity,andobtaintheimportanceandrecencyaccordingtoauxiliaryinformation.\nMemoryBank[6]employsadual-towerdenseretrievalmodeltofindrelatedinformationfrompastconversations.\nEachmemoryentryisencodedintoanembeddingandsubsequentlyindexedbyFAISS[124]toimprovetheefficiencyofretrieval.\nWhenreadingmemories,thecurrentcontextwillbeencodedasrepresentationstoobtainthemostrelevantmemory.\nMoreover,RET-LLM[7]intendstodesignawrite-readmemorymoduleforgeneralusage.\nItutilizesLocality-SensitiveHashing(LSH)toretrievetupleswithrelativeentriesinthedatabasetoprovidemoreinformation.\nInaddition,ChatDB[96]designstoutilizesymbolicmemory,andproposestogenerateSQLstatementstoretrievefromdatabasetoobtainstoredinformation.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nThereflectionprocesswillbeactivatedwhenthereareaccumulatedeventsthatareenoughtoaddress.\nForGITM[93],inordertoestablishcommonreferenceplansforvarioussituations,keyactionsfrommultipleplansarefurthersummarizedinthememorymodule.\nDiscussion.\nMostofthememorymanagementoperationsareinspiredbytheworkingmechanismofhumanbrains.\nWiththestrongcapabilityofLLMstosimulatehumanminds,theseoperationscanhelptheagentstobettergeneratehigh-levelinformationandinteractwithenvironments.\n18Table3:Summarizationofthememoryoperations.\nIfamodeldoesnothavespecialdesignsonthememoryoperations,weuse◦tolabelit,otherwise,itisdenotedby✓.\n×meansthatthememoryoperationsarenotdiscussedinthepaper.\nModelsWritingMergingReflectionForgettingReadingManagementMemoryBank[6]RET-LLM[7]ChatDB[96]TiM[97]SCM[98]Voyager[99]MemGPT[100]MemoChat[94]MPC[101]GenerativeAgents[83]RecMind[102]Retroformer[103]ExpeL[82]Synapse[91]GITM[93]ReAct[104]Reflexion[5]RecAgent[95]Character-LLM[105]MAC[106]Huatuo[107]ChatDev[1]InteRecAgent[108]MetaAgents[109]TPTU[110,111]MetaGPT[112]S3[2]InvestLM[113]✓✓✓✓✓✓✓✓✓✓◦✓✓✓◦◦✓✓✓✓✓✓✓✓◦✓✓✓✓××✓✓××××××✓✓×✓×✓✓×✓××✓×××××✓×✓××✓✓××✓×✓✓×✓×✓✓×✓×✓✓✓✓✓✓×✓××✓×××××✓×××××××✓××××××××✓×✓✓✓✓✓✓✓✓✓✓✓◦◦✓✓◦◦✓◦✓◦✓✓✓✓✓✓◦5.\n3.\n3MemoryReadingWhentheagentsrequireinformationforreasoninganddecision-making,thememoryreadingoperationwillextractrelatedinformationfrommemoryforusage.\nTherefore,howtoaccesstherelatedinformationforthecurrentstateisimportant.\nDuetothemassivequantityofmemoryentities,andthefactthatnotallofthemarepertinenttothecurrentstate,carefuldesignisrequiredtoextractusefulinformationbasedonrelevanceandothertask-orientatedfactors.\nRepresentativeStudies.\nInChatDB[96],thememoryreadingoperationisexecutedbytheSQLstatements.\nThesestatementswillbegeneratedbyagentsasaseriesofChain-of-Memoryinadvance.\nInMPC[101],theagentscanretrieverelevantmemoryfromthememorypool.\nThismethodalsoproposestoprovideChain-of-Thoughtexamplesforignoringcertainmemory.",
      "#memory_survey#MemoryReading#memory_survey#MemoryReading\nThesethreeperspectivesprovideacomprehensivereviewofmemoryimplementationmethods,whichishelpfulforfutureresearch.\nForbetterdemonstration,wepresentanoverviewofimplementationmethodsinFigure4.\n5.\n1MemorySourcesInpreviousworks,thememorycontentsmaycomefromdifferentsources.\nBasedonourformulationinSection3,thesesourcescanbeclassifiedintothreecategories,thatis,theinformationinsideatrial,theinformationacrossdifferenttrials,andtheexternalknowledge.\nTheformertwoaredynamically11Table1:Summarizationofthememorysources.\nWeuse✓and×tolabelwhetherornotthecorrespondingsourceisadoptedinthemodel.\nModelsInside-trialInformationCross-trialInformationExternalKnowledgeMemoryBank[6]RET-LLM[7]ChatDB[96]TiM[97]SCM[98]Voyager[99]MemGPT[100]MemoChat[94]MPC[101]GenerativeAgents[83]RecMind[102]Retroformer[103]ExpeL[82]Synapse[91]GITM[93]ReAct[104]Reflexion[5]RecAgent[95]Character-LLM[105]MAC[106]Huatuo[107]ChatDev[1]InteRecAgent[108]MetaAgents[109]TPTU[110,111]MetaGPT[112]S3[2]InvestLM[113]✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓×××××××××××✓✓✓✓×✓××××××××✓×××✓✓×××××××✓✓✓×✓✓✓×✓×✓×✓×✓××✓generatedintheagent-environmentinteractionprocess(e.\ng.\n,taskinternalinformation),whilethelatterisstaticinformationoutsidetheloop(e.\ng.\n,taskexternalinformation).\nWesummarizepreviousworksonmemorysourcesinTable1.\n5.\n1.\n1Inside-trialInformationIntheagent-environmentinteractionprocess,thehistoricalstepswithinatrialareusuallythemostrelevantandinformativesignalstosupporttheagent’sfutureactions.\nAlmostallthepreviousworksusethisinformationasapartofthememorysources.\nRepresentativeStudies.\nGenerativeAgents[83]aimstosimulatehuman’sdailybehaviorsbyusingLLM-basedagents.\nThememoryofanagentisderivedfromthehistoricalbehaviorstoachieveatarget,forexample,thecollectionofrelevantpaperswhenresearchingonaspecifictopic.\nMemoChat[94]aimstochatwithhumans,wherethememoryoftheagentisderivedbasedontheconversationhistoryofadialoguesession.",
      "#memory_survey#MemoryinTextualForm#memory_survey#MemoryinTextualForm\nForexample,SCM[98]proposesaflashmemorybasedonthecachemechanism,whichpreservesobservationsfromtherecentt−1timesteps,aimedatenhancingtherecencyofinformation.\nMemGPT[100]considerstheagentasanoperatingsystem,whichcandynamicallyinteractwithusersthroughanaturalinterface.\nItdesignstheworkingcontexttoholdrecenthistories,asapartofvirtualcontextmanagement.\nInRecAgent[95],theagentsaredesignedtosimulateuserbehaviorsinmovierecommendations.\nItstoressometemporalinformationinshort-termmemoryasanintermediatecache,whichcansimulatethememorymechanismofthehumanbrain[122,123].\nTheserepresentativemethodscandynamicallyupdatememoriesbasedonrecentinteractions,andpaymoreattentiontotherecentcontextthatisimportantforthecurrentstage.\nCachingthememoryaccordingtorecencyisaneffectivewaytoenhancememoryefficiency,anditenablesagentstofocusmoreontherecentinformation.\nHowever,inlong-termtasks,thismethodfailstoaccesskeyinformationfromdistantmemories.\nItcanresultinthelossofpotentiallycrucialinformationthatisnotwithintheimmediatecachewindow.\nInotherwords,emphasizingonrecencycaninherentlyneglectearlier,yetcriticalinformation,thusposingchallengesinscenariosrequiringacomprehensiveunderstandingofpastevents.\nRetrievedInteractions.\nUnliketheabovemethodwhichtruncatesmemoriesbasedontime,thismethodtypicallyselectsmemorycontentsbasedontheirrelevance,importance,andtopics.\nItensurestheinclusionofdistantbutcrucialmemoriesinthedecision-makingprocess,therebyaddressingthelimitationofonlymemorizingrecentinformation.\nIntask(A)oftheexampleinSection3.\n1,Alice’spreferenceshavebeenstoredinthememorybeforethistask.\nAt[Step2],theagentwillretrievethemostrelevantaspectsofAlice’spreferencesfrommemorybasedonthequerykeyword\"travel\",obtainingAlice’sscenicspotpreferenceforancientarchitectures.\nIngeneral,retrievalmethodswillgenerateembeddingsasindexesformemoryentriesduringmemorywriting,alongwithrecordingauxiliaryinformationtoassistinretrieval.",
      "#memory_survey#Memory-basedLifelongLearning#memory_survey#Memory-basedLifelongLearning\nMemory-basedLifelongLearningLifelonglearningisanadvancedtopicinartificialintelligence,extendingthelearningcapabilitiesofagentsacrosstheirlife-longspan[173].\nAgentscancontinuouslyinteractwiththeirenvironment,persistentlyobserveenvironments,andacquireexternalknowledge,enablingamodeofenhancementlikehumans.\nThememoryofanagentiskeytoachievinglifelonglearning,asitneedstolearntostoreandapplythepastobservations.\nLifelonglearninginLLM-basedagentsholdssignificantpracticalvalue,suchasinlong-termsocialsimulationsandpersonalassistance.\nHowever,italsofacesseveralchallenges.\nFirstly,lifelonglearningistemporal,necessitatingthatanagent’smemorycapturestemporality.\nThistemporalitycouldcauseinteractionsbetweenmemories,suchasmemoryoverlap.\nFurthermore,duetotheextendedperiodoflifelonglearning,itneedstostoreavastamountofmemoriesandretrievethemwhenneeded,possiblyincorporatingacertainmechanismforforgetting.\n8.\n4"
    ]
  ],
  "ground_truth": [
    "Memory-driven communication frameworks foster a common understanding among agents.",
    "The adaptation time refers to the time of memory writing and memory management.",
    "The challenges associated with storing information about agent-environment interactions include the token limitation of LLM prompts, which makes it hard for the agent to store extensive information, and the potential for information loss when transforming texts into parameters in parametric memory, along with the additional challenges brought by complex memory training.",
    "Typical agent applications demonstrate the importance of the memory module in different scenarios.",
    "Integrating domain-specific knowledge through fine-tuning methods benefits agents by enriching their domain-specific knowledge on top of their general knowledge. This approach significantly improves the agent's ability to accomplish domain-specific tasks.",
    "Some approaches used in recommendation systems include simulating users to represent user profiles and histories, improving the performance of recommendations, and providing different formats of recommendation interfaces. Specifically, Wang et al. simulate user behaviors to generate data for recommender systems.",
    "The context mentions a comprehensive survey on advancing transformer architecture in long-context large language models, but specific advancements are not detailed.",
    "Practical downstream scenarios contribute to the evaluation of memory in agents by providing broader approaches to assess the function of memory.",
    "Memory-driven communication frameworks foster a common understanding among agents.",
    "LLM-based agents are adapted for use in the medical domain by fine-tuning an acquisition process to retrieve external knowledge from Wikipedia and medical databases.",
    "The Faiss vector store acts as the pool of memory and is used to obtain the top-K successful trajectories that share the highest similarity scores with the current task.",
    "The two types of approaches for representing memory in parametric form are fine-tuning methods and memory editing methods.",
    "The knowledge, alignment, and safety control capabilities of LLMs are evaluated as described by Guo et al., who focus on these evaluation targets.",
    "Macroeconomic trends impact agents' decision-making in social network simulation systems by maintaining conversation contexts that encompass the economic environment and agent decisions from previous months. This allows the simulation to reflect the influence of broad macroeconomic trends on agents' decision-making and helps agents grasp market dynamics.",
    "The purpose of the agent memory pool in social network simulation systems is to consist of diverse user messages from online platforms to identify the user.",
    "The key problems in subjective evaluation are (1) what aspects should be evaluated and (2) how to conduct the evaluation process.",
    "The focus of the survey on multimodal large language models is not explicitly detailed in the context provided.",
    "In ChatDB, the memory reading operation is executed by the SQL statements, which are generated by agents as a series of Chain-of-Memory in advance.",
    "The purpose of using a flash memory cache mechanism in storing recent textual memories is to preserve observations from the recent t - 1 time steps, aimed at enhancing the recency of information.",
    "LLM inaccuracies, such as hallucination, can lead to misconceptions or fabrications, impacting their reliability for downstream applications. Bias and unfairness in LLMs can result in unequal treatment of different humans or objectives, propagating societal stereotypes and discrimination. These issues can be addressed by using mainstream models and methods summarized by various researchers to alleviate hallucination, bias, and unfairness.",
    "LLM agents can improve themselves by autonomously exploring and learning from the real world, such as sending requests and observing responses or adjusting behaviors based on user feedback.",
    "Reflexion uses verbal reinforcement learning to derive experiences from past trials in verbal form and applies them in subsequent trials to improve task performance. This approach is compared to other models like Generative Agents, which derive memory from historical behaviors, and MemoChat, which bases memory on conversation history.",
    "Measuring a memory module independently improves its reliability over task-based evaluations because it allows for the effectiveness of the memory module to be evaluated without the influence of other factors that can affect task performance, thus providing a more reliable evaluation result.",
    "The societal issues stemming from LLM bias include the unequal treatment of different humans or objectives, which can lead to the propagation of societal stereotypes and discrimination. Trust can be improved by addressing challenges such as hallucination, bias, unfairness, explainability, security, and privacy in LLMs.",
    "Agents use temporal caching for film suggestions by storing some temporal information in short-term memory as an intermediate cache, which can simulate the memory mechanism of the human brain.",
    "Domain-specific tuning could potentially lead to overfitting and raises concerns about catastrophic forgetting, where LLMs may forget the original knowledge because of updating their parameters.",
    "Memory read latency is measured as the inference time, which indicates the time latency of memory reading. It matters for computational efficiency because it contributes to the total time cost, which includes both memory adaptation and inference times.",
    "Contextual memory improves code consistency and refinement by enhancing the coherence of the generated code and improving the continuity and consistency in code generation. It helps the agent better understand the requirements for software development.",
    "Memory synchronization among agents is fundamental for establishing a unified knowledge base, ensuring consistency in decision-making across different modules. This enhances agent synchronization, enables more effective communication, and provides strategic advantages in information-rich environments, thereby boosting the adaptability and intelligence of multi-agent systems.",
    "Memory effectiveness in LLM agents is evaluated through direct evaluation methods, which include subjective and objective evaluations, and indirect evaluation methods, such as task completion. The intuition behind indirect evaluation is that if the agent can successfully complete a task that highly depends on memory, it suggests that the designed memory module is effective.",
    "Agents use public information from digital sources by acquiring external knowledge through tools, such as accessing information via Application Programming Interfaces (APIs), to transform additional relevant knowledge into their own memories for decision-making.",
    "True positives (TP) and false negatives (FN) are used to calculate precision and recall, which are components of the F1-score. The F1-score is utilized to evaluate the retrieval process of memory, as mentioned in the context.",
    "Memory consistency with roles boosts realism and task adherence in social simulations by ensuring that the memory aligns with the roles' characteristics, which helps in identifying and distinguishing each role. This consistency is crucial for improving the realism of role-play and ensuring that the agent consistently follows the role profiles, preventing the agent from stepping out of the role during the simulation process.",
    "Historical data is combined for memory in agent loops by storing four types of information: (1) complete agent-environment interactions, (2) recent agent-environment interactions, (3) retrieved agent-environment interactions, and (4) external knowledge. The memory leverages natural languages to describe the information within the agent-environment interaction loop.",
    "Memory trade-offs impact LLM inference cost and time by requiring textual memory to be integrated into the context prompt, leading to higher costs and longer processing times. In contrast, parametric memory integrates information into the parameters of the LLM, eliminating these extra costs, although it incurs additional costs in the writing process.",
    "Long-term memory affects an agent's exploration by allowing the agent to accumulate experiences from past interactions, which can be applied to subsequent exploration. It utilizes feedback from different trials to support a wider range of agent exploration.",
    "LLM-based agents use past experiences and resources to enhance exploration and code generation by maintaining post observations as task contexts, storing experiences from previous successful trials, and leveraging these past experiences to avoid repeating mistakes. This helps them achieve a high-level understanding of environments for more effective exploration. In code generation, they search relevant information from memory to obtain more knowledge for development, save previous experiences for future problems, and maintain context in conversational development interfaces.",
    "Using past interactions and external knowledge helps an agent adapt over trials by allowing the agent to reflect on past interactions and draw experiences that can be applied to subsequent exploration. This accumulation of experience enhances the exploratory capabilities of the agent, enabling it to adjust actions based on overall feedback from the whole process.",
    "The context does not provide a direct explanation of how synced memory modules boost message interpretation and decision consistency.",
    "Using external expertise, such as integrating domain-specific knowledge through supervised fine-tuning, boosts an agent's performance by enriching its domain-specific knowledge on top of its general knowledge. However, this process risks overfitting and memory loss, as fine-tuning LLMs for specific domains could lead to overfitting and raise concerns about catastrophic forgetting, where LLMs may forget the original knowledge due to parameter updates.",
    "Fine-tuning with domain expertise improves LLM agents' decision-making by enriching domain-specific knowledge on top of their general knowledge. This process, known as supervised fine-tuning, empowers agents with the memory of domain experts, significantly enhancing their ability to accomplish domain-specific tasks.",
    "Selective fact adjustments in LLMs, through knowledge editing methods, are more suitable for small-scale memory adjustments and provide a more efficient and less resource-intensive way to update information compared to pattern extraction methods like fine-tuning. Knowledge editing specifically targets and adjusts only the facts that need to be changed, ensuring unrelated knowledge remains unaffected and mitigating catastrophic forgetting.",
    "High-level information from past trials boosts an agent's adaptability in new settings by allowing the agent to summarize and abstract high-level information from raw observations, which serves as the basis for being more adaptive and generalizable to unseen environments.",
    "RAG improves LLMs' accuracy and reduces errors by providing them with factual and up-to-date knowledge, which helps in removing hallucinations.",
    "Lifelong learning in LLM-based agents faces challenges such as the need for the agent's memory to capture temporality, which could cause interactions between memories, like memory overlap.",
    "LLM misconceptions, referred to as hallucinations, impact reliability by generating misconceptions or fabrications, which affect their reliability for downstream applications. Zhang et al., Huang et al., Rawte et al., Ye et al., Ji et al., Tonmoy et al., and Jiang et al. summarize the mainstream models for alleviating the hallucination problem in LLMs.",
    "Bubble sort repeatedly steps through the list, compares adjacent elements and swaps them if they are in wrong order.",
    "RAG boosts LLMs' accuracy and domain adaptation by providing them with factual and up-to-date knowledge and removing hallucinations.",
    "The key questions and design factors crucial for memory in LLM agents include 'What is', 'Why do we need', and 'How to design and evaluate' the memory module in LLM-based agents.",
    "TP (True Positives) represent the number of true positive memory contents, FP (False Positives) represent the number of false positive memory contents, and FN (False Negatives) indicate the number of false negative memory contents. These metrics are used to calculate precision and recall, which are then used to compute the F1-score for evaluating the retrieval process of memory.",
    "Memory models aid agent synchronization and strategy in multi-agent systems (MAS) by enhancing communication and providing strategic advantages in information-rich environments. They facilitate more robust, intelligent, and adaptable MAS by addressing challenges of memory integration and management, and by exploring the potentials of memory in these systems.",
    "LLM-based agents use past interactions to improve decisions by accumulating information across multiple trials, which includes successful and failed actions, insights such as failure reasons, and common action patterns to succeed.",
    "The memory module helps to accurately simulate human dynamic behaviors by maintaining conversation contexts, encompassing the economic environment and agent decisions from previous months, in order to simulate the impact of broad macroeconomic trends on agents’ decision-making and to make the agents grasp market dynamics.",
    "LLM agents use concatenated sequences for better memory in personalized dialogues by concatenating context QA pairs to form episode memory, which helps in maintaining context consistency and generating more personalized and relevant responses.",
    "Lifelong learning in LLM-based agents faces challenges such as capturing temporality in an agent's memory, which could cause interactions between memories, like memory overlap.",
    "LLM-based agents boost code coherence and error fixing by searching relevant information from memory, maintaining context in conversational development interfaces, and leveraging external resources. They store compiler errors and human expert instructions in an external non-parametric memory database for automatic syntax error fixing, enhancing the capabilities of code generation and improving continuity and consistency.",
    "Reflexion uses past trials by deriving experiences in verbal form and applying them in subsequent trials to improve the performance of the same task.",
    "GPT-4 is used to score the consistency of agents on interactive dialogues.",
    "CodeAgent focuses on the repo-level code generation task, which commonly requires complex dependencies and extensive documentation.",
    "Memory can represent user profiles and histories, and simulation of user behaviors can generate data for recommender systems.",
    "ChatDB is designed to utilize symbolic memory and proposes to generate SQL statements to retrieve information from the database, thereby boosting data retrieval.",
    "The deployment issue for LLMs with more computing needs and memory limits includes requiring much more computing resources, significantly increasing inference latency, and the necessity of truncating memory due to exceeding the upper bound of sequence length during pretraining, which can lead to information loss and biases in inference.",
    "LLM-based agents excel in dialogue and information gathering, as they are well-suited for creating personal assistants capable of engaging in long-term conversations and automatically seeking information.",
    "Agents boost efficiency with past successes by recording cross-trial information through successful exemplars, which are used as references on similar trials. They store and organize completed trajectories and recall similar ones for new tasks, comparing successful cases.",
    "LLMs get molecule data by including a molecule database as external knowledge for memory in LLM-based agents, which can be retrieved when they need related information.",
    "LLMs aid in the areas of information retrieval (IR) and information extraction (IE).",
    "Quadratic growth in attention impacts latency by significantly increasing inference latency due to the high computational cost associated with the fast-growing long-context memory, which requires much more computing resources.",
    "Imitation learning boosts agents' tool use in math.",
    "The positions of text segments in a long context can greatly affect their utilization, so the memory in the long-context prompt cannot be treated equally and stably.",
    "Memory retrieval scores are derived using TP (true positives), FP (false positives), and FN (false negatives) by calculating precision and recall. Precision is calculated as TP / (TP + FP), and recall is calculated as TP / (TP + FN). The F1-score is then calculated as 2 * (Precision * Recall) / (Precision + Recall).",
    "A reinforcement learning framework for relevance feedback.",
    "Targeted LLM tweaks avoid losing other information by specifically targeting and adjusting the facts, ensuring that non-targeted knowledge remains unaffected during updates, thus mitigating the issue of catastrophic forgetting.",
    "Memory-driven communication frameworks foster a common understanding among agents, which helps them cooperate.",
    "MemGPT considers the agent as an operating system, which can dynamically interact with users through a natural interface. It designs the working context to hold recent histories, as a part of virtual context management.",
    "LLM agents use memory for suggestions in scenarios such as role-playing and social simulation, personal assistant, open-world games, code generation, recommendation, expert systems in specific domains, and other applications.",
    "LLM tweaks, through knowledge editing methods, stop forgetting during updates by specifically targeting and adjusting the facts, ensuring that non-targeted knowledge remains unaffected, thus mitigating the issue of catastrophic forgetting.",
    "SCM proposes a flash memory based on the cache mechanism, which preserves observations from the recent t - 1 time steps, aimed at enhancing the recency of information.",
    "In MemoChat, the agents summarize each conversation segment by abstracting the mainly discussed topics and storing them as keys for indexing memory pieces."
  ],
  "evolution_type": [
    "simple",
    "simple",
    "simple",
    "simple",
    "simple",
    "simple",
    "simple",
    "simple",
    "simple",
    "simple",
    "simple",
    "simple",
    "simple",
    "simple",
    "simple",
    "simple",
    "simple",
    "simple",
    "simple",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "multi_context",
    "reasoning",
    "reasoning",
    "reasoning",
    "reasoning",
    "reasoning",
    "reasoning",
    "reasoning",
    "reasoning",
    "reasoning",
    "reasoning",
    "reasoning",
    "reasoning",
    "reasoning",
    "reasoning",
    "reasoning",
    "reasoning",
    "reasoning",
    "reasoning",
    "reasoning",
    "reasoning",
    "reasoning",
    "reasoning"
  ],
  "metadata": [
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      },
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ],
    [
      {
        "source": "data/mixed_documents/memory_survey.pdf"
      }
    ]
  ],
  "episode_done": [
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true,
    true
  ],
  "answer": [
    "Memory-driven communication frameworks play a crucial role in fostering a common understanding among agents by maintaining context and interpreting messages effectively. They rely heavily on memory to ensure that the information exchanged between agents is consistent and meaningful, which is vital for building a unified knowledge base. These frameworks utilize synchronized memory modules to enable efficient communication, reduce information asymmetry, and enhance decision-making processes. In cooperative settings, such as multi-agent systems, memory synchronization is fundamental for maintaining consistency and facilitating seamless collaboration, ultimately improving communication and providing strategic advantages in information-rich environments.",
    "Adaptation time in the context of memory writing and management refers to the period during which memory writing and memory management operations are conducted. It measures the time consumed by these processes, which are essential components of memory operations within systems that manage and utilize memory effectively. Memory writing involves projecting raw observations into stored memory contents, making them more informative and concise. Memory management processes the stored information by summarizing, merging similar entries, and discarding irrelevant data. Understanding adaptation time helps in assessing the overall time cost associated with memory operations and provides insights into optimizing memory management for better performance.",
    "The challenges associated with storing information about agent-environment interactions include:\n\n1. **High Computational Cost**: Maintaining a long-context memory has a high computational cost. This is because, during LLM (Large Language Model) inference, the computational cost increases due to the quadratic growth of the time complexity of attention computation with sequence length. This requires more computing resources and significantly increases inference latency, which can hinder practical deployment.\n\n2. **Memory Truncation**: As the memory length grows rapidly, it can easily exceed the upper bound of the sequence length during LLM’s pretraining. This necessitates memory truncation, which can lead to information loss due to the incompleteness of agent memory.\n\n3. **Bias Introduction**: Storing all agent-environment interactions can introduce biases and affect the robustness of LLM’s inference. This can compromise the reliability of the model's predictions and decisions.\n\nOverall, while maintaining comprehensive information about agent-environment interactions is beneficial, these challenges must be addressed to optimize the storage and use of such data.",
    "Typical agent applications demonstrate that memory modules are crucial for the functionality and effectiveness of agents across various scenarios. In conversational agents, memory is essential for storing historical conversations, which allows the agent to generate contextually appropriate responses and continue conversations effectively. In simulation agents, memory helps ensure agents consistently adhere to their intended roles, preventing deviation during simulations. Moreover, memory modules enable agents to evolve and adapt to new environments, which is vital in complex applications like autonomous driving. These applications show that memory is not just an optional component but a necessity for agents to perform specific tasks effectively and enhance their capabilities.",
    "Integrating domain-specific knowledge through fine-tuning methods benefits agents by significantly enhancing their capabilities in performing tasks that require high accuracy and reliability in domain-specific contexts. Fine-tuning involves adjusting a model's parameters using supervised learning on specialized datasets, which equips agents with memory akin to that of domain experts. This process effectively bridges the gap between general and specialized agents, improving their performance in domain-specific tasks. Examples include biomedical applications like Huatuo, which fine-tunes Llama on Chinese medical knowledge bases, and financial applications like InvestLM, which collects investment data to enhance domain-specific abilities in financial investment.",
    "Some approaches used in recommendation systems to simulate user behaviors and improve performance include:\n\n1. **Using Memory Mechanisms**: Memory is used to represent user profiles and histories, which is crucial for accurately simulating user behavior in recommendation scenarios. For example, hierarchical memory structures can store past observations and insights, capturing both extended conversational histories and recent dialogues.\n\n2. **Dynamic Memory Modules**: These are integrated into systems to enhance recommendation performance. Item agents may have memory modules to capture and preserve information related to their attributes and adopters' preferences, while user agents use adaptive memory updating mechanisms to align with user behaviors and preferences.\n\n3. **Actor-Critic Reflection Models**: This approach involves feedback loops to continually refine the agent's memory and decision-making processes, improving the robustness of agents in recommendation systems. This method emphasizes retaining personalized information through memory, aligning it with recommendation tasks.\n\nEach of these approaches leverages memory in different ways to capture and make use of user behavior and preferences, ultimately aiming to provide more personalized and effective recommendations.",
    "Recent advancements in transformer architecture for long-context large language models (LLMs) have focused on enhancing their ability to effectively manage and utilize extremely long prompts, which are important for driving agent behaviors. These advancements include improving the models' performance in tasks such as long-context passage retrieval, where agents need to accurately identify the correct paragraph within a lengthy context that corresponds to specific questions or descriptions. Another key task is long-context summarization, which requires the model to develop a global understanding of the entire context and produce a summary based on given descriptions. These enhancements are evaluated using metrics like ROUGE to assess the quality of the summaries. Comprehensive benchmarks provide objective assessments of the long-context understanding capabilities, further driving innovation in transformer architectures for these applications.",
    "Practical downstream scenarios contribute to the evaluation of memory in agents by providing real-world tasks that test the effectiveness and significance of the memory module. These scenarios allow for indirect evaluation, where the success of task completion demonstrates the utility of the memory module. For example, tasks like passage retrieval and summarization require the agent to utilize memory to identify relevant information and synthesize a coherent summary. Metrics such as ROUGE scores can objectively measure the contribution of memory to task performance. Additionally, exploratory games or interactive environments enable assessment by observing the agent's ability to explore, learn, and interact with the environment, with success rates in tasks providing quantitative measures of memory's effectiveness. Ablation studies further highlight memory's significance by comparing performance with and without memory modules. Overall, these scenarios provide a comprehensive understanding of how memory modules enhance an agent's capabilities and facilitate improvements in memory design and implementation.",
    "Memory-driven communication frameworks play a crucial role in fostering a common understanding among agents by integrating and synchronizing memory modules. This integration allows agents to maintain context, interpret messages effectively, and establish a unified knowledge base. The synchronization process enables agents to share and align their knowledge, ensuring consistency in decision-making across different agents. This leads to more coherent communication and successful collaboration within multi-agent systems.",
    "LLM-based agents are adapted for use in the medical domain by integrating external knowledge into their memory, which enhances their capability to handle domain-specific tasks. This is done through fine-tuning methods that incorporate medical knowledge into the agents. For example, Wang et al. fine-tuned LLaMA with a medical knowledge graph to improve its understanding of medical domain questions. Similarly, ChatDoctor adapts LLM-based agents by utilizing external medical databases and Wikipedia to fine-tune its acquisition process, thereby enhancing its ability to provide accurate medical information. Additionally, approaches like LoRA are used to efficiently fine-tune foundation models specifically for healthcare applications. These methods allow LLM-based agents to retain domain-specific knowledge and function effectively as expert systems within the medical field. However, challenges such as overfitting and catastrophic forgetting, where the agents might lose their general knowledge due to parameter updates, are also associated with these adaptations.",
    "The role of the Faiss vector store in obtaining top-K successful trajectories for a task is to enhance the efficiency of retrieving the most relevant information from past interactions. During the memory writing phase, each memory entry is encoded into an embedding and indexed by Faiss. When the agent needs to obtain the top-K successful trajectories, the current context is encoded into representations, and matching scores are calculated for each memory entry. The Faiss vector store allows for efficient retrieval of these top-K entries based on the scores, which are then used in the decision-making process. This method ensures that the agent can access distant but crucial memories quickly and efficiently, supporting comprehensive understanding in scenarios that require insights from past events.",
    "The two types of approaches for representing memory in parametric form are fine-tuning methods and memory editing methods. \n\nFine-tuning methods involve adjusting the parameters of language models to infuse domain-specific knowledge, which enhances the model's ability to perform tasks requiring specialized information. This approach is more suitable for offline scenarios due to its computational cost and time consumption.\n\nMemory editing methods focus on selectively modifying specific facts within the model's parameters. This ensures that only targeted knowledge is altered while leaving unrelated information intact. Memory editing is more appropriate for online and dynamic interactions, as it allows for small-scale adjustments and provides an efficient way to update information.",
    "The knowledge, alignment, and safety control capabilities of Large Language Models (LLMs) are evaluated through specific assessments:\n\n1. **Knowledge Evaluation**: This involves assessing how well an LLM can access, process, and generate information accurately and comprehensively. It focuses on the model's ability to provide correct and complete information.\n\n2. **Alignment Evaluation**: This examines how closely the outputs of an LLM align with human values and ethical considerations. The goal is to ensure that the model's behavior is consistent with societal norms and does not produce content that is misaligned with human values.\n\n3. **Safety Control Evaluation**: This addresses the mechanisms in place to prevent the generation of harmful or inappropriate content. It ensures that the LLM operates within safe and acceptable boundaries, thereby supplementing traditional performance metrics and providing a broader understanding of the model's overall capabilities and trustworthiness in various applications. \n\nThese evaluations help in understanding how well an LLM can be trusted and utilized in different contexts while maintaining safety and ethical standards.",
    "Macroeconomic trends impact agents' decision-making in social network simulation systems by influencing the conversation contexts that these systems maintain. According to the information provided, these contexts include the economic environment and previous decisions made by the agents. By incorporating macroeconomic trends into the agents' memory, the simulation can accurately reflect how these trends affect decision-making processes. This allows agents to better understand and adapt to changes in the economic landscape, ensuring their behaviors are consistent and rational. The memory module is crucial in allowing agents to process and respond to macroeconomic information, which shapes their decisions and actions within the simulation, enhancing the realism and effectiveness of the simulation.",
    "The purpose of the agent memory pool in social network simulation systems is to simulate human dynamic behaviors accurately. The memory pool stores diverse user messages sourced from online platforms, which helps identify and understand users within the simulation. This enables agents to maintain a consistent and realistic representation of user interactions and behaviors, contributing to the realism and effectiveness of the simulation. The memory pool allows agents to store and recall information about user profiles, dialogues, and other relevant data, ensuring appropriate responses to various social scenarios. By incorporating elements of human memory, such as forgetting and differentiating between long-term and short-term memory, the system aligns closely with cognitive psychology theories, enhancing the agents' decision-making processes and ability to simulate social dynamics.",
    "The key problems in subjective evaluation are: (1) determining which aspects should be evaluated, and (2) deciding how to conduct the evaluation process.",
    "The focus of the survey on multimodal large language models presented at the 2023 IEEE International Conference on Big Data is on summarizing the advancements and methodologies in the field of multimodal large language models (LLMs). It explores how these models expand the capabilities of LLMs from purely text-based to include visual and other modalities. The survey provides a comprehensive overview of the design and evaluation of multimodal LLMs, highlighting their effectiveness and efficiency in processing and integrating information across multiple types of data. Additionally, it discusses potential applications and challenges associated with implementing these models in various practical scenarios, and aims to provide clear taxonomies and insights to guide future research in this domain.",
    "SQL statements in ChatDB are used in the memory reading operation to efficiently access and retrieve stored information from databases. Agents generate these SQL statements in advance as a series of Chain-of-Memory. This structured approach allows for systematic extraction of relevant data from the memory, facilitating reasoning and decision-making processes. The use of SQL ensures that the retrieval process is both structured and scalable, allowing for precise access to the necessary information stored within the system.",
    "The purpose of using a flash memory cache mechanism in storing recent textual memories is to enhance the recency of information. This mechanism is designed to preserve observations from the recent t-1 timesteps, focusing on the most recently acquired memories. It aligns with the Principle of Locality, emphasizing the importance of recent information in memory utilization. This strategy allows for dynamically updating memories based on recent interactions and helps agents pay more attention to the context most relevant to the current stage, thereby enhancing memory efficiency for tasks where immediate context and recent interactions are significant.",
    "LLM inaccuracies and biases cause several problems, including reliability issues, the propagation of societal stereotypes, and potential discrimination. Inaccuracies can lead to hallucinations, where models generate misconceptions or fabrications, which pose a threat to their reliability in downstream applications. Bias and unfairness can lead to the unequal treatment of different humans or objectives, further perpetuating stereotypes.\n\nThese problems can be addressed by improving the trustworthiness of LLMs, ensuring their outputs are consistent with human values and free from harmful biases. Researchers such as Zhang et al., Huang et al., Rawte et al., Ye et al., Ji et al., Tonmoy et al., and Jiang et al. have worked on summarizing mainstream models aimed at alleviating hallucinations. Meanwhile, Gallegos et al., Kotek et al., and Li et al. have discussed challenges related to bias and proposed methods to mitigate them.",
    "LLM-based agents possess several key self-evolving features that help them adapt autonomously in dynamic environments:\n\n1. **Experience Accumulation**: Agents utilize their memory to remember past errors, inappropriate behaviors, or failed experiences. This allows them to improve their effectiveness in handling similar tasks in the future, enhancing their learning efficiency during the self-evolving process.\n\n2. **Environment Exploration**: Agents explore different actions and learn from the feedback they receive. By recalling historical information, they can make more informed decisions about when and how to conduct explorations, focusing on previously failed trials or actions with lower exploring frequencies.\n\n3. **Knowledge Abstraction**: Agents can summarize and abstract high-level information from raw observations. This process is crucial for becoming more adaptive and generalizable to unseen environments.\n\nThese features collectively enable LLM-based agents to self-evolve and adapt autonomously.",
    "Reflexion uses past experiences by applying verbal reinforcement learning to enhance the performance of LLM-based agents. It derives experiences from past trials in verbal form and applies them in subsequent trials. This allows the agents to accumulate experiences and adjust their actions based on feedback from the entire process. \n\nIn comparison to other models: \n- MemoChat builds its memory based on the conversation history of a dialogue session, which is essential for chatting with humans.\n- TiM enhances reasoning by self-generating multiple thoughts after achieving a task, using these thoughts as memory to provide more generalized information.\n- Voyager creates memory in the form of executable codes for basic actions to accomplish tasks in the game Minecraft.\n\nEach model uses memory differently to support their specific task performance, with Reflexion specifically leveraging past experiences through verbal reinforcement learning to adjust and improve future actions.",
    "Measuring a memory module independently improves its reliability over task-based evaluations by isolating the specific impact and effectiveness of the memory component itself. This approach allows for the assessment of the memory module's capabilities without the influence of other variables that might affect task performance. By focusing solely on the memory module, independent evaluations provide more reliable and accurate insights into its true performance and effectiveness. This method eliminates the confounding effects that can arise in task-based assessments, thus enhancing the overall reliability of the evaluation process.",
    "The societal issues that stem from LLM bias include the unequal treatment of different humans or objectives, the propagation of societal stereotypes, and discrimination. These biases in large language models (LLMs) can lead to significant societal concerns, particularly in the application of artificial intelligence technologies.\n\nTo improve trust in LLMs, it is essential to develop models that can recognize and correct biases, ensuring fair and equitable treatment across different demographics and scenarios. Additionally, enhancing the explainability of LLMs can contribute to building trust by making their internal workings clearer and more transparent. Researchers have discussed these challenges and summarized existing methods to alleviate them, focusing on understanding and mitigating the inherent biases present in LLMs.",
    "Agents use temporal caching for film suggestions by maintaining recent interactions in short-term memory, which allows them to focus on the most current and relevant information. This approach is based on the Principle of Locality, which emphasizes the importance of recency in information processing. By dynamically updating memories based on recent interactions, agents can simulate user behaviors and preferences more effectively, leading to better-aligned film suggestions. This mechanism is similar to how the human brain processes memory, prioritizing recent experiences to make decisions. However, while this method enhances the efficiency of memory utilization, it may also overlook important earlier information, which could be critical in some contexts.",
    "Domain-specific tuning can potentially affect LLMs' general knowledge by causing issues such as overfitting and catastrophic forgetting. During the fine-tuning process with domain-specific data, the model can become too tailored to the specific domain, which might lead it to lose its ability to generalize across different contexts. Additionally, there is a risk of catastrophic forgetting, where the model might forget or overwrite its original, general knowledge due to the updating of its parameters during fine-tuning. This could result in a narrowed knowledge base, where the model excels in domain-specific areas but at the expense of its broader knowledge capabilities.",
    "Memory read latency is measured by calculating the time difference between the end time and the start time of memory reading operations. This can be quantified using the formula: \\(\\Delta \\text{time} = \\frac{1}{M} \\sum_{i=1}^M (t_{\\text{end}_i} - t_{\\text{start}_i})\\), where \\(M\\) is the number of operations, \\(t_{\\text{end}_i}\\) is the end time of the \\(i\\)-th operation, and \\(t_{\\text{start}_i}\\) is the start time of that operation.\n\nThis measurement is crucial for computational efficiency because it directly impacts the time cost associated with memory adaptation and inference. Efficient memory read latency ensures that agents can quickly access the necessary information, which is essential for real-world applications where time and efficiency are critical. Faster memory reading allows AI systems to perform more effectively, especially in scenarios that require quick access to relevant information, thereby maintaining overall system performance.",
    "Contextual memory improves code consistency and refinement by storing previous experiences and maintaining context within conversational development interfaces. This allows LLM-based agents to search for relevant information from their memory, acquiring additional knowledge for development tasks. By preserving compiler errors and human expert instructions, agents can automatically fix syntax errors, which enhances the quality and consistency of the code. Additionally, the ability to retain context and knowledge for decision-making enables agents to draw upon past interactions to inform current tasks, ensuring continuity in refining code as it evolves. This adaptive application of learned experiences to new challenges enhances the agent's capabilities in generating consistent and refined code outputs over time.",
    "Memory synchronization and communication boost the adaptability and intelligence of multi-agent systems (MAS) by ensuring a unified knowledge base and consistent decision-making across different agents. Memory synchronization is crucial for establishing a shared understanding among agents, which enhances their ability to collaborate effectively. This is particularly important in cooperative scenarios, such as multi-robot collaboration, where a synchronized memory allows for cohesive operation.\n\nCommunication among agents relies on memory to maintain context and accurately interpret messages, fostering mutual understanding and more effective interactions. By integrating memory-driven communication frameworks, agents can maintain context, which is essential for interpreting messages coherently. This capability is crucial in both cooperative and competitive scenarios, where managing information asymmetry is a significant challenge.\n\nAs memory mechanisms within large language model-based MAS continue to evolve, they enhance agent synchronization and enable more effective communication. This evolution addresses current challenges in memory integration and management, allowing MAS to become more robust, intelligent, and adaptable. The continuous development of memory models pushes the boundaries of MAS capabilities, setting new benchmarks and paving the way for future innovations in memory utilization and management.",
    "Memory effectiveness in LLM-based agents is evaluated using two broad strategies: direct evaluation and indirect evaluation.\n\n1. **Direct Evaluation**: This strategy measures the capability of the memory module independently. It provides a more reliable assessment of its effectiveness because it isolates the memory's contribution from other factors. However, there is a lack of open-sourced benchmarks specifically designed for memory modules in LLM-based agents.\n\n2. **Indirect Evaluation**: This approach assesses the memory module through end-to-end agent tasks. If these tasks are accomplished effectively, it suggests that the memory module is useful. Indirect evaluation is often easier to conduct due to the availability of many public benchmarks, though the results may be biased since task performance can be influenced by various elements beyond just memory.\n\nAdditionally, ablation studies are frequently used, where performance is compared with and without memory modules in specific scenarios, to practically reflect memory's significance for downstream applications.",
    "Agents use public information from digital sources to enhance their decision-making processes by integrating external knowledge through various methods. One common approach is accessing public information via Application Programming Interfaces (APIs), which allow agents to retrieve up-to-date data from sources such as Wikipedia and OpenWeatherMap. This provides a convenient way to incorporate additional relevant knowledge into the agents’ memory systems, enabling them to make more informed decisions. Models like Toolformer and ToolLLM have been developed to teach large language models (LLMs) how to effectively use such tools, expanding their ability to access diverse sources of information. This capability allows agents to perform complex tasks and significantly enhances their decision-making processes.",
    "True positives (TP) and false negatives (FN) are crucial in assessing memory retrieval as they help evaluate the effectiveness of an agent's ability to discover relevant memory contents to answer questions. True positives refer to the number of relevant memory contents correctly identified by the agent, while false negatives indicate the relevant memory contents that the agent failed to retrieve. By calculating precision (TP / (TP + FN)) and recall (also defined as TP / (TP + FN)), researchers can determine how accurately the memory module retrieves necessary information. The F1-score, which combines precision and recall, is used to evaluate reference accuracy, providing insights into the effectiveness and efficiency of the memory retrieval process. This comprehensive evaluation helps identify areas for improvement and guides future developments in memory module performance.",
    "Memory consistency with roles boosts realism and task adherence in social simulations by allowing agents to exhibit behaviors that are authentic to human dynamics. By designing an agent's memory to align with the characteristics of specific roles, it helps in distinguishing and differentiating each role from others. This distinction is crucial for improving the realism of role-play and the diversity of social simulation. When the memory is consistent with the roles, it ensures that agents' behaviors are more realistic and aligned with human interactions and decision-making processes. Additionally, memory consistency influences the subsequent actions of the agent, ensuring consistency and rationality in behaviors, which maintains the integrity of the role being played and ensures adherence to the tasks or scenarios being simulated. This alignment with human-like memory processes, such as forgetting and long/short-term memory, according to cognitive psychology theories, further enhances the authenticity and credibility of the agents' behaviors in social simulation environments.",
    "In the context of agent loops, historical data is combined in memory through a structured approach that incorporates information from various sources. There are two primary definitions of agent memory: narrow and broad. \n\nIn the narrow sense, the agent's memory is limited to historical information within the same trial. For a given task, the historical data before a certain step is captured as ξt, which includes previous actions and observations within that trial. This information is then used to guide the agent's decision-making in subsequent steps of the same task.\n\nIn contrast, the broad definition of agent memory includes a wider range of sources. It not only considers the historical information within the same trial but also encompasses data across different trials and external knowledge beyond the immediate agent-environment interactions. For a series of sequential tasks, memory information at a given step comes from three sources: (1) the historical information within the same trial, (2) historical information across different trials, and (3) external knowledge. \n\nAdditionally, methods like caching based on recency and retrieval ensure that the agent's memory is efficient and relevant. Caching focuses on retaining recent information crucial for current tasks, while retrieval methods allow the agent to access distant but significant memories. This dual strategy ensures that the agent's memory is both current and comprehensive, addressing the need for both immediate and historical context in decision-making processes.",
    "The memory trade-offs impact LLM inference cost and time primarily by increasing the computational burden associated with storing and processing long-context memory. As the memory length increases, the computational resources required for LLM inference escalate due to the quadratic growth of the time complexity of attention computation with sequence length. This results in significantly increased inference latency, requiring more computing power and extending the time taken to produce results. Additionally, as the memory length expands, it often surpasses the sequence length upper bound established during LLM pretraining, necessitating memory truncation, which can lead to information loss and negatively affect the robustness of LLM inference. These trade-offs highlight the importance of designing extra memory modules to manage information storage effectively while balancing computational cost and inference time.",
    "Long-term memory significantly enhances an agent's exploration capabilities. It allows the agent to retain past experiences and historical information, which helps in avoiding the repetition of previous mistakes and navigating environments more effectively. By storing successful trajectories and learned skills, the agent can handle similar tasks more efficiently in the future. Additionally, long-term memory aids in knowledge abstraction, enabling the agent to summarize and abstract high-level information from raw observations. This enhances the agent's adaptability and generalizability to new environments. Furthermore, memory helps the agent focus on actions that have previously resulted in failures or have been explored less frequently, optimizing its exploration strategies. Overall, long-term memory is crucial for facilitating an agent's self-evolution and improving its ability to explore and learn from its environment effectively.",
    "LLM-based agents use past experiences and external resources to enhance their exploration and code generation capabilities in several ways. They have memory mechanisms that allow them to store and organize completed tasks or trajectories, which can be recalled for new tasks. By comparing successful cases with failed ones, these agents can identify patterns that lead to success, effectively using past interactions as a long-term memory resource. This reflection on past interactions provides valuable experiences that inform their subsequent explorations.\n\nAdditionally, LLM agents incorporate external knowledge, such as information from Wikipedia, to make informed decisions beyond their immediate environment. This external knowledge is especially useful in scenarios where interactions alone are insufficient to acquire necessary information.\n\nFor code generation, agents use their memory to search for relevant information, retaining context and maintaining continuity in development. Previous experiences, such as compiler errors and human expert instructions, are stored to aid in automatic syntax error fixing. The non-parametric memory database allows agents to retrieve historical records when errors occur, enhancing their problem-solving abilities.\n\nBy combining internal memory with external resources, LLM agents continuously learn and adapt, improving their performance in exploratory tasks and complex code generation scenarios. This integration enables them to navigate challenges more effectively, advancing their exploratory and developmental capabilities.",
    "Using past interactions and external knowledge helps an agent adapt over trials by enhancing its ability to learn from experience and access a broad range of information. \n\n1. **Past Interactions**: These serve as a form of long-term memory for the agent, containing insights from both successful and unsuccessful actions. By analyzing these interactions, the agent can identify patterns that lead to success or reasons for failure. This accumulated experience allows the agent to adjust its actions in future trials based on feedback from previous ones, thereby improving performance on similar tasks.\n\n2. **External Knowledge**: This provides agents with information beyond their immediate environment, which they might not be able to gather through interactions alone. By incorporating external knowledge from sources like Wikipedia, agents can access a vast reservoir of information. This helps them make more informed decisions and enhances their adaptability across different trials.\n\nBy leveraging both past experiences and external knowledge, agents are better equipped to navigate and adapt to various challenges they encounter over multiple trials.",
    "Synced memory modules boost message interpretation and decision consistency by simulating human-like memory processes, which allow agents to generate high-level information and interact more effectively with their environments. These modules facilitate memory reading operations, where relevant information is extracted from memory based on the current state, ensuring that only useful data is used for reasoning and decision-making. The design of these operations considers relevance and other task-oriented factors, which enhances the quality of message interpretation and decision consistency.\n\nAdditionally, the collaborative nature of memory reading and writing operations influences information processing. By strategically extracting and abstracting information during memory writing, agents can manage memory more efficiently, leading to improved message interpretation. Memory-based lifelong learning also plays a role, as it enables agents to continuously interact with and learn from their environments, applying past observations to maintain decision consistency over time. Synced memory modules ensure that agents can consistently retrieve and apply relevant information, which boosts decision consistency and accurate message interpretation.",
    "Using external expertise boosts an agent's performance by expanding its knowledge beyond what it can acquire through interactions with its internal environment alone. This is achieved by accessing up-to-date and well-founded information from various sources, such as APIs, which helps the agent make informed decisions and tackle complex problems more effectively. For example, models like Toolformer and ToolLLM enable agents to dynamically acquire necessary information to solve tasks by teaching them how to use tools and APIs.\n\nHowever, relying heavily on external expertise introduces potential risks, such as inaccuracies and biases in the retrieved information. Moreover, the process of integrating this knowledge requires a comprehensive understanding, which can lead to higher computational costs and complications in aligning external data with the agent's internal decision-making processes. This complexity may cause overfitting, where the agent becomes too tailored to specific external data, and memory loss, where the agent struggles to manage and utilize the vast amount of acquired knowledge effectively.",
    "Fine-tuning with domain expertise improves LLM agents' decision-making by infusing them with specialized knowledge relevant to specific domains. This process involves supervised fine-tuning, which integrates external domain knowledge into the agents' memory. As a result, the agents' domain-specific understanding is enriched on top of their general knowledge. This enrichment helps bridge the gap between general-purpose agents and those tailored for specific tasks, such as in the biomedical or financial domains. Consequently, the agents become more adept at handling tasks requiring high accuracy and reliability in domain-specific information. Despite challenges like the risk of overfitting and catastrophic forgetting, fine-tuning equips agents with the necessary expertise to make informed decisions in specialized areas, allowing them to utilize role-related data and experiences effectively.",
    "Selective fact adjustments and pattern extraction in Large Language Models (LLMs) both aim to enhance the efficiency of memory use, but they do so through different mechanisms.\n\nSelective fact adjustments involve editing specific facts within the memory of an LLM. This method allows for the modification of particular information without requiring the entire model to be retrained, conserving computational resources and time. By focusing on updating only the necessary information, selective fact adjustments help mitigate issues such as overfitting and catastrophic forgetting, which are common with fine-tuning methods.\n\nPattern extraction, on the other hand, involves identifying and utilizing relevant patterns from the memory. This approach is particularly useful for managing long-context memory by focusing on the most pertinent information. Pattern extraction helps reduce computational cost and inference time, thereby enhancing inference robustness.\n\nIn summary, both methods strive to optimize memory use: selective fact adjustments do so by updating specific facts efficiently, while pattern extraction focuses on the efficient retrieval and use of relevant patterns. Both approaches highlight the importance of balancing memory retention with computational efficiency in LLMs.",
    "High-level information from past trials boosts an agent's adaptability in new settings by serving as a repository of accumulated knowledge and experiences. This includes successful actions, failed attempts, and the insights gained from them, such as reasons for failures and patterns that lead to success. By analyzing this cross-trial information, agents can identify common action patterns and adjust their strategies based on comprehensive feedback from their previous experiences. This accumulated memory functions like long-term memory, providing prolonged experiential support that enhances the agent's evolution and adaptability in diverse environments. By building on this foundational knowledge, agents can navigate new settings with greater agility, making informed decisions based on a wealth of prior experiences.",
    "RAG improves LLMs' accuracy and reduces errors by integrating a retrieval mechanism with the generation process of the models. This allows the LLMs to access external sources of factual and up-to-date information during their operations, which helps in providing more precise and factually accurate outputs. By consulting these external sources, RAG helps in removing hallucinations—misconceptions or fabrications that LLMs might generate—thereby enhancing their reliability for applications requiring high accuracy and dependability on domain-specific information.",
    "LLM-based agents face several time and memory challenges in learning over time, primarily due to the temporal nature of lifelong learning and the need to manage a vast amount of information. The key challenges include:\n\n1. **Temporality of Lifelong Learning**: The agents need to effectively capture the time-related aspects of their observations and experiences, such as when they occurred and their sequence. This temporal aspect can lead to memory overlap, where different memories might interact or interfere with each other.\n\n2. **Storage and Retrieval**: Lifelong learning spans an extended period, requiring agents to store a significant amount of memories and retrieve them efficiently when needed. This necessitates mechanisms for storing vast quantities of information and possibly forgetting irrelevant or outdated information to optimize memory usage.\n\n3. **Balancing Information Accumulation**: Agents must balance between inside-trial and cross-trial information accumulation. Inside-trial information is useful for current tasks but might limit the agent's ability to generalize and learn from broader experiences. Cross-trial information serves as long-term memory, helping agents accumulate experiences across different tasks.\n\n4. **Direct Interactions Requirement**: Both inside-trial and cross-trial information require direct interactions with the environment, which means these agents might not incorporate external experiences and knowledge that could benefit comprehensive learning.",
    "LLM misconceptions impact reliability by generating false or fabricated information, known as hallucinations, which lead to misconceptions that compromise the trustworthiness of these models. This issue is crucial because it affects the dependability of LLMs when they are used for various tasks, including decision-making processes and information retrieval.\n\nTo tackle this problem, several models and approaches have been designed to address the hallucination issue in LLMs. Researchers such as Zhang et al., Huang et al., Rawte et al., Ye et al., Ji et al., Tonmoy et al., and Jiang et al. have summarized mainstream models that focus on alleviating these misconceptions. These models use different techniques to enhance the accuracy and reliability of the information generated by LLMs, thereby improving their overall performance and trustworthiness in real-world applications.",
    "The method that swaps adjacent elements to sort a list is Bubble Sort. This is because Bubble Sort repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order, continuing this process until the list is sorted.",
    "RAG (Retrieval-Augmented Generation) boosts the accuracy and domain adaptation of Large Language Models (LLMs) by integrating external, up-to-date, and real-world information from diverse sources into the model's outputs. This integration allows LLMs to overcome the limitations of relying solely on the pre-existing data embedded within their parameters. The retrieval mechanism in RAG accesses external knowledge bases, which is crucial for maintaining the relevance of information, especially in tasks that require high accuracy and reliability in domain-specific contexts. By aligning external data with internal decision-making processes, RAG-equipped LLMs can provide more precise and contextually appropriate responses. This approach effectively narrows the gap between general and specialized knowledge without the extensive computational costs and risks of overfitting associated with supervised fine-tuning.",
    "The key questions and design factors crucial for memory in LLM (Large Language Model) agents, as mentioned in the evidence, include:\n\n1. **Effects of Memory on Performance**: Understanding what specific effects memory components should have on the agent's performance is crucial. This involves determining the types of information the memory should store and how these data will be utilized to enhance the agent's capabilities.\n\n2. **Necessity of Memory**: Exploring why memory is necessary for building LLM-based agents is important. This can be examined from perspectives such as cognitive psychology, which highlights the role of memory in learning, social interaction, and decision-making - all critical for agents aiming to replicate human-like behavior.\n\n3. **Interaction Process**: The interaction process between the agent and its environment is pivotal. It encompasses three main phases: perception and storage of environmental information, processing of stored information to make it more usable, and decision-making based on processed memory data.\n\n4. **Definitions of Memory**: The distinction between narrow and broad memory definitions influences design. Narrow memory involves iteration within the same trial, with memory emptied at the end, while broad memory encompasses iterations across different trials or tasks and integrates external knowledge. This affects how the memory reading operation is implemented to support the next actions of the agent.\n\nOverall, the design of memory in LLM-based agents must be guided by a comprehensive understanding of these key questions and factors to facilitate advanced functionalities and improve task performance across various domains.",
    "True Positives (TP), False Positives (FP), and False Negatives (FN) are crucial metrics in assessing memory retrieval performance. \n\n- **True Positives (TP)** represent memory contents that are correctly identified as relevant. A higher TP indicates successful retrieval of necessary information, enhancing the effectiveness of the memory system.\n\n- **False Positives (FP)** denote irrelevant memory contents mistakenly retrieved as relevant. A higher FP can introduce noise and reduce the efficiency of decision-making by providing unnecessary or incorrect information.\n\n- **False Negatives (FN)** refer to relevant memory contents that were not retrieved. A higher FN could lead to incomplete or wrong answers, as essential information is missed.\n\nThese metrics are used to calculate the F1-score, which is the harmonic mean of precision and recall. Precision is the ratio of TP to the sum of TP and FP, indicating the accuracy of the relevant information retrieved. Recall is the ratio of TP to the sum of TP and FN, reflecting the ability to retrieve all relevant information. The balance between these metrics, encapsulated by the F1-score, determines the effectiveness of the memory retrieval process in supporting decision-making.",
    "Memory models aid agent synchronization and strategy in multi-agent systems (MAS) by enhancing communication in several ways. Firstly, they facilitate memory synchronization among agents, which is crucial for establishing a unified knowledge base. This synchronization ensures consistency in decision-making across different agents, as it allows them to share and align their understanding of the environment and tasks. For example, research by Chen et al. highlights the importance of synchronized memory modules for effective multi-robot collaboration.\n\nAdditionally, memory-driven communication frameworks help maintain context and interpret messages among agents, fostering a common understanding and enabling more effective communication. This is crucial in both cooperative and competitive scenarios, where addressing information asymmetry is critical. By exploring novel memory modules, these systems can enhance synchronization further, enable more effective communication, and provide strategic advantages in information-rich environments. Overall, memory models push the boundaries of MAS capabilities by overcoming current challenges and setting new benchmarks in the field.",
    "LLM-based agents use past interactions to enhance their decision-making processes by leveraging both inside-trial and cross-trial information. Inside-trial information involves immediate observations and interactions within a single trial, which serve as short-term memory for the current task. Cross-trial information, on the other hand, acts as long-term memory and includes insights from both successful and failed actions across multiple trials. This helps agents identify patterns for success and understand reasons for failures. By storing and organizing completed trajectories, agents can recall similar ones for new tasks, comparing successful cases with failed ones to determine effective strategies. Additionally, LLM-based agents can incorporate external knowledge from textual sources like Wikipedia to augment their internal memory, which allows them to make informed decisions even in unfamiliar situations. This combination of internal and external knowledge enables agents to adjust their actions based on overall feedback, supporting a wider range of trials and providing prolonged experiential support.",
    "The memory module boosts agent accuracy and decisions in multi-agent simulations by storing and utilizing past experiences, conversation contexts, and decision-making processes. This allows agents to simulate human dynamic behaviors more accurately. For example, in social network simulations, agents use a memory pool of user messages to better identify users and adapt interactions. In job-seeking simulations, memory includes profiles, goals, and dialogues to simulate real-world decision-making. Memory modules also ensure consistency and rationality in agent behavior by maintaining a coherent role profile. They incorporate cognitive psychology features, such as forgetting and distinguishing between long-term and short-term memory, enhancing realism and effectiveness. Additionally, memory modules integrate information from multiple sources, allowing agents to learn from past experiences and make informed decisions, optimizing performance in complex simulations.",
    "LLM agents use concatenated sequences as a method to manage and utilize memory in personalized dialogues by storing information about the agent-environment interactions comprehensively. This approach involves combining all relevant information into a single, continuous sequence, which serves as the agent's memory. By doing so, the agent can refer back to previous interactions when needed, maintaining a detailed and holistic view of the interaction history. This is crucial for understanding and responding to user preferences and actions effectively in personalized dialogues.",
    "LLM-based agents face several challenges with time and memory in learning:\n\n1. **Temporal Management**: Lifelong learning is inherently temporal, requiring agents to effectively capture and manage temporality. This involves dealing with memory interactions, such as overlap.\n\n2. **Memory Storage and Retrieval**: Agents need to store a vast amount of memories over extended periods and be able to retrieve them when needed. This process might require a forgetting mechanism for efficient memory management.\n\n3. **Computational Costs**: Storing all agent-environment interactions increases computational costs because of the quadratic growth in attention computation time complexity with sequence length. This requires more resources and increases inference latency, which hinders practical deployment.\n\n4. **Memory Limitations**: The fast growth of memory length can surpass the sequence length upper bound during an LLM's pretraining, leading to memory truncation and potential information loss.\n\n5. **Bias and Robustness**: Memory truncation and the handling of large sequences can introduce biases and reduce the robustness of the LLM's inference, presenting significant challenges to efficient and effective learning.\n\nThese challenges highlight the complexity of managing time and memory in LLM agents designed for lifelong learning.",
    "LLM agents boost code coherence and error fixing via chat interfaces and memory by utilizing memory mechanisms to store and retrieve relevant information from past experiences. This allows them to maintain context in conversational development interfaces and apply solutions to future problems. They can search their memory for relevant information, which helps in gaining more knowledge for development. For example, storing compiler errors and human expert instructions facilitates automatic syntax error fixing, preventing similar errors in the future. Additionally, in multi-agent systems, each role maintains a memory of past interactions, which enhances decision-making capabilities by preserving context. This use of memory and external resources improves the continuity and consistency of code generation, creating a more seamless development experience.",
    "Reflexion uses past trials to boost LLM agents' performance by deriving experiences from these trials in a verbal form. These verbalized experiences are then applied in subsequent trials to improve task performance. Reflexion allows agents to learn from both successful and failed actions by providing insights such as the reasons for failures and common action patterns that lead to success. This approach enables agents to adjust their actions based on feedback from the entire process, enhancing their adaptability and efficiency in similar future tasks. By converting trial experiences into verbal reinforcement, Reflexion facilitates an effective learning mechanism for LLM-based agents.",
    "The model that rates dialogue consistency is GPT-4. This is mentioned in the evidence provided, where GPT-4 is employed to score the responses generated by agents in the context of evaluating dialogue consistency.",
    "CodeAgent aims for the repository-level code generation task when dealing with complex dependencies. This involves generating code that considers the interconnected nature of various components within a software repository, ensuring that all dependencies are managed effectively for seamless integration and functionality across the entire codebase.",
    "Memory and simulation improve user modeling in recommender systems in several ways:\n\n1. **Personalization through Memory**: Memory allows recommender systems to retain personalized information such as user profiles and interaction histories. This information is crucial for tailoring recommendations to individual preferences. By storing this information in a hierarchical memory structure, systems can more effectively simulate real-world user behaviors.\n\n2. **Interactive Recommendation Scenarios**: Memory modules archive a user’s conversational history over extended periods, capturing both past interactions and the most recent dialogues. This capability is key for simulating interactive recommendation scenarios, as it allows the system to understand user preferences and behaviors over time, enhancing robustness and accuracy.\n\n3. **Simulation for Training and Testing**: Simulation is used to generate realistic user behavior data, which can train or test recommender systems. By simulating users in recommendation scenarios, systems can predict user responses and preferences more accurately. This helps bridge the gap between conventional recommendation models and large language models (LLMs) by using memory to align personal information and feedback with LLMs, thereby improving the system's ability to predict and satisfy user needs.\n\n4. **Iterative Optimization**: The integration of memory supports iterative optimization by allowing the system to identify and adapt to user targets based on historical data. This ensures continuity and consistency in recommendations, leading to improved performance and a more personalized user experience.\n\nOverall, the combination of memory and simulation allows recommender systems to model users more accurately, resulting in enhanced performance and a more personalized experience for the user.",
    "ChatDB boosts data retrieval by incorporating symbolic memory and generating SQL statements. Symbolic memory allows ChatDB to effectively manage and utilize structured data, ensuring consistent and efficient data access and manipulation. By generating SQL statements, ChatDB can directly query databases to retrieve the precise information needed. This approach leverages the power of relational databases for structured data retrieval, ensuring accurate and efficient methods that minimize the acquisition of unrelated information and reduce computational costs and latency. The use of SQL statements enables seamless interaction with databases, providing a robust mechanism for retrieving and utilizing stored information.",
    "The deployment issue for Large Language Models (LLMs) with more computing needs and memory limits involves the efficiency of resource utilization. LLMs require substantial computational resources for both training and inference, which poses a challenge in environments with limited resources. To address this issue, techniques such as model compression and parameter-efficient fine-tuning are used to enhance efficiency without compromising performance. Additionally, the integration of memory modules is complex, as these components are necessary for accumulating and retrieving knowledge. This complexity is further increased in multi-agent systems, where memory synchronization among agents is crucial for consistent decision-making and communication. Therefore, the key issues are the high computational demands and the challenges associated with implementing and managing memory effectively in LLMs.",
    "Based on the given reference, agents such as RoleLLM, CharacterGLM, and Character-LLM excel in dialogue, while ReAct, GITM, CodeAgent, and ChatDoctor excel in information gathering. However, there is no evidence that any single agent excels in both dialogue and information gathering simultaneously. Each agent is specialized in its respective domain, with some focusing on conversational engagement and others on effective information retrieval.",
    "Agents boost efficiency with past successes by accumulating and analyzing cross-trial information, which includes insights from both successful and failed actions. They store and organize completed trajectories, allowing them to recall similar past experiences. By comparing successful cases with failed ones, agents identify effective strategies and adjust their actions based on feedback from previous trials. This process helps them avoid repeating mistakes and achieve a higher-level understanding of their environment. In doing so, agents can enhance their decision-making and task execution, as seen in examples like the ExpeL study and open-world games, where they use past successful experiences to solve complex tasks and explore more effectively.",
    "LLMs acquire molecule data through several methodologies. One critical technique is supervised fine-tuning, which involves training LLMs with domain-specific data, such as molecule data, to enhance their capabilities. Additionally, LLMs can leverage external tools and methods to expand their knowledge in specialized domains like molecular sciences. Another important technique is the retrieval-augmented generation (RAG) capability, which provides LLMs with factual and up-to-date knowledge necessary for accurate molecule data retrieval and processing. These methodologies ensure that LLMs can effectively acquire and process molecule data for tasks related to molecular sciences.",
    "LLMs aid in the areas of information retrieval (IR) and information extraction (IE). In information retrieval, they improve query processes for more efficient and accurate data retrieval. In information extraction, they help extract pertinent information from large datasets to streamline analysis and extraction tasks.",
    "The quadratic growth in attention mechanisms impacts latency by significantly increasing it, especially when handling long-context memory in large language models (LLMs). As the sequence length increases, the time complexity of attention computation grows quadratically, leading to a substantial rise in computational costs during LLM inference. This increased demand for computing resources results in greater inference latency, posing challenges to the practical deployment and efficiency of LLM-based applications.",
    "The method that boosts agents' tool use in math is imitation learning. This is because imitation learning allows agents to observe and mimic the successful strategies of others, thereby improving their proficiency in employing tools necessary for tackling complex mathematical challenges.",
    "LLMs don't handle all text equally in long contexts primarily due to the computational cost and limitations of attention mechanisms. The computational cost during LLM inference grows quadratically with the sequence length, which requires substantial computing resources and results in higher inference latency, making it impractical for deployment. Additionally, as the memory length expands, it can exceed the sequence length limits set during an LLM's pretraining phase, necessitating memory truncation. This truncation can lead to information loss and incomplete agent memory. Furthermore, the position of text segments within a long context can significantly affect their utilization, meaning that memory in long-context prompts cannot be treated equally and stably. These factors collectively hinder the ability of LLMs to manage all text equally in long contexts and highlight the need for additional memory modules to better handle such scenarios.",
    "Memory retrieval scores are derived using true positives (TP), false positives (FP), and false negatives (FN) through the calculation of the F1-score, which combines precision and recall. Precision is calculated as the number of true positives divided by the sum of true positives and false positives (\\( \\text{Precision} = \\frac{TP}{TP + FP} \\)), and recall is calculated as the number of true positives divided by the sum of true positives and false negatives (\\( \\text{Recall} = \\frac{TP}{TP + FN} \\)). The F1-score is then calculated as the harmonic mean of precision and recall: \\( F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\). These metrics are crucial for evaluating the effectiveness of memory retrieval systems.",
    "Montazeralghaem et al. proposed a reinforcement learning framework for relevance feedback at the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval in 2020. This framework utilizes reinforcement learning techniques to improve the relevance feedback process in information retrieval systems.",
    "Targeted LLM tweaks, also known as knowledge editing methods, avoid losing other information by specifically targeting and adjusting only the facts that need to be updated while ensuring that non-targeted knowledge remains unaffected. This approach mitigates the issue of catastrophic forgetting, allowing for precise changes without disturbing unrelated information stored within the model's parameters.",
    "Memory frameworks help agents cooperate by facilitating memory synchronization among them, which is essential for establishing a unified knowledge base. This synchronization ensures consistency in decision-making across different agents, allowing them to work together effectively. Memory also plays a crucial role in maintaining context and interpreting messages, which is vital for effective communication among agents. By supporting a common understanding, memory frameworks enhance the ability of agents to cooperate in various scenarios. For example, in multi-robot collaboration, synchronized memory modules help maintain consistency and ensure that all agents are operating with the same information. Additionally, memory-driven communication frameworks allow agents to maintain context during interactions, fostering a shared understanding that is crucial for cooperative tasks. Overall, memory frameworks are indispensable in aiding agent cooperation by ensuring consistency, supporting effective communication, and building a unified knowledge base.",
    "MemGPT uses virtual context to manage recent histories by holding them as part of virtual context management. It maintains these recent interactions in natural language form, allowing it to dynamically update memories based on these interactions. This ensures that the most relevant and recent information is prioritized for the current stage of interaction, enhancing the efficiency of memory information utilization. This approach aligns with the Principle of Locality, emphasizing the importance of recency in memory management.",
    "LLM-based agents use memory for suggestions in the following scenarios:\n\n1. **Recommendation Systems**: Memory is used to simulate user behavior, store user profiles, and conversation histories. This allows the agents to provide personalized recommendations by aligning their operations with user preferences and behaviors.\n\n2. **Code Generation**: Memory helps in maintaining continuity and consistency, understanding requirements, and optimizing code iteratively by recalling past interactions and developer targets.\n\n3. **Conversational Agents**: Memory is essential for storing historical conversations, enabling the agent to generate contextually relevant responses. This helps the agent continue a conversation effectively by retaining the necessary context.\n\nMemory in these scenarios is crucial for providing informed, coherent, and personalized suggestions.",
    "Large language models (LLMs) use a technique called knowledge editing to stop forgetting during updates. This involves modifying the model's parameters in a targeted way to update specific facts without affecting unrelated knowledge. By doing this, the problem of catastrophic forgetting, where previously acquired information is lost when new knowledge is integrated, is mitigated. Techniques such as training a hyper-network to predict parameter modifications and using meta-learning frameworks like MEND are used to ensure efficient and precise updates, preserving existing memories while incorporating new information.",
    "SCM boosts information recency by utilizing a flash memory system based on a cache mechanism. This system preserves observations from the most recent t−1 timesteps, which effectively enhances the recency of the information processed. By focusing on the latest acquired data, SCM ensures that the most current and relevant information is readily available for decision-making processes. This approach aligns with the principle of locality, emphasizing the importance of recent interactions and allowing agents to dynamically update memories based on the latest interactions.",
    "MemoChat uses topics to index memory by generating embeddings as indexes during memory writing. These embeddings, along with auxiliary information, help in efficiently retrieving relevant information. By calculating matching scores for each memory entry, MemoChat is able to retrieve the most pertinent aspects of past interactions, which likely includes considering the topics of those interactions. This ensures that both recent and crucial past information related to certain topics can be incorporated into the agent's responses."
  ]
}